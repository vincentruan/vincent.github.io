<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[详解分布式协调服务 ZooKeeper]]></title>
    <url>%2F2018%2F10%2F07%2F%E8%AF%A6%E8%A7%A3%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E6%9C%8D%E5%8A%A1-ZooKeeper%2F</url>
    <content type="text"><![CDATA[作者 | Draveness 本文作者 Draveness，文章转载自 https://draveness.me/zookeeper-chubby， 对其内容进行过编辑。 这篇文章主要会介绍 Zookeeper 的实现原理以及常见的应用 在 2006 年，Google 发表了一篇名为 The Chubby lock service for loosely-coupled distributed systems 的论文，其中描述了一个分布式锁服务 Chubby 的设计理念和实现原理；作为 Google 内部的一个基础服务，虽然 Chubby 与 GFS、Bigtable 和 MapReduce 相比并没有那么大的名气，不过它在 Google 内部也是非常重要的基础设施。 相比于名不见经传的 Chubby，作者相信 Zookeeper 更被广大开发者所熟知，作为非常出名的分布式协调服务，Zookeeper 有非常多的应用，包括发布订阅、命名服务、分数是协调和分布式锁，这篇文章主要会介绍 Zookeeper 的实现原理以及常见的应用，但是在具体介绍 Zookeeper 的功能和原理之前，我们会简单介绍一下分布式锁服务 Chubby 以及它与 Zookeeper 之间的异同。 Chubby作为分布式锁服务，Chubby 的目的就是允许多个客户端对它们的行为进行同步，同时也能够解决客户端的环境相关信息的分发和粗粒度的同步问题，GFS 和 Bigtable 都使用了 Chubby 以解决主节点的选举等问题。在网络上你很难找到关于 Chubby 的相关资料，我们只能从 The Chubby lock service for loosely-coupled distributed systems 一文中窥见它的一些设计思路、技术架构等信息。 虽然 Chubby 和 Zookeeper 有着比较相似的功能，但是它们的设计理念却非常不同，Chubby 在论文的摘要中写道： We describe our experiences with the Chubby lock service, which is intended to provide coarse-grained locking as well as reliable (though low-volume) storage for a loosely-coupled distributed system. 从论文的摘要中我们可以看出 Chubby 首先被定义成一个 分布式的锁服务，它能够为分布式系统提供 松耦合、粗粒度 的分布式锁功能，然而我们并不能依赖于它来做一些重量的数据存储。 Chubby 在设计时做了两个重要的设计决定，一是提供完整、独立的分布式锁服务而非一个用于共识的库或者服务，另一个是选择提供小文件的的读写功能，使得主节点能够方便地发布自己的状态信息。 系统架构Chubby 总共由两部分组成，一部分是用于提供数据的读写接口并管理相关的配置数据的服务端，另一部分就是客户端使用的 SDK，为了提高系统的稳定性，每一个 Chubby 单元都由一组服务器组成，它会使用 共识算法 从集群中选举出主节点。 在一个 Chubby Cell 中，只有 主节点会对外提供读写服务，其他的节点其实都是当前节点的副本（Replica），它们只是维护一个数据的拷贝并会在主节点更新时对它们持有的数据库进行更新；客户端通过向副本发送请求获取主节点的位置，一旦它获取到了主节点的位置，就会向所有的读写请求发送给主节点，直到其不再响应为止。写请求都会通过一致性协议传播到所有的副本中，当集群中的多数节点都同步了请求时就会认为当前的写入已经被确认。 当主节点宕机时，副本会在其租约到期时重新进行选举，副本节点如果在宕机几小时还没有回复，那么系统就会从资源池中选择一个新的节点并在该节点上启动 Chubby 服务并更新 DNS 表。 主节点会不停地轮训 DNS 表获取集群中最新的配置，每次 DNS 表更新时，主节点都会将新的配置下发给 Chubby 集群中其他的副本节点。 Zookeeper很多人都会说 Zookeeper 是 Chubby 的一个开源实现，这其实是有问题的，它们两者只不过都提供了具有层级结构的命名空间： Chubby 和 Zookeeper 从最根本的设计理念上就有着非常明显的不同，在上文中我们已经提到了 Chubby 被设计成一个分布式的锁服务，它能够为分布式系统提供松耦合、粗粒度的分布式锁功能，然而我们并不能依赖于它来做一些重量的数据存储，而 Zookeeper 的论文在摘要中介绍到，它是一个能够为分布式系统提供协调功能的服务： In this paper, we describe ZooKeeper, a service for co- ordinating processes of distributed applications. Zookeeper 的目的是为客户端构建复杂的协调功能提供简单、高效的核心 API，相比于 Chubby 对外提供已经封装好的更上层的功能，Zookeeper 提供了更抽象的接口以便于客户端自行实现想要完成的功能。 Chubby 直接为用户提供封装好的锁和解锁的功能，内部完成了锁的实现，只是将 API 直接暴露给用户，而 Zookeeper 却需要用户自己实现分布式锁；总的来说，使用 Zookeeper 往往需要客户端做更多的事情，但是也享有更多的自由。 技术架构与 Chubby 集群中，多个节点只有一个能够对外提供服务不同，Zookeeper 集群中所有的节点都可以对外提供服务，但是集群中的节点也分为主从两种节点，所有的节点都能处理来自客户端的读请求，但是只有主节点才能处理写入操作： 这里所说的 Zookeeper 集群主从节点实际上分别是 Leader 和 Follower 节点。 客户端使用 Zookeeper 时会连接到集群中的任意节点，所有的节点都能够直接对外提供读操作，但是写操作都会被从节点路由到主节点，由主节点进行处理。 Zookeeper 在设计上提供了以下的两个基本的顺序保证，线性写和先进先出的客户端顺序： 其中线性写是指所有更新 Zookeeper 状态的请求都应该按照既定的顺序串行执行；而先进先出的客户端顺序是指，所有客户端发出的请求会按照发出的顺序执行。 Zab 协议在我们简单介绍 Zookeeper 的技术架构之后，这一节将谈及 Zookeeper 中的 Zab 协议，Zookeeper 的 Zab 协议是为了解决分布式一致性而设计出的一种协议，它的全称是 Zookeeper 原子广播协议，它能够在发生崩溃时快速恢复服务，达到高可用性。 如上一节提到的，客户端在使用 Zookeeper 服务时会随机连接到集群中的一个节点，所有的读请求都会由当前节点处理，而写请求会被路由给主节点并由主节点向其他节点广播事务，与 2PC 非常相似，如果在所有的节点中超过一半都返回成功，那么当前写请求就会被提交。 当主节点崩溃时，其他的 Replica 节点会进入崩溃恢复模式并重新进行选举，Zab 协议必须确保提交已经被 Leader 提交的事务提案，同时舍弃被跳过的提案，这也就是说当前集群中最新 ZXID 最大的服务器会被选举成为 Leader 节点；但是在正式对外提供服务之前，新的 Leader 也需要先与 Follower 中的数据进行同步，确保所有节点拥有完全相同的提案列表。 在上面提到 ZXID 其实就是 Zab 协议中设计的事务编号，它是一个 64 位的整数，其中最低的 32 位是一个计数器，每当客户端修改 Zookeeper 集群状态时，Leader 都会以当前 ZXID 值作为提案的编号创建一个新的事务，在这之后会将当前计数器加一；ZXID 中高的 32 位表示当前 Leader 的任期，每当发生崩溃进入恢复模式，集群的 Leader 重新选举之后都会将 epoch 加一。 Zab 和 PaxosZab 和 Paxos 协议在实现上其实有非常多的相似点，例如： 主节点会向所有的从节点发出提案； 主节点在接收到一组从节点中 50% 以上节点的确认后，才会认为当前提案被提交了； Zab 协议中的每一个提案都包含一个 epoch 值，与 Paxos 中的 Ballot 非常相似； 因为它们有一些相同的特点，所以有的观点会认为 Zab 是 Paxos 的一个简化版本，但是 Zab 和 Paxos 在设计理念上就有着比较大的不同，两者的主要区别就在于 Zab 主要是为构建高可用的主备系统设计的，而 Paxos 能够帮助工程师搭建具有一致性的状态机系统。 作为一个一致性状态机系统，它能够保证集群中任意一个状态机副本都按照客户端的请求执行了相同顺序的请求，即使来自客户端请求是异步的并且不同客户端的接收同一个请求的顺序不同，集群中的这些副本就是会使用 Paxos 或者它的变种对提案达成一致；在集群运行的过程中，如果主节点出现了错误导致宕机，其他的节点会重新开始进行选举并处理未提交的请求。 但是在类似 Zookeeper 的高可用主备系统中，所有的副本都需要对增量的状态更新顺序达成一致，这些状态更新的变量都是由主节点创建并发送给其他的从节点的，每一个从节点都会严格按照顺序逐一的执行主节点生成的状态更新请求，如果 Zookeeper 集群中的主节点发生了宕机，新的主节点也必须严格按照顺序对请求进行恢复。 总的来说，使用状态更新节点数据的主备系统相比根据客户端请求改变状态的状态机系统对于请求的执行顺序有着更严格的要求。 实现原理这一节会简单介绍 Zookeeper 的一些实现原理，重点会介绍以下几个部分的内容：文件系统、临时 / 持久节点和通知的实现原理。 文件系统了解或者使用 Zookeeper 或者其他分布式协调服务的读者对于使用类似文件系统的方式比较熟悉，与 Unix 中的文件系统份上相似的是，Zookeeper 中也使用文件系统组织系统中存储的资源。 Zookeeper 中其实并没有文件和文件夹的概念，它只有一个 Znode 的概念，它既能作为容器存储数据，也可以持有其他的 Znode 形成父子关系。 Znode 其实有 PERSISTENT、PERSISTENT_SEQUENTIAL、EPHEMERAL 和 EPHEMERAL_SEQUENTIAL 四种类型，它们是临时与持久、顺序与非顺序两个不同的方向组合成的四种类型。 临时节点是客户端在连接 Zookeeper 时才会保持存在的节点，一旦客户端和服务端之间的连接中断，当前连接持有的所有节点都会被删除，而持久的节点不会随着会话连接的中断而删除，它们需要被客户端主动删除；Zookeeper 中另一种节点的特性就是顺序和非顺序，如果我们使用 Zookeeper 创建了顺序的节点，那么所有节点就会在名字的末尾附加一个序列号，序列号是一个由父节点维护的单调递增计数器。 通知常见的通知机制往往都有两种，一种是客户端使用『拉』的方式从服务端获取最新的状态，这种方式获取的状态很有可能都是过期的，需要客户端不断地通过轮训的方式获取服务端最新的状态，另一种方式就是在客户端订阅对应节点后由服务端向所有订阅者推送该节点的变化，相比于客户端主动获取数据的方式，服务端主动推送更能够保证客户端数据的实时性。 作为分布式协调工具的 Zookeeper 就实现了这种服务端主动推送请求的机制，也就是 Watch，当客户端使用 getData 等接口获取 Znode 状态时传入了一个用于处理节点变更的回调，那么服务端就会主动向客户端推送节点的变更： 1public byte[] getData(final String path, Watcher watcher, Stat stat) 从这个方法中传入的 Watcher 对象实现了相应的 process 方法，每次对应节点出现了状态的改变，WatchManager 都会通过以下的方式调用传入 Watcher 的方法： 1234567891011Set&lt;Watcher&gt; triggerWatch(String path, EventType type, Set&lt;Watcher&gt; supress) &#123; WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path); Set&lt;Watcher&gt; watchers; synchronized (this) &#123; watchers = watchTable.remove(path); &#125; for (Watcher w : watchers) &#123; w.process(e); &#125; return watchers;&#125; Zookeeper 中的所有数据其实都是由一个名为 DataTree 的数据结构管理的，所有的读写数据的请求最终都会改变这颗树的内容，在发出读请求时可能会传入 Watcher 注册一个回调函数，而写请求就可能会触发相应的回调，由 WatchManager 通知客户端数据的变化。 通知机制的实现其实还是比较简单的，通过读请求设置 Watcher 监听事件，写请求在触发事件时就能将通知发送给指定的客户端。 会话在 Zookeeper 中一个非常重要的概念就是会话，客户端与服务器之间的任何操作都与 Zookeeper 中会话的概念有关，比如我们再上一节中提到的临时节点生命周期以及通知的机制等等，它们都是基于会话来实现的。 每当客户端与服务端建立连接时，其实创建了一个新的会话，在每一个会话的生命周期中，Zookeeper 会在不同的会话状态之间进行切换，比如说：CONNECTING、CONNECTED、RECONNECTING、RECONNECTED 和 CLOSE 等。 作为 Zookeeper 中最重要的概念之一，每一个 Session 都包含四个基本属性，会话的唯一 ID、会话超时时间、下次会话的超时时间点和表示会话是否被关闭的标记。 SessionTracker 是 Zookeeper 中的会话管理器，它负责所有会话的创建、管理以及清理工作，但是它本身只是一个 Java 的接口，定义了一系列用于管理会话的相关接口： 1234567891011121314151617181920public interface SessionTracker &#123; public static interface Session &#123; long getSessionId(); int getTimeout(); boolean isClosing(); &#125; public static interface SessionExpirer &#123; void expire(Session session); long getServerId(); &#125; long createSession(int sessionTimeout); boolean trackSession(long id, int to); boolean commitSession(long id, int to); boolean touchSession(long sessionId, int sessionTimeout); void setSessionClosing(long sessionId); void shutdown(); void removeSession(long sessionId);&#125; 与其他的长连接一样，Zookeeper 中的会话也需要客户端与服务端之间进行心跳检测，客户端会在超时时间内向服务端发送心跳请求来保证会话不会被服务端关闭，一旦服务端检测到某一个会话长时间没有收到心跳包就会中断当前会话释放服务器上的资源。 应用作为分布式协调服务，Zookeeper 能够为集群提供分布式一致性的保证，我们可以通过 Zookeeper 提供的最基本的 API 组合成更高级的功能： 12345678public class Zookeeper &#123; public String create(final String path, byte data[], List&lt;ACL&gt; acl, CreateMode createMode) public void delete(final String path, int version) throws InterruptedException, KeeperException public Stat exists(final String path, Watcher watcher) throws KeeperException, InterruptedException public byte[] getData(final String path, Watcher watcher, Stat stat) throws KeeperException, InterruptedException public Stat setData(final String path, byte data[], int version) throws KeeperException, InterruptedException public void sync(final String path, VoidCallback cb, Object ctx)&#125; 在这一节中，我们将介绍如何在生产环境中使用 Zookeeper 实现发布订阅、命名服务、分布式协调以及分布式锁等功能。 发布订阅通过 Zookeeper 进行数据的发布与订阅其实可以说是它提供的最基本功能，它能够允许多个客户端同时订阅某一个节点的变更并在变更发生时执行我们预先设置好的回调函数，在运行时改变服务的配置和行为： 123456789ZooKeeper zk = new ZooKeeper("localhost", 3000, null);zk.getData("/config", new Watcher() &#123; public void process(WatchedEvent watchedEvent) &#123; System.out.println(watchedEvent.toString()); &#125;&#125;, null);zk.setData("/config", "draven".getBytes(), 0);// WatchedEvent state:SyncConnected type:NodeDataChanged path:/config 发布与订阅是 Zookeeper 提供的一个最基本的功能，它的使用非常的简单，我们可以在 getData 中传入实现 process 方法的 Watcher 对象，在每次改变节点的状态时，process 方法都会被调用，在这个方法中就可以对变更进行响应动态修改一些行为。 通过 Zookeeper 这个中枢，每一个客户端对节点状态的改变都能够推送给节点的订阅者，在发布订阅模型中，Zookeeper 的每一个节点都可以被理解成一个主题，每一个客户端都可以向这个主题推送详细，同时也可以订阅这个主题中的消息；只是 Zookeeper 引入了文件系统的父子层级的概念将发布订阅功能实现得更加复杂。 1234567public static enum EventType &#123; None(-1), NodeCreated(1), NodeDeleted(2), NodeDataChanged(3), NodeChildrenChanged(4);&#125; 如果我们订阅了一个节点的变更信息，那么该节点的子节点出现数量变更时就会调用 process 方法通知观察者，这也意味着更复杂的实现，同时和专门做发布订阅的中间件相比也没有性能优势，在海量推送的应用场景下，消息队列更能胜任，而 Zookeeper 更适合做一些类似服务配置的动态下发的工作。 命名服务除了实现服务配置数据的发布与订阅功能，Zookeeper 还能帮助分布式系统实现命名服务，在每一个分布式系统中，客户端应用都有根据指定名字获取资源、服务器地址的需求，在这时就要求整个集群中的全部服务有着唯一的名字。 在大型分布式系统中，有两件事情非常常见，一是不同服务之间的可能拥有相同的名字，另一个是同一个服务可能会在集群中部署很多的节点，Zookeeper 就可以通过文件系统和顺序节点解决这两个问题。 在上图中，我们创建了两个命名空间，/infrastructure 和 /business 分别代表架构和业务部门，两个部门中都拥有名为 metrics 的服务，而业务部门的 metrics 服务也部署了两个节点，在这里使用了命名空间和顺序节点解决唯一标志符的问题。 1234567ZooKeeper zk = new ZooKeeper("localhost", 3000, null);zk.create("/metrics", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);zk.create("/metrics", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);List children = zk.getChildren("/", null);System.out.println(children);// [metrics0000000001, metrics0000000002] 使用上面的代码就能在 Zookeeper 中创建两个带序号的 metrics 节点，分别是 metrics0000000001 和 metrics0000000002，也就是说 Zookeeper 帮助我们保证了节点的唯一性，让我们能通过唯一的 ID 查找到对应服务的地址等信息。 协调分布式事务Zookeeper 的另一个作用就是担任分布式事务中的协调者角色，在之前介绍 分布式事务 的文章中我们曾经介绍过分布式事务本质上都是通过 2PC 来实现的，在两阶段提交中就需要一个协调者负责协调分布式事务的执行。 123456789ZooKeeper zk = new ZooKeeper("localhost", 3000, null);String path = zk.create("/transfer/tx", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);List ops = Arrays.asList( Op.create(path + "/cohort", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL), Op.create(path + "/cohort", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL), Op.create(path + "/cohort", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL));zk.multi(ops); 当前节点作为协调者在每次发起分布式事务时都会创建一个 /transfer/tx 的持久顺序节点，然后为几个事务的参与者创建几个空白的节点，事务的参与者在收到事务时会向这些空白的节点中写入信息并监听这些节点中的内容。 所有的事务参与者会向当前节点中写入提交或者终止，一旦当前的节点改变了事务的状态，其他节点就会得到通知，如果出现一个写入终止的节点，所有的节点就会回滚对分布式事务进行回滚。 使用 Zookeeper 实现强一致性的分布式事务其实还是一件比较困难的事情，一方面是因为强一致性的分布式事务本身就有一定的复杂性，另一方面就是 Zookeeper 为了给客户端提供更多的自由，对外暴露的都是比较基础的 API，对它们进行组装实现复杂的分布式事务还是比较麻烦的，对于如何使用 Zookeeper 实现分布式事务，我们可以在 ZooKeeper Recipes and Solutions 一文中找到更为详细的内容。 分布式锁在数据库中，锁的概念其实是非常重要的，常见的关系型数据库就会对排他锁和共享锁进行支持，而 Zookeeper 提供的 API 也可以让我们非常简单的实现分布式锁。 1234567891011121314151617181920212223242526272829ZooKeeper zk = new ZooKeeper("localhost", 3000, null);final String resource = "/resource";final String lockNumber = zk .create("/resource/lock-", null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);List&lt;String&gt; locks = zk.getChildren(resource, false, null);Collections.sort(locks);if (locks.get(0).equals(lockNumber.replace("/resource/", ""))) &#123; System.out.println("Acquire Lock"); zk.delete(lockNumber, 0);&#125; else &#123; zk.getChildren(resource, new Watcher() &#123; public void process(WatchedEvent watchedEvent) &#123; try &#123; ZooKeeper zk = new ZooKeeper("localhost", 3000, null); List locks = zk.getChildren(resource, null, null); Collections.sort(locks); if (locks.get(0).equals(lockNumber.replace("/resource/", ""))) &#123; System.out.println("Acquire Lock"); zk.delete(lockNumber, 0); &#125; &#125; catch (Exception e) &#123;&#125; &#125; &#125;, null);&#125; 如果多个服务同时要对某个资源进行修改，就可以使用上述的代码来实现分布式锁，假设集群中存在一个资源 /resource，几个服务需要通过分布式锁保证资源只能同时被一个节点使用，我们可以用创建临时顺序节点的方式实现分布式锁；当我们创建临时节点后，通过 getChildren 获取当前等待锁的全部节点，如果当前节点是所有节点中序号最小的就得到了当前资源的使用权限，在对资源进行处理后，就可以通过删除 /resource/lock-00000000x 来释放锁，如果当前节点不是最小值，就会注册一个 Watcher 等待 /resource 子节点的变化直到当前节点的序列号成为最小值。 上述代码在集群中争夺同一资源的服务器特别多的情况下会出现羊群效应，每次子节点改变时都会通知当前节点，造成资源的浪费，我们其实可以将 getChildren 换成 getData，让当前节点只监听前一个节点的删除事件： 1234567891011121314Integer number = Integer.parseInt(lockNumber.replace("/resource/lock-", "")) + 1;String previousLock = "/resource/lock-" + String.format("%010d", number);zk.getData(previousLock, new Watcher() &#123; public void process(WatchedEvent watchedEvent) &#123; try &#123; if (watchedEvent.getType() == Event.EventType.NodeDeleted) &#123; System.out.println("Acquire Lock"); ZooKeeper zk = new ZooKeeper("localhost", 3000, null); zk.delete(lockNumber, 0); &#125; &#125; catch (Exception e) &#123;&#125; &#125;&#125;, null); 在新的分布式锁实现中，我们减少了每一个服务需要关注的事情，只让它们监听需要关心的数据变更，减少 Zookeeper 发送不必要的通知影响效率。 分布式锁作为分布式系统中比较重要的一个工具，确实有着比较多的应用，同时也有非常多的实现方式，除了 Zookeeper 之外，其他服务例如 Redis 和 etcd 也能够实现分布式锁，为分布式系统的构建提供支持，不过在这篇文章中就不展开介绍了。 总结我们在这篇文章中简单介绍了 Google 的分布式锁服务 Chubby 以及同样能够提供分布式锁服务功能的 Zookeeper。 作为分布式协调服务，Zookeeper 的应用场景非常广泛，不仅能够用于服务配置的下发、命名服务、协调分布式事务以及分布式锁，还能够用来实现微服务治理中的服务注册以及发现等功能，这些其实都源于 Zookeeper 能够提供高可用的分布式协调服务，能够为客户端提供分布式一致性的支持，在后面的文章中作者也会介绍其他用于分布式协调的服务。 参考资料https://zookeeper.apache.org/doc/r3.4.4/recipes.html https://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf]]></content>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks服务器代理]]></title>
    <url>%2F2018%2F07%2F13%2FShadowsocks%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[前言本文讲述如何安装配置Shadowsocks Server，并支持通过代理方式（http/sock v4/5)连接因特网. 这里主要阐述服务端通过proxy连接的解决方案，shadowsocks server直连网络的方式比较简单，网上这块资料也比较齐全，不做过多描述， ssserver代理安装配置安装Shadowsocks Server参考Install Shadowsocks Server on Windows， 客户端的安装方式参考Shadowsocks Client安装, 这里主要解决服务端通过代理解决shadowsocks server无法直连网络的问题，客户端这块不做过多描述。 更新代理脚本​ 这个问题的解决方案来自github的一个issue 通过猴子补丁的方式给ss添加了一个前置代理的功能 有兴趣深入了解的推荐star一下该作者的项目PySocket ​ 在上述步骤安装了python版的Shadowsocks Server之后，通过猴子补丁的方式给给 shadowsocks 服务端添加前置代理的功能（原则上也适用于客户端），支持 http、socks4、socks5 代理。并且通过 hook 的方式去掉了ss的dns查询，ss在接收到数据之后会直接把域名和请求一起发给代理。 使用的时候修改 socket.py 文件中 PROXY_TYPE、PROXY_ADDR、PROXY_PORT 等字段为你的代理地址，然后把 socket.py 文件放到 shadowsocks 根目录即可生效，不用修改任何源码。 通过pip安装的话要放到ssserver所在的目录，一般都在 Python27\Scripts （python27上验证OK） 12pip install win_inet_pton --proxy=http://your-proxy-host:your-proxy-portpip install shadowsocks --proxy=http://your-proxy-host:your-proxy-port 配置部分： 1234# the proxy type. SOCKS5 SOCKS4 HTTPPROXY_TYPE = SOCKS5PROXY_ADDR = "127.0.0.1"PROXY_PORT = 1080 socket.py 文末部分，因为我选择 hook shadowsocks的代码，实际使用时在del module会报异常，因此将文末修改为 12345678910111213# hook shadowsocks's code remove the dns reqdef new_resolve(self, hostname, callback): callback((hostname, hostname), None)modules_list = ["shadowsocks.common", "shadowsocks.shell"]for x in modules_list: try: del sys.modules[x] except KeyError: print "Error: key", x, "not found"import shadowsocks.asyncdnsshadowsocks.asyncdns.DNSResolver.resolve = new_resolve 如果不想 hook shadowsocks的代码的话，把文件中末尾的代码删除即可，原文件代码末尾如下: 12345678910# hook shadowsocks's code remove the dns reqdef new_resolve(self, hostname, callback): callback((hostname, hostname), None)modules_list = ["shadowsocks.common", "shadowsocks.shell"]for x in modules_list: del sys.modules[x]import shadowsocks.asyncdnsshadowsocks.asyncdns.DNSResolver.resolve = new_resolve ssserver配置参考Configuration via Config File 创建一个配置文件 /etc/shadowsocks.json. 示例如下: 12345678910&#123; "server":"my_server_ip", "server_port":8388, "local_address": "127.0.0.1", "local_port":1080, "password":"mypassword", "timeout":300, "method":"aes-256-cfb", "fast_open": false&#125; 配置文件字段详解: Name Explanation server ssserver监听地址，0.0.0.0监听本地所有网卡地址 server_port ssserver服务端口 local_address 本地监听地址 local_port 本地端口 password 用于加密的密码 timeout 超时设置，单位秒，不建议太长 method 默认: “aes-256-cfb”, 详见 Encryption fast_open 是否使用 TCP_FASTOPEN, true / false workers worker数量, 仅在Unix/Linux生效 在控制台中执行，日志直接显示在控制台，首次测试使用建议该方式，可通过ctrl+C退出: 1ssserver -c /etc/shadowsocks.json 后台静默执行: 1234# 启动服务ssserver -c /etc/shadowsocks.json -d start# 停止服务ssserver -c /etc/shadowsocks.json -d stop]]></content>
      <categories>
        <category>developer tools</category>
      </categories>
      <tags>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker碎片拾遗]]></title>
    <url>%2F2018%2F06%2F24%2Fdocker%E7%A2%8E%E7%89%87%E6%8B%BE%E9%81%97%2F</url>
    <content type="text"><![CDATA[进入shell环境12docker psdocker exec -it &lt;container&gt; bash and run 12apt-get updateapt-get install vim ！不要去改系统配置正常运行的docker先保存一下docker的ID，之后不要去改下面的配置，否则docker会更新为新的那个，导致数据丢失]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Xshell显示X11图形化界面]]></title>
    <url>%2F2018%2F06%2F17%2FXshell%E6%98%BE%E7%A4%BAX11%E5%9B%BE%E5%BD%A2%E5%8C%96%E7%95%8C%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[安装Xmanager全家桶使用前检查一下是否安装了Xshell、Xstart、Xmanager - Passive，正常安装Xmanager全家桶应该是全的 使用XStart登录通过SSH的方式尝试登录VPS， 正常成功后会这样提示 当然更多的可能是弹出个错误框提示“已拒绝X11转移申请”，这是因为默认的VPS一般不会安装XAUTH导致， 1sudo yum install xorg-x11-xauth 这里可能会缺一些其他组件，见招拆招即可，谷歌或者百度解决 设置XSHELL 打开会话对话框 选择要激活X11转发功能的会话 点击[属性]按钮 在[类别]中选择[连接-&gt;SSH-&gt;隧道] 选择[转发X11连接到] 如用户的PC上已安装Xmanager，请勾选[Xmanager(M)]。如使用其他PC X 服务器，请选择[X DISPLAY(D)]后输入适用的DISPLAY 点击[确定] 检查当前监听端口IMPORTANT 1sudo netstat -tnlp|grep sshd 注意上面监听的6010，Xmanager会把X DISPLAY选项自动查找为Xshell。其他 PC X 服务器程序需由用户进行设置。如果PC X 服务器使用TCP 6000号端口，DISPLAY设置为“localhost:0.0” ，也就是说，X11的偏移量是6000，因此下面需要设置一个最终要的DISPLAY的值:10.0，如下 123export DISPLAY=:10.0或者export DISPLAY=localhost:10.0 测试X11 DISPLAY如果本地已经有需要X11界面展示的应用，直接运行查看即可，如无，推荐使用xclock检查是否生效[以下步骤不是必须，自行选择] 1sudo yum install xclock 这里可能出现乱码之类的，可能需要安装x窗口相关包，和字体显示包 1sudo yum groupinstall "X Window System" "Fonts" 然后执行xclock，看是否在PC桌面显示对应的时钟图形。如果xclock出现Warning: Missing charsets in String to FontSet conversion，可以执行下面执行，然后重新执行 1export LC_ALL=C]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>X11 Display</tag>
        <tag>XSHELL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo添加Gitalk评论插件]]></title>
    <url>%2F2018%2F06%2F01%2FHexo%E6%B7%BB%E5%8A%A0Gitalk%E8%AF%84%E8%AE%BA%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[安装Gitalk提供了两种方式： 直接引入 1234567&lt;link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"&gt;&lt;script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"&gt;&lt;/script&gt;&lt;!-- or --&gt;&lt;link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"&gt;&lt;script src="https://unpkg.com/gitalk/dist/gitalk.min.js"&gt;&lt;/script&gt; npm安装 123npm i --save gitalkimport &apos;gitalk/dist/gitalk.css&apos;import Gitalk from &apos;gitalk&apos; 相对来说第一种会更简单。 使用A GitHub Application is needed for authorization, if you don’t have one, Click here to register a new one. Note: You must specify the website domain url in the Authorization callback URL field. 1234567891011const gitalk = new Gitalk(&#123; clientID: &apos;GitHub Application Client ID&apos;, clientSecret: &apos;GitHub Application Client Secret&apos;, repo: &apos;GitHub repo&apos;, owner: &apos;GitHub repo owner&apos;, admin: [&apos;GitHub repo owner and collaborators, only these guys can initialize github issues&apos;], id: location.pathname, // Ensure uniqueness and length less than 50 distractionFreeMode: false // Facebook-like distraction free mode&#125;)gitalk.render(&apos;gitalk-container&apos;) 修改主题文件 这里以next主题为例，参考Feature: Add Gitalk Support 不同的主题目录和模板引擎不同，可以自己修改, 修改next主题配置文件_config.yml，添加字段： 12345678910# Gitalk# more info please open https://github.com/gitalk/gitalkgitalk: enable: false clientID: clientSecret: repo: owner: admin: # support multiple admins split with comma, e.g. foo,bar pagerDirection: first 找到next/layout/_third-party/comments文件夹，新建gitalk.swig文件，代码如下： 1234567891011121314151617181920&#123;% if not (theme.duoshuo and theme.duoshuo.shortname) and not theme.duoshuo_shortname %&#125; &#123;% if theme.gitalk.enable %&#125; &#123;% if page.comments %&#125; &lt;script src=&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; const gitalk = new Gitalk(&#123; clientID: &apos;&#123;&#123;theme.gitalk.clientID&#125;&#125;&apos;, clientSecret: &apos;&#123;&#123;theme.gitalk.clientSecret&#125;&#125;&apos;, repo: &apos;&#123;&#123;theme.gitalk.repo&#125;&#125;&apos;, owner: &apos;&#123;&#123;theme.gitalk.owner&#125;&#125;&apos;, admin: &apos;&#123;&#123;theme.gitalk.admin&#125;&#125;&apos;.split(&apos;,&apos;), pagerDirection: &apos;&#123;&#123;theme.gitalk.pagerDirection&#125;&#125;&apos;, // facebook-like distraction free mode distractionFreeMode: false &#125;) gitalk.render(&apos;gitalk-container&apos;) &lt;/script&gt; &#123;% endif %&#125; &#123;% endif %&#125;&#123;% endif %&#125; 同目录下在index.swig文件末尾添加： 1&#123;% include &apos;gitalk.swig&apos; %&#125; 下步搞起，next/layout/_partials文件夹下，找到comments.swig文件，添加代码： 123&#123;% elseif theme.gitalk.enable %&#125; &lt;div id=&quot;gitalk-container&quot;&gt;&lt;/div&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;&gt; 因为github限制了issue的提交title长度不能超过50，可能会遇到Error: Validation Failed 按照这里的方案，使用MD5的方式降低长度即可 参考文档 Hexo添加Gitalk评论插件 Next 第三方服务集成 在hexo next主题上使用gitalk]]></content>
      <categories>
        <category>Hexo使用攻略</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo集成Algolia搜索插件]]></title>
    <url>%2F2018%2F06%2F01%2FHexo%E9%9B%86%E6%88%90Algolia%E6%90%9C%E7%B4%A2%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[本文转载自Hexo集成Algolia搜索插件 前言个人博客自从2016年10月21日搭建以来，迄今为止已经有49 篇日志了。虽然不是很多篇文章，但是搜索站内的内容已经力不从心了。 搜索了网上很多关于“Hexo 站内搜索”的内容，发现大部分都是使用Swiftype，但是发现Swiftype 搜索只有15 天的免费，之后就需要开始收费了。 因为只是为自己的个人博客 使用站内搜索，所以希望找一个类似与Swiftype 的，但是免费的站内搜索。最后找了Algolia 这个免费版本替代。 下面简单说下搭建过程： 搭建过程前提条件如果你的Next 版本为5.1.0 之后，可以使用Algolia。如果不是，请先升级到5.1.0 版本之后 一个Algolia 帐号官网地址 使用GitHub 或Google 帐号登录。 创建Index进入Dashboard，选择Indices 新建一个Index。 安装Hexo AlgoliaIndex 创建完成后，此时Index 为包含任何数据。需要安装Hexo Aloglia 扩展，这个扩展的功能是搜集站点的内容并通过API 发送给Aloglia。前往站点根目录，执行命令安装： 1npm install --save hexo-algolia 获取Key，更新站点信配置点击Dashborad 左侧的API Keys，其中的信息接下来将会被用到。包括Application ID 、Search-Only API Key 和 Admin API Key，其中Admin API Key需要保密保存 编辑站点配置文件，新增以下配置： 123456algolia: applicationID: &apos;SV57WJ53OS&apos; apiKey: &apos;c7d219504e44d09ab55f5f7a195fce98&apos; adminApiKey: &apos;adminApiKey&apos; indexName: &apos;dev_jobbymsblog&apos; chunkSize: 5000 更新Index当配置完成，在站点根目录下执行hexo algolia 来更新Index。请注意观察命令的输出。 主题集成更改主题配置文件，找到Algolia Search 配置部分： 123456789# Algolia Searchalgolia_search: enable: false hits: per_page: 10 labels: input_placeholder: Search for Posts hits_empty: &quot;We didn&apos;t find any results for the search: $&#123;query&#125;&quot; hits_stats: &quot;$&#123;hits&#125; results found in $&#123;time&#125; ms&quot; 将enable 改为true 即可，根据需要你可以调整labels 中的文本。 问题11. 点击搜索结果，结果跳转地址为： 1Cannot GET /undefined/ 按照5.1.0使用algolia搜索问题这里进行的处理，在这里总结一下： 因为hexo-aloglia 的作者没有把post.path 加入index，所以data.path 是undefined。 遇到这个问题，首先运行npm uninstll hexo-algolia 卸载之前的版本，再运行npm install hexo-algolia@0.2.0 --save,最后运行hexo algolia 命令重新index 就可以了。 参考文档 Swiftype站内搜索 Next 第三方服务集成]]></content>
      <categories>
        <category>Hexo使用攻略</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Algolia</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux xmr-stak挖矿教程]]></title>
    <url>%2F2018%2F05%2F27%2FLinux-xmr-stak%E6%8C%96%E7%9F%BF%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[在Linux上编译 xmr-stakInstall DependenciesAMD APP SDK 3.0 (only needed to use AMD GPUs) download and install the latest version from https://www.dropbox.com/sh/mpg882ekirnsfa7/AADWz5X-TgVdsmWt0QwMgTWLa/AMD-APP-SDKInstaller-v3.0.130.136-GA-linux64.tar.bz2?dl=0(do not wonder why it is a link to a dropbox but AMD has removed the SDK downloads, see https://community.amd.com/thread/228059) Cuda 8.0+ (only needed to use NVIDIA GPUs) download and install https://developer.nvidia.com/cuda-downloads for minimal install choose Custom installation options during the install and select CUDA/Develpment CUDA/Runtime Driver components GNU Compiler12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# Ubuntu / Debiansudo apt install libmicrohttpd-dev libssl-dev cmake build-essential libhwloc-devgit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake ..make install# Archsudo pacman -S --needed base-devel hwloc openssl cmake libmicrohttpdgit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake ..make install# Fedorasudo dnf install gcc gcc-c++ hwloc-devel libmicrohttpd-devel libstdc++-static make openssl-devel cmakegit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake ..make install# CentOSsudo yum install centos-release-scl epel-releasesudo yum install cmake3 devtoolset-4-gcc* hwloc-devel libmicrohttpd-devel openssl-devel makescl enable devtoolset-4 bashgit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake3 ..make install# Ubuntu 14.04sudo add-apt-repository ppa:ubuntu-toolchain-r/testsudo apt updatesudo apt install gcc-5 g++-5 makesudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 1 --slave /usr/bin/g++ g++ /usr/bin/g++-5curl -L http://www.cmake.org/files/v3.4/cmake-3.4.1.tar.gz | tar -xvzf - -C /tmp/cd /tmp/cmake-3.4.1/ &amp;&amp; ./configure &amp;&amp; make &amp;&amp; sudo make install &amp;&amp; cd -sudo update-alternatives --install /usr/bin/cmake cmake /usr/local/bin/cmake 1 --forcesudo apt install libmicrohttpd-dev libssl-dev libhwloc-devgit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake ..make install# TinyCore Linux 8.x# TinyCore is 32-bit only, but there is an x86-64 port, known as &quot;Pure 64,&quot;# hosted on the TinyCore home page, and it works well.# Beware that huge page support is not enabled in the kernel distributed# with Pure 64. Consider http://wiki.tinycorelinux.net/wiki:custom_kernel# Note that as of yet there are no distro packages for microhttpd or hwloc.# hwloc is easy enough to install manually though, shown below.# Also note that only CPU mining has been tested on this platform, thus the# disabling of CUDA and OpenCL shown below.tce-load -iw openssl-dev.tcz cmake.tcz make.tcz gcc.tcz git.tcz \ glibc_base-dev.tcz linux-4.8.1_api_headers.tcz \ glibc_add_lib.tczwget https://www.open-mpi.org/software/hwloc/v1.11/downloads/hwloc-1.11.8.tar.gztar xzvf hwloc-1.11.8.tar.gzcd hwloc-1.11.8./configure --prefix=/usr/localmakesudo make installcd ..git clone http://github.com/fireice-uk/xmr-stakcd xmr-stakmkdir buildcd buildCC=gcc cmake .. -DCUDA_ENABLE=OFF \ -DOpenCL_ENABLE=OFF \ -DMICROHTTPD_ENABLE=OFFmake install g++ version 5.1 or higher is required for full C++11 support.If you want to compile the binary without installing libraries / compiler or just compile binary for some other distribution, please check the build_xmr-stak_docker.sh script. Some newer gcc versions are not supported by CUDA (e.g. Ubuntu 17.10). It will require installing gcc 5 but you can avoid changing defaults. In that case you can force CUDA to use an older compiler in the following way:1cmake -DCUDA_HOST_COMPILER=/usr/bin/gcc-5 .. To do a generic and static build for a system without gcc 5.1+1234cmake -DCMAKE_LINK_STATIC=ON -DXMR-STAK_COMPILE=generic .make installcd bin\Releasecopy C:\xmr-stak-dep\openssl\bin\* . Note - cmake caches variables, so if you want to do a dynamic build later you need to specify ‘-DCMAKE_LINK_STATIC=OFF’ Reference xmr-stak]]></content>
      <categories>
        <category>block-chain</category>
      </categories>
      <tags>
        <tag>xmr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Day 1: Bower —— 管理你的客户端依赖关系]]></title>
    <url>%2F2018%2F05%2F26%2FDay-1-Bower-%E2%80%94%E2%80%94-%E7%AE%A1%E7%90%86%E4%BD%A0%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[编者注：我们发现了比较有趣的系列文章《30天学习30种新技术》，准备翻译，一天一篇更新，年终礼包。以下是第一天技术的译文。 我决定将第一天的学习主题选为Bower。 什么是Bower？Bower是一个客户端技术的软件包管理器，它可用于搜索、安装和卸载如JavaScript、HTML、CSS之类的网络资源。其他一些建立在Bower基础之上的开发工具，如YeoMan和Grunt，这个会在以后的文章中介绍。 为什么我会在意Bower？ 节省时间。为什么要学习Bower的第一个原因，就是它会为你节省寻找客户端的依赖关系的时间。每次我需要安装jQuery的时候，我都需要去jQuery网站下载包或使用CDN版本。但是有了Bower，你只需要输入一个命令，jquery就会安装在本地计算机上，你不需要去记版本号之类的东西，你也可以通过Bower的info命令去查看任意库的信息。 脱机工作。Bower会在用户主目录下创建一个.bower的文件夹，这个文件夹会下载所有的资源、并安装一个软件包使它们可以离线使用。如果你熟悉Java，Bower即是一个类似于现在流行的Maven构建系统的.m2仓库。每次你下载任何资源库都将被安装在两个文件夹中 —— 一个在的应用程序文件夹，另一个在用户主目录下的.bower文件夹。因此，下一次你需要这个仓库时，就会用那个用户主目录下.bower中的版本。 可以很容易地展现客户端的依赖关系。你可以创建一个名为bower.json的文件，在这个文件里你可以指定所有客户端的依赖关系，任何时候你需要弄清楚你正在使用哪些库，你可以参考这个文件。 让升级变得简单。假设某个库的新版本发布了一个重要的安全修补程序，为了安装新版本，你只需要运行一个命令，bower会自动更新所有有关新版本的依赖关系。 前提准备为了安装bower，你首先需要安装如下文件： Node：下载最新版本的node.js NPM：NPM是node程序包管理器。它是捆绑在nodejs的安装程序上的，所以一旦你已经安装了node，NPM也就安装好了。 Git：你需要从git仓库获取一些代码包。 安装Bower一旦你已经安装了上面所说的所有必要文件，键入以下命令安装Bower： 1$ npm install -g bower 这行命令是Bower的全局安装，-g 操作表示全局。 开始使用Bower安装完bower之后就可以使用所有的bower命令了。可以键入help 命令来查看bower可以完成那些操作，如下： 1234567891011121314151617181920212223242526272829303132$ bower helpUsage: bower &lt;command&gt; [&lt;args&gt;] [&lt;options&gt;]Commands: cache Manage bower cache help Display help information about Bower home Opens a package homepage into your favorite browser info Info of a particular package init Interactively create a bower.json file install Install a package locally link Symlink a package folder list List local packages lookup Look up a package URL by name prune Removes local extraneous packages register Register a package search Search for a package by name update Update a local package uninstall Remove a local packageOptions: -f, --force Makes various commands more forceful -j, --json Output consumable JSON -l, --log-level What level of logs to report -o, --offline Do not hit the network -q, --quiet Only output important information -s, --silent Do not output anything, besides errors -V, --verbose Makes output more verbose --allow-root Allows running commands as root 包的安装Bower是一个软件包管理器，所以你可以在应用程序中用它来安装新的软件包。举例来看一下来如何使用Bower安装JQuery，在你想要安装该包的地方创建一个新的文件夹，键入如下命令： 1$ bower install jquery 上述命令完成以后，你会在你刚才创建的目录下看到一个bower_components的文件夹，其中目录如下： 123456789101112131415$ tree bower_components/bower_components/└── jquery ├── README.md ├── bower.json ├── component.json ├── composer.json ├── jquery-migrate.js ├── jquery-migrate.min.js ├── jquery.js ├── jquery.min.js ├── jquery.min.map └── package.json1 directory, 10 files 包的使用现在就可以在应用程序中使用jQuery包了，在jQuery里创建一个简单的html5文件： 12345678910111213141516171819202122&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Learning Bower&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;button&gt;Animate Me!!&lt;/button&gt;&lt;div style=&quot;background:red;height:100px;width:100px;position:absolute;&quot;&gt;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;bower_components/jquery/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; $(document).ready(function()&#123; $(&quot;button&quot;).click(function()&#123; $(&quot;div&quot;).animate(&#123;left:&apos;250px&apos;&#125;); &#125;); &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 正如你所看到的，你刚刚引用jquery.min.js文件，现阶段完成。 所有包的列表如果你想找出所有安装在应用程序中的包，可以使用list命令： 1234$ bower listbower check-new Checking for new versions of the project dependencies..blog /Users/shekhargulati/day1/blog└── jquery#2.0.3 extraneous 包的搜索假如你想在你的应用程序中使用twitter的bootstrap框架，但你不确定包的名字，这时你可以使用search 命令： 123456$ bower search bootstrapSearch results: bootstrap git://github.com/twbs/bootstrap.git angular-bootstrap git://github.com/angular-ui/bootstrap-bower.git sass-bootstrap git://github.com/jlong/sass-twitter-bootstrap.git 包的信息如果你想看到关于特定的包的信息，可以使用info 命令来查看该包的所有信息： 1234567891011121314151617181920212223242526272829$ bower info bootstrapbower bootstrap#* not-cached git://github.com/twbs/bootstrap.git#*bower bootstrap#* resolve git://github.com/twbs/bootstrap.git#*bower bootstrap#* download https://github.com/twbs/bootstrap/archive/v3.0.0.tar.gzbower bootstrap#* extract archive.tar.gzbower bootstrap#* resolved git://github.com/twbs/bootstrap.git#3.0.0&#123; name: &apos;bootstrap&apos;, version: &apos;3.0.0&apos;, main: [ &apos;./dist/js/bootstrap.js&apos;, &apos;./dist/css/bootstrap.css&apos; ], ignore: [ &apos;**/.*&apos; ], dependencies: &#123; jquery: &apos;&gt;= 1.9.0&apos; &#125;, homepage: &apos;https://github.com/twbs/bootstrap&apos;&#125;Available versions: - 3.0.0 - 3.0.0-rc1 - 3.0.0-rc.2 - 2.3.2 ..... 如果你想得到单个包的信息，也可以使用info 命令： 12345678910111213141516171819$ bower info bootstrap#3.0.0bower bootstrap#3.0.0 cached git://github.com/twbs/bootstrap.git#3.0.0bower bootstrap#3.0.0 validate 3.0.0 against git://github.com/twbs/bootstrap.git#3.0.0&#123; name: &apos;bootstrap&apos;, version: &apos;3.0.0&apos;, main: [ &apos;./dist/js/bootstrap.js&apos;, &apos;./dist/css/bootstrap.css&apos; ], ignore: [ &apos;**/.*&apos; ], dependencies: &#123; jquery: &apos;&gt;= 1.9.0&apos; &#125;, homepage: &apos;https://github.com/twbs/bootstrap&apos;&#125; 包的卸载卸载包可以使用uninstall 命令： 1$ bower uninstall jquery bower.json文件的使用bower.json文件的使用可以让包的安装更容易，你可以在应用程序的根目录下创建一个名为“bower.json”的文件，并定义它的依赖关系。使用bower init 命令来创建bower.json文件： 123456789101112131415161718192021222324252627282930313233$ bower init[?] name: blog[?] version: 0.0.1[?] description:[?] main file:[?] keywords:[?] authors: Shekhar Gulati &lt;shekhargulati84@gmail.com&gt;[?] license: MIT[?] homepage:[?] set currently installed components as dependencies? Yes[?] add commonly ignored files to ignore list? Yes[?] would you like to mark this package as private which prevents it from being accidentally published to the registry? No&#123; name: &apos;blog&apos;, version: &apos;0.0.1&apos;, authors: [ &apos;Shekhar Gulati &lt;shekhargulati84@gmail.com&gt;&apos; ], license: &apos;MIT&apos;, ignore: [ &apos;**/.*&apos;, &apos;node_modules&apos;, &apos;bower_components&apos;, &apos;test&apos;, &apos;tests&apos; ], dependencies: &#123; jquery: &apos;~2.0.3&apos; &#125;&#125;[?] Looks good? Yes 可以查看该文件： 123456789101112131415161718&#123; &quot;name&quot;: &quot;blog&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;authors&quot;: [ &quot;Shekhar Gulati &lt;shekhargulati84@gmail.com&gt;&quot; ], &quot;license&quot;: &quot;MIT&quot;, &quot;ignore&quot;: [ &quot;**/.*&quot;, &quot;node_modules&quot;, &quot;bower_components&quot;, &quot;test&quot;, &quot;tests&quot; ], &quot;dependencies&quot;: &#123; &quot;jquery&quot;: &quot;~2.0.3&quot; &#125;&#125; 注意看，它已经加入了jQuery依赖关系。 现在假设也想用twitter bootstrap，我们可以用下面的命令安装twitter bootstrap并更新bower.json文件： 1$ bower install bootstrap --save 它会自动安装最新版本的bootstrap并更新bower.json文件： 12345678910111213141516171819&#123; &quot;name&quot;: &quot;blog&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;authors&quot;: [ &quot;Shekhar Gulati &lt;shekhargulati84@gmail.com&gt;&quot; ], &quot;license&quot;: &quot;MIT&quot;, &quot;ignore&quot;: [ &quot;**/.*&quot;, &quot;node_modules&quot;, &quot;bower_components&quot;, &quot;test&quot;, &quot;tests&quot; ], &quot;dependencies&quot;: &#123; &quot;jquery&quot;: &quot;~2.0.3&quot;, &quot;bootstrap&quot;: &quot;~3.0.0&quot; &#125;&#125; 这就是今天的学习，希望能让你对bower有个足够的了解，最好可以自己尝试一下。 原文 Day 1: Bower–Manage Your Client Side Dependencies翻译 SegmentFault]]></content>
      <categories>
        <category>30天学习30种新技术系列</category>
      </categories>
      <tags>
        <tag>30天学习30种新技术系列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[30天学习30种新技术系列]]></title>
    <url>%2F2018%2F05%2F26%2F30-%E5%A4%A9%E5%AD%A6%E4%B9%A0-30-%E7%A7%8D%E6%96%B0%E6%8A%80%E6%9C%AF%E7%B3%BB%E5%88%97%2F</url>
    <content type="text"><![CDATA[编者注：我们发现了比较有趣的系列文章《30 天学习 30 种新技术》，准备翻译，一天一篇更新，年终礼包。以下是译文，英文标题表示还未翻译，附原文链接；中文标题表示已翻译，附译文链接。 更新：全系列已经全部翻译完成。 让你 30 天学习 30 种新技术，你会觉得这是挑战吗？ 我已经接受了挑战，我会在一个月的时间内每天学习一门新技术，挑战开始于 2013 年 10 月 29 日。下面就是我将要学习的新技术的列表，我会把每天学到的内容写出来。在我每天正常的工作之后，我会花几个小时学习一门新技术，再用一小时将今天学到的写在博客上。这项活动的目的是熟悉许多在开发者社区所使用的新技术。 我会把重点放在 JavaScript 及其相关技术的学习上，当然也会去了解一下像 Java 这类我比较感兴趣的其他技术。我也可能会在一门技术上花费好几天的时间，但我每次会选择和这门技术相关的不同的主题来讲。只要是有意义的，我将尽量展示它如何与 OpenShift 工作，我希望这是一次充满乐趣并能学到很多东西的旅程。（你可以在 twitter 上follow 我） 下边是学习列表： 2013.10.29 - Day 1: Bower —— 管理你的客户端依赖关系 2013.10.30 - Day 2: AngularJS —— 对 AngularJS 的初步认识 2013.10.31 - Day 3: Flask —— 使用 Python 和 OpenShift 进行即时 Web 开发 2013.11.01 - Day 4: PredictionIO —— 如何创建一个博客推荐器 2013.11.02 - Day 5: GruntJS —— 重复乏味的工作总会有人做（反正我不做） 2013.11.03 - Day 6: 在 Java 虚拟机上使用 Grails 进行快速 Web 开发 2013.11.04 - Day 7: GruntJS 在线重载 提升生产率至新境界 2013.11.05 - Day 8: Harp.JS —— 现代静态 Web 服务器 2013.11.06 - Day 9: TextBlob —— 对文本进行情感分析 2013.11.07 - Day 10: PhoneGap —— 开发手机应用如此简单 2013.11.08 - Day 11: AeroGear 推送服务器：使应用的通知推送变得简单 2013.11.09 - Day 12: OpenCV —— Java 开发者的人脸检测 2013.11.10 - Day 13: Dropwizard —— 非常棒的 Java REST 服务器栈 2013.11.11 - Day14：使用斯坦福 NER 软件包实现你自己的命名实体识别器（Named Entity Recognition，NER） 2013.11.12 - Day 15：Meteor —— 从零开始创建一个 Web 应用 2013.11.13 - Day 16: Goose Extractor —— 好用的文章提取工具 2013.11.14 - Day 17: 使用 JBoss Forge 和 OpenShift 构建部署 JAVA EE 6 应用 2013.11.15 - Day 18: BoilerPipe —— Java开发者的文章提取工具 2013.11.16 - Day 19: EmberJS 入门指南 2013.11.17 - Day 20: 斯坦福CoreNLP —— 用 Java 给 Twitter 情感分析 2013.11.18 - Day 21：Docker 入门教程 2013.11.19 - Day 22： 使用 Spring、MongoDB 和 AngularJS 开发单页面应用 2013.11.20 - Day 23： 使用 TimelineJS 构建精美的时间轴 2013.11.21 - Day 24: 使用 Yeoman 自动构建 Ember 项目 2013.11.22 - Day 25: Tornado —— 联合 Tornado、MongoDB 和 AngularJS 进行应用开发 2013.11.23 - Day 26: TogetherJS —— 让我们一起来编程！ 2013.11.24 - Day 27: Restify —— 在Node.js中构建正确的REST Web服务 2013.11.25 - Day 28: OpenShift 的 Eclipse 集成 2013.11.26 - Day 29: 编写你的第一个 Google Chrome 扩展程序 2013.11.27 - Day 30: Play Framework —— Java 开发者的梦想框架 原文 Learning 30 Technologies in 30 Days: A Developer Challenge翻译 SegmentFault]]></content>
      <categories>
        <category>30天学习30种新技术系列</category>
      </categories>
      <tags>
        <tag>30天学习30种新技术系列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教你免费搭建个人博客，Hexo&Github]]></title>
    <url>%2F2018%2F05%2F26%2F%E6%95%99%E4%BD%A0%E5%85%8D%E8%B4%B9%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%EF%BC%8CHexo-Github%2F</url>
    <content type="text"><![CDATA[什么是 Hexo？https://hexo.io/zh-cn/docs/ Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 一、配置Github首先注册、登录 https://github.com/ 记住自己的Username（很重要） 然后右上角选择 Create a new repository https://github.com/new Repository name （填自己的名字） yourname.github.io(yourname与你的注册用户名一致,这个就是你博客的域名了) 例如，我的域名是github.com/zhihuya，就填入zhihuya.github.io。成功后出现下面的画面 二、环境安装（node、git）1、安装 Node.js https://nodejs.org/en/ 2、安装 Git https://github.com/waylau/git-for-win Git教程 https://github.com/waylau/git-for-win廖雪峰老师的教程，非常好。 3、安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，名称和邮箱是Github上的 4、安装 Hexo。所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。 1$ npm install -g hexo-cli （使用的cmder，超级好用~~。等待时间可能有点长） 好了到这一步我们环境全部安装好了。 三、设置在电脑F盘（自己随意）目录下新建文件夹 test，进入test，按住Shift键点击鼠标右键 因为我有安装Cmder，没有安装的点击“在此处打开命令窗口”，输入 1hexo init blog 稍微等待下，速度有点慢。成功提示 1INFO Start blogging with Hexo! 因为你初始化hexo 之后source目录下自带一篇hello world文章, 所以直接执行下方命令 123456$ hexo generate# 启动本地服务器$ hexo server# 在浏览器输入 http://localhost:4000/就可以看见网页和模板了INFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 访问http://localhost:4000/，便可以看到网站初步的模样，不要激动，我们还要把网页发布到Github上去。 重新打开CMD，输入： 1ssh-keygen -t rsa -C &quot;Github的注册邮箱地址&quot; 一路Enter过来就好，得到信息： 1Your public key has been saved in /c/Users/user/.ssh/id_rsa.pub. 找到该文件，打开（sublime text），Ctrl + a复制里面的所有内容，然后进入Sign in to GitHub：https://github.com/settings/ssh New SSH key ——Title：blog —— Key：输入刚才复制的—— Add SSH key 四、配置博客在blog目录下，用sublime打开_config.yml文件，修改参数信息 特别提醒，在每个参数的：后都要加一个空格 修改网站相关信息 123456title: 崔斯特测试所用博客subtitle: 副标题description: 网页描述author: 崔斯特language: zh-CNtimezone: Asia/Shanghai 配置部署（我的是zhihuya，修改成自己的） 1234deploy: type: git repo: https://github.com/zhihuya/zhihuya.github.io.git branch: master 五、发表文章在CMD中输入 12$ hexo new &quot;崔斯特测试文章&quot;INFO Created: F:\test\blog\source\_posts\崔斯特测试文章.md 找到该文章，打开，使用Markdown语法，该语法介绍可以查看https://zhangslob.github.io/2017/02/26/%E5%88%A9%E7%94%A8HEXO%E6%90%AD%E5%BB%BA%E7%9A%84%E5%8D%9A%E5%AE%A2/ 123456---title: 崔斯特测试文章date: 2017-02-28 13:03:44tags:---这是一篇测试文章，欢迎关注作者博客[1]: https://zhangslob.github.io/ 保存，然后执行下列步骤： 12345678910111213141516F:\test\blog$ hexo cleanINFO Deleted database.INFO Deleted public folder.F:\test\blog$ hexo generateINFO Start processingINFO Files loaded in 1.48 s#省略INFO 29 files generated in 4.27 sF:\test\blog$ hexo serverINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 这个时候，打开http://localhost:4000/，发现刚才的文章已经成功了 最后一步，发布到网上，执行： 123456F:\test\blog$ hexo deployINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...#省略 其中会跳出Github登录，直接登录，如果没有问题输入zhihuya（换成你的）.github.io/ 崔斯特测试所用博客https://zhihuya.github.io/ 然后就可以看到已经发布了 六、总结发布文章的步骤： 1、hexo new 创建文章 2、Markdown语法编辑文章 3、部署（所有打开CMD都是在blog目录下） 1234hexo clean #清除缓存 网页正常情况下可以忽略此条命令hexo generate #生成hexo server #启动服务预览，非必要，可本地浏览网页hexo deploy #部署发布 简写Tips： hexo n “我的博客” == hexo new “我的博客” #新建文章 hexo p == hexo publish hexo g == hexo generate#生成 hexo s == hexo server #启动服务预览 hexo d == hexo deploy#部署 如果在执行 hexo deploy 后,出现 error deployer not found:github 的错误，执行： 1npm install hexo-deployer-git --save 出错是正常的，出错了自己先百度或google，实在不知道的可以询问我。 托管的话不仅有github可以用，还有个国内的https://coding.net/可选 引用说明 作者：zhangslob 链接：https://zhangslob.github.io/2017/02/28/教你免费搭建个人博客，Hexo-Github]]></content>
      <categories>
        <category>Hexo使用攻略</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>个人博客搭建</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo使用攻略-添加分类及标签]]></title>
    <url>%2F2018%2F05%2F26%2FHexo%E4%BD%BF%E7%94%A8%E6%94%BB%E7%95%A5-%E6%B7%BB%E5%8A%A0%E5%88%86%E7%B1%BB%E5%8F%8A%E6%A0%87%E7%AD%BE%2F</url>
    <content type="text"><![CDATA[1、创建“分类”选项1.1 生成“分类”页并添加tpye属性打开命令行，进入博客所在文件夹。执行命令 1$ hexo new page categories 成功后会提示： 1INFO Created: ~/Documents/blog/source/categories/index.md 根据上面的路径，找到index.md这个文件，打开后默认内容是这样的： 1234---title: 文章分类date: 2017-05-27 13:47:40--- 添加type: &quot;categories&quot;到内容中，添加后是这样的： 123456---title: 文章分类date: 2017-05-27 13:47:40type: &quot;categories&quot;comments: false--- 保存并关闭文件。 1.2 给文章添加“categories”属性打开需要添加分类的文章，为其添加categories属性。下方的categories: web前端表示添加这篇文章到“web前端”这个分类。注意：hexo一篇文章只能属于一个分类，也就是说如果在“- web前端”下方添加“-xxx”，hexo不会产生两个分类，而是把分类嵌套（即该文章属于 “- web前端”下的 “-xxx ”分类）。 123456---title: jQuery对表单的操作及更多应用date: 2017-05-26 12:12:57categories: - web前端--- 至此，成功给文章添加分类，点击首页的“分类”可以看到该分类下的所有文章。当然，只有添加了categories: xxx的文章才会被收录到首页的“分类”中。 2、创建“标签”选项2.1 生成“标签”页并添加tpye属性打开命令行，进入博客所在文件夹。执行命令 1$ hexo new page tags 成功后会提示： 1INFO Created: ~/Documents/blog/source/tags/index.md 根据上面的路径，找到index.md这个文件，打开后默认内容是这样的： 1234---title: 标签date: 2017-05-27 14:22:08--- 添加type: &quot;tags&quot;到内容中，添加后是这样的： 123456---title: 文章分类date: 2017-05-27 13:47:40type: &quot;tags&quot;comments: false--- 保存并关闭文件。 2.2 给文章添加“tags”属性打开需要添加标签的文章，为其添加tags属性。下方的tags:下方的- jQuery - 表格 - 表单验证就是这篇文章的标签了 12345678910---title: jQuery对表单的操作及更多应用date: 2017-05-26 12:12:57categories: - web前端tags:- jQuery- 表格- 表单验证--- 至此，成功给文章添加分类，点击首页的“标签”可以看到该标签下的所有文章。当然，只有添加了tags: xxx的文章才会被收录到首页的“标签”中。 细心的朋友可能已经发现，这两个的设置几乎一模一样！是的，没错，思路都是一样的。所以我们可以打开scaffolds/post.md文件，在tages:上面加入categories:,保存后，之后执行hexo new 文章名命令生成的文件，页面里就有categories:项了。 scaffolds目录下，是新建页面的模板，执行新建命令时，是根据这里的模板页来完成的，所以可以在这里根据你自己的需求添加一些默认值。]]></content>
      <categories>
        <category>Hexo使用攻略</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Hello World]]></title>
    <url>%2F2018%2F05%2F26%2Fhexo-hello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment hexo algolia12$ export HEXO_ALGOLIA_INDEXING_KEY=[algolia.apiKey]$ hexo algolia CI with jenkins使用Jenkins实现Hexo自动部署 hexo使用jenkins自动部署到阿里云 ###Cooperation 使用git clonegit@github.com:vincentruan/vincentruan.github.io.git拷贝仓库（git checkout -b hexo）； 在新拷贝的vincentruan.github.io文件夹下通过Git bash依次执行下列指令： npm install hexo-cli -g(首次安装)、npm install hexo、npm install、npm install hexo-deployer-git（记得，不需要hexo init这条指令,如果不慎在此时用了hexo init，则站点的配置文件_config.yml里面内容会被清空使用默认值，所以这一步一定要慎重 ）]]></content>
      <categories>
        <category>Hexo使用攻略</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown吃了吗?]]></title>
    <url>%2F2018%2F05%2F20%2FMarkdown%E5%90%83%E4%BA%86%E5%90%97%2F</url>
    <content type="text"><![CDATA[markdown 介绍 Markdown 是一种轻量级标记语言，它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML(或者HTML)文档”。 - wikipedia Daring Fireball: Markdown Project markdown Markdown wikipedia 介绍 MultiMarkdown 引入更多标记特性和输出选项的改进版Markdown why markdown 纯文本，兼容性极强，可以用任意文本编辑器打开. 语法简单（the syntax is so simple you can barely call it “syntax.”），零学习成本，极好的可读性，让你专注于文字写作而不是页面排版，并且兼容 HTML，simple but powerful . 格式转换方便，Markdown 的文本你可以轻松转换为 html、pdf、epub、电子书等。 适合团队协作，可以使用 git/svn 等进行版本控制管理。 阳志平：为什么 Markdown 成为科技界写作主流？ 图灵社区：用Markdown来写自由书籍-开源技术的方案 目前很多在线服务商均支持使用markdown编写： Github 最先支持，使用Markdown的一个分支版本来格式化评论、消息以及其它内容。 Stack Overflow 使用一种 Markdown 的分支作为它的文章格式化系统。 博客园 国内技术人的博客家园，每天活跃上万用户，高质量社区。 CSDN 号称全球最大中文IT社区，涵盖了多种语言、架构、博客、俱乐部等模块的技术论坛。 图灵社区 使用markdown语法供用户写作电子书. 简书 重拾文字的力量，交流故事，沟通想法，一个基于内容分享的社区。 为知笔记 国内顶尖笔记软件，支持使用Markdown语法编辑笔记。 有道云笔记 最新版本开始支持，并且支持一些扩展语法。 …… markdown 使用 Markdown: Basics （快速入门） Markdown 完整语法说明 (简体中文版) Github: Mastering Markdown GitHub 帮助中关于 Markdown 的语法帮助 MarkDown 语法团队规范 语法规范简洁版 Markdown Style Guide 语法规范复杂版 Markdown Cheatsheet GitHub Flavored Markdown GitHub 使用的 Markdown 语法，略微不同于标准 Markdown 语法。提供了一些更加简洁的语法，类似 URL autolinking, Strikethrough, Fenced code blocks, Syntax highlighting 等等 MultiMarkdown 介绍 对 markdown 进行的扩展功能 markdown 工具 马克飞象 web/chrome 离线客户端，markdown 全功能支持，最大特点内容能够同步到印象笔记（evernote）中，笔记的用户重度推荐，按年收费，目前作者 @weibo 正在开发跨平台的客户端。 StackEdit 在线 markdown 编辑器，可同步文档到Google Drive和 Dropbox，可发布文章到 Blogger，GitHub，Google Drive，Dropbox，Tumblr和WordPress。 cmd 作业部落 支持 win/mac/linux/web/chrome 全平台，支持实时同步预览，支持代码高亮、数学公式，区分写作和阅读模式，支持在线存储，分享文稿网址。 MacDown OSX 上的 Markdown 开源编辑器，支持代码高亮，实时预览等。 MarkdownPad Windows上的全功能Markdown编辑器，推荐win上使用，基本全部功能。 Marked2 多种 md 显示方案，不能够编辑文件，只用来展示文件，配合 subline text markdown edit 插件，完美使用； MWeb 专业的 Markdown 写作、记笔记、静态博客生成软件，由国内独立开发者@oulvhai开发，支持Toc、Table、代码高亮、支持发布到 Wordrpess 博客、支持 Metaweblog API 的博客服务、Wordpress.com、Evernote 和印象笔记、Blogger、Scriptogr.am、Tumblr等服务。 Haroopad 又一款简洁多功能的跨平台编辑器，全功能支持，再加上对社交网络友好的连接，多种主题等，感兴趣的可以看看。详情参考issue#1 Typora 不分栏，实时展示看到写出的内容，对于不喜欢「两栏」设计的人来说是一个选择 MarkEditor - ME MarkEditor以markdown为基础语法，多标签栏、文件夹结构，纯文本的方式带来优雅、高效的体验。 确实很棒的工具，带来很多新鲜的理念，支持、重构、提升 markdown，加快写作的体验。具体可以查看几篇评测文章： 简洁与强大，从不是矛盾的事物：写作工具 MarkEditor 功能详解 不止是一款简单的码字工具：MarkEditor 进阶功能介绍 码字必备：18 款优秀的 Markdown 写作工具 | 2015 年度盘点 喜欢哪一款，就看你的了。 这几款就够了，多了就有选择症 …… reference 参考 Why Markdown? A two-minute explanation 简书：献给写作者的 Markdown 新手指南 Markdown simple world]]></content>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
</search>
