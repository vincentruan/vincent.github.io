{"meta":{"title":"星辰大海","subtitle":"My Conquest Is the Sea of Stars.","description":"The King is dead, long live the King!","author":"vincent","url":"https://vincentruan.github.io"},"pages":[{"title":"tags","date":"2018-05-26T09:22:14.000Z","updated":"2018-05-26T09:22:57.773Z","comments":false,"path":"tags/index.html","permalink":"https://vincentruan.github.io/tags/index.html","excerpt":"","text":""},{"title":"文章分类","date":"2018-05-26T09:18:05.000Z","updated":"2018-05-26T09:19:34.334Z","comments":false,"path":"categories/index.html","permalink":"https://vincentruan.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Java性能优化和JVM GC（垃圾回收机制）详解","slug":"Java性能优化和JVM-GC（垃圾回收机制）详解","date":"2020-02-24T06:42:01.000Z","updated":"2020-02-24T07:02:34.899Z","comments":true,"path":"2020/02/24/Java性能优化和JVM-GC（垃圾回收机制）详解/","link":"","permalink":"https://vincentruan.github.io/2020/02/24/Java性能优化和JVM-GC（垃圾回收机制）详解/","excerpt":"","text":"Java的性能优化，JVM GC（垃圾回收机制）在学习Java GC 之前，我们需要记住一个单词：stop-the-world 。它会在任何一种GC算法中发生。stop-the-world 意味着JVM因为需要执行GC而停止了应用程序的执行。当stop-the-world 发生时，除GC所需的线程外，所有的线程都进入等待状态，直到GC任务完成。GC优化很多时候就是减少stop-the-world 的发生。 JVM GC回收哪个区域内的垃圾？需要注意的是，JVM GC只回收堆区和方法区内的对象。而栈区的数据，在超出作用域后会被JVM自动释放掉，所以其不在JVM GC的管理范围内。 JVM GC怎么判断对象可以被回收了？ 对象没有引用 作用域发生未捕获异常 程序在作用域正常执行完毕 程序执行了System.exit() 程序发生意外终止（被杀线程等） 在Java程序中不能显式的分配和注销缓存，因为这些事情JVM都帮我们做了，那就是GC。 有些时候我们可以将相关的对象设置成null 来试图显示的清除缓存，但是并不是设置为null 就会一定被标记为可回收，有可能会发生逃逸。 将对象设置成null 至少没有什么坏处，但是使用System.gc() 便不可取了，使用System.gc() 时候并不是马上执行GC操作，而是会等待一段时间，甚至不执行，而且System.gc() 如果被执行，会触发Full GC ，这非常影响性能。 JVM GC什么时候执行？eden区空间不够存放新对象的时候，执行Minro GC。升到老年代的对象大于老年代剩余空间的时候执行Full GC，或者小于的时候被HandlePromotionFailure 参数强制Full GC 。调优主要是减少 Full GC 的触发次数，可以通过 NewRatio 控制新生代转老年代的比例，通过MaxTenuringThreshold 设置对象进入老年代的年龄阀值（后面会介绍到）。 按代的垃圾回收机制新生代（Young generation）：绝大多数最新被创建的对象都会被分配到这里，由于大部分在创建后很快变得不可达，很多对象被创建在新生代，然后“消失”。对象从这个区域“消失”的过程我们称之为：Minor GC 。 老年代（Old generation）：对象没有变得不可达，并且从新生代周期中存活了下来，会被拷贝到这里。其区域分配的空间要比新生代多。也正由于其相对大的空间，发生在老年代的GC次数要比新生代少得多。对象从老年代中消失的过程，称之为：Major GC 或者 Full GC。 持久代（Permanent generation）也称之为 方法区（Method area）：用于保存类常量以及字符串常量。注意，这个区域不是用于存储那些从老年代存活下来的对象，这个区域也可能发生GC。发生在这个区域的GC事件也被算为 Major GC 。只不过在这个区域发生GC的条件非常严苛，必须符合以下三种条件才会被回收： 所有实例被回收 加载该类的ClassLoader 被回收 Class 对象无法通过任何途径访问（包括反射） 可能我们会有疑问： 如果老年代的对象需要引用新生代的对象，会发生什么呢？ 为了解决这个问题，老年代中存在一个 card table ，它是一个512byte大小的块。所有老年代的对象指向新生代对象的引用都会被记录在这个表中。当针对新生代执行GC的时候，只需要查询 card table 来决定是否可以被回收，而不用查询整个老年代。这个 card table 由一个write barrier 来管理。write barrier给GC带来了很大的性能提升，虽然由此可能带来一些开销，但完全是值得的。 默认的新生代（Young generation）、老年代（Old generation）所占空间比例为 1 : 2 。 新生代空间的构成与逻辑为了更好的理解GC，我们来学习新生代的构成，它用来保存那些第一次被创建的对象，它被分成三个空间： 一个伊甸园空间（Eden） 两个幸存者空间（Fron Survivor、To Survivor） 默认新生代空间的分配：Eden : Fron : To = 8 : 1 : 1 每个空间的执行顺序如下： 绝大多数刚刚被创建的对象会存放在伊甸园空间（Eden）。 在伊甸园空间执行第一次GC（Minor GC）之后，存活的对象被移动到其中一个幸存者空间（Survivor）。 此后，每次伊甸园空间执行GC后，存活的对象会被堆积在同一个幸存者空间。 当一个幸存者空间饱和，还在存活的对象会被移动到另一个幸存者空间。然后会清空已经饱和的哪个幸存者空间。 在以上步骤中重复N次（N = MaxTenuringThreshold（年龄阀值设定，默认15））依然存活的对象，就会被移动到老年代。 从上面的步骤可以发现，两个幸存者空间，必须有一个是保持空的。如果两个两个幸存者空间都有数据，或两个空间都是空的，那一定是你的系统出现了某种错误。 我们需要重点记住的是，对象在刚刚被创建之后，是保存在伊甸园空间的（Eden）。那些长期存活的对象会经由幸存者空间（Survivor）转存到老年代空间（Old generation）。 也有例外出现，对于一些比较大的对象（需要分配一块比较大的连续内存空间）则直接进入到老年代。一般在Survivor 空间不足的情况下发生。 老年代空间的构成与逻辑老年代空间的构成其实很简单，它不像新生代空间那样划分为几个区域，它只有一个区域，里面存储的对象并不像新生代空间绝大部分都是朝闻道，夕死矣。这里的对象几乎都是从Survivor 空间中熬过来的，它们绝不会轻易的狗带。因此，Full GC（Major GC）发生的次数不会有Minor GC 那么频繁，并且做一次Major GC 的时间比Minor GC 要更长（约10倍）。 JVM GC 算法讲解根搜索算法根搜索算法是从离散数学中的图论引入的，程序把所有引用关系看作一张图，从一个节点GC ROOT 开始，寻找对应的引用节点，找到这个节点后，继续寻找这个节点的引用节点。当所有的引用节点寻找完毕后，剩余的节点则被认为是没有被引用到的节点，即无用的节点。 上图红色为无用的节点，可以被回收。 目前Java中可以作为GC ROOT的对象有： 虚拟机栈中引用的对象（本地变量表） 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈中引用的对象（Native对象） 基本所有GC算法都引用根搜索算法这种概念。 标记 - 清除算法标记-清除算法采用从根集合进行扫描，对存活的对象进行标记，标记完毕后，再扫描整个空间中未被标记的对象进行直接回收，如上图。 标记-清除算法不需要进行对象的移动，并且仅对不存活的对象进行处理，在存活的对象比较多的情况下极为高效，但由于标记-清除算法直接回收不存活的对象，并没有对还存活的对象进行整理，因此会导致内存碎片。 复制算法复制算法将内存划分为两个区间，使用此算法时，所有动态分配的对象都只能分配在其中一个区间（活动区间），而另外一个区间（空间区间）则是空闲的。 复制算法采用从根集合扫描，将存活的对象复制到空闲区间，当扫描完毕活动区间后，会的将活动区间一次性全部回收。此时原本的空闲区间变成了活动区间。下次GC时候又会重复刚才的操作，以此循环。 复制算法在存活对象比较少的时候，极为高效，但是带来的成本是牺牲一半的内存空间用于进行对象的移动。所以复制算法的使用场景，必须是对象的存活率非常低才行，而且最重要的是，我们需要克服50%内存的浪费。 标记 - 整理算法标记-整理算法采用 标记-清除 算法一样的方式进行对象的标记、清除，但在回收不存活的对象占用的空间后，会将所有存活的对象往左端空闲空间移动，并更新对应的指针。标记-整理 算法是在标记-清除 算法之上，又进行了对象的移动排序整理，因此成本更高，但却解决了内存碎片的问题。 JVM为了优化内存的回收，使用了分代回收的方式，对于新生代内存的回收（Minor GC）主要采用复制算法。而对于老年代的回收（Major GC），大多采用标记-整理算法。 垃圾回收器简介需要注意的是，每一个回收器都存在Stop The World 的问题，只不过各个回收器在Stop The World 时间优化程度、算法的不同，可根据自身需求选择适合的回收器。 Serial（-XX:+UseSerialGC）从名字我们可以看出，这是一个串行收集器。 Serial收集器是Java虚拟机中最基本、历史最悠久的收集器。在JDK1.3之前是Java虚拟机新生代收集器的唯一选择。目前也是ClientVM下ServerVM 4核4GB以下机器默认垃圾回收器。Serial收集器并不是只能使用一个CPU进行收集，而是当JVM需要进行垃圾回收的时候，需暂停所有的用户线程，直到回收结束。 使用算法：复制算法 JVM中文名称为Java虚拟机，因此它像一台虚拟的电脑在工作，而其中的每一个线程都被认为是JVM的一个处理器，因此图中的CPU0、CPU1实际上为用户的线程，而不是真正的机器CPU，不要误解哦。 Serial收集器虽然是最老的，但是它对于限定单个CPU的环境来说，由于没有线程交互的开销，专心做垃圾收集，所以它在这种情况下是相对于其他收集器中最高效的。 SerialOld（-XX:+UseSerialGC）SerialOld是Serial收集器的老年代收集器版本，它同样是一个单线程收集器，这个收集器目前主要用于Client模式下使用。如果在Server模式下，它主要还有两大用途：一个是在JDK1.5及之前的版本中与Parallel Scavenge收集器搭配使用，另外一个就是作为CMS收集器的后备预案，如果CMS出现Concurrent Mode Failure，则SerialOld将作为后备收集器。 使用算法：标记 - 整理算法 运行示意图与上图一致。 ParNew（-XX:+UseParNewGC）ParNew其实就是Serial收集器的多线程版本。除了Serial收集器外，只有它能与CMS收集器配合工作。 使用算法：复制算法 ParNew是许多运行在Server模式下的JVM首选的新生代收集器。但是在单CPU的情况下，它的效率远远低于Serial收集器，所以一定要注意使用场景。 ParallelScavenge（-XX:+UseParallelGC）ParallelScavenge又被称为吞吐量优先收集器，和ParNew 收集器类似，是一个新生代收集器。 使用算法：复制算法 ParallelScavenge收集器的目标是达到一个可控件的吞吐量，所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量 = 运行用户代码时间 / （运行用户代码时间 + 垃圾收集时间）。如果虚拟机总共运行了100分钟，其中垃圾收集花了1分钟，那么吞吐量就是99% 。 ParallelOld（-XX:+UseParallelOldGC）ParallelOld是并行收集器，和SerialOld一样，ParallelOld是一个老年代收集器，是老年代吞吐量优先的一个收集器。这个收集器在JDK1.6之后才开始提供的，在此之前，ParallelScavenge只能选择SerialOld来作为其老年代的收集器，这严重拖累了ParallelScavenge整体的速度。而ParallelOld的出现后，“吞吐量优先”收集器才名副其实！ 使用算法：标记 - 整理算法 在注重吞吐量与CPU数量大于1的情况下，都可以优先考虑ParallelScavenge + ParalleloOld收集器。 CMS （-XX:+UseConcMarkSweepGC）CMS是一个老年代收集器，全称 Concurrent Low Pause Collector，是JDK1.4后期开始引用的新GC收集器，在JDK1.5、1.6中得到了进一步的改进。它是对于响应时间的重要性需求大于吞吐量要求的收集器。对于要求服务器响应速度高的情况下，使用CMS非常合适。 CMS的一大特点，就是用两次短暂的暂停来代替串行或并行标记整理算法时候的长暂停。 使用算法：标记 - 清理 CMS的执行过程如下： · 初始标记（STW initial mark） 在这个阶段，需要虚拟机停顿正在执行的应用线程，官方的叫法STW（Stop Tow World）。这个过程从根对象扫描直接关联的对象，并作标记。这个过程会很快的完成。 · 并发标记（Concurrent marking） 这个阶段紧随初始标记阶段，在“初始标记”的基础上继续向下追溯标记。注意这里是并发标记，表示用户线程可以和GC线程一起并发执行，这个阶段不会暂停用户的线程哦。 · 并发预清理（Concurrent precleaning） 这个阶段任然是并发的，JVM查找正在执行“并发标记”阶段时候进入老年代的对象（可能这时会有对象从新生代晋升到老年代，或被分配到老年代）。通过重新扫描，减少在一个阶段“重新标记”的工作，因为下一阶段会STW。 · 重新标记（STW remark） 这个阶段会再次暂停正在执行的应用线程，重新重根对象开始查找并标记并发阶段遗漏的对象（在并发标记阶段结束后对象状态的更新导致），并处理对象关联。这一次耗时会比“初始标记”更长，并且这个阶段可以并行标记。 · 并发清理（Concurrent sweeping） 这个阶段是并发的，应用线程和GC清除线程可以一起并发执行。 · 并发重置（Concurrent reset） 这个阶段任然是并发的，重置CMS收集器的数据结构，等待下一次垃圾回收。 CMS的缺点： 1、内存碎片。由于使用了 标记-清理 算法，导致内存空间中会产生内存碎片。不过CMS收集器做了一些小的优化，就是把未分配的空间汇总成一个列表，当有JVM需要分配内存空间的时候，会搜索这个列表找到符合条件的空间来存储这个对象。但是内存碎片的问题依然存在，如果一个对象需要3块连续的空间来存储，因为内存碎片的原因，寻找不到这样的空间，就会导致Full GC。 2、需要更多的CPU资源。由于使用了并发处理，很多情况下都是GC线程和应用线程并发执行的，这样就需要占用更多的CPU资源，也是牺牲了一定吞吐量的原因。 3、需要更大的堆空间。因为CMS标记阶段应用程序的线程还是执行的，那么就会有堆空间继续分配的问题，为了保障CMS在回收堆空间之前还有空间分配给新加入的对象，必须预留一部分空间。CMS默认在老年代空间使用68%时候启动垃圾回收。可以通过-XX:CMSinitiatingOccupancyFraction=n来设置这个阀值。 GarbageFirst（G1）这是一个新的垃圾回收器，既可以回收新生代也可以回收老年代，SunHotSpot1.6u14以上EarlyAccess版本加入了这个回收器，Sun公司预期SunHotSpot1.7发布正式版本。通过重新划分内存区域，整合优化CMS，同时注重吞吐量和响应时间。杯具的是Oracle收购这个收集器之后将其用于商用收费版收集器。因此目前暂时没有发现哪个公司使用它，这个放在之后再去研究吧。 整理一下新生代和老年代的收集器。 新生代收集器： Serial （-XX:+UseSerialGC） ParNew（-XX:+UseParNewGC） ParallelScavenge（-XX:+UseParallelGC） G1 收集器 老年代收集器： SerialOld（-XX:+UseSerialOldGC） ParallelOld（-XX:+UseParallelOldGC） CMS（-XX:+UseConcMarkSweepGC） G1 收集器 调优jvm参数介绍堆设置 -Xmx3550m：设置JVM最大堆内存 为3550M。 -Xms3550m：设置JVM初始堆内存 为3550M。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。 -Xss128k：设置每个线程的栈 大小。JDK5.0以后每个线程栈大小为1M，之前每个线程栈大小为256K。应当根据应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能 生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 -Xmn2g：设置堆内存年轻代 大小为2G。整个堆内存大小 = 年轻代大小 + 年老代大小 + 持久代大小 。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 -XX:PermSize=256M：设置堆内存持久代 初始值为256M。(貌似是Eclipse等IDE的初始化参数) -XX:MaxNewSize=size：新生成的对象能占用内存的最大值。 -XX:MaxPermSize=512M：设置持久代最大值为512M。 -XX:NewRatio=4：设置堆内存年轻代（包括Eden和两个Survivor区）与堆内存年老代的比值（除去持久代） 。设置为4，则年轻代所占与年老代所占的比值为1:4。 -XX:SurvivorRatio=4：设置堆内存年轻代中Eden区与Survivor区大小的比值 。设置为4，则两个Survivor区（JVM堆内存年轻代中默认有2个Survivor区）与一个Eden区的比值为2:4，一个Survivor区占 整个年轻代的1/6。 -XX:MaxTenuringThreshold=7：表示一个对象如果在救助空间（Survivor区）移动7次还没有被回收就放入年老代。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代，对于年老代比较多的应用，这样做可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象在年轻代存活时间，增加对象在年轻代即被回收的概率。 回收器选择JVM给了三种选择：串行收集器、并行收集器、并发收集器，但是串行收集器只适用于小数据量的情况，所以这里的选择主要针对并行收集器和并发收集器。 默认情况下，JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行智能判断。 串行收集器 -XX:+UseSerialGC：设置串行收集器 并行收集器(吞吐量优先) -XX:+UseParallelGC：选择垃圾收集器为并行收集器。此配置仅对年轻代有效。即上述配置下，年轻代使用并发收集，而年老代仍旧使用串行收集。 -XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。 -XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0支持对年老代并行收集。 -XX:MaxGCPauseMillis=100：设置每次年轻代垃圾回收的最长时间（单位毫秒），如果无法满足此时间，JVM会自动调整年轻代大小，以满足此值。 -XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低响应时间或者收集频率等。 此参数建议使用并行收集器时，一直打开。 并发收集器(响应时间优先) -XX:+UseParNewGC：设置年轻代为并发收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。 CMS全称Concurrent Low Pause Collector，是jdk1.4后期版本开始引入的新gc算法，在jdk5和jdk6中得到了进一步改进，它的主要适合场景是对响应时间的重要性需求 大于对吞吐量的要求，能够承受垃圾回收线程和应用线程共享处理器资源，并且应用中存在比较多的长生命周期的对象的应用。CMS是用于对tenured generation的回收，也就是年老代的回收，目标是尽量减少应用的暂停时间，减少FullGC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代。 -XX:+UseConcMarkSweepGC：设置年老代为并发收集。测试中配置这个以后，-XX:NewRatio=4的配置失效了。所以，此时年轻代大小最好用-Xmn设置。 -XX:CMSFullGCsBeforeCompaction=：由于并发收集器不对内存空间进行压缩、整理，所以运行一段时间以后会产生“碎片”，使得运行效率降低。此参数设置运行次FullGC以后对内存空间进行压缩、整理。 -XX:+UseCMSCompactAtFullCollection：打开对年老代的压缩。可能会影响性能，但是可以消除内存碎片。 -XX:+CMSIncrementalMode：设置为增量收集模式。一般适用于单CPU情况。 -XX:CMSInitiatingOccupancyFraction=70：表示年老代空间到70%时就开始执行CMS，确保年老代有足够的空间接纳来自年轻代的对象。 注：如果使用 throughput collector 和 concurrent low pause collector 这两种垃圾收集器，需要适当的挺高内存大小，为多线程做准备。 其它 -XX:+ScavengeBeforeFullGC：新生代GC优先于Full GC执行。 -XX:-DisableExplicitGC：禁止调用System.gc()，但JVM的gc仍然有效。 -XX:+MaxFDLimit：最大化文件描述符的数量限制。 -XX:+UseThreadPriorities：启用本地线程优先级API，即使 java.lang.Thread.setPriority() 生效，反之无效。 -XX:SoftRefLRUPolicyMSPerMB=0：“软引用”的对象在最后一次被访问后能存活0毫秒（默认为1秒）。 -XX:TargetSurvivorRatio=90：允许90%的Survivor空间被占用（默认为50%）。提高对于Survivor的使用率——超过就会尝试垃圾回收。 辅助信息 -XX:-CITime：打印消耗在JIT编译的时间 -XX:ErrorFile=./hs_err_pid.log：保存错误日志或者数据到指定文件中 -XX:-ExtendedDTraceProbes：开启solaris特有的dtrace探针 -XX:HeapDumpPath=./java_pid.hprof：指定导出堆信息时的路径或文件名 -XX:-HeapDumpOnOutOfMemoryError：当首次遭遇内存溢出时导出此时堆中相关信息 -XX:OnError=”;”：出现致命ERROR之后运行自定义命令 -XX:OnOutOfMemoryError=”;”：当首次遭遇内存溢出时执行自定义命令 -XX:-PrintClassHistogram：遇到Ctrl-Break后打印类实例的柱状信息，与jmap -histo功能相同 -XX:-PrintConcurrentLocks：遇到Ctrl-Break后打印并发锁的相关信息，与jstack -l功能相同 -XX:-PrintCommandLineFlags：打印在命令行中出现过的标记 -XX:-PrintCompilation：当一个方法被编译时打印相关信息 -XX:-PrintGC：每次GC时打印相关信息 -XX:-PrintGC Details：每次GC时打印详细信息 -XX:-PrintGCTimeStamps：打印每次GC的时间戳 -XX:-TraceClassLoading：跟踪类的加载信息 -XX:-TraceClassLoadingPreorder：跟踪被引用到的所有类的加载信息 -XX:-TraceClassResolution：跟踪常量池 -XX:-TraceClassUnloading：跟踪类的卸载信息 -XX:-TraceLoaderConstraints：跟踪类加载器约束的相关信息 JVM服务调优实战服务器：8 cup, 8G mem e.g. java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0 调优方案：-Xmx5g：设置JVM最大可用内存为5G。 -Xms5g：设置JVM初始内存为5G。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。 -Xmn2g：设置年轻代大小为2G。整个堆内存大小 = 年轻代大小 + 年老代大小 + 持久代大小 。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 -XX:+UseParNewGC：设置年轻代为并行收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。 -XX:ParallelGCThreads=8：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。 -XX:SurvivorRatio=6：设置年轻代中Eden区与Survivor区的大小比值。根据经验设置为6，则两个Survivor区与一个Eden区的比值为2:6，一个Survivor区占整个年轻代的1/8。 -XX:MaxTenuringThreshold=30：设置垃圾最大年龄（次数）。如果设置为0的话，则年轻代对象不经过Survivor区直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值 设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概率。设置为30表示 一个对象如果在Survivor空间移动30次还没有被回收就放入年老代。 -XX:+UseConcMarkSweepGC：设置年老代为并发收集。测试配置这个参数以后，参数-XX:NewRatio=4就失效了，所以，此时年轻代大小最好用-Xmn设置，因此这个参数不建议使用。 参考资料 - JVM堆内存的分代虚拟机的堆内存共划分为三个代：年轻代（Young Generation）、年老代（Old Generation）和持久代（Permanent Generation）。其中持久代主要存放的是Java类的类信息，与垃圾收集器要收集的Java对象关系不大。所以，年轻代和年老代的划分才是对垃圾 收集影响比较大的。 年轻代所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。年轻代分三个区。一个Eden区，两个 Survivor区(一般而言)。 大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区（两个中的一个），当一个Survivor区满 时，此区的存活对象将被复制到另外一个Survivor区，当另一个Survivor区也满了的时候，从前一个Survivor区复制过来的并且此时还存 活的对象，将被复制“年老区(Tenured)”。 需要注意，两个Survivor区是对称的，没先后关系，所以同一个Survivor区中可能同时存在从Eden区复制过来对象，和从另一个 Survivor区复制过来的对象；而复制到年老区的只有从前一个Survivor区（相对的）过来的对象。而且，Survivor区总有一个是空的。特 殊的情况下，根据程序需要，Survivor区是可以配置为多个的（多于两个），这样可以增加对象在年轻代中的存在时间，减少被放到年老代的可能。 年老代在年轻代中经历了N（可配置）次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 持久代用于存放静态数据，如 Java Class, Method 等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些Class，例如 Hibernate 等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中动态增加的类型。持久代大小通过 -XX:MaxPermSize= 进行设置。1.8已经移除改为metaspace。","categories":[{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://vincentruan.github.io/tags/JVM/"}]},{"title":"zookeeper入门摘要","slug":"zookeeper入门摘要","date":"2020-02-14T10:01:16.000Z","updated":"2020-02-21T03:42:47.283Z","comments":true,"path":"2020/02/14/zookeeper入门摘要/","link":"","permalink":"https://vincentruan.github.io/2020/02/14/zookeeper入门摘要/","excerpt":"","text":"1.ZooKeeper是什么？ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了监听器，这个监听器也是由所连接的zookeeper机器来处理。对于写请求，这些请求会同时发给其他zookeeper机器并且达成一致后，请求才会返回成功。因此，随着zookeeper的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。 有序性是zookeeper中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为zxid（Zookeeper Transaction Id）。而读请求只会相对于更新有序，也就是读请求的返回结果中会带有这个zookeeper最新的zxid。 2.ZooKeeper提供了什么？1、文件系统 2、通知机制 3.Zookeeper文件系统Zookeeper提供一个多层级的节点命名空间（节点称为znode）。与文件系统不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可以存放数据而目录节点不行。Zookeeper为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，这种特性使得Zookeeper不能用于存放大量的数据，每个节点的存放数据上限为1M。 4.四种类型的znode1、PERSISTENT-持久化目录节点客户端与zookeeper断开连接后，该节点依旧存在 2、PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 3、EPHEMERAL-临时目录节点客户端与zookeeper断开连接后，该节点被删除 4、EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号 5.Zookeeper通知机制client端会对某个znode建立一个watcher事件，当该znode发生变化时，这些client会收到zk的通知，然后client可以根据znode变化来做出业务上的改变等。 6.Zookeeper做了什么？1、命名服务 2、配置管理 3、集群管理 4、分布式锁 5、队列管理 7.zk的命名服务（文件系统）命名服务是指通过指定的名字来获取资源或者服务的地址，利用zk创建一个全局的路径，即是唯一的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。 8.zk的配置管理（文件系统、通知机制）程序分布式的部署在不同的机器上，将程序的配置信息放在zk的znode下，当有配置发生改变时，也就是znode发生变化时，可以通过改变zk中某个目录节点的内容，利用watcher通知给各个客户端，从而更改配置。 9.Zookeeper集群管理（文件系统、通知机制）所谓集群管理无在乎两点：是否有机器退出和加入、选举master。 对于第一点，所有机器约定在父目录下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。 新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount又有了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。 10.Zookeeper分布式锁（文件系统、通知机制）有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。 对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的distribute_lock 节点就释放出锁。 对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。 11.获取分布式锁的流程 在获取分布式锁的时候在locker节点下创建临时顺序节点，释放锁的时候删除该临时节点。客户端调用createNode方法在locker下创建临时顺序节点，然后调用getChildren(“locker”)来获取locker下面的所有子节点，注意此时不用设置任何Watcher。客户端获取到所有的子节点path之后，如果发现自己创建的节点在所有创建的子节点序号最小，那么就认为该客户端获取到了锁。如果发现自己创建的节点并非locker所有子节点中最小的，说明自己还没有获取到锁，此时客户端需要找到比自己小的那个节点，然后对其调用exist()方法，同时对其注册事件监听器。之后，让这个被关注的节点删除，则客户端的Watcher会收到相应通知，此时再次判断自己创建的节点是否是locker子节点中序号最小的，如果是则获取到了锁，如果不是则重复以上步骤继续获取到比自己小的一个节点并注册监听。当前这个过程中还需要许多的逻辑判断。 代码的实现主要是基于互斥锁，获取分布式锁的重点逻辑在于BaseDistributedLock，实现了基于Zookeeper实现分布式锁的细节。 12.Zookeeper队列管理（文件系统、通知机制）两种类型的队列： 1、同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。 2、队列按照 FIFO 方式进行入队和出队操作。 第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。在特定的目录下创建PERSISTENT_SEQUENTIAL节点，创建成功时Watcher通知等待的队列，队列删除序列号最小的节点用以消费。此场景下Zookeeper的znode用于消息存储，znode存储的数据就是消息队列中的消息内容，SEQUENTIAL序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，所以不必担心队列消息的丢失问题。 13.Zookeeper数据复制Zookeeper作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处： 1、容错：一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作； 2、提高系统的扩展能力 ：把负载分布到多个节点上，或者增加节点来提高系统的负载能力； 3、提高性能：让客户端本地访问就近的节点，提高用户访问速度。 从客户端读写访问的透明度来看，数据复制集群系统分下面两种： 1、写主(WriteMaster) ：对数据的修改提交给指定的节点。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离； 2、写任意(Write Any)：对数据的修改可提交给任意的节点，跟读一样。这种情况下，客户端对集群节点的角色与变化透明。 对zookeeper来说，它采用的方式是写任意。通过增加机器，它的读吞吐能力和响应能力扩展性非常好，而写，随着机器的增多吞吐能力肯定下降（这也是它建立observer的原因），而响应能力则取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。 14.Zookeeper工作原理Zookeeper 的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。 15.zookeeper是如何保证事务的顺序一致性的？zookeeper采用了递增的事务Id来标识，所有的proposal（提议）都在被提出的时候加上了zxid，zxid实际上是一个64位的数字，高32位是epoch（时期; 纪元; 世; 新时代）用来标识leader是否发生改变，如果有新的leader产生出来，epoch会自增，低32位用来递增计数。当新产生proposal的时候，会依据数据库的两阶段过程，首先会向其他的server发出事务执行请求，如果超过半数的机器都能执行并且能够成功，那么就会开始执行。 16.Zookeeper 下 Server工作状态每个Server在工作过程中有三种状态： LOOKING：当前Server不知道leader是谁，正在搜寻 LEADING：当前Server即为选举出来的leader FOLLOWING：leader已经选举出来，当前Server与之同步 17.zookeeper是如何选取主leader的？当leader崩溃或者leader失去大多数的follower，这时zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的Server都恢复到一个正确的状态。Zk的选举算法有两种：一种是基于basic paxos实现的，另外一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。 1、Zookeeper选主流程(basic paxos) （1）选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的Server； （2）选举线程首先向所有Server发起一次询问(包括自己)； （3）选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(id,zxid)，并将这些信息存储到当次选举的投票记录表中； （4）收到所有Server回复以后，就计算出zxid最大的那个Server，并将这个Server相关信息设置成下一次要投票的Server； （5）线程将当前zxid最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n/2 + 1的Server票数，设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态，否则，继续这个过程，直到leader被选举出来。通过流程分析我们可以得出：要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1，且存活的Server的数目不得少于n+1. 每个Server启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的server还会从磁盘快照中恢复数据和会话信息，zk会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。 2、Zookeeper选主流程(basic paxos) fast paxos流程是在选举过程中，某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和 zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。 18.Zookeeper同步流程选完Leader以后，zk就进入状态同步过程。 1、Leader等待server连接； 2、Follower连接leader，将最大的zxid发送给leader； 3、Leader根据follower的zxid确定同步点； 4、完成同步后通知follower 已经成为uptodate状态； 5、Follower收到uptodate消息后，又可以重新接受client的请求进行服务了。 sequenceDiagram participant L as Leader participant F as Follower F->>L: 1.Fllower连接Leader，发送最大zxid L->>F: 2.Leader确定同步点，发送同步消息 F->>L: 3.完成同步，通知Leader，并修改自身状态 19.分布式通知和协调对于系统调度来说：操作人员发送通知实际是通过控制台改变某个节点的状态，然后zk将这些变化发送给注册了这个节点的watcher的所有客户端。 对于执行情况汇报：每个工作进程都在某个目录下创建一个临时节点。并携带工作的进度数据，这样汇总的进程可以监控目录子节点的变化获得工作进度的实时的全局情况。 20.机器中为什么会有leader？在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果，这样可以大大减少重复计算，提高性能，于是就需要进行leader选举。 21.zk节点宕机如何处理？Zookeeper本身也是集群，推荐配置不少于3个服务器。Zookeeper自身也要保证当一个节点宕机时，其他节点会继续提供服务。 如果是一个Follower宕机，还有2台服务器提供访问，因为Zookeeper上的数据是有多个副本的，数据并不会丢失； 如果是一个Leader宕机，Zookeeper会选举出新的Leader。 ZK集群的机制是只要超过半数的节点正常，集群就能正常提供服务。只有在ZK节点挂得太多，只剩一半或不到一半节点能工作，集群才失效。 所以 3个节点的cluster可以挂掉1个节点(leader可以得到2票&gt;1.5) 2个节点的cluster就不能挂掉任何1个节点了(leader可以得到1票&lt;=1) 22.zookeeper负载均衡和nginx负载均衡区别zk的负载均衡是可以调控，nginx只是能调权重，其他需要可控的都需要自己写插件；但是nginx的吞吐量比zk大很多，应该说按业务选择用哪种方式。 23.zookeeper watch机制Watch机制官方声明：一个Watch事件是一个一次性的触发器，当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端，以便通知它们。 Zookeeper机制的特点： 1、一次性触发数据发生改变时，一个watcher event会被发送到client，但是client只会收到一次这样的信息。 2、watcher event异步发送watcher的通知事件从server发送到client是异步的，这就存在一个问题，不同的客户端和服务器之间通过socket进行通信，由于网络延迟或其他因素导致客户端在不通的时刻监听到事件，由于Zookeeper本身提供了ordering guarantee，即客户端监听事件后，才会感知它所监视znode发生了变化。所以我们使用Zookeeper不能期望能够监控到节点每次的变化。Zookeeper只能保证最终的一致性，而无法保证强一致性。 3、数据监视Zookeeper有数据监视和子数据监视getdata() and exists()设置数据监视，getchildren()设置了子节点监视。 4、注册watcher getData、exists、getChildren 5、触发watcher create、delete、setData 6、setData()会触发znode上设置的data watch（如果set成功的话）。一个成功的create() 操作会触发被创建的znode上的数据watch，以及其父节点上的child watch。而一个成功的delete()操作将会同时触发一个znode的data watch和child watch（因为这样就没有子节点了），同时也会触发其父节点的child watch。 7、当一个客户端连接到一个新的服务器上时，watch将会被以任意会话事件触发。当与一个服务器失去连接的时候，是无法接收到watch的。而当client重新连接时，如果需要的话，所有先前注册过的watch，都会被重新注册。通常这是完全透明的。只有在一个特殊情况下，watch可能会丢失：对于一个未创建的znode的exist watch，如果在客户端断开连接期间被创建了，并且随后在客户端连接上之前又删除了，这种情况下，这个watch事件可能会被丢失。 8、Watch是轻量级的，其实就是本地JVM的Callback，服务器端只是存了是否有设置了Watcher的布尔类型","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/categories/架构设计/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://vincentruan.github.io/tags/zookeeper/"},{"name":"分布式","slug":"分布式","permalink":"https://vincentruan.github.io/tags/分布式/"}]},{"title":"MyBatis中的九种设计模式","slug":"MyBatis中的九种设计模式","date":"2020-02-12T08:54:07.000Z","updated":"2020-02-17T02:40:44.693Z","comments":true,"path":"2020/02/12/MyBatis中的九种设计模式/","link":"","permalink":"https://vincentruan.github.io/2020/02/12/MyBatis中的九种设计模式/","excerpt":"","text":"虽然我们都知道有26个设计模式，但是大多停留在概念层面，真实开发中很少遇到，Mybatis源码中使用了大量的设计模式，阅读源码并观察设计模式在其中的应用，能够更深入的理解设计模式。 Mybatis至少遇到了以下的设计模式的使用： Builder模式，例如SqlSessionFactoryBuilder、XMLConfigBuilder、XMLMapperBuilder、XMLStatementBuilder、CacheBuilder； 工厂模式，例如SqlSessionFactory、ObjectFactory、MapperProxyFactory； 单例模式，例如ErrorContext和LogFactory； 代理模式，Mybatis实现的核心，比如MapperProxy、ConnectionLogger，用的jdk的动态代理；还有executor.loader包使用了cglib或者javassist达到延迟加载的效果； 组合模式，例如SqlNode和各个子类ChooseSqlNode等； 模板方法模式，例如BaseExecutor和SimpleExecutor，还有BaseTypeHandler和所有的子类例如IntegerTypeHandler； 适配器模式，例如Log的Mybatis接口和它对jdbc、log4j等各种日志框架的适配实现； 装饰者模式，例如Cache包中的cache.decorators子包中等各个装饰者的实现； 迭代器模式，例如迭代器模式PropertyTokenizer； 1、Builder模式Builder模式的定义是“将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。”，它属于创建类模式，一般来说，如果一个对象的构建比较复杂，超出了构造函数所能包含的范围，就可以使用工厂模式和Builder模式，相对于工厂模式会产出一个完整的产品，Builder应用于更加复杂的对象的构建，甚至只会构建产品的一个部分。 在Mybatis环境的初始化过程中，SqlSessionFactoryBuilder会调用XMLConfigBuilder读取所有的MybatisMapConfig.xml和所有的*Mapper.xml文件，构建Mybatis运行的核心对象Configuration对象，然后将该Configuration对象作为参数构建一个SqlSessionFactory对象。 其中XMLConfigBuilder在构建Configuration对象时，也会调用XMLMapperBuilder用于读取*Mapper文件，而XMLMapperBuilder会使用XMLStatementBuilder来读取和build所有的SQL语句。 在这个过程中，有一个相似的特点，就是这些Builder会读取文件或者配置，然后做大量的XpathParser解析、配置或语法的解析、反射生成对象、存入结果缓存等步骤，这么多的工作都不是一个构造函数所能包括的，因此大量采用了Builder模式来解决。 对于builder的具体类，方法都大都用build*开头，比如SqlSessionFactoryBuilder为例，它包含以下方法： 即根据不同的输入参数来构建SqlSessionFactory这个工厂对象。 2、工厂模式在Mybatis中比如SqlSessionFactory使用的是工厂模式，该工厂没有那么复杂的逻辑，是一个简单工厂模式。 简单工厂模式(Simple Factory Pattern)：又称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。 SqlSession可以认为是一个Mybatis工作的核心的接口，通过这个接口可以执行执行SQL语句、获取Mappers、管理事务。类似于连接MySQL的Connection对象。 可以看到，该Factory的openSession方法重载了很多个，分别支持autoCommit、Executor、Transaction等参数的输入，来构建核心的SqlSession对象。 在DefaultSqlSessionFactory的默认工厂实现里，有一个方法可以看出工厂怎么产出一个产品： 123456789101112131415private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; 这是一个openSession调用的底层方法，该方法先从configuration读取对应的环境配置，然后初始化TransactionFactory获得一个Transaction对象，然后通过Transaction获取一个Executor对象，最后通过configuration、Executor、是否autoCommit三个参数构建了SqlSession。 在这里其实也可以看到端倪，SqlSession的执行，其实是委托给对应的Executor来进行的。 而对于LogFactory，它的实现代码： 123456789101112131415161718192021public final class LogFactory &#123; private static Constructor&lt;? extends Log&gt; logConstructor; private LogFactory() &#123; // disable construction &#125; public static Log getLog(Class&lt;?&gt; aClass) &#123; return getLog(aClass.getName()); &#125; public static Log getLog(String logger) &#123; try &#123; return logConstructor.newInstance(logger); &#125; catch (Throwable t) &#123; throw new LogException(\"Error creating logger for logger \" + logger + \". Cause: \" + t, t); &#125; &#125;&#125; 这里有个特别的地方，是Log变量的的类型是Constructor，也就是说该工厂生产的不只是一个产品，而是具有Log公共接口的一系列产品，比如Log4jImpl、Slf4jImpl等很多具体的Log。 3、单例模式单例模式(Singleton Pattern)：单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。 单例模式的要点有三个：一是某个类只能有一个实例；二是它必须自行创建这个实例；三是它必须自行向整个系统提供这个实例。单例模式是一种对象创建型模式。单例模式又名单件模式或单态模式。 在Mybatis中有两个地方用到单例模式，ErrorContext和LogFactory，其中ErrorContext是用在每个线程范围内的单例，用于记录该线程的执行环境错误信息，而LogFactory则是提供给整个Mybatis使用的日志工厂，用于获得针对项目配置好的日志对象。 ErrorContext的单例实现代码： 1234567891011121314151617public class ErrorContext &#123; private static final ThreadLocal&lt;ErrorContext&gt; LOCAL = new ThreadLocal&lt;ErrorContext&gt;(); private ErrorContext() &#123; &#125; public static ErrorContext instance() &#123; ErrorContext context = LOCAL.get(); if (context == null) &#123; context = new ErrorContext(); LOCAL.set(context); &#125; return context; &#125;&#125; 构造函数是private修饰，具有一个static的局部instance变量和一个获取instance变量的方法，在获取实例的方法中，先判断是否为空如果是的话就先创建，然后返回构造好的对象。 只是这里有个有趣的地方是，LOCAL的静态实例变量使用了ThreadLocal修饰，也就是说它属于每个线程各自的数据，而在instance()方法中，先获取本线程的该实例，如果没有就创建该线程独有的ErrorContext。 4、代理模式代理模式可以认为是Mybatis的核心使用的模式，正是由于这个模式，我们只需要编写Mapper.java接口，不需要实现，由Mybatis后台帮我们完成具体SQL的执行。 代理模式(Proxy Pattern) ：给某一个对象提供一个代 理，并由代理对象控制对原对象的引用。代理模式的英 文叫做Proxy或Surrogate，它是一种对象结构型模式。 代理模式包含如下角色： Subject: 抽象主题角色 Proxy: 代理主题角色 RealSubject: 真实主题角色 这里有两个步骤，第一个是提前创建一个Proxy，第二个是使用的时候会自动请求Proxy，然后由Proxy来执行具体事务； 当我们使用Configuration的getMapper方法时，会调用mapperRegistry.getMapper方法，而该方法又会调用mapperProxyFactory.newInstance(sqlSession)来生成一个具体的代理： 12345678910111213141516171819202122232425262728public class MapperProxyFactory&lt;T&gt; &#123; private final Class&lt;T&gt; mapperInterface; private final Map&lt;Method, MapperMethod&gt; methodCache = new ConcurrentHashMap&lt;Method, MapperMethod&gt;(); public MapperProxyFactory(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; public Class&lt;T&gt; getMapperInterface() &#123; return mapperInterface; &#125; public Map&lt;Method, MapperMethod&gt; getMethodCache() &#123; return methodCache; &#125; @SuppressWarnings(\"unchecked\") protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy); &#125; public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &#125;&#125; 在这里，先通过T newInstance(SqlSession sqlSession)方法会得到一个MapperProxy对象，然后调用T newInstance(MapperProxy mapperProxy)生成代理对象然后返回。 而查看MapperProxy的代码，可以看到如下内容： 123456789101112131415161718public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else if (isDefaultMethod(method)) &#123; return invokeDefaultMethod(proxy, method, args); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); &#125;&#125; 非常典型的，该MapperProxy类实现了InvocationHandler接口，并且实现了该接口的invoke方法。 通过这种方式，我们只需要编写Mapper.java接口类，当真正执行一个Mapper接口的时候，就会转发给MapperProxy.invoke方法，而该方法则会调用后续的sqlSession.cud&gt;executor.execute&gt;prepareStatement等一系列方法，完成SQL的执行和返回。 5、组合模式组合模式组合多个对象形成树形结构以表示“整体-部分”的结构层次。 组合模式对单个对象(叶子对象)和组合对象(组合对象)具有一致性，它将对象组织到树结构中，可以用来描述整体与部分的关系。同时它也模糊了简单元素(叶子对象)和复杂元素(容器对象)的概念，使得客户能够像处理简单元素一样来处理复杂元素，从而使客户程序能够与复杂元素的内部结构解耦。 在使用组合模式中需要注意一点也是组合模式最关键的地方：叶子对象和组合对象实现相同的接口。这就是组合模式能够将叶子节点和对象节点进行一致处理的原因。 Mybatis支持动态SQL的强大功能，比如下面的这个SQL： 123456789101112131415&lt;update id=\"update\" parameterType=\"org.format.dynamicproxy.mybatis.bean.User\"&gt; UPDATE users &lt;trim prefix=\"SET\" prefixOverrides=\",\"&gt; &lt;if test=\"name != null and name != ''\"&gt; name = #&#123;name&#125; &lt;/if&gt; &lt;if test=\"age != null and age != ''\"&gt; , age = #&#123;age&#125; &lt;/if&gt; &lt;if test=\"birthday != null and birthday != ''\"&gt; , birthday = #&#123;birthday&#125; &lt;/if&gt; &lt;/trim&gt; where id = $&#123;id&#125;&lt;/update&gt; 在这里面使用到了trim、if等动态元素，可以根据条件来生成不同情况下的SQL； 在DynamicSqlSource.getBoundSql方法里，调用了rootSqlNode.apply(context)方法，apply方法是所有的动态节点都实现的接口： 123public interface SqlNode&#123; booleanapply(DynamicContext context);&#125; 对于实现该SqlSource接口的所有节点，就是整个组合模式树的各个节点： 组合模式的简单之处在于，所有的子节点都是同一类节点，可以递归的向下执行，比如对于TextSqlNode，因为它是最底层的叶子节点，所以直接将对应的内容append到SQL语句中： 123456@Overridepublic boolean apply(DynamicContext context) &#123; GenericTokenParser parser = createParser(new BindingTokenParser(context, injectionFilter)); context.appendSql(parser.parse(text)); return true;&#125; 但是对于IfSqlNode，就需要先做判断，如果判断通过，仍然会调用子元素的SqlNode，即contents.apply方法，实现递归的解析。 12345678@Overridepublic boolean apply(DynamicContext context) &#123; if (evaluator.evaluateBoolean(test, context.getBindings())) &#123; contents.apply(context); return true; &#125; return false;&#125; 6、模板方法模式模板方法模式是所有模式中最为常见的几个模式之一，是基于继承的代码复用的基本技术。 模板方法模式需要开发抽象类和具体子类的设计师之间的协作。一个设计师负责给出一个算法的轮廓和骨架，另一些设计师则负责给出这个算法的各个逻辑步骤。代表这些具体逻辑步骤的方法称做基本方法(primitive method)；而将这些基本方法汇总起来的方法叫做模板方法(template method)，这个设计模式的名字就是从此而来。 模板类定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 在Mybatis中，sqlSession的SQL执行，都是委托给Executor实现的，Executor包含以下结构： 其中的BaseExecutor就采用了模板方法模式，它实现了大部分的SQL执行逻辑，然后把以下几个方法交给子类定制化完成： 12345protected abstract int doUpdate(MappedStatement ms, Object parameter) throws SQLException; protected abstract List&lt;BatchResult&gt; doFlushStatements(boolean isRollback) throws SQLException; protected abstract &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException; 该模板方法类有几个子类的具体实现，使用了不同的策略： 简单SimpleExecutor：每执行一次update或select，就开启一个Statement对象，用完立刻关闭Statement对象。（可以是Statement或PrepareStatement对象） 重用ReuseExecutor：执行update或select，以sql作为key查找Statement对象，存在就使用，不存在就创建，用完后，不关闭Statement对象，而是放置于Map内，供下一次使用。（可以是Statement或PrepareStatement对象） 批量BatchExecutor：执行update（没有select，JDBC批处理不支持select），将所有sql都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个Statement对象，每个Statement对象都是addBatch()完毕后，等待逐一执行executeBatch()批处理的；BatchExecutor相当于维护了多个桶，每个桶里都装了很多属于自己的SQL，就像苹果蓝里装了很多苹果，番茄蓝里装了很多番茄，最后，再统一倒进仓库。（可以是Statement或PrepareStatement对象） 比如在SimpleExecutor中这样实现update方法： 12345678910111213@Overridepublic int doUpdate(MappedStatement ms, Object parameter) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(this, ms, parameter, RowBounds.DEFAULT, null, null); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.update(stmt); &#125; finally &#123; closeStatement(stmt); &#125;&#125; 7、适配器模式适配器模式(Adapter Pattern) ：将一个接口转换成客户希望的另一个接口，适配器模式使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。 在Mybatsi的logging包中，有一个Log接口： 1234567891011121314151617public interface Log &#123; boolean isDebugEnabled(); boolean isTraceEnabled(); void error(String s, Throwable e); void error(String s); void debug(String s); void trace(String s); void warn(String s);&#125; 该接口定义了Mybatis直接使用的日志方法，而Log接口具体由谁来实现呢？Mybatis提供了多种日志框架的实现，这些实现都匹配这个Log接口所定义的接口方法，最终实现了所有外部日志框架到Mybatis日志包的适配： 比如对于Log4jImpl的实现来说，该实现持有了org.apache.log4j.Logger的实例，然后所有的日志方法，均委托该实例来实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Log4jImpl implements Log &#123; private static final String FQCN = Log4jImpl.class.getName(); private final Logger log; public Log4jImpl(String clazz) &#123; log = Logger.getLogger(clazz); &#125; @Override public boolean isDebugEnabled() &#123; return log.isDebugEnabled(); &#125; @Override public boolean isTraceEnabled() &#123; return log.isTraceEnabled(); &#125; @Override public void error(String s, Throwable e) &#123; log.log(FQCN, Level.ERROR, s, e); &#125; @Override public void error(String s) &#123; log.log(FQCN, Level.ERROR, s, null); &#125; @Override public void debug(String s) &#123; log.log(FQCN, Level.DEBUG, s, null); &#125; @Override public void trace(String s) &#123; log.log(FQCN, Level.TRACE, s, null); &#125; @Override public void warn(String s) &#123; log.log(FQCN, Level.WARN, s, null); &#125;&#125; 8、装饰者模式装饰模式(Decorator Pattern) ：动态地给一个对象增加一些额外的职责(Responsibility)，就增加对象功能来说，装饰模式比生成子类实现更为灵活。其别名也可以称为包装器(Wrapper)，与适配器模式的别名相同，但它们适用于不同的场合。根据翻译的不同，装饰模式也有人称之为“油漆工模式”，它是一种对象结构型模式。 在mybatis中，缓存的功能由根接口Cache（org.apache.ibatis.cache.Cache）定义。整个体系采用装饰器设计模式，数据存储和缓存的基本功能由PerpetualCache（org.apache.ibatis.cache.impl.PerpetualCache）永久缓存实现，然后通过一系列的装饰器来对PerpetualCache永久缓存进行缓存策略等方便的控制。如下图： 用于装饰PerpetualCache的标准装饰器共有8个（全部在org.apache.ibatis.cache.decorators包中）： FifoCache：先进先出算法，缓存回收策略 LoggingCache：输出缓存命中的日志信息 LruCache：最近最少使用算法，缓存回收策略 ScheduledCache：调度缓存，负责定时清空缓存 SerializedCache：缓存序列化和反序列化存储 SoftCache：基于软引用实现的缓存管理策略 SynchronizedCache：同步的缓存装饰器，用于防止多线程并发访问 WeakCache：基于弱引用实现的缓存管理策略 另外，还有一个特殊的装饰器TransactionalCache：事务性的缓存 正如大多数持久层框架一样，mybatis缓存同样分为一级缓存和二级缓存 一级缓存，又叫本地缓存，是PerpetualCache类型的永久缓存，保存在执行器中（BaseExecutor），而执行器又在SqlSession（DefaultSqlSession）中，所以一级缓存的生命周期与SqlSession是相同的。 二级缓存，又叫自定义缓存，实现了Cache接口的类都可以作为二级缓存，所以可配置如encache等的第三方缓存。二级缓存以namespace名称空间为其唯一标识，被保存在Configuration核心配置对象中。 二级缓存对象的默认类型为PerpetualCache，如果配置的缓存是默认类型，则mybatis会根据配置自动追加一系列装饰器。 Cache对象之间的引用顺序为： SynchronizedCache–&gt;LoggingCache–&gt;SerializedCache–&gt;ScheduledCache–&gt;LruCache–&gt;PerpetualCache 9、迭代器模式迭代器（Iterator）模式，又叫做游标（Cursor）模式。GOF给出的定义为：提供一种方法访问一个容器（container）对象中各个元素，而又不需暴露该对象的内部细节。 Java的Iterator就是迭代器模式的接口，只要实现了该接口，就相当于应用了迭代器模式： 比如Mybatis的PropertyTokenizer是property包中的重量级类，该类会被reflection包中其他的类频繁的引用到。这个类实现了Iterator接口，在使用时经常被用到的是Iterator接口中的hasNext这个函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class PropertyTokenizer implements Iterator&lt;PropertyTokenizer&gt; &#123; private String name; private String indexedName; private String index; private String children; publicPropertyTokenizer(String fullname) &#123; int delim = fullname.indexOf('.'); if (delim &gt; -1) &#123; name = fullname.substring(0, delim); children = fullname.substring(delim + 1); &#125; else &#123; name = fullname; children = null; &#125; indexedName = name; delim = name.indexOf('['); if (delim &gt; -1) &#123; index = name.substring(delim + 1, name.length() - 1); name = name.substring(0, delim); &#125; &#125; public String getName() &#123; return name; &#125; public String getIndex() &#123; return index; &#125; public String getIndexedName() &#123; return indexedName; &#125; public String getChildren() &#123; return children; &#125; @Override publicbooleanhasNext() &#123; return children != null; &#125; @Override public PropertyTokenizer next() &#123; return new PropertyTokenizer(children); &#125; @Override publicvoidremove() &#123; throw new UnsupportedOperationException( \"Remove is not supported, as it has no meaning in the context of properties.\"); &#125;&#125; 可以看到，这个类传入一个字符串到构造函数，然后提供了iterator方法对解析后的子串进行遍历，是一个很常用的方法类。 参考资料： 图说设计模式 http://design-patterns.readthedocs.io/zh_CN/latest/index.html 深入浅出Mybatis系列（十）—SQL执行流程分析（源码篇） http://www.cnblogs.com/dongying/p/4142476.html 设计模式读书笔记—–组合模式 http://www.cnblogs.com/chenssy/p/3299719.html Mybatis3.3.x技术内幕（四）：五鼠闹东京之执行器Executor设计原本 http://blog.csdn.net/wagcy/article/details/32963235 mybatis缓存机制详解（一）——Cache https://my.oschina.net/lixin91/blog/620068","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/tags/JAVA/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://vincentruan.github.io/tags/Mybatis/"},{"name":"设计模式","slug":"设计模式","permalink":"https://vincentruan.github.io/tags/设计模式/"}]},{"title":"不可不说的Java锁事","slug":"不可不说的Java锁事","date":"2020-02-12T08:39:06.000Z","updated":"2020-02-17T02:40:44.799Z","comments":true,"path":"2020/02/12/不可不说的Java锁事/","link":"","permalink":"https://vincentruan.github.io/2020/02/12/不可不说的Java锁事/","excerpt":"","text":"转载自美团技术团队，原文地址，在原文基础上有修改. 前言Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。本文旨在对锁相关源码（本文中的源码来自JDK 8和Netty 3.10.6）、使用场景进行举例，为读者介绍主流锁的知识点，以及不同的锁的适用场景。 JAVA主流锁Java中往往是按照是否含有某一特性来定义锁，我们通过特性将锁进行分组归类，再使用对比的方式进行介绍，帮助大家更快捷的理解相关知识。下面给出本文内容的总体分类目录： 1. 乐观锁 VS 悲观锁乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。 先说概念。对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。 而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。 乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。 根据从上面的概念描述我们可以发现： 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。 光说概念有些抽象，我们来看下乐观锁和悲观锁的调用方式示例： 12345678910111213141516// ------------------------- 悲观锁的调用方式 -------------------------// synchronizedpublic synchronized void testMethod() &#123; // 操作同步资源&#125;// ReentrantLockprivate ReentrantLock lock = new ReentrantLock(); // 需要保证多个线程使用的是同一个锁public void modifyPublicResources() &#123; lock.lock(); // 操作同步资源 lock.unlock();&#125;// ------------------------- 乐观锁的调用方式 -------------------------private AtomicInteger atomicInteger = new AtomicInteger(); // 需要保证多个线程使用的是同一个AtomicIntegeratomicInteger.incrementAndGet(); //执行自增1 通过调用方式示例，我们可以发现悲观锁基本都是在显式的锁定之后再操作同步资源，而乐观锁则直接去操作同步资源。那么，为何乐观锁能够做到不锁定同步资源也可以正确的实现线程同步呢？我们通过介绍乐观锁的主要实现方式 “CAS” 的技术原理来为大家解惑。 CAS全称 Compare And Swap（比较与交换），是一种无锁算法。在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。java.util.concurrent包中的原子类就是通过CAS来实现了乐观锁。 CAS算法涉及到三个操作数： 需要读写的内存值 V。 进行比较的值 A。 要写入的新值 B。 当且仅当 V 的值等于 A 时，CAS通过原子方式用新值B来更新V的值（“比较+更新”整体是一个原子操作），否则不会执行任何操作。一般情况下，“更新”是一个不断重试的操作。 之前提到java.util.concurrent包中的原子类，就是通过CAS来实现了乐观锁，那么我们进入原子类AtomicInteger的源码，看一下AtomicInteger的定义： 123456789101112131415public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; 根据定义我们可以看出各属性的作用： unsafe： 获取并操作内存的数据。 valueOffset： 存储value在AtomicInteger中的偏移量。 value： 存储AtomicInteger的int值，该属性需要借助volatile关键字保证其在线程间是可见的。 接下来，我们查看AtomicInteger的自增函数incrementAndGet()的源码时，发现自增函数底层调用的是unsafe.getAndAddInt()。但是由于JDK本身只有Unsafe.class，只通过class文件中的参数名，并不能很好的了解方法的作用，所以我们通过OpenJDK 8 来查看Unsafe的源码： 123456789101112131415161718192021222324// ------------------------- JDK 8 -------------------------// AtomicInteger 自增方法public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125;// Unsafe.classpublic final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125;// ------------------------- OpenJDK 8 -------------------------// Unsafe.javapublic final int getAndAddInt(Object o, long offset, int delta) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!compareAndSwapInt(o, offset, v, v + delta)); return v;&#125; 根据OpenJDK 8的源码我们可以看出，getAndAddInt()循环获取给定对象o中的偏移量处的值v，然后判断内存值是否等于v。如果相等则将内存值设置为 v + delta，否则返回false，继续循环进行重试，直到设置成功才能退出循环，并且将旧值返回。整个“比较+更新”操作封装在compareAndSwapInt()中，在JNI里是借助于一个CPU指令完成的，属于原子操作，可以保证多个线程都能够看到同一个变量的修改值。 后续JDK通过CPU的cmpxchg指令，去比较寄存器中的 A 和 内存中的值 V。如果相等，就把要写入的新值 B 存入内存中。如果不相等，就将内存值 V 赋值给寄存器中的值 A。然后通过Java代码中的while循环再次调用cmpxchg指令进行重试，直到设置成功为止。 CAS虽然很高效，但是它也存在三大问题，这里也简单说一下： ABA问题 。CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。 JDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。 循环时间长开销大。CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。 只能保证一个共享变量的原子操作 。对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。 Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。 2. 自旋锁 VS 适应性自旋锁在介绍自旋锁前，我们需要介绍一些前提知识来帮助大家明白自旋锁的概念。 阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。 在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。 而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。 自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。 自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。 123456789// sun.misc.Unsafe#getAndAddIntpublic final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。 自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。 在自旋锁中 另有三种常见的锁形式:TicketLock、CLHlock和MCSlock，本文中仅做名词介绍，不做深入讲解，感兴趣的同学可以自行查阅相关资料。 3. 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁这四种锁是指锁的状态，专门针对synchronized的。在介绍这四种锁状态之前还需要介绍一些额外的知识。 首先为什么Synchronized能实现线程同步？ 在回答这个问题之前我们需要了解两个重要的概念：“Java对象头”、“Monitor”。 Java对象头synchronized是悲观锁，在操作同步资源之前需要给同步资源先加锁，这把锁就是存在Java对象头里的，而Java对象头又是什么呢？ 我们以Hotspot虚拟机为例，Hotspot的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。 Mark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。 Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 MonitorMonitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。 Monitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。 现在话题回到synchronized，synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。 如同我们在自旋锁中提到的“阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长”。这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。 所以目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。 通过上面的介绍，我们对synchronized的加锁机制以及相关知识有了一个了解，那么下面我们给出四种锁状态对应的的Mark Word内容，然后再分别讲解四种锁状态的思路以及特点： 锁状态 存储内容 存储内容 无锁 对象的hashCode、对象分代年龄、是否是偏向锁（0） 01 偏向锁 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1） 01 轻量级锁 指向栈中锁记录的指针 00 重量级锁 指向互斥量（重量级锁）的指针 10 无锁 无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。 无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 偏向锁 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。 在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。 当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。 偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。 轻量级锁 是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。 如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。 若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。 重量级锁 升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 整体的锁状态升级流程如下： 综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 4. 公平锁 VS 非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。 非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。 直接用语言描述可能有点抽象，这里作者用从别处看到的一个例子来讲述一下公平锁和非公平锁。 如上图所示，假设有一口水井，有管理员看守，管理员有一把锁，只有拿到锁的人才能够打水，打完水要把锁还给管理员。每个过来打水的人都要管理员的允许并拿到锁之后才能去打水，如果前面有人正在打水，那么这个想要打水的人就必须排队。管理员会查看下一个要去打水的人是不是队伍里排最前面的人，如果是的话，才会给你锁让你去打水；如果你不是排第一的人，就必须去队尾排队，这就是公平锁。 但是对于非公平锁，管理员对打水的人没有要求。即使等待队伍里有排队等待的人，但如果在上一个人刚打完水把锁还给管理员而且管理员还没有允许等待队伍里下一个人去打水时，刚好来了一个插队的人，这个插队的人是可以直接从管理员那里拿到锁去打水，不需要排队，原本排队等待的人只能继续等待。如下图所示： 接下来我们通过ReentrantLock的源码来讲解公平锁和非公平锁。 根据代码可知，ReentrantLock里面有一个内部类Sync，Sync继承AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在Sync中实现的。它有公平锁FairSync和非公平锁NonfairSync两个子类。ReentrantLock默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。 下面我们来看一下公平锁与非公平锁的加锁方法的源码: 通过上图中的源代码对比，我们可以明显的看出公平锁与非公平锁的lock()方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件：hasQueuedPredecessors()。 再进入hasQueuedPredecessors()，可以看到该方法主要做一件事情：主要是判断当前线程是否位于同步队列中的第一个。如果是则返回true，否则返回false。 综上，公平锁就是通过同步队列来实现多个线程按照申请锁的顺序来获取锁，从而实现公平的特性。非公平锁加锁时不考虑排队等待问题，直接尝试获取锁，所以存在后申请却先获得锁的情况。 5. 可重入锁 VS 非可重入锁可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。下面用示例代码来进行分析： 12345678910public class Widget &#123; public synchronized void doSomething() &#123; System.out.println(\"方法1执行...\"); doOthers(); &#125; public synchronized void doOthers() &#123; System.out.println(\"方法2执行...\"); &#125;&#125; 在上面的代码中，类中的两个方法都是被内置锁synchronized修饰的，doSomething()方法中调用doOthers()方法。因为内置锁是可重入的，所以同一个线程在调用doOthers()时可以直接获得当前对象的锁，进入doOthers()进行操作。 如果是一个不可重入锁，那么当前线程在调用doOthers()之前需要将执行doSomething()时获取当前对象的锁释放掉，实际上该对象锁已被当前线程所持有，且无法释放。所以此时会出现死锁。 而为什么可重入锁就可以在嵌套调用时可以自动获得锁呢？我们通过图示和源码来分别解析一下。 还是打水的例子，有多个人在排队打水，此时管理员允许锁和同一个人的多个水桶绑定。这个人用多个水桶打水时，第一个水桶和锁绑定并打完水之后，第二个水桶也可以直接和锁绑定并开始打水，所有的水桶都打完水之后打水人才会将锁还给管理员。这个人的所有打水流程都能够成功执行，后续等待的人也能够打到水。这就是可重入锁。 但如果是非可重入锁的话，此时管理员只允许锁和同一个人的一个水桶绑定。第一个水桶和锁绑定打完水之后并不会释放锁，导致第二个水桶不能和锁绑定也无法打水。当前线程出现死锁，整个等待队列中的所有线程都无法被唤醒。 之前我们说过ReentrantLock和synchronized都是重入锁，那么我们通过重入锁ReentrantLock以及非可重入锁NonReentrantLock的源码来对比分析一下为什么非可重入锁在重复调用同步资源时会出现死锁。 首先ReentrantLock和NonReentrantLock都继承父类AQS，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。 当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞。 释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。 6. 独享锁 VS 共享锁独享锁和共享锁同样是一种概念。我们先介绍一下具体的概念，然后通过ReentrantLock和ReentrantReadWriteLock的源码来介绍独享锁和共享锁。 独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。 共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 下图为ReentrantReadWriteLock的部分源码： 我们看到ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。 在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。 那读锁和写锁的具体加锁方式有什么区别呢？在了解源码之前我们需要回顾一下其他知识。 在最开始提及AQS的时候我们也提到了state字段（int类型，32位），该字段用来描述有多少线程获持有锁。 在独享锁中这个值通常是0或者1（如果是重入锁的话state值就是重入的次数），在共享锁中state就是持有锁的数量。但是在ReentrantReadWriteLock中有读、写两把锁，所以需要在一个整型变量state上分别描述读锁和写锁的数量（或者也可以叫状态）。于是将state变量“按位切割”切分成了两个部分，高16位表示读锁状态（读锁个数），低16位表示写锁状态（写锁个数）。如下图所示： 了解了概念之后我们再来看代码，先看写锁的加锁源码： 12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); // 取到当前锁的个数 int w = exclusiveCount(c); // 取写锁的个数w if (c != 0) &#123; // 如果已经有线程持有了锁(c!=0) // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) // 如果写线程数（w）为0（换言之存在读锁） 或者持有锁的线程不是当前线程就返回失败 return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) // 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。 throw new Error(\"Maximum lock count exceeded\"); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) // 如果当且写线程数为0，并且当前线程需要阻塞那么就返回失败；或者如果通过CAS增加写线程数失败也返回失败。 return false; setExclusiveOwnerThread(current); // 如果c=0，w=0或者c&gt;0，w&gt;0（重入），则设置当前线程或锁的拥有者 return true;&#125; 这段代码首先取到当前锁的个数c，然后再通过c来获取写锁的个数w。因为写锁是低16位，所以取低16位的最大值与当前的c做与运算（ int w = exclusiveCount©; ），高16位和0与运算后是0，剩下的就是低位运算的值，同时也是持有写锁的线程数目。 在取到写锁线程的数目后，首先判断是否已经有线程持有了锁。如果已经有线程持有了锁(c!=0)，则查看当前写锁线程的数目，如果写线程数为0（即此时存在读锁）或者持有锁的线程不是当前线程就返回失败（涉及到公平锁和非公平锁的实现）。 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。 如果当且写线程数为0（那么读线程也应该为0，因为上面已经处理c!=0的情况），并且当前线程需要阻塞那么就返回失败；如果通过CAS增加写线程数失败也返回失败。 如果c=0,w=0或者c&gt;0,w&gt;0（重入），则设置当前线程或锁的拥有者，返回成功！ tryAcquire()除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：必须确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。 因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，然后等待的读写线程才能够继续访问读写锁，同时前次写线程的修改对后续的读写线程可见。 接着是读锁的代码： 123456789101112131415161718192021222324252627protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态 int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 可以看到在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是“1&lt;&lt;16”。所以读写锁才能实现读读的过程共享，而读写、写读、写写的过程互斥。 此时，我们再回头看一下互斥锁ReentrantLock中公平锁和非公平锁的加锁源码： 我们发现在ReentrantLock虽然有公平锁和非公平锁两种，但是它们添加的都是独享锁。根据源码所示，当某一个线程调用lock方法获取锁时，如果同步资源没有被其他线程锁住，那么当前线程在使用CAS更新state成功后就会成功抢占该资源。而如果公共资源被占用且不是被当前线程占用，那么就会加锁失败。所以可以确定ReentrantLock无论读操作还是写操作，添加的锁都是都是独享锁。 其他锁细节synchronizedsynchronized 关键字是一把经典的锁，也是我们平时用得最多的。在 JDK1.6 之前， syncronized 是一把重量级的锁，不过随着 JDK 的升级，也在对它进行不断的优化，如今它变得不那么重了，甚至在某些场景下，它的性能反而优于轻量级锁。在加了 syncronized 关键字的方法、代码块中，一次只允许一个线程进入特定代码段，从而避免多线程同时修改同一数据。 synchronized 锁有如下几个特点： 有锁升级过程 在 JDK1.5 (含)之前， synchronized 的底层实现是重量级的，所以之前一致称呼它为”重量级锁”，在 JDK1.5 之后，对 synchronized 进行了各种优化，它变得不那么重了，实现原理就是锁升级的过程。我们先聊聊 1.5 之后的 synchronized 实现原理是怎样的。说到 synchronized 加锁原理，就不得不先说 Java 对象在内存中的布局， Java 对象内存布局如下: 如上图所示，在创建一个对象后，在 JVM 虚拟机( HotSpot )中，对象在 Java 内存中的存储布局 可分为三块: 对象头区域此处存储的信息包括两部分： 1、对象自身的运行时数据( MarkWord ) 存储 hashCode、GC 分代年龄、锁类型标记、偏向锁线程 ID 、 CAS 锁指向线程 LockRecord 的指针等， synconized 锁的机制与这个部分( markwork )密切相关，用 markword 中最低的三位代表锁的状态，其中一位是偏向锁位，另外两位是普通锁位。 2、对象类型指针( Class Pointer ) 对象指向它的类元数据的指针、 JVM 就是通过它来确定是哪个 Class 的实例。 实例数据区域 此处存储的是对象真正有效的信息，比如对象中所有字段的内容 对齐填充区域 JVM 的实现 HostSpot 规定对象的起始地址必须是 8 字节的整数倍，换句话来说，现在 64 位的 OS 往外读取数据的时候一次性读取 64bit 整数倍的数据，也就是 8 个字节，所以 HotSpot 为了高效读取对象，就做了”对齐”，如果一个对象实际占的内存大小不是 8byte 的整数倍时，就”补位”到 8byte 的整数倍。所以对齐填充区域的大小不是固定的。 当线程进入到 synchronized 处尝试获取该锁时， synchronized 锁升级流程如下： 如上图所示， synchronized 锁升级的顺序为：偏向锁-&gt;轻量级锁-&gt;重量级锁，每一步触发锁升级的情况如下： 偏向锁在 JDK1.8 中，其实默认是轻量级锁，但如果设定了 -XX:BiasedLockingStartupDelay = 0 ，那在对一个 Object 做 syncronized 的时候，会立即上一把偏向锁。当处于偏向锁状态时， markwork 会记录当前线程 ID 。 升级到轻量级锁当下一个线程参与到偏向锁竞争时，会先判断 markword 中保存的线程 ID 是否与这个线程 ID 相等，如果不相等，会立即撤销偏向锁，升级为轻量级锁。每个线程在自己的线程栈中生成一个 LockRecord ( LR )，然后每个线程通过 CAS (自旋)的操作将锁对象头中的 markwork 设置为指向自己的 LR 的指针，哪个线程设置成功，就意味着获得锁。关于 synchronized 中此时执行的 CAS 操作是通过 native 的调用 HotSpot 中 bytecodeInterpreter.cpp 文件 C++ 代码实现的，有兴趣的可以继续深挖。 升级到重量级锁如果锁竞争加剧(如线程自旋次数或者自旋的线程数超过某阈值， JDK1.6 之后，由 JVM 自己控制该规则)，就会升级为重量级锁。此时就会向操作系统申请资源，线程挂起，进入到操作系统内核态的等待队列中，等待操作系统调度，然后映射回用户态。在重量级锁中，由于需要做内核态到用户态的转换，而这个过程中需要消耗较多时间，也就是”重”的原因之一。 可重入synchronized 拥有强制原子性的内部锁机制，是一把可重入锁。因此，在一个线程使用 synchronized 方法时调用该对象另一个 synchronized 方法，即一个线程得到一个对象锁后再次请求该对象锁，是永远可以拿到锁的。在 Java 中线程获得对象锁的操作是以线程为单位的，而不是以调用为单位的。 synchronized 锁的对象头的 markwork 中会记录该锁的线程持有者和计数器，当一个线程请求成功后， JVM 会记下持有锁的线程，并将计数器计为1。此时其他线程请求该锁，则必须等待。而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增。当线程退出一个 synchronized 方法/块时，计数器会递减，如果计数器为 0 则释放该锁锁。 悲观锁(互斥锁、排他锁) synchronized 是一把悲观锁(独占锁)，当前线程如果获取到锁，会导致其它所有需要锁该的线程等待，一直等待持有锁的线程释放锁才继续进行锁的争抢。 ReentrantLockReentrantLock 从字面可以看出是一把可重入锁，这点和 synchronized 一样，但实现原理也与 syncronized 有很大差别，它是基于经典的 AQS(AbstractQueueSyncronized) 实现的, AQS 是基于 volitale 和 CAS 实现的，其中 AQS 中维护一个 valitale 类型的变量 state 来做一个可重入锁的重入次数，加锁和释放锁也是围绕这个变量来进行的。 ReentrantLock 也提供了一些 synchronized 没有的特点，因此比 synchronized 好用。 AQS模型如下图： ReentrantLock 有如下特点： 可重入 ReentrantLock 和 syncronized 关键字一样，都是可重入锁，不过两者实现原理稍有差别， RetrantLock 利用 AQS 的的 state 状态来判断资源是否已锁，同一线程重入加锁， state 的状态 +1 ; 同一线程重入解锁, state 状态 -1 (解锁必须为当前独占线程，否则异常); 当 state 为 0 时解锁成功。 需要手动加锁、解锁synchronized 关键字是自动进行加锁、解锁的，而 ReentrantLock 需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成，来手动加锁、解锁。 支持设置锁的超时时间 synchronized 关键字无法设置锁的超时时间，如果一个获得锁的线程内部发生死锁，那么其他线程就会一直进入阻塞状态，而 ReentrantLock 提供 tryLock 方法，允许设置线程获取锁的超时时间，如果超时，则跳过，不进行任何操作，避免死锁的发生。 支持公平/非公平锁synchronized 关键字是一种非公平锁，先抢到锁的线程先执行。而 ReentrantLock 的构造方法中允许设置 true/false 来实现公平、非公平锁，如果设置为 true ，则线程获取锁要遵循”先来后到”的规则，每次都会构造一个线程 Node ，然后到双向链表的”尾巴”后面排队，等待前面的 Node 释放锁资源。 可中断锁 ReentrantLock 中的 lockInterruptibly() 方法使得线程可以在被阻塞时响应中断，比如一个线程 t1 通过 lockInterruptibly() 方法获取到一个可重入锁，并执行一个长时间的任务，另一个线程通过 interrupt() 方法就可以立刻打断 t1 线程的执行，来获取t1持有的那个可重入锁。而通过 ReentrantLock 的 lock() 方法或者 Synchronized 持有锁的线程是不会响应其他线程的 interrupt() 方法的，直到该方法主动释放锁之后才会响应 interrupt() 方法。 ReentrantReadWriteLockReentrantReadWriteLock (读写锁)其实是两把锁，一把是 WriteLock (写锁)，一把是读锁， ReadLock 。读写锁的规则是：读读不互斥、读写互斥、写写互斥。在一些实际的场景中，读操作的频率远远高于写操作，如果直接用一般的锁进行并发控制的话，就会读读互斥、读写互斥、写写互斥，效率低下，读写锁的产生就是为了优化这种场景的操作效率。一般情况下独占锁的效率低来源于高并发下对临界区的激烈竞争导致线程上下文切换。因此当并发不是很高的情况下，读写锁由于需要额外维护读锁的状态，可能还不如独占锁的效率高，因此需要根据实际情况选择使用。 ReentrantReadWriteLock 的原理也是基于 AQS 进行实现的，与 ReentrantLock 的差别在于 ReentrantReadWriteLock 锁拥有共享锁、排他锁属性。读写锁中的加锁、释放锁也是基于 Sync (继承于 AQS )，并且主要使用 AQS 中的 state 和 node 中的 waitState 变量进行实现的。实现读写锁与实现普通互斥锁的主要区别在于需要分别记录读锁状态及写锁状态，并且等待队列中需要区别处理两种加锁操作。 ReentrantReadWriteLock 中将 AQS 中的 int 类型的 state 分为高 16 位与第 16 位分别记录读锁和写锁的状态，如下图所示： WriteLock(写锁)是悲观锁(排他锁、互斥锁) 通过计算 state&amp;((1&lt;&lt;16)-1) ，将 state 的高 16 位全部抹去，因此 state 的低位记录着写锁的重入计数。 获取写锁源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889/** * 获取写锁 Acquires the write lock. * 如果此时没有任何线程持有写锁或者读锁，那么当前线程执行CAS操作更新status， * 若更新成功，则设置读锁重入次数为1，并立即返回 * &lt;p&gt;Acquires the write lock if neither the read nor write lock * are held by another thread * and returns immediately, setting the write lock hold count to * one. * 如果当前线程已经持有该写锁，那么将写锁持有次数设置为1，并立即返回 * &lt;p&gt;If the current thread already holds the write lock then the * hold count is incremented by one and the method returns * immediately. * 如果该锁已经被另外一个线程持有，那么停止该线程的CPU调度并进入休眠状态， * 直到该写锁被释放，且成功将写锁持有次数设置为1才表示获取写锁成功 * &lt;p&gt;If the lock is held by another thread then the current * thread becomes disabled for thread scheduling purposes and * lies dormant until the write lock has been acquired, at which * time the write lock hold count is set to one. */ public void lock() &#123; sync.acquire(1); &#125;/** * 该方法为以独占模式获取锁，忽略中断 * 如果调用一次该“tryAcquire”方法更新status成功，则直接返回，代表抢锁成功 * 否则，将会进入同步队列等待，不断执行“tryAcquire”方法尝试CAS更新status状态，直到成功抢到锁 * 其中“tryAcquire”方法在NonfairSync(公平锁)中和FairSync(非公平锁)中都有各自的实现 * * Acquires in exclusive mode, ignoring interrupts. Implemented * by invoking at least once &#123;@link #tryAcquire&#125;, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking &#123;@link * #tryAcquire&#125; until success. This method can be used * to implement method &#123;@link Lock#lock&#125;. * * @param arg the acquire argument. This value is conveyed to * &#123;@link #tryAcquire&#125; but is otherwise uninterpreted and * can represent anything you like. */ public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; protected final boolean tryAcquire(int acquires) &#123; /* * Walkthrough: * 1、如果读写锁的计数不为0，且持有锁的线程不是当前线程，则返回false * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2、如果持有锁的计数不为0且计数总数超过限定的最大值，也返回false * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3、如果该锁是可重入或该线程在队列中的策略是允许它尝试抢锁，那么该线程就能获取锁 * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); //获取读写锁的状态 int c = getState(); //获取该写锁重入的次数 int w = exclusiveCount(c); //如果读写锁状态不为0，说明已经有其他线程获取了读锁或写锁 if (c != 0) &#123; //如果写锁重入次数为0，说明有线程获取到读锁，根据“读写锁互斥”原则，返回false //或者如果写锁重入次数不为0，且获取写锁的线程不是当前线程，根据\"写锁独占\"原则，返回false // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; //如果写锁可重入次数超过最大次数（65535），则抛异常 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); //到这里说明该线程是重入写锁，更新重入写锁的计数(+1)，返回true // Reentrant acquire setState(c + acquires); return true; &#125; //如果读写锁状态为0,说明读锁和写锁都没有被获取，会走下面两个分支： //如果要阻塞或者执行CAS操作更新读写锁的状态失败，则返回false //如果不需要阻塞且CAS操作成功，则当前线程成功拿到锁，设置锁的owner为当前线程，返回true if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; &#125; 释放写锁源码： 123456789101112131415161718192021/* * Note that tryRelease and tryAcquire can be called by * Conditions. So it is possible that their arguments contain * both read and write holds that are all released during a * condition wait and re-established in tryAcquire. */ protected final boolean tryRelease(int releases) &#123; //若锁的持有者不是当前线程，抛出异常 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //写锁的可重入计数减掉releases个 int nextc = getState() - releases; //如果写锁重入计数为0了，则说明写锁被释放了 boolean free = exclusiveCount(nextc) == 0; if (free) //若写锁被释放，则将锁的持有者设置为null，进行GC setExclusiveOwnerThread(null); //更新写锁的重入计数 setState(nextc); return free; &#125; ReadLock(读锁)是共享锁(乐观锁) 通过计算 state&gt;&gt;&gt;16 进行无符号补 0 ，右移 16 位，因此 state 的高位记录着写锁的重入计数. 读锁获取锁的过程比写锁稍微复杂些，首先判断写锁是否为 0 并且当前线程不占有独占锁，直接返回；否则，判断读线程是否需要被阻塞并且读锁数量是否小于最大值并且比较设置状态成功，若当前没有读锁，则设置第一个读线程 firstReader 和 firstReaderHoldCount ；若当前线程线程为第一个读线程，则增加 firstReaderHoldCount ；否则，将设置当前线程对应的 HoldCounter 对象的值，更新成功后会在 firstReaderHoldCount 中 readHolds ( ThreadLocal 类型的)的本线程副本中记录当前线程重入数，这是为了实现 JDK1.6 中加入的 getReadHoldCount ()方法的，这个方法能获取当前线程重入共享锁的次数( state 中记录的是多个线程的总重入次数)，加入了这个方法让代码复杂了不少，但是其原理还是很简单的：如果当前只有一个线程的话，还不需要动用 ThreadLocal ，直接往 firstReaderHoldCount 这个成员变量里存重入数，当有第二个线程来的时候，就要动用 ThreadLocal 变量 readHolds 了，每个线程拥有自己的副本，用来保存自己的重入数。 获取读锁源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166/** * 获取读锁 * Acquires the read lock. * 如果写锁未被其他线程持有，执行CAS操作更新status值，获取读锁后立即返回 * &lt;p&gt;Acquires the read lock if the write lock is not held by * another thread and returns immediately. * * 如果写锁被其他线程持有，那么停止该线程的CPU调度并进入休眠状态，直到该读锁被释放 * &lt;p&gt;If the write lock is held by another thread then * the current thread becomes disabled for thread scheduling * purposes and lies dormant until the read lock has been acquired. */ public void lock() &#123; sync.acquireShared(1); &#125; /** * 该方法为以共享模式获取读锁，忽略中断 * 如果调用一次该“tryAcquireShared”方法更新status成功，则直接返回，代表抢锁成功 * 否则，将会进入同步队列等待，不断执行“tryAcquireShared”方法尝试CAS更新status状态，直到成功抢到锁 * 其中“tryAcquireShared”方法在NonfairSync(公平锁)中和FairSync(非公平锁)中都有各自的实现 * (看这注释是不是和写锁很对称) * Acquires in shared mode, ignoring interrupts. Implemented by * first invoking at least once &#123;@link #tryAcquireShared&#125;, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking &#123;@link * #tryAcquireShared&#125; until success. * * @param arg the acquire argument. This value is conveyed to * &#123;@link #tryAcquireShared&#125; but is otherwise uninterpreted * and can represent anything you like. */ public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; protected final int tryAcquireShared(int unused) &#123; /* * Walkthrough: * 1、如果已经有其他线程获取到了写锁，根据“读写互斥”原则，抢锁失败，返回-1 * 1.If write lock held by another thread, fail. * 2、如果该线程本身持有写锁，那么看一下是否要readerShouldBlock，如果不需要阻塞， * 则执行CAS操作更新state和重入计数。 * 这里要注意的是，上面的步骤不检查是否可重入(因为读锁属于共享锁，天生支持可重入) * 2. Otherwise, this thread is eligible for * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3、如果因为CAS更新status失败或者重入计数超过最大值导致步骤2执行失败 * 那就进入到fullTryAcquireShared方法进行死循环，直到抢锁成功 * 3. If step 2 fails either because thread * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ //当前尝试获取读锁的线程 Thread current = Thread.currentThread(); //获取该读写锁状态 int c = getState(); //如果有线程获取到了写锁 ，且获取写锁的不是当前线程则返回失败 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; //获取读锁的重入计数 int r = sharedCount(c); //如果读线程不应该被阻塞，且重入计数小于最大值，且CAS执行读锁重入计数+1成功，则执行线程重入的计数加1操作，返回成功 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; //如果还未有线程获取到读锁，则将firstReader设置为当前线程，firstReaderHoldCount设置为1 if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; //如果firstReader是当前线程，则将firstReader的重入计数变量firstReaderHoldCount加1 firstReaderHoldCount++; &#125; else &#123; //否则说明有至少两个线程共享读锁，获取共享锁重入计数器HoldCounter //从HoldCounter中拿到当前线程的线程变量cachedHoldCounter，将此线程的重入计数count加1 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; //如果上面的if条件有一个都不满足，则进入到这个方法里进行死循环重新获取 return fullTryAcquireShared(current); &#125; /** * 用于处理CAS操作state失败和tryAcquireShared中未执行获取可重入锁动作的full方法(补偿方法？) * Full version of acquire for reads, that handles CAS misses * and reentrant reads not dealt with in tryAcquireShared. */ final int fullTryAcquireShared(Thread current) &#123; /* * 此代码与tryAcquireShared中的代码有部分相似的地方， * 但总体上更简单，因为不会使tryAcquireShared与重试和延迟读取保持计数之间的复杂判断 * This code is in part redundant with that in * tryAcquireShared but is simpler overall by not * complicating tryAcquireShared with interactions between * retries and lazily reading hold counts. */ HoldCounter rh = null; //死循环 for (;;) &#123; //获取读写锁状态 int c = getState(); //如果有线程获取到了写锁 if (exclusiveCount(c) != 0) &#123; //如果获取写锁的线程不是当前线程，返回失败 if (getExclusiveOwnerThread() != current) return -1; // else we hold the exclusive lock; blocking here // would cause deadlock. &#125; else if (readerShouldBlock()) &#123;//如果没有线程获取到写锁，且读线程要阻塞 // Make sure we're not acquiring read lock reentrantly //如果当前线程为第一个获取到读锁的线程 if (firstReader == current) &#123; // assert firstReaderHoldCount &gt; 0; &#125; else &#123; //如果当前线程不是第一个获取到读锁的线程(也就是说至少有有一个线程获取到了读锁) // if (rh == null) &#123; rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) &#123; rh = readHolds.get(); if (rh.count == 0) readHolds.remove(); &#125; &#125; if (rh.count == 0) return -1; &#125; &#125; /** *下面是既没有线程获取写锁，当前线程又不需要阻塞的情况 */ //重入次数等于最大重入次数，抛异常 if (sharedCount(c) == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); //如果执行CAS操作成功将读写锁的重入计数加1，则对当前持有这个共享读锁的线程的重入计数加1，然后返回成功 if (compareAndSetState(c, c + SHARED_UNIT)) &#123; if (sharedCount(c) == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; cachedHoldCounter = rh; // cache for release &#125; return 1; &#125; &#125; &#125; 释放读锁源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100/** * Releases in shared mode. Implemented by unblocking one or more * threads if &#123;@link #tryReleaseShared&#125; returns true. * * @param arg the release argument. This value is conveyed to * &#123;@link #tryReleaseShared&#125; but is otherwise uninterpreted * and can represent anything you like. * @return the value returned from &#123;@link #tryReleaseShared&#125; */public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123;//尝试释放一次共享锁计数 doReleaseShared();//真正释放锁 return true; &#125; return false;&#125;/** *此方法表示读锁线程释放锁。 *首先判断当前线程是否为第一个读线程firstReader， *若是，则判断第一个读线程占有的资源数firstReaderHoldCount是否为1， 若是，则设置第一个读线程firstReader为空，否则，将第一个读线程占有的资源数firstReaderHoldCount减1； 若当前线程不是第一个读线程， 那么首先会获取缓存计数器（上一个读锁线程对应的计数器 ）， 若计数器为空或者tid不等于当前线程的tid值，则获取当前线程的计数器， 如果计数器的计数count小于等于1，则移除当前线程对应的计数器， 如果计数器的计数count小于等于0，则抛出异常，之后再减少计数即可。 无论何种情况，都会进入死循环，该循环可以确保成功设置状态state */protected final boolean tryReleaseShared(int unused) &#123; // 获取当前线程 Thread current = Thread.currentThread(); if (firstReader == current) &#123; // 当前线程为第一个读线程 // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) // 读线程占用的资源数为1 firstReader = null; else // 减少占用的资源 firstReaderHoldCount--; &#125; else &#123; // 当前线程不为第一个读线程 // 获取缓存的计数器 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) // 计数器为空或者计数器的tid不为当前正在运行的线程的tid // 获取当前线程对应的计数器 rh = readHolds.get(); // 获取计数 int count = rh.count; if (count &lt;= 1) &#123; // 计数小于等于1 // 移除 readHolds.remove(); if (count &lt;= 0) // 计数小于等于0，抛出异常 throw unmatchedUnlockException(); &#125; // 减少计数 --rh.count; &#125; for (;;) &#123; // 死循环 // 获取状态 int c = getState(); // 获取状态 int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) // 比较并进行设置 // Releasing the read lock has no effect on readers, // but it may allow waiting writers to proceed if // both read and write locks are now free. return nextc == 0; &#125; &#125; /**真正释放锁 * Release action for shared mode -- signals successor and ensures * propagation. (Note: For exclusive mode, release just amounts * to calling unparkSuccessor of head if it needs signal.) */private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125; &#125; 通过分析可以看出： 在线程持有读锁的情况下，该线程不能取得写锁(因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有)。 在线程持有写锁的况下，该线程可以继续获取读锁（获取读锁时如果发现写锁被占用，只有写锁没有被当前线程占用的情况才会获取失败）。 LongAdder在高并发的情况下，我们对一个 Integer 类型的整数直接进行 i++ 的时候，无法保证操作的原子性，会出现线程安全的问题。为此我们会用 juc 下的 AtomicInteger ，它是一个提供原子操作的 Interger 类，内部也是通过 CAS 实现线程安全的。但当大量线程同时去访问时，就会因为大量线程执行 CAS 操作失败而进行空旋转，导致 CPU 资源消耗过多，而且执行效率也不高。 Doug Lea 大神应该也不满意，于是在 JDK1.8 中对 CAS 进行了优化，提供了 LongAdder ，它是基于了 CAS 分段锁的思想实现的。 线程去读写一个 LongAdder 类型的变量时，流程如下： LongAdder 也是基于 Unsafe 提供的 CAS 操作 +valitale 去实现的。在 LongAdder 的父类 Striped64 中维护着一个 base 变量和一个 cell 数组，当多个线程操作一个变量的时候，先会在这个 base 变量上进行 cas 操作，当它发现线程增多的时候，就会使用 cell 数组。比如当 base 将要更新的时候发现线程增多（也就是调用 casBase 方法更新 base 值失败），那么它会自动使用 cell 数组，每一个线程对应于一个 cell ，在每一个线程中对该 cell 进行 cas 操作，这样就可以将单一 value 的更新压力分担到多个 value 中去，降低单个 value 的 “热度”，同时也减少了大量线程的空转，提高并发效率，分散并发压力。这种分段锁需要额外维护一个内存空间 cells ，不过在高并发场景下，这点成本几乎可以忽略。分段锁是一种优秀的优化思想， juc 中提供的的 ConcurrentHashMap 也是基于分段锁保证读写操作的线程安全。 结语本文Java中常用的锁以及常见的锁的概念进行了基本介绍，并从源码以及实际应用的角度进行了对比分析。限于篇幅以及个人水平，没有在本篇文章中对所有内容进行深层次的讲解。 其实Java本身已经对锁本身进行了良好的封装，降低了研发同学在平时工作中的使用难度。但是研发同学也需要熟悉锁的底层原理，不同场景下选择最适合的锁。而且源码中的思路都是非常好的思路，也是值得大家去学习和借鉴的。 参考资料 《Java并发编程艺术》 Java中的锁 Java CAS 原理剖析 Java并发——关键字synchronized解析 Java synchronized原理总结 聊聊并发（二）——Java SE1.6中的Synchronized 深入理解读写锁—ReadWriteLock源码分析 【JUC】JDK1.8源码分析之ReentrantReadWriteLock Java多线程（十）之ReentrantReadWriteLock深入分析 Java–读写锁的实现原理","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/tags/JAVA/"},{"name":"并发","slug":"并发","permalink":"https://vincentruan.github.io/tags/并发/"}]},{"title":"从ReentrantLock的实现看AQS的原理及应用","slug":"从ReentrantLock的实现看AQS的原理及应用","date":"2020-02-12T08:27:06.000Z","updated":"2020-02-17T02:40:44.847Z","comments":true,"path":"2020/02/12/从ReentrantLock的实现看AQS的原理及应用/","link":"","permalink":"https://vincentruan.github.io/2020/02/12/从ReentrantLock的实现看AQS的原理及应用/","excerpt":"","text":"前言Java中的大部分同步类（Lock、Semaphore、ReentrantLock等）都是基于AbstractQueuedSynchronizer（简称为AQS）实现的。AQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。本文会从应用层逐渐深入到原理层，并通过ReentrantLock的基本特性和ReentrantLock与AQS的关联，来深入解读AQS相关独占锁的知识点，同时采取问答的模式来帮助大家理解AQS。由于篇幅原因，本篇文章主要阐述AQS中独占锁的逻辑和Sync Queue，不讲述包含共享锁和Condition Queue的部分（本篇文章核心为AQS原理剖析，只是简单介绍了ReentrantLock，感兴趣同学可以阅读一下ReentrantLock的源码）。 下面列出本篇文章的大纲和思路，以便于大家更好地理解： 1 ReentrantLock1.1 ReentrantLock特性概览ReentrantLock意思为可重入锁，指的是一个线程能够对一个临界资源重复加锁。为了帮助大家更好地理解ReentrantLock的特性，我们先将ReentrantLock跟常用的Synchronized进行比较，其特性如下（蓝色部分为本篇文章主要剖析的点）： 下面通过伪代码，进行更加直观的比较： 1234567891011121314151617181920212223242526272829// **************************Synchronized的使用方式**************************// 1.用于代码块synchronized (this) &#123;&#125;// 2.用于对象synchronized (object) &#123;&#125;// 3.用于方法public synchronized void test () &#123;&#125;// 4.可重入for (int i = 0; i &lt; 100; i++) &#123; synchronized (this) &#123;&#125;&#125;// **************************ReentrantLock的使用方式**************************public void test () throw Exception &#123; // 1.初始化选择公平锁、非公平锁 ReentrantLock lock = new ReentrantLock(true); // 2.可用于代码块 lock.lock(); try &#123; try &#123; // 3.支持多种加锁方式，比较灵活; 具有可重入特性 if(lock.tryLock(100, TimeUnit.MILLISECONDS))&#123; &#125; &#125; finally &#123; // 4.手动释放锁 lock.unlock() &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; 1.2 ReentrantLock与AQS的关联通过上文我们已经了解，ReentrantLock支持公平锁和非公平锁（关于公平锁和非公平锁的原理分析，可参考《不可不说的Java“锁”事》），并且ReentrantLock的底层就是由AQS来实现的。那么ReentrantLock是如何通过公平锁和非公平锁与AQS关联起来呢？ 我们着重从这两者的加锁过程来理解一下它们与AQS之间的关系（加锁过程中与AQS的关联比较明显，解锁流程后续会介绍）。 非公平锁源码中的加锁流程如下： 12345678910111213// java.util.concurrent.locks.ReentrantLock#NonfairSync// 非公平锁static final class NonfairSync extends Sync &#123; ... final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; ...&#125; 这块代码的含义为： 若通过CAS设置变量State（同步状态）成功，也就是获取锁成功，则将当前线程设置为独占线程。 若通过CAS设置变量State（同步状态）失败，也就是获取锁失败，则进入Acquire方法进行后续处理。 第一步很好理解，但第二步获取锁失败后，后续的处理策略是怎么样的呢？这块可能会有以下思考： 某个线程获取锁失败的后续流程是什么呢？有以下两种可能： (1) 将当前线程获锁结果设置为失败，获取锁流程结束。这种设计会极大降低系统的并发度，并不满足我们实际的需求。所以就需要下面这种流程，也就是AQS框架的处理流程。 (2) 存在某种排队等候机制，线程继续等待，仍然保留获取锁的可能，获取锁流程仍在继续。 对于问题1的第二种情况，既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢？ 处于排队等候机制中的线程，什么时候可以有机会获取锁呢？ 如果处于排队等候机制中的线程一直无法获取锁，还是需要一直等待吗，还是有别的策略来解决这一问题？ 带着非公平锁的这些问题，再看下公平锁源码中获锁的方式： 123456789// java.util.concurrent.locks.ReentrantLock#FairSyncstatic final class FairSync extends Sync &#123; ... final void lock() &#123; acquire(1); &#125; ...&#125; 看到这块代码，我们可能会存在这种疑问：Lock函数通过Acquire方法进行加锁，但是具体是如何加锁的呢？ 结合公平锁和非公平锁的加锁流程，虽然流程上有一定的不同，但是都调用了Acquire方法，而Acquire方法是FairSync和UnfairSync的父类AQS中的核心方法。 对于上边提到的问题，其实在ReentrantLock类源码中都无法解答，而这些问题的答案，都是位于Acquire方法所在的类AbstractQueuedSynchronizer中，也就是本文的核心——AQS。下面我们会对AQS以及ReentrantLock和AQS的关联做详细介绍（相关问题答案会在2.3.5小节中解答）。 2 AQS首先，我们通过下面的架构图来整体了解一下AQS框架： 上图中有颜色的为Method，无颜色的为Attribution。 总的来说，AQS框架共分为五层，自上而下由浅入深，从AQS对外暴露的API到底层基础数据。 当有自定义同步器接入时，只需重写第一层所需要的部分方法即可，不需要关注底层具体的实现流程。当自定义同步器进行加锁或者解锁操作时，先经过第一层的API进入AQS内部方法，然后经过第二层进行锁的获取，接着对于获取锁失败的流程，进入第三层和第四层的等待队列处理，而这些处理方式均依赖于第五层的基础数据提供层。 下面我们会从整体到细节，从流程到方法逐一剖析AQS框架，主要分析过程如下： 2.1 原理概览AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。 CLH：Craig、Landin and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。 主要原理图如下： AQS使用一个Volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。 2.1.1 AQS数据结构先来看下AQS中最基本的数据结构——Node，Node即为上面CLH变体队列中的节点。 解释一下几个方法和属性值的含义： 方法和属性值 含义 waitStatus 当前节点在队列中的状态 thread 表示处于该节点的线程 prev 前驱指针 predecessor 返回前驱节点，没有的话抛出npe nextWaiter 指向下一个处于CONDITION状态的节点（由于本篇文章不讲述Condition Queue队列，这个指针不多介绍） next 后继指针 线程两种锁的模式： 模式 含义 SHARED 表示线程以共享的模式等待锁 EXCLUSIVE 表示线程正在以独占的方式等待锁 waitStatus有下面几个枚举值： 枚举 含义 0 当一个Node被初始化的时候的默认值 CANCELLED 为1，表示线程获取锁的请求已经取消了 CONDITION 为-2，表示节点在等待队列中，节点线程等待唤醒 PROPAGATE 为-3，当前线程处在SHARED情况下，该字段才会使用 SIGNAL 为-1，表示线程已经准备好了，就等资源释放了 2.1.2 同步状态State在了解数据结构后，接下来了解一下AQS的同步状态——State。AQS中维护了一个名为state的字段，意为同步状态，是由Volatile修饰的，用于展示当前临界资源的获锁情况。 123// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate volatile int state; 下面提供了几个访问这个字段的方法： 方法名 描述 protected final int getState() 获取State的值 protected final void setState(int newState) 设置State的值 protected final boolean compareAndSetState(int expect, int update) 使用CAS方式更新State 这几个方法都是Final修饰的，说明子类中无法重写它们。我们可以通过修改State字段表示的同步状态来实现多线程的独占模式和共享模式（加锁过程）。 对于我们自定义的同步工具，需要自定义获取同步状态和释放状态的方式，也就是AQS架构图中的第一层：API层。 2.2 AQS重要方法与ReentrantLock的关联从架构图中可以得知，AQS提供了大量用于自定义同步器实现的Protected方法。自定义同步器实现的相关方法也只是为了通过修改State字段来实现多线程的独占模式或者共享模式。自定义同步器需要实现以下方法（ReentrantLock需要实现的方法如下，并不是全部）： 方法名 描述 protected boolean isHeldExclusively() 该线程是否正在独占资源。只有用到Condition才需要去实现它。 protected boolean tryAcquire(int arg) 独占方式。arg为获取锁的次数，尝试获取资源，成功则返回True，失败则返回False。 protected boolean tryRelease(int arg) 独占方式。arg为释放锁的次数，尝试释放资源，成功则返回True，失败则返回False。 protected int tryAcquireShared(int arg) 共享方式。arg为获取锁的次数，尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 protected boolean tryReleaseShared(int arg) 共享方式。arg为释放锁的次数，尝试释放资源，如果释放后允许唤醒后续等待结点返回True，否则返回False。 一般来说，自定义同步器要么是独占方式，要么是共享方式，它们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。ReentrantLock是独占锁，所以实现了tryAcquire-tryRelease。 以非公平锁为例，这里主要阐述一下非公平锁与AQS之间方法的关联之处，具体每一处核心方法的作用会在文章后面详细进行阐述。 为了帮助大家理解ReentrantLock和AQS之间方法的交互过程，以非公平锁为例，我们将加锁和解锁的交互流程单独拎出来强调一下，以便于对后续内容的理解。 加锁： 通过ReentrantLock的加锁方法Lock进行加锁操作。 会调用到内部类Sync的Lock方法，由于Sync#lock是抽象方法，根据ReentrantLock初始化选择的公平锁和非公平锁，执行相关内部类的Lock方法，本质上都会执行AQS的Acquire方法。 AQS的Acquire方法会执行tryAcquire方法，但是由于tryAcquire需要自定义同步器实现，因此执行了ReentrantLock中的tryAcquire方法，由于ReentrantLock是通过公平锁和非公平锁内部类实现的tryAcquire方法，因此会根据锁类型不同，执行不同的tryAcquire。 tryAcquire是获取锁逻辑，获取失败后，会执行框架AQS的后续逻辑，跟ReentrantLock自定义同步器无关。 解锁： 通过ReentrantLock的解锁方法Unlock进行解锁。 Unlock会调用内部类Sync的Release方法，该方法继承于AQS。 Release中会调用tryRelease方法，tryRelease需要自定义同步器实现，tryRelease只在ReentrantLock中的Sync实现，因此可以看出，释放锁的过程，并不区分是否为公平锁。 释放成功后，所有处理由AQS框架完成，与自定义同步器无关。 通过上面的描述，大概可以总结出ReentrantLock加锁解锁时API层核心方法的映射关系。 2.3 通过ReentrantLock理解AQSReentrantLock中公平锁和非公平锁在底层是相同的，这里以非公平锁为例进行分析。 在非公平锁中，有一段这样的代码： 123456789101112// java.util.concurrent.locks.ReentrantLockstatic final class NonfairSync extends Sync &#123; ... final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; ...&#125; 看一下这个Acquire是怎么写的： 123456// java.util.concurrent.locks.AbstractQueuedSynchronizerpublic final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 再看一下tryAcquire方法： 12345// java.util.concurrent.locks.AbstractQueuedSynchronizerprotected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; 可以看出，这里只是AQS的简单实现，具体获取锁的实现方法是由各自的公平锁和非公平锁单独实现的（以ReentrantLock为例）。如果该方法返回了True，则说明当前线程获取锁成功，就不用往后执行了；如果获取失败，就需要加入到等待队列中。下面会详细解释线程是何时以及怎样被加入进等待队列中的。 2.3.1 线程加入等待队列2.3.1.1 加入队列的时机当执行Acquire(1)时，会通过tryAcquire获取锁。在这种情况下，如果获取锁失败，就会调用addWaiter加入到等待队列中去。 2.3.1.2 如何加入队列获取锁失败后，会执行addWaiter(Node.EXCLUSIVE)加入等待队列，具体实现方法如下： 12345678910111213141516171819// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125;private final boolean compareAndSetTail(Node expect, Node update) &#123; return unsafe.compareAndSwapObject(this, tailOffset, expect, update);&#125; 主要的流程如下： 通过当前的线程和锁模式新建一个节点。 Pred指针指向尾节点Tail。 将New中Node的Prev指针指向Pred。 通过compareAndSetTail方法，完成尾节点的设置。这个方法主要是对tailOffset和Expect进行比较，如果tailOffset的Node和Expect的Node地址是相同的，那么设置Tail的值为Update的值。 12345678910111213// java.util.concurrent.locks.AbstractQueuedSynchronizerstatic &#123; try &#123; stateOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(\"state\")); headOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(\"head\")); tailOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(\"tail\")); waitStatusOffset = unsafe.objectFieldOffset(Node.class.getDeclaredField(\"waitStatus\")); nextOffset = unsafe.objectFieldOffset(Node.class.getDeclaredField(\"next\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125; 从AQS的静态代码块可以看出，都是获取一个对象的属性相对于该对象在内存当中的偏移量，这样我们就可以根据这个偏移量在对象内存当中找到这个属性。tailOffset指的是tail对应的偏移量，所以这个时候会将new出来的Node置为当前队列的尾节点。同时，由于是双向链表，也需要将前一个节点指向尾节点。 如果Pred指针是Null（说明等待队列中没有元素），或者当前Pred指针和Tail指向的位置不同（说明被别的线程已经修改），就需要看一下Enq的方法。 1234567891011121314151617// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 如果没有被初始化，需要进行初始化一个头结点出来。但请注意，初始化的头结点并不是当前线程节点，而是调用了无参构造函数的节点。如果经历了初始化或者并发导致队列中有元素，则与之前的方法相同。其实，addWaiter就是一个在双端链表添加尾节点的操作，需要注意的是，双端链表的头结点是一个无参构造函数的头结点。 总结一下，线程获取锁的时候，过程大体如下： 当没有线程获取到锁时，线程1获取锁成功。 线程2申请锁，但是锁被线程1占有。 如果再有线程要获取锁，依次在队列中往后排队即可。 回到上边的代码，hasQueuedPredecessors是公平锁加锁时判断等待队列中是否存在有效节点的方法。如果返回False，说明当前线程可以争取共享资源；如果返回True，说明队列中存在有效节点，当前线程必须加入到等待队列中。 1234567891011// java.util.concurrent.locks.ReentrantLockpublic final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; 看到这里，我们理解一下h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());为什么要判断的头结点的下一个节点？第一个节点储存的数据是什么？ 双向链表中，第一个节点为虚节点，其实并不存储任何信息，只是占位。真正的第一个有数据的节点，是在第二个节点开始的。当h != t时： 如果(s = h.next) == null，等待队列正在有线程进行初始化，但只是进行到了Tail指向Head，没有将Head指向Tail，此时队列中有元素，需要返回True（这块具体见下边代码分析）。 如果(s = h.next) != null，说明此时队列中至少有一个有效节点。如果此时s.thread == Thread.currentThread()，说明等待队列的第一个有效节点中的线程与当前线程相同，那么当前线程是可以获取资源的；如果s.thread != Thread.currentThread()，说明等待队列的第一个有效节点线程与当前线程不同，当前线程必须加入进等待队列。 123456789101112// java.util.concurrent.locks.AbstractQueuedSynchronizer#enqif (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head;&#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125;&#125; 节点入队不是原子操作，所以会出现短暂的head != tail，此时Tail指向最后一个节点，而且Tail指向Head。如果Head没有指向Tail（可见5、6、7行），这种情况下也需要将相关线程加入队列中。所以这块代码是为了解决极端情况下的并发问题。 2.3.1.3 等待队列中线程出队列时机回到最初的源码： 123456// java.util.concurrent.locks.AbstractQueuedSynchronizerpublic final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 上文解释了addWaiter方法，这个方法其实就是把对应的线程以Node的数据结构形式加入到双端队列里，返回的是一个包含该线程的Node。而这个Node会作为参数，进入到acquireQueued方法中。acquireQueued方法可以对排队中的线程进行“获锁”操作。 总的来说，一个线程获取锁失败了，被放入等待队列，acquireQueued会把放入队列中的线程不断去获取锁，直到获取成功或者不再需要获取（中断）。 下面我们从“何时出队列？”和“如何出队列？”两个方向来分析一下acquireQueued源码： 1234567891011121314151617181920212223242526272829// java.util.concurrent.locks.AbstractQueuedSynchronizerfinal boolean acquireQueued(final Node node, int arg) &#123; // 标记是否成功拿到资源 boolean failed = true; try &#123; // 标记等待过程中是否中断过 boolean interrupted = false; // 开始自旋，要么获取锁，要么中断 for (;;) &#123; // 获取当前节点的前驱节点 final Node p = node.predecessor(); // 如果p是头结点，说明当前节点在真实数据队列的首部，就尝试获取锁（别忘了头结点是虚节点） if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 获取锁成功，头指针移动到当前node setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 说明p为头节点且当前没有获取到锁（可能是非公平锁被抢占了）或者是p不为头结点，这个时候就要判断当前node是否要被阻塞（被阻塞条件：前驱节点的waitStatus为-1），防止无限循环浪费资源。具体两个方法下面细细分析 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 注：setHead方法是把当前节点置为虚节点，但并没有修改waitStatus，因为它是一直需要用的数据。 123456789101112131415161718192021222324252627282930// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null;&#125;// java.util.concurrent.locks.AbstractQueuedSynchronizer// 靠前驱节点判断当前线程是否应该被阻塞private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 获取头结点的节点状态 int ws = pred.waitStatus; // 说明头结点处于唤醒状态 if (ws == Node.SIGNAL) return true; // 通过枚举值我们知道waitStatus&gt;0是取消状态 if (ws &gt; 0) &#123; do &#123; // 循环向前查找取消节点，把取消节点从队列中剔除 node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 设置前任节点等待状态为SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; parkAndCheckInterrupt主要用于挂起当前线程，阻塞调用栈，返回当前线程的中断状态。 123456// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 上述方法的流程图如下： 从上图可以看出，跳出当前循环的条件是当“前置节点是头结点，且当前线程获取锁成功”。为了防止因死循环导致CPU资源被浪费，我们会判断前置节点的状态来决定是否要将当前线程挂起，具体挂起流程用流程图表示如下（shouldParkAfterFailedAcquire流程）： 从队列中释放节点的疑虑打消了，那么又有新问题了： shouldParkAfterFailedAcquire中取消节点是怎么生成的呢？什么时候会把一个节点的waitStatus设置为-1？ 是在什么时间释放节点通知到被挂起的线程呢？ 2.3.2 CANCELLED状态节点生成acquireQueued方法中的Finally代码： 12345678910111213141516171819// java.util.concurrent.locks.AbstractQueuedSynchronizerfinal boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; ... for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; ... failed = false; ... &#125; ... &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 通过cancelAcquire方法，将Node的状态标记为CANCELLED。接下来，我们逐行来分析这个方法的原理： 123456789101112131415161718192021222324252627282930313233343536// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate void cancelAcquire(Node node) &#123; // 将无效节点过滤 if (node == null) return; // 设置该节点不关联任何线程，也就是虚节点 node.thread = null; Node pred = node.prev; // 通过前驱节点，跳过取消状态的node while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // 获取过滤后的前驱节点的后继节点 Node predNext = pred.next; // 把当前node的状态设置为CANCELLED node.waitStatus = Node.CANCELLED; // 如果当前节点是尾节点，将从后往前的第一个非取消状态的节点设置为尾节点 // 更新失败的话，则进入else，如果更新成功，将tail的后继节点设置为null if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; int ws; // 如果当前节点不是head的后继节点，1:判断当前节点前驱节点的是否为SIGNAL，2:如果不是，则把前驱节点设置为SINGAL看是否成功 // 如果1和2中有一个为true，再判断当前节点的线程是否为null // 如果上述条件都满足，把当前节点的前驱节点的后继指针指向当前节点的后继节点 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; // 如果当前节点是head的后继节点，或者上述条件不满足，那就唤醒当前节点的后继节点 unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125; 当前的流程： 获取当前节点的前驱节点，如果前驱节点的状态是CANCELLED，那就一直往前遍历，找到第一个waitStatus &lt;= 0的节点，将找到的Pred节点和当前Node关联，将当前Node设置为CANCELLED。 根据当前节点的位置，考虑以下三种情况： (1) 当前节点是尾节点。 (2) 当前节点是Head的后继节点。 (3) 当前节点不是Head的后继节点，也不是尾节点。 根据上述第二条，我们来分析每一种情况的流程。 当前节点是尾节点。 当前节点是Head的后继节点。 当前节点不是Head的后继节点，也不是尾节点。 通过上面的流程，我们对于CANCELLED节点状态的产生和变化已经有了大致的了解，但是为什么所有的变化都是对Next指针进行了操作，而没有对Prev指针进行操作呢？什么情况下会对Prev指针进行操作？ 执行cancelAcquire的时候，当前节点的前置节点可能已经从队列中出去了（已经执行过Try代码块中的shouldParkAfterFailedAcquire方法了），如果此时修改Prev指针，有可能会导致Prev指向另一个已经移除队列的Node，因此这块变化Prev指针不安全。 shouldParkAfterFailedAcquire方法中，会执行下面的代码，其实就是在处理Prev指针。shouldParkAfterFailedAcquire是获取锁失败的情况下才会执行，进入该方法后，说明共享资源已被获取，当前节点之前的节点都不会出现变化，因此这个时候变更Prev指针比较安全。 1234&gt; do &#123;&gt; node.prev = pred = pred.prev;&gt; &#125; while (pred.waitStatus &gt; 0);&gt; 2.3.3 如何解锁我们已经剖析了加锁过程中的基本流程，接下来再对解锁的基本流程进行分析。由于ReentrantLock在解锁的时候，并不区分公平锁和非公平锁，所以我们直接看解锁的源码： 12345// java.util.concurrent.locks.ReentrantLockpublic void unlock() &#123; sync.release(1);&#125; 可以看到，本质释放锁的地方，是通过框架来完成的。 1234567891011// java.util.concurrent.locks.AbstractQueuedSynchronizerpublic final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 在ReentrantLock里面的公平锁和非公平锁的父类Sync定义了可重入锁的释放锁机制。 123456789101112131415161718// java.util.concurrent.locks.ReentrantLock.Sync// 方法返回当前锁是不是没有被线程持有protected final boolean tryRelease(int releases) &#123; // 减少可重入次数 int c = getState() - releases; // 当前线程不是持有锁的线程，抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 如果持有线程全部释放，将当前独占锁所有线程设置为null，并更新state if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 我们来解释下述源码： 1234567891011121314// java.util.concurrent.locks.AbstractQueuedSynchronizerpublic final boolean release(int arg) &#123; // 上边自定义的tryRelease如果返回true，说明该锁没有被任何线程持有 if (tryRelease(arg)) &#123; // 获取头结点 Node h = head; // 头结点不为空并且头结点的waitStatus不是初始化节点情况，解除线程挂起状态 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 这里的判断条件为什么是h != null &amp;&amp; h.waitStatus != 0？ h == null Head还没初始化。初始情况下，head == null，第一个节点入队，Head会被初始化一个虚拟节点。所以说，这里如果还没来得及入队，就会出现head == null 的情况。 h != null &amp;&amp; waitStatus == 0 表明后继节点对应的线程仍在运行中，不需要唤醒。 h != null &amp;&amp; waitStatus &lt; 0 表明后继节点可能被阻塞了，需要唤醒。 再看一下unparkSuccessor方法： 123456789101112131415161718192021// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate void unparkSuccessor(Node node) &#123; // 获取头结点waitStatus int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 获取当前节点的下一个节点 Node s = node.next; // 如果下个节点是null或者下个节点被cancelled，就找到队列最开始的非cancelled的节点 if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 就从尾部节点开始找，到队首，找到队列第一个waitStatus&lt;0的节点。 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 如果当前节点的下个节点不为空，而且状态&lt;=0，就把当前节点unpark if (s != null) LockSupport.unpark(s.thread);&#125; 为什么要从后往前找第一个非Cancelled的节点呢？原因如下。 之前的addWaiter方法： 12345678910111213141516// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 我们从这里可以看到，节点入队并不是原子操作，也就是说，node.prev = pred; compareAndSetTail(pred, node) 这两个地方可以看作Tail入队的原子操作，但是此时pred.next = node;还没执行，如果这个时候执行了unparkSuccessor方法，就没办法从前往后找了，所以需要从后往前找。还有一点原因，在产生CANCELLED状态节点的时候，先断开的是Next指针，Prev指针并未断开，因此也是必须要从后往前遍历才能够遍历完全部的Node。 综上所述，如果是从前往后找，由于极端情况下入队的非原子操作和CANCELLED节点产生过程中断开Next指针的操作，可能会导致无法遍历所有的节点。所以，唤醒对应的线程后，对应的线程就会继续往下执行。继续执行acquireQueued方法以后，中断如何处理？ 2.3.4 中断恢复后的执行流程唤醒后，会执行return Thread.interrupted();，这个函数返回的是当前执行线程的中断状态，并清除。 123456// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 再回到acquireQueued代码，当parkAndCheckInterrupt返回True或者False的时候，interrupted的值不同，但都会执行下次循环。如果这个时候获取锁成功，就会把当前interrupted返回。 12345678910111213141516171819202122// java.util.concurrent.locks.AbstractQueuedSynchronizerfinal boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 如果acquireQueued为True，就会执行selfInterrupt方法。 12345// java.util.concurrent.locks.AbstractQueuedSynchronizerstatic void selfInterrupt() &#123; Thread.currentThread().interrupt();&#125; 该方法其实是为了中断线程。但为什么获取了锁以后还要中断线程呢？这部分属于Java提供的协作式中断知识内容，感兴趣同学可以查阅一下。这里简单介绍一下： 当中断线程被唤醒时，并不知道被唤醒的原因，可能是当前线程在等待中被中断，也可能是释放了锁以后被唤醒。因此我们通过Thread.interrupted()方法检查中断标记（该方法返回了当前线程的中断状态，并将当前线程的中断标识设置为False），并记录下来，如果发现该线程被中断过，就再中断一次。 线程在等待资源的过程中被唤醒，唤醒后还是会不断地去尝试获取锁，直到抢到锁为止。也就是说，在整个流程中，并不响应中断，只是记录中断记录。最后抢到锁返回了，那么如果被中断过的话，就需要补充一次中断。 这里的处理方式主要是运用线程池中基本运作单元Worder中的runWorker，通过Thread.interrupted()进行额外的判断处理，感兴趣的同学可以看下ThreadPoolExecutor源码。 2.3.5 小结我们在1.3小节中提出了一些问题，现在来回答一下。 Q：某个线程获取锁失败的后续流程是什么呢？ A：存在某种排队等候机制，线程继续等待，仍然保留获取锁的可能，获取锁流程仍在继续。 Q：既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢？ A：是CLH变体的FIFO双端队列。 Q：处于排队等候机制中的线程，什么时候可以有机会获取锁呢？ A：可以详细看下2.3.1.3小节。 Q：如果处于排队等候机制中的线程一直无法获取锁，需要一直等待么？还是有别的策略来解决这一问题？ A：线程所在节点的状态会变成取消状态，取消状态的节点会从队列中释放，具体可见2.3.2小节。 Q：Lock函数通过Acquire方法进行加锁，但是具体是如何加锁的呢？ A：AQS的Acquire会调用tryAcquire方法，tryAcquire由各个自定义同步器实现，通过tryAcquire完成加锁过程。 3 AQS应用3.1 ReentrantLock的可重入应用ReentrantLock的可重入性是AQS很好的应用之一，在了解完上述知识点以后，我们很容易得知ReentrantLock实现可重入的方法。在ReentrantLock里面，不管是公平锁还是非公平锁，都有一段逻辑。 公平锁： 123456789101112131415// java.util.concurrent.locks.ReentrantLock.FairSync#tryAcquireif (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125;&#125;else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true;&#125; 非公平锁： 123456789101112131415// java.util.concurrent.locks.ReentrantLock.Sync#nonfairTryAcquireif (c == 0) &#123; if (compareAndSetState(0, acquires))&#123; setExclusiveOwnerThread(current); return true; &#125;&#125;else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true;&#125; 从上面这两段都可以看到，有一个同步状态State来控制整体可重入的情况。State是Volatile修饰的，用于保证一定的可见性和有序性。 123// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate volatile int state; 接下来看State这个字段主要的过程： State初始化的时候为0，表示没有任何线程持有锁。 当有线程持有该锁时，值就会在原来的基础上+1，同一个线程多次获得锁是，就会多次+1，这里就是可重入的概念。 解锁也是对这个字段-1，一直到0，此线程对锁释放。 3.2 JUC中的应用场景除了上边ReentrantLock的可重入性的应用，AQS作为并发编程的框架，为很多其他同步工具提供了良好的解决方案。下面列出了JUC中的几种同步工具，大体介绍一下AQS的应用场景： 同步工具 同步工具与AQS的关联 ReentrantLock 使用AQS保存锁重复持有的次数。当一个线程获取锁时，ReentrantLock记录当前获得锁的线程标识，用于检测是否重复获取，以及错误线程试图解锁操作时异常情况的处理。 Semaphore 使用AQS同步状态来保存信号量的当前计数。tryRelease会增加计数，acquireShared会减少计数。 CountDownLatch 使用AQS同步状态来表示计数。计数为0时，所有的Acquire操作（CountDownLatch的await方法）才可以通过。 ReentrantReadWriteLock 使用AQS同步状态中的16位保存写锁持有的次数，剩下的16位用于保存读锁的持有次数。 ThreadPoolExecutor Worker利用AQS同步状态实现对独占线程变量的设置（tryAcquire和tryRelease）。 3.3 自定义同步工具了解AQS基本原理以后，按照上面所说的AQS知识点，自己实现一个同步工具。 123456789101112131415161718192021222324252627282930public class LeeLock &#123; private static class Sync extends AbstractQueuedSynchronizer &#123; @Override protected boolean tryAcquire (int arg) &#123; return compareAndSetState(0, 1); &#125; @Override protected boolean tryRelease (int arg) &#123; setState(0); return true; &#125; @Override protected boolean isHeldExclusively () &#123; return getState() == 1; &#125; &#125; private Sync sync = new Sync(); public void lock () &#123; sync.acquire(1); &#125; public void unlock () &#123; sync.release(1); &#125;&#125; 通过我们自己定义的Lock完成一定的同步功能。 1234567891011121314151617181920212223242526272829303132public class LeeMain &#123; static int count = 0; static LeeLock leeLock = new LeeLock(); public static void main (String[] args) throws InterruptedException &#123; Runnable runnable = new Runnable() &#123; @Override public void run () &#123; try &#123; leeLock.lock(); for (int i = 0; i &lt; 10000; i++) &#123; count++; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; leeLock.unlock(); &#125; &#125; &#125;; Thread thread1 = new Thread(runnable); Thread thread2 = new Thread(runnable); thread1.start(); thread2.start(); thread1.join(); thread2.join(); System.out.println(count); &#125;&#125; 上述代码每次运行结果都会是20000。通过简单的几行代码就能实现同步功能，这就是AQS的强大之处。 总结我们日常开发中使用并发的场景太多，但是对并发内部的基本框架原理了解的人却不多。由于篇幅原因，本文仅介绍了可重入锁ReentrantLock的原理和AQS原理，希望能够成为大家了解AQS和ReentrantLock等同步器的“敲门砖”。 参考资料 Lea D. The java. util. concurrent synchronizer framework[J]. Science of Computer Programming, 2005, 58(3): 293-309. 《Java并发编程实战》 不可不说的Java“锁”事","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/tags/JAVA/"},{"name":"并发","slug":"并发","permalink":"https://vincentruan.github.io/tags/并发/"},{"name":"ReentrantLock","slug":"ReentrantLock","permalink":"https://vincentruan.github.io/tags/ReentrantLock/"},{"name":"AQS","slug":"AQS","permalink":"https://vincentruan.github.io/tags/AQS/"}]},{"title":"MySQL增删改查都会用到什么锁?","slug":"MySQL增删改查都会用到什么锁","date":"2020-02-12T07:11:11.000Z","updated":"2020-02-17T02:40:44.708Z","comments":true,"path":"2020/02/12/MySQL增删改查都会用到什么锁/","link":"","permalink":"https://vincentruan.github.io/2020/02/12/MySQL增删改查都会用到什么锁/","excerpt":"","text":"日常的操作中，增删改查都会使用什么类型的锁？其实这个问题，可以分为两个方面，一方面是读，一方面是写。 01 读（select） 我们先来看读的部分。读的操作，其实分为两种，分别是一致性读和锁定读， 这里我们温习一下，一致性读其实就是利用事务的MVCC机制，来读取一份数据的快照，所以有的书上也称之为快照读，一致性读是不加锁的，其他的事务是可以对表中的数据记录进行改动的。一般情况下，常见的读，例如： select * from table； select * from table left join table2; 这种操作，在RU，RC，RR隔离级别下都是采用一直性读，不加锁的操作。这种情况下，读的并发可以非常高。 再来看看锁定读，如果我们的表当中有索引，我们想在读取记录的时候，获取某一条记录的锁，禁止别的事务对这条记录进行修改，那么我们可以使用下面的语句来对读取的记录加锁： select … lock in share mode;加共享锁。(其他事务可读，不可写) select … for update;加排它锁。(其他事务不可读，不可写)，这样，其他事务就不能对这条记录进行读取和更改了。 关于读操作的是否加锁，还有以下几点需要注意： 1、在Serializable这种事务的隔离级别下，普通的select操作会升级为select…in share mode；的模式。 2、在唯一索引上使用唯一的查询条件，会使用记录锁，而不会封锁记录之间的间隔，即不会使用间隙锁。 3、其他类型的索引使用范围的查询条件或者唯一的查询条件，innodb会自动锁定被扫描的范围，避免索引范围区间内插入新的记录。这块儿可能比较模糊，文章最后面给出各种类型下的加锁测试结果。 02 写（update、delete、insert）关于delete 对一条数据做delete的过程实际上是要先在索引的B+树上获取该记录的位置，然后再这个记录所在的位置加X锁，也就是排它锁。 如果对某个范围内的数据做delete操作，则会在索引B+树上对范围内符合查询条件的记录以及记录之前的区间加next-key锁(本质是记录锁和间隙锁的组合，后面的文章会讲到)。 加完锁之后，再进行delete操作。这个delete操作的本质，其实是先将delete的标识为标识为1，而不是真正进行删除，如果下次这块空间可以复用，则innodb会直接进行复用。 更多详情请见：Innodb数据页简介 关于update 对一条记录做update的时候，我们知道，如果该要更新的列在更新前后的存储空间没有发生变化，则会直接在该记录上进行更新操作。而如果发生了存储空间的变化，则会现将这条记录彻底删除掉，然后再插入一条新的记录。 基本上分为一下三种情况： 1、如果update操作没有更新索引键值并且没有导致存储空间变化，则会直接在索引B+树上使用X锁来锁定update的记录。 2、如果update操作没有更新索引键值但却导致了数据的存储空间发生变化，则会现将这表数据记录删除掉，然后再插入一条新的记录，在这个过程中，先会获取索引B+树的X锁，然后insert过程会使用隐式锁来进行保护。 3、如果update修改了某条记录的索引键值，则需要先进行delete，然后再进行一次insert，加锁的规则就和delete以及insert一样了。 这里有几点需要注意： 1、如果在唯一索引上使用唯一的查询条件来进行update和delete操作，那么这个过程中只会对记录加锁。 2、除了第一种情况之外，都会加排他的next-key锁，来锁定记录和记录之前的范围。 3、如果update的是主键的记录，则对应的普通索引的记录也会被隐式加锁，这是因为innodb中的普通索引会存储主键的值，检索普通索引本质上要进行回表操作，二次扫描聚集索引。 关于insert insert操作会用排它锁封锁被插入的索引记录，而不会封锁记录之前的范围。除此之外，会在插入区间加入插入意向锁 最后，今天我做了一点测试，测试的数据太多了，不方便整理，这里把测试结果放在这里，大家可以看看，和自己设想的情况一样不一样： （注意：所有测试均在RR隔离级别下，RC隔离级别下只有记录锁，没有间隙锁，相对比较简单，大家可以自行研究） RR隔离级别下，如果会话1锁定了一个空的记录，例如id=6的记录，表中只有id=5和id=9的值，那么会话2中不能插入id=6、7、8的值，因为这个间隙已经被锁定。其中，id可以是主键或者唯一索引。 RR隔离级别下，如果会话1锁定了一个存在记录，例如id=5的记录，表中有id=5的值，那么会话2中可以插入id=4、6、7、8的值，间隙没有锁定。其中，id可以是主键或者唯一索引。 RR隔离级别下，如果会话1锁定了一个范围记录，例如id&lt;6的记录，表中有id=5的值和id=9的值，那么会话2中不能插入id=6、7、8的值，间隙被锁定。其中，id可以是主键或者唯一索引。 RR隔离级别下，如果会话1锁定了一个范围记录，例如id&gt;6 and id &lt;11的记录，表中有id=5的值和id=9的值，那么会话2中不能插入id=6、7、8的值以及id大于9的所有值，间隙被锁定。其中，id可以是主键或者唯一索引。 RR隔离级别下，如果会话1锁定了一个空的记录，例如id=6的记录，表中有id=5的值和id=9的值，那么会话2中不能插入id=5、6、7、8的值，间隙被锁定。但是可以插入9的值，其中，id是普通索引。 RR隔离级别下，如果会话1锁定了一个存在记录，例如id=5的记录，表中有id=5的值和id=9的值，那么会话2中不能插入id=4、6、7、8的值，但是可以插入9的值。间隙被锁定。其中，id是普通索引。 RR隔离级别下，如果会话1锁定了一个范围记录，例如id&lt;6的记录，表中有id=5的值和id=9的值，那么会话2中不能插入id=4、6、7、8的值，但是可以插入9的值，间隙被锁定。其中，id是普通索引**。** RR隔离级别下，如果会话1锁定了一个范围记录，例如id&gt;6 and id&lt;11的记录，表中有id=5的值和id=9的值，那么会话2中不能插入所有值的记录，所有**间隙被锁定，类似全表锁。其中，id是普通索引**。 附录关于MySQL锁的两个知识点MySQL快照读和当前读 当我们对数据库中的表进行select、update、delete以及insert的时候，innodb存储引擎会根据操作类型的不同来给这些操作添加具体的锁。 在MySQL中，读操作可以分成两类：快照读 (snapshot read)与当前读 (current read)。快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。当前读，读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。 这里我们首先给出快照读和当前读的例子： 快照读：简单的select操作，属于快照读，不加锁。(当然，也有例外，下面会分析) 1select * from table where id&gt;10; 当前读：特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。 12345select * from table where id&gt;10 lock in share mode;select * from table where id&gt;10 for update;insert into table values (…);update table set id=11 where id=10;delete from table where id&gt;10; 读取之后，需要保证其他并发事务不能修改当前记录，对读取记录加锁。其中，除了第一条语句明确指出了lock in share mode之外，也就是对读取记录加S锁 (共享锁)外，其他的操作，都加的是X锁 (排它锁)。 这里我们给出一个update操作过程中，mysql server和innodb存储引擎进行交互的过程如下： 从上图中，我们可以看出一个update操作的具体流程。当update SQL被发给MySQL后，MySQL Server会根据where条件，读取第一条满足条件的记录，然后InnoDB引擎会将第一条记录返回，并加锁 (current read)。待MySQL Server收到这条加锁的记录之后，会再发起一个update请求，更新这条记录。一条记录操作完成，再读取下一条记录，直至没有满足条件的记录为止。因此，update操作内部，就包含了一个当前读。同理，delete操作也一样。insert操作会稍微有些不同，简单来说，就是insert操作可能会触发Unique Key的冲突检查，也会进行一个当前读。 关于死锁 死锁是指两个或者两个以上的事务在执行的过程中，因争夺资源而造成的一种互相等待的现象。若无外力作用，这两个事务将保持等待状态，无法推进下去。很明显，这是我们不想看到的。 从上面的概念可以看出，死锁的关键点在于互相等待，如果我们要解决死锁的问题，就要从“等待”这个关键词上面入手，如果我们将等待都转化为回滚操作，并且事务都重新开始，这种方法无疑可以避免死锁问题的产生。但是会导致数据库并发性能的降低，这样的问题也是我们无法接受的。 为了解决这一问题，我们采用一种超时的方法进行折中进行处理，超时是指当两个事务互相等待时，当某一方的等待时间超过一个阈值，我们将它进行回滚，这样，另一个事务就能够继续进行，在innodb存储引擎中，我们使用参数innodb_lock_wait_timeout来设置超时时间，这个参数如下： 1234567mysql&gt; show variables like \"innodb_lock_wait_timeout\";+--------------------------+-------+| Variable_name | Value |+--------------------------+-------+| innodb_lock_wait_timeout | 50 |+--------------------------+-------+1 row in set, 1 warning (0.11 sec) 为了加深印象，我们模拟一个死锁的现象，让大家感受一下。 首先，要模拟死锁，程序必须并发运行，串行的方法是无法模拟死锁的，这里我们采用两个连接会话进行模拟： 会话A 我们先开启事务，然后锁定id=3的行； 12345678910111213141516171819202122mysql&gt; select * from t;+----+-----+| id | age |+----+-----+| 1 | 5 || 2 | 4 || 3 | 3 || 4 | 2 || 5 | 1 |+----+-----+5 rows in set (0.00 sec)mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from t where id=3 for update;+----+-----+| id | age |+----+-----+| 3 | 3 |+----+-----+1 row in set (0.02 sec) 会话B 在会话B上锁定id=2的行 12345678910mysql&gt; begin -&gt; ;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from t where id=2 for update;+----+-----+| id | age |+----+-----+| 2 | 4 |+----+-----+1 row in set (0.00 sec) 会话A 我们在会话A上获取id=2的记录的锁，发现无法获取，产生了等待： 1234mysql&gt; select * from t where id=2 for update;##产生等待mysql&gt; 会话B 在会话A进行等待的过程中，我们在会话B上面获取id=3的记录的锁，我们发现了两个变化： 第一、会话B上输出了死锁的提示信息，如下； 1234mysql&gt; select * from t where id=3 for update;ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting tractionmysql&gt; 第二、会话A上输出了id=2的记录，也就是A会话得到了特定的资源，但是产生了9s的延迟，如下； 会话A 123456789mysql&gt; select * from t where id=2 for update;+----+-----+| id | age |+----+-----+| 2 | 4 |+----+-----+1 row in set (9.04 sec)mysql&gt; 在上述操作中，会话B抛出了1213这个错误状态码，它代表事务发生了死锁，死锁的原因是会话A和B的资源进行了相互等待，但是此时我们发现会话B中抛出死锁提示信息之后会话A中立即得到了记录为2的这个资源，这其实是因为会话B中的事务发生了回滚，否则的话，会话A中的事务是不可能得到相应的资源的。 这里又不得不提innodb的一个特性，那就是它会回滚死锁情况下的一个事务，因此当我们在程序中捕获了一个1213的错误，其实不需要我们手动进行回滚。 Innodb数据页简介 页是内存和磁盘交互的基本单位，它的大小一般是16KB，可以被分为如下几个部分： 上次的文章里面，我们对这几个部分大概做了介绍，今天我们说说上面数据页的蓝色部分。 该部分保存的是数据页中真正的数据记录，也就是用户存储的记录。当我们一开始生成页的时候，其实并没有蓝色的Record部分，而是随着我们不断给数据库中插入记录，才逐渐从Free Space中划分出来的空间。用示意图来描述就是： 如果Free Space中的数据页被分配完了，则去申请新的数据页。 为了方便理解，我们现在创建一个表进行演示： 1234567CREATE TABLE test( -&gt; c1 INT, -&gt; c2 INT, -&gt; c3 VARCHAR(1000), -&gt; PRIMARY KEY (c1) -&gt; ) engine=innodb charset=utf8;Query OK, 0 rows affected (0.03 sec) 现在我们给这个表里面插入几条数据： 12345insert into test values(1,2,'a'),(2,3,'bb'),(3,4,'ccc'),(4,5,'dddd'); 我们可以把上面的数据页结构简单表示如下： 我们可以看到，每条记录由三个部分构成，分别是记录头、记录数据以及其他信息，其中记录头里面包含很多字段来表示该条记录的信息，这些字段我们会逐渐进行讲解。目前4条记录都已经插入到record部分了，在实际过程中这四条记录是通过链表的方式进行连接的，如下： 在第一张图的数据页中，蓝色部分还有一部分是infimum和supermun，它们是两条伪记录，它们分别是这个数据页中”指定的”最大的记录和最小的记录。它们的作用是作为当前数据页内数据链表的首末两端。这样，数据页中的数据就可以被我们排列成下面的样子： 我们已经可以看到，我们的主键按照从大到小的顺序形成了一个链表，链表的首末位置分别是两条伪记录。 当我们对数据记录中id=2的一条记录进行删除时，实际上，在数据记录链表里面发生的变化如下： 可以看出，实际上并没有删除那条记录，而是通过将头信息中的delete标识位改为1、偏移量改为0来实现的，也就是说，这条记录所占用的空间并没有还给Free Space，当下一次插入id=2的记录的时候，这块空间还可以接着使用。 在这个过程中，我们加入了record_type字段，这两条伪记录和正常记录的区别之处在于数据记录的头信息里面的record_type字段，最小记录的record_type为2，最大记录的record为3，正常记录的record_type为0，record_type为1的记录，稍后我们会进行解释。 到现在为止，我们已经知道了头信息中的3个字段，分别是next_record和record_type以及delete字段，next_record保存的是下一条数据记录的真是数据的偏移量，record_type代表的是数据记录的类型，delete标示的是该字段是否被删除。除此之外，我们还需要知道记录头信息里面的另外一个字段n_owned，这个字段保存的是改组内一共有多少个数据记录，在上述删除的操作中，最大记录中该字段的变化过程如下： 关于这个初始值为何是5，后续的文章中我们会说明。至此，我们已经了解到，一个数据页，大概可以描述成如下形式： MySQL锁优化MySQL 锁分类当多个事务或者进程访问同一个资源的时候，为了保证数据的一致性，就需要用到锁机制。 从锁定资源的角度来看，MySQL 中的锁分为： 表级锁 行级锁 页面锁 表级锁：对整张表加锁。开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 行级锁：对某行记录加锁。开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 在实际开发过程中，主要会使用到表级锁和行级锁两种。既然锁是针对资源的，那么这些资源就是数据，在 MySQL 提供插件式存储引擎对数据进行存储。 插件式存储引擎的好处是，开发人员可以根据需要选择适合的存储引擎。 在众多的存储引擎中，有两种引擎被比较多的使用，他们分别是： MyISAM 存储引擎，它不支持事务、表锁设计，支持全文索引，主要面向一些在线分析处理（OLAP）数据库应用。说白了主要就是查询数据，对数据的插入，更新操作比较少。 InnoDB 存储引擎，它支持事务，其设计目标主要面向在线事务处理（OLTP）的应用。 其特点是行锁设计、支持外键，并支持类似于 Oracle 的非锁定读，即默认读取操作不会产生锁。 简单来说，就是对数据的插入，更新操作比较多。从 MySQL 数据库 5.5.8 版本开始，InnoDB 存储引擎是默认的存储引擎。 上面两种存储引擎在处理多进程数据操作的时候是如何表现的，就是我们接下来要讨论的问题。 为了让整个描述更加清晰，我们将表级锁和行级锁以及 MyISAM，InnoDB 存储引擎，就形成了一个 2*2 的象限。 2\\2 表行锁，MyISAM，InnoDB 示意图* 由于 MyISAM 存储引擎不支持行级锁，实际上后面讨论的问题会围绕三个象限的讨论展开。 从内容上来看，InnoDB 作为使用最多的存储引擎遇到的问题和值得注意的地方较多，也是本文的重点。 MyISAM 存储引擎和表级锁 首先，来看第一象限的内容： 2\\2 表行锁，MyISAM，InnoDB 示意图-第一象限* MyISAM 存储引擎支持表级锁，并且支持两种锁模式： 对 MyISAM 表的读操作（共享锁），不会阻塞其他进程对同一表的读请求，但会阻塞对其的写请求。当读锁释放后，才会执行其他进程的写操作。 对 MyISAM 表的写操作（排他锁），会阻塞其他进程对同一表的读写操作，当该锁释放后，才会执行其他进程的读写操作。 MyISAM 优化建议在使用 MyISAM 存储引擎时。执行 SQL 语句，会自动为 SELECT 语句加上共享锁，为 UDI（更新，删除，插入）操作加上排他锁。 由于这个特性在多进程并发插入同一张表的时候，就会因为排他锁而进行等待。 因此可以通过配置 concurrent_insert 系统变量，来控制其并发的插入行为。 ①concurrent_insert=0 时，不允许并发插入。 ②concurrent_insert=1 时，如果 MyISAM 表中没有空洞（即表中没有被删除的行），允许一个进程读表时，另一个进程向表的尾部插入记录（MySQL 默认设置）。 注：空洞是行记录被删除以后，只是被标记为“已删除”其存储空间没有被回收，也就是说没有被物理删除。由另外一个进程，异步对这个数据进行删除。 因为空间长度问题，删除以后的物理空间不能被新的记录所使用，从而形成了空洞。 ③concurrent_insert=2 时，无论 MyISAM 表中有没有空洞，都允许在表尾并发插入记录。 如果在数据插入的时候，没有并发删除操作的话，可以尝试把 concurrent_insert 设置为 1。 反之，在数据插入的时候有删除操作且量较大时，也就是会产生“空洞”的时候，就需要把 concurrent_insert 设置为 2。 另外，当一个进程请求某个 MyISAM 表的读锁，另一个进程也请求同一表的写锁。 即使读请求先到达，写请求后到达，写请求也会插到读请求之前。因为 MySQL 的默认设置认为，写请求比读请求重要。 我们可以通过 low_priority_updates 来调节读写行为的优先级： 数据库以读为主时，要优先保证查询性能时，可通过 low_priority_updates=1 设置读优先级高于写优先级。 数据库以写为主时，则不用设置 low_priority_updates 参数。 InnoDB 存储引擎和表级锁再来看看第二象限的内容： 2\\2 表行锁，MyISAM，InnoDB 示意图-第二象限* InnoDB 存储引擎表锁。当没有对数据表中的索引数据进行查询时，会执行表锁操作。 上面是 InnoDB 实现行锁，同时它也可以实现表锁。其方式就是意向锁（Intention Locks）。 这里介绍两种意向锁： 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前，必须先取得该表的 IS 锁。 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前，必须先取得该表的 IX 锁。 注：意向共享锁和意向排他锁是数据库主动加的，不需要我们手动处理。对于 UPDATE、DELETE 和 INSERT 语句，InnoDB 会自动给数据集加排他锁。 InnoDB表锁的实现方式：假设有一个表 test2，有两个字段分别是 id 和 name。 没有设置主键同时也没有设置任何索引（index）如下： InnoDB 表锁实现方式图 InnoDB 存储引擎和行级锁第四象限我们使用的比较多，讨论的内容也相对多些： 2\\2 表行锁，MyISAM，InnoDB 示意图-第四象限* InnoDB 存储引擎行锁，当数据查询时针对索引数据进行时，会使用行级锁。 共享锁（S）：当一个事务读取一条记录的时候，不会阻塞其他事务对同一记录的读请求，但会阻塞对其的写请求。当读锁释放后，才会执行其他事务的写操作。 例如：select … lock in share mode 排他锁（X）：当一个事务对一条记录进行写操作时，会阻塞其他事务对同一表的读写操作，当该锁释放后，才会执行其他事务的读写操作。 例如：select … for update 行锁的实现方式：假设有一个表 test1，有两个字段分别是 id 和 name。 id 作为主键同时也是 table 的索引（index）如下： InnoDB 行锁实现方式图 在高并发的情况下，多个事务同时请求更新数据，由于资源被占用等待事务增多。 如此，会造成性能问题，可以通过 innodb_lock_wait_timeout 来解决。innodb_lock_wait_timeout 是事务等待获取资源的最长时间，单位为秒。如果超过时间还未分配到资源，则会返回应用失败。 四种锁的兼容情况 共享锁，排他锁，意向共享锁，意向排他锁兼容图例 如果一个事务请求的锁模式与当前的锁兼容， InnoDB 就将请求的锁授予该事务；反之， 如果两者不兼容，该事务就要等待锁释放。 间隙锁前面谈到行锁是针对一条记录进行加锁。当对一个范围内的记录加锁的时候，我们称之为间隙锁。 当使用范围条件索引数据时，InnoDB 会对符合条件的数据索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB 也会对这个“间隙”加锁，这就是间隙锁。间隙锁和行锁合称（Next-Key锁）。 如果表中只有 11 条记录，其 id 的值分别是 1,2,…,10，11 下面的 SQL： 1Select * from table_gapwhere id &gt; 10 for update; 这是一个范围条件的检索，InnoDB 不仅会对符合条件的 id 值为 10 的记录加锁，会对 id 大于 10 的“间隙”加锁，即使大于 10 的记录不存在，例如 12，13。 InnoDB 使用间隙锁的目的： 一方面是为了防止幻读。对于上例，如果不使用间隙锁，其他事务插入了 id 大于 10 的任何记录，本事务再次执行 select 语句，就会发生幻读。 另一方面，也是为了满足恢复和复制的需要。 间隙锁图 死锁两个事务都需要获得对方持有的排他锁才能继续完成任务，这种互相等待对方释放资源的情况就是死锁。 死锁图 检测死锁：InnoDB 存储引擎能检测到死锁的循环依赖并立即返回一个错误。 死锁恢复：死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁。 InnoDB 方法是，将持有最少行级排他锁的事务回滚。在应用程序设计时必须考虑处理死锁，多数情况下重新执行因死锁回滚的事务即可。 避免死锁： 在事务开始时，如果有记录要修改，先使用 SELECT… FOR UPDATE 语句获取锁，即使这些修改语句是在后面执行。 在事务中，如果要更新记录，直接申请排他锁。而不是查询时申请共享锁、更新时再申请排他锁。 这样做会导致，当申请排他锁时，其他事务可能已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。 简单来说，如果你要更新记录要做两步操作，第一步查询，第二步更新。就不要第一步上共享锁，第二部上排他锁了，直接在第一步就上排他锁，抢占先机。 如果事务需要锁定多个表，那么尽量按照相同的顺序使用加锁语句，可以降低产生死锁的机会。 通过 SELECT … LOCK INSHARE MODE（共享锁）获取行的读锁后，如果当前事务再需要对该记录进行更新操作，则很有可能造成死锁。所以，如果要对行记录进行修改，直接上排他锁。 改变事务隔离级别（事务隔离级别在后面详细说明）。 MySQL 锁定情况的查询在实际开发中无法避免数据被锁的问题，那么我们可以通过哪些手段来查询锁呢？ 表级锁可以通过两个变量的查询： Table_locks_immediate，产生表级锁的次数。 Table_locks_waited，数显表级锁而等待的次数。 行级锁可以通过下面几个变量查询： Innodb_row_lock_current_waits，当前正在等待锁定的数量。 Innodb_row_lock_time（重要），从系统启动到现在锁定总时长。 Innodb_row_lock_time_avg（重要），每次等待所花平均时间。 Innodb_row_lock_time_max，从系统启动到现在等待最长的一次花费时间。 Innodb_row_lock_waits（重要），从系统启动到现在总共等待的次数。 MySQL 事务隔离级别 前面讲的死锁是因为并发访问数据库造成。当多个事务同时访问数据库，做并发操作的时候会发生以下问题。 脏读（dirty read），一个事务在处理过程中，读取了另外一个事务未提交的数据。未提交的数据称之为脏数据。 脏读例子 不可重复读（non-repeatable read），在事务范围内，多次查询某条记录，每次得到不同的结果。 第一个事务中的两次读取数据之间，由于第二个事务的修改，第一个事务两次读到的数据可能不一样。 不可重复读例子 幻读（phantom read），是事务非独立执行时发生的一种现象。 幻读的例子 在同一时间点，数据库允许多个并发事务，同时对数据进行读写操作，会造成数据不一致性。 四种隔离级别，解决事务并发问题对照图 隔离性就是用来防止这种数据不一致的。事务隔离根据级别不同，从低到高包括： 读未提交（read uncommitted）：它是最低的事务隔离级别，一个事务还没提交时，它做的变更就能被别的事务看到。有脏读的可能性。 读提交（read committed）：保证一个事物提交后才能被另外一个事务读取。另外一个事务不能读取该事物未提交的数据。可避免脏读的发生，但是可能会造成不可重复读。 可重复读（repeatable read MySQL 默认方式）：多次读取同一范围的数据会返回第一次查询的快照，即使其他事务对该数据做了更新修改。事务在执行期间看到的数据前后必须是一致的。 串行化（serializable）：是最可靠的事务隔离级别。“写”会加“排他锁”，“读”会加“共享锁”。 当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，所以事务执行是串行的。可避免脏读、不可重复读、幻读。 InnoDB 优化建议从锁机制的实现方面来说，InnoDB 的行级锁带来的性能损耗可能比表级锁要高一点，但在并发方面的处理能力远远优于 MyISAM 的表级锁。这也是大多数公司的 MySQL 都是使用 InnoDB 模式的原因。 但是，InnoDB 也有脆弱的一面，下面提出几个优化建议供大家参考： 尽可能让数据检索通过索引完成，避免 InnoDB 因为无法通过索引加行锁，而导致升级为表锁的情况。换句话说就是，多用行锁，少用表锁。 加索引的时候尽量准确，避免造成不必要的锁定影响其他查询。 尽量减少给予范围的数据检索（间隙锁），避免因为间隙锁带来的影响，锁定了不该锁定的记录。 尽量控制事务的大小，减少锁定的资源量和锁定时间。 尽量使用较低级别的事务隔离，减少 MySQL 因为事务隔离带来的成本。 总结 MySQL 数据库锁的思维导图 MySQL 的锁主要分为表级锁和行级锁。MyISAM 引擎使用的是表级锁，针对表级的共享锁和排他锁，可以通过 concurrent_insert 和 low_priority_updates 参数来优化。 InnoDB 支持表锁和行锁，根据索引来判断如何选择。行锁有，行共享锁和行排他锁；表锁有，意向共享锁，意向排他锁，表锁是系统自己加上的；锁范围的是间隙锁。遇到死锁，我们如何检测，恢复以及如何避免。 MySQL 有四个事务级别分别是，读未提交，读提交，可重复读，串行化。他们的隔离级别依次升高。 通过隔离级别的设置，可以避免，脏读，不可重复读和幻读的情况。最后，对于使用比较多的 InnoDB 引擎，提出了一些优化建议。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentruan.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentruan.github.io/tags/MySQL/"},{"name":"锁","slug":"锁","permalink":"https://vincentruan.github.io/tags/锁/"}]},{"title":"Linux实用的服务异常处理指南","slug":"JAVA实用的服务异常处理指南","date":"2020-02-12T02:49:31.000Z","updated":"2020-02-24T06:36:58.034Z","comments":true,"path":"2020/02/12/JAVA实用的服务异常处理指南/","link":"","permalink":"https://vincentruan.github.io/2020/02/12/JAVA实用的服务异常处理指南/","excerpt":"","text":"服务异常的处理流程 CPU负载说明针对应用程序，我们通常关注的是内核CPU调度器功能和性能。 线程的状态分析主要是分析线程的时间用在什么地方，而线程状态的分类一般分为： a. on-CPU：执行中，执行中的时间通常又分为用户态时间user和系统态时间sys。 b. off-CPU：等待下一轮上CPU，或者等待I/O、锁、换页等等，其状态可以细分为可执行、匿名换页、睡眠、锁、空闲等状态。 如果大量时间花在CPU上，对CPU的剖析能够迅速解释原因；如果系统时间大量处于off-cpu状态，定位问题就会费时很多。但是仍然需要清楚一些概念： 处理器 核 硬件线程 CPU内存缓存 时钟频率 每指令周期数CPI和每周期指令数IPC CPU指令 使用率 用户时间／内核时间 调度器 运行队列 抢占 多进程 多线程 字长 分析工具 工具 描述 uptime 平均负载 vmstat 包括系统范围的cpu平均负载 mpstat 查看所有cpu核信息 top 监控每个进程cpu用量 sar -u 查看cpu信息 pidstat 每个进程cpu用量分解 perf cpu剖析和跟踪，性能计数分析 说明: uptime,vmstat,mpstat,top,pidstat只能查询到cpu及负载的的使用情况。 perf可以跟着到进程内部具体函数耗时情况，并且可以指定内核函数进行统计，指哪打哪。 使用方式1234567891011121314//查看系统cpu使用情况top//查看所有cpu核信息mpstat -P ALL 1//查看cpu使用情况以及平均负载vmstat 1//进程cpu的统计信息pidstat -u 1 -p pid//跟踪进程内部函数级cpu使用情况perf top -p pid -e cpu-clock 查看机器 cpu 的负载1top -b -n 1 |grep java|awk '&#123;print \"VIRT:\"$5,\"RES:\"$6,\"cpu:\"$9\"%\",\"mem:\"$10\"%\"&#125;' 查找 cpu 占用率高的线程1234top -p 25603 -Hprintf 0x%x 25842jstack 25603 | grep 0x64f2cat /proc/interrupts （1）CPU（2）Memory（3）IO（4）Network 可以从以下几个方面监控CPU的信息：（1）中断；（2）上下文切换；（3）可运行队列；（4）CPU 利用率 内存说明内存是为提高效率而生，实际分析问题的时候，内存出现问题可能不只是影响性能，而是影响服务或者引起其他问题。同样对于内存有些概念需要清楚： 主存 虚拟内存 常驻内存 地址空间 OOM 页缓存 缺页 换页 交换空间 交换 用户分配器libc、glibc、libmalloc和mtmalloc LINUX内核级SLUB分配器 分析工具 工具 描述 free 缓存容量统计信息 vmstat 虚拟内存统计信息 top 监视每个进程的内存使用情况 pidstat 显示活动进程的内存使用统计 pmap 查看进程的内存映像信息 sar -r 查看内存 dtrace 动态跟踪 valgrind 分析程序性能及程序中的内存泄露错误 说明： free,vmstat,top,pidstat,pmap只能统计内存信息以及进程的内存使用情况。 valgrind可以分析内存泄漏问题。 dtrace动态跟踪。需要对内核函数有很深入的了解，通过D语言编写脚本完成跟踪。 使用方式1234567891011121314151617//查看系统内存使用情况free -m//虚拟内存统计信息vmstat 1//查看系统内存情况top//1s采集周期，获取内存的统计信息pidstat -p pid -r 1//查看进程的内存映像信息pmap -d pid//检测程序内存问题valgrind --tool=memcheck --leak-check=full --log-file=./log.txt ./程序名 系统内存free 命令123456[root@server ~]# free total used free shared buffers cachedMem: 3266180 3250000 10000 0 201000 3002000-/+ buffers/cache: 47000 3213000Swap: 2048276 80160 1968116 这里的默认显示单位是kb。各项指标解释 total:总计物理内存的大小。 used:已使用多大。 free:可用有多少。 Shared:多个进程共享的内存总额。 buffers: 磁盘缓存的大小。 cache:磁盘缓存的大小。 -/+ buffers/cached): used:已使用多大，free:可用有多少。 已用内存 = 系统used memory - buffers - cached（47000 = 3250000-201000-3002000） 可用内存 = 系统free memory + buffers + cached（3213000 = 10000+201000+3002000） 什么是buffer/cache？ buffer 指 Linux 内存的：Buffer cache，缓冲区缓 cache 指 Linux内存中的：Page cache，页面缓存 page cachepage cache 主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有 read／write 操作的时候。如果你仔细想想的话，作为可以映射文件到内存的系统调用：mmap是不是很自然的也应该用到 page cache？在当前的系统实现里，page cache 也被作为其它文件类型的缓存设备来用，所以事实上 page cache 也负责了大部分的块设备文件的缓存工作。 buffer cachebuffer cache 主要用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。这意味着某些对块的操作会使用 buffer cache 进行缓存，比如我们在格式化文件系统的时候。一般情况下两个缓存系统是一起配合使用的，比如当我们对一个文件进行写操作的时候，page cache 的内容会被改变，而 buffer cache 则可以用来将 page 标记为不同的缓冲区，并记录是哪一个缓冲区被修改了。这样，内核在后续执行脏数据的回写（writeback）时，就不用将整个 page 写回，而只需要写回修改的部分即可。 在当前的内核中，page cache 是针对内存页的缓存，说白了就是，如果有内存是以page进行分配管理的，都可以使用page cache作为其缓存来管理使用。当然，不是所有的内存都是以页（page）进行管理的，也有很多是针对块（block）进行管理的，这部分内存使用如果要用到 cache 功能，则都集中到buffer cache中来使用。（从这个角度出发，是不是buffer cache改名叫做block cache更好？）然而，也不是所有块（block）都有固定长度，系统上块的长度主要是根据所使用的块设备决定的，而页长度在X86上无论是32位还是64位都是4k。 系统如何回收cache？Linux内核会在内存将要耗尽的时候，触发内存回收的工作，以便释放出内存给急需内存的进程使用。一般情况下，这个操作中主要的内存释放都来自于对buffer／cache的释放。尤其是被使用更多的cache空间。既然它主要用来做缓存，只是在内存够用的时候加快进程对文件的读写速度，那么在内存压力较大的情况下，当然有必要清空释放cache，作为free空间分给相关进程使用。所以一般情况下，我们认为buffer/cache空间可以被释放，这个理解是正确的。 但是这种清缓存的工作也并不是没有成本。理解cache是干什么的就可以明白清缓存必须保证cache中的数据跟对应文件中的数据一致，才能对cache进行释放。所以伴随着cache清除的行为的，一般都是系统IO飙高。因为内核要对比cache中的数据和对应硬盘文件上的数据是否一致，如果不一致需要写回，之后才能回收。 在系统中除了内存将被耗尽的时候可以清缓存以外，我们还可以人工触发缓存清除的操作。 进程内存进程内存统计/proc/[pid]/status通过/proc//status可以查看进程的内存使用情况，包括虚拟内存大小（VmSize），物理内存大小（VmRSS），数据段大小（VmData），栈的大小（VmStk），代码段的大小（VmExe），共享库的代码段大小（VmLib）等等。 cat /proc/[pid]/status 1234567891011121314151617Name: gedit /*进程的程序名*/State: S (sleeping) /*进程的状态信息,具体参见http://blog.chinaunix.net/u2/73528/showart_1106510.html*/Tgid: 9744 /*线程组号*/Pid: 9744 /*进程pid*/PPid: 7672 /*父进程的pid*/TracerPid: 0 /*跟踪进程的pid*/VmPeak: 60184 kB /*进程地址空间的大小*/VmSize: 60180 kB /*进程虚拟地址空间的大小reserved_vm：进程在预留或特殊的内存间的物理页*/VmLck: 0 kB /*进程已经锁住的物理内存的大小.锁住的物理内存不能交换到硬盘*/VmHWM: 18020 kB /*文件内存映射和匿名内存映射的大小*/VmRSS: 18020 kB /*应用程序正在使用的物理内存的大小，就是用ps命令的参数rss的值 (rss)*/VmData: 12240 kB /*程序数据段的大小（所占虚拟内存的大小），存放初始化了的数据*/VmStk: 84 kB /*进程在用户态的栈的大小*/VmExe: 576 kB /*程序所拥有的可执行虚拟内存的大小,代码段,不包括任务使用的库 */VmLib: 21072 kB /*被映像到任务的虚拟内存空间的库的大小*/VmPTE: 56 kB /*该进程的所有页表的大小*/Threads: 1 /*共享使用该信号描述符的任务的个数*/ JVM 内存分配java内存组成介绍：堆(Heap)和非堆(Non-heap)内存 按照官方的说法：“Java 虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在 Java 虚拟机启动时创建的。”“在JVM中堆之外的内存称为非堆内存(Non-heap memory)”。可以看出JVM主要管理两种类型的内存：堆和非堆。 简单来说堆就是Java代码可及的内存，是留给开发人员使用的；非堆就是JVM留给 自己用的，所以方法区、JVM内部处理或优化所需的内存(如JIT编译后的代码缓存)、每个类结构(如运行时常数池、字段和方法数据)以及方法和构造方法 的代码都在非堆内存中。 JVM本身需要的内存，包括其加载的第三方库以及这些库分配的内存 NIO的DirectBuffer是分配的native memory 内存映射文件，包括JVM加载的一些JAR和第三方库，以及程序内部用到的。上面 pmap 输出的内容里，有一些静态文件所占用的大小不在Java的heap里，因此作为一个Web服务器，赶紧把静态文件从这个Web服务器中人移开吧，放到nginx或者CDN里去吧。 JIT， JVM会将Class编译成native代码，这些内存也不会少，如果使用了Spring的AOP，CGLIB会生成更多的类，JIT的内存开销也会随之变大，而且Class本身JVM的GC会将其放到Perm Generation里去，很难被回收掉，面对这种情况，应该让JVM使用ConcurrentMarkSweep GC，并启用这个GC的相关参数允许将不使用的class从Perm Generation中移除， 参数配置： -XX:+UseConcMarkSweepGC -X:+CMSPermGenSweepingEnabled -X:+CMSClassUnloadingEnabled，如果不需要移除而Perm Generation空间不够，可以加大一点： -X:PermSize=256M -X:MaxPermSize=512M JNI，一些JNI接口调用的native库也会分配一些内存，如果遇到JNI库的内存泄露，可以使用valgrind等内存泄露工具来检测 线程栈，每个线程都会有自己的栈空间，如果线程一多，这个的开销就很明显了 jmap/jstack 采样，频繁的采样也会增加内存占用，如果你有服务器健康监控，记得这个频率别太高，否则健康监控变成致病监控了。 方法区也称”永久代” 、“非堆”，它用于存储虚拟机加载的类信息、常量、静态变量、是各个线程共享的内存区域。默认最小值为16MB，最大值为64MB，可以通过-XX:PermSize 和 -XX:MaxPermSize 参数限制方法区的大小。 运行时常量池：是方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译器生成的各种符号引用，这部分内容将在类加载后放到方法区的运行时常量池中。 虚拟机栈描述的是java 方法执行的内存模型：每个方法被执行的时候 都会创建一个“栈帧”用于存储局部变量表(包括参数)、操作栈、方法出口等信息。每个方法被调用到执行完的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。声明周期与线程相同，是线程私有的。 局部变量表存放了编译器可知的各种基本数据类型(boolean、byte、char、short、int、float、long、double)、对象引用(引用指针，并非对象本身)，其中64位长度的long和double类型的数据会占用2个局部变量的空间，其余数据类型只占1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量是完全确定的，在运行期间栈帧不会改变局部变量表的大小空间。 本地方法栈与虚拟机栈基本类似，区别在于虚拟机栈为虚拟机执行的java方法服务，而本地方法栈则是为Native方法服务。 堆也叫做java 堆、GC堆是java虚拟机所管理的内存中最大的一块内存区域，也是被各个线程共享的内存区域，在JVM启动时创建。该内存区域存放了对象实例及数组(所有new的对象)。其大小通过-Xms(最小值)和-Xmx(最大值)参数设置，-Xms为JVM启动时申请的最小内存，默认为操作系统物理内存的1/64但小于1G，-Xmx为JVM可申请的最大内存，默认为物理内存的1/4但小于1G，默认当空余堆内存小于40%时，JVM会增大Heap到-Xmx指定的大小，可通过-XX:MinHeapFreeRation=来指定这个比列；当空余堆内存大于70%时，JVM会减小heap的大小到-Xms指定的大小，可通过XX:MaxHeapFreeRation=来指定这个比列，对于运行系统，为避免在运行时频繁调整Heap的大小，通常-Xms与-Xmx的值设成一样。 由于现在收集器都是采用分代收集算法，堆被划分为新生代和老年代。新生代主要存储新创建的对象和尚未进入老年代的对象。老年代存储经过多次新生代GC(Minor GC)任然存活的对象。 程序计数器是最小的一块内存区域，它的作用是当前线程所执行的字节码的行号指示器，在虚拟机的模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、异常处理、线程恢复等基础功能都需要依赖计数器完成。 直接内存直接内存并不是虚拟机内存的一部分，也不是Java虚拟机规范中定义的内存区域。jdk1.4中新加入的NIO，引入了通道与缓冲区的IO方式，它可以调用Native方法直接分配堆外内存，这个堆外内存就是本机内存，不会影响到堆内存的大小。 JVM 内存分析查看 JVM 堆内存情况jmap -heap [pid] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@server ~]$ jmap -heap 837Attaching to process ID 837, please wait...Debugger attached successfully.Server compiler detected.JVM version is 24.71-b01using thread-local object allocation.Parallel GC with 4 thread(s)//GC 方式Heap Configuration: //堆内存初始化配置 MinHeapFreeRatio = 0 //对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40) MaxHeapFreeRatio = 100 //对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70) MaxHeapSize = 2082471936 (1986.0MB) //对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小 NewSize = 1310720 (1.25MB)//对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小 MaxNewSize = 17592186044415 MB//对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小 OldSize = 5439488 (5.1875MB)//对应jvm启动参数-XX:OldSize=&lt;value&gt;:设置JVM堆的‘老生代’的大小 NewRatio = 2 //对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率 SurvivorRatio = 8 //对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值 PermSize = 21757952 (20.75MB) //对应jvm启动参数-XX:PermSize=&lt;value&gt;:设置JVM堆的‘永生代’的初始大小 MaxPermSize = 85983232 (82.0MB)//对应jvm启动参数-XX:MaxPermSize=&lt;value&gt;:设置JVM堆的‘永生代’的最大大小 G1HeapRegionSize = 0 (0.0MB)Heap Usage://堆内存使用情况PS Young GenerationEden Space://Eden区内存分布 capacity = 33030144 (31.5MB)//Eden区总容量 used = 1524040 (1.4534378051757812MB) //Eden区已使用 free = 31506104 (30.04656219482422MB) //Eden区剩余容量 4.614088270399305% used //Eden区使用比率From Space: //其中一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% usedTo Space: //另一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% usedPS Old Generation //当前的Old区内存分布 capacity = 86507520 (82.5MB) used = 0 (0.0MB) free = 86507520 (82.5MB) 0.0% usedPS Perm Generation//当前的 “永生代” 内存分布 capacity = 22020096 (21.0MB) used = 2496528 (2.3808746337890625MB) free = 19523568 (18.619125366210938MB) 11.337498256138392% used670 interned Strings occupying 43720 bytes. 关于这里的几个generation网上资料一大把就不细说了，这里算一下求和可以得知前者总共给Java环境分配了644M的内存，而ps输出的VSZ和RSS分别是7.4G和2.9G，这到底是怎么回事呢？前面jmap输出的内容里，MaxHeapSize 是在命令行上配的，-Xmx4096m，这个java程序可以用到的最大堆内存。VSZ是指已分配的线性空间大小，这个大小通常并不等于程序实际用到的内存大小，产生这个的可能性很多，比如内存映射，共享的动态库，或者向系统申请了更多的堆，都会扩展线性空间大小，要查看一个进程有哪些内存映射，可以使用 pmap 命令来查看：pmap -x [pid] 12345678910111213141516[root@server ~]$ pmap -x 837837: javaAddress Kbytes RSS Dirty Mode Mapping0000000040000000 36 4 0 r-x-- java0000000040108000 8 8 8 rwx-- java00000000418c9000 13676 13676 13676 rwx-- [ anon ]00000006fae00000 83968 83968 83968 rwx-- [ anon ]0000000700000000 527168 451636 451636 rwx-- [ anon ]00000007202d0000 127040 0 0 ----- [ anon ]......00007f55ee124000 4 4 0 r-xs- az.png00007fff017ff000 4 4 0 r-x-- [ anon ]ffffffffff600000 4 0 0 r-x-- [ anon ]---------------- ------ ------ ------total kB 7796020 3037264 3023928 这里可以看到很多anon，这些表示这块内存是由mmap分配的。 RSZ是Resident Set Size，常驻内存大小，即进程实际占用的物理内存大小， 在现在这个例子当中，RSZ和实际堆内存占用差了2.3G，这2.3G的内存组成分别为： 查看 JVM 堆各个分区的内存情况jstat -gcutil [pid] 1234[root@server ~]$ jstat -gcutil 837 1000 20 S0 S1 E O P YGC YGCT FGC FGCT GCT 0.00 80.43 24.62 87.44 98.29 7101 119.652 40 19.719 139.371 0.00 80.43 33.14 87.44 98.29 7101 119.652 40 19.719 139.371 分析 JVM 堆内存中的对象查看存活的对象统计jmap -histo:live [pid] dump 内存jmap -dump:format=b,file=heapDump [pid] 然后用jhat命令可以参看jhat -port 5000 heapDump在浏览器中访问：http://localhost:5000/ 查看详细信息 磁盘IO说明磁盘通常是计算机最慢的子系统，也是最容易出现性能瓶颈的地方，因为磁盘离 CPU 距离最远而且 CPU 访问磁盘要涉及到机械操作，比如转轴、寻轨等。访问硬盘和访问内存之间的速度差别是以数量级来计算的，就像1天和1分钟的差别一样。要监测 IO 性能，有必要了解一下基本原理和 Linux 是如何处理硬盘和内存之间的 IO 的。 在理解磁盘IO之前，同样我们需要理解一些概念，例如： 文件系统 VFS 文件系统缓存 页缓存page cache 缓冲区高速缓存buffer cache 目录缓存 inode inode缓存 noop调用策略 分析工具 工具 描述 iostat 磁盘详细统计信息 iotop 按进程查看磁盘IO的使用情况 pidstat 按进程查看磁盘IO的使用情况 perf 动态跟踪工具 使用方式12345678910111213//查看系统io信息iotop//统计io详细信息iostat -d -x -k 1 10//查看进程级io的信息pidstat -d 1 -p pid//查看系统IO的请求，比如可以在发现系统IO异常时，可以使用该命令进行调查，就能指定到底是什么原因导致的IO异常perf record -e block:block_rq_issue -ag^Cperf report 网络说明网络的监测是所有 Linux 子系统里面最复杂的，有太多的因素在里面，比如：延迟、阻塞、冲突、丢包等，更糟的是与 Linux 主机相连的路由器、交换机、无线信号都会影响到整体网络并且很难判断是因为 Linux 网络子系统的问题还是别的设备的问题，增加了监测和判断的复杂度。现在我们使用的所有网卡都称为自适应网卡，意思是说能根据网络上的不同网络设备导致的不同网络速度和工作模式进行自动调整。 分析工具 工具 描述 ping 主要透过 ICMP 封包 来进行整个网络的状况报告 traceroute 用来检测发出数据包的主机到目标主机之间所经过的网关数量的工具 netstat 用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况 ss 可以用来获取socket统计信息，而且比netstat更快速更高效 host 可以用来查出某个主机名的 IP,跟nslookup作用一样 tcpdump 是以包为单位进行输出的，阅读起来不是很方便 tcpflow 是面向tcp流的, 每个tcp传输会保存成一个文件,很方便的查看 sar -n DEV 网卡流量情况 sar -n SOCK 查询网络以及tcp，udp状态信息 使用方式1234567891011121314151617181920212223242526272829303132//显示网络统计信息netstat -s//显示当前UDP连接状况netstat -nu//显示UDP端口号的使用情况netstat -apu//统计机器中网络连接各个状态个数netstat -a | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;'//显示TCP连接ss -t -a//显示sockets摘要信息ss -s//显示所有udp socketsss -u -a//tcp,etcp状态sar -n TCP,ETCP 1//查看网络IOsar -n DEV 1//抓包以包为单位进行输出tcpdump -i eth1 host 192.168.1.1 and port 80 //抓包以流为单位显示数据内容tcpflow -cp host 192.168.1.1 服务指标响应时间(RT)响应时间是指系统对请求作出响应的时间。直观上看，这个指标与人对软件性能的主观感受是非常一致的，因为它完整地记录了整个计算机系统处理请求的时间。由于一个系统通常会提供许多功能，而不同功能的处理逻辑也千差万别，因而不同功能的响应时间也不尽相同，甚至同一功能在不同输入数据的情况下响应时间也不相同。所以，在讨论一个系统的响应时间时，人们通常是指该系统所有功能的平均时间或者所有功能的最大响应时间。当然，往往也需要对每个或每组功能讨论其平均响应时间和最大响应时间。 对于单机的没有并发操作的应用系统而言，人们普遍认为响应时间是一个合理且准确的性能指标。需要指出的是，响应时间的绝对值并不能直接反映软件的性能的高低，软件性能的高低实际上取决于用户对该响应时间的接受程度。对于一个游戏软件来说，响应时间小于100毫秒应该是不错的，响应时间在1秒左右可能属于勉强可以接受，如果响应时间达到3秒就完全难以接受了。而对于编译系统来说，完整编译一个较大规模软件的源代码可能需要几十分钟甚至更长时间，但这些响应时间对于用户来说都是可以接受的。 吞吐量(Throughput)吞吐量是指系统在单位时间内处理请求的数量。对于无并发的应用系统而言，吞吐量与响应时间成严格的反比关系，实际上此时吞吐量就是响应时间的倒数。前面已经说过，对于单用户的系统，响应时间（或者系统响应时间和应用延迟时间）可以很好地度量系统的性能，但对于并发系统，通常需要用吞吐量作为性能指标。 对于一个多用户的系统，如果只有一个用户使用时系统的平均响应时间是t，当有你n个用户使用时，每个用户看到的响应时间通常并不是n×t，而往往比n×t小很多（当然，在某些特殊情况下也可能比n×t大，甚至大很多）。这是因为处理每个请求需要用到很多资源，由于每个请求的处理过程中有许多不走难以并发执行，这导致在具体的一个时间点，所占资源往往并不多。也就是说在处理单个请求时，在每个时间点都可能有许多资源被闲置，当处理多个请求时，如果资源配置合理，每个用户看到的平均响应时间并不随用户数的增加而线性增加。实际上，不同系统的平均响应时间随用户数增加而增长的速度也不大相同，这也是采用吞吐量来度量并发系统的性能的主要原因。一般而言，吞吐量是一个比较通用的指标，两个具有不同用户数和用户使用模式的系统，如果其最大吞吐量基本一致，则可以判断两个系统的处理能力基本一致。 并发用户数并发用户数是指系统可以同时承载的正常使用系统功能的用户的数量。与吞吐量相比，并发用户数是一个更直观但也更笼统的性能指标。实际上，并发用户数是一个非常不准确的指标，因为用户不同的使用模式会导致不同用户在单位时间发出不同数量的请求。一网站系统为例，假设用户只有注册后才能使用，但注册用户并不是每时每刻都在使用该网站，因此具体一个时刻只有部分注册用户同时在线，在线用户就在浏览网站时会花很多时间阅读网站上的信息，因而具体一个时刻只有部分在线用户同时向系统发出请求。这样，对于网站系统我们会有三个关于用户数的统计数字：注册用户数、在线用户数和同时发请求用户数。由于注册用户可能长时间不登陆网站，使用注册用户数作为性能指标会造成很大的误差。而在线用户数和同事发请求用户数都可以作为性能指标。相比而言，以在线用户作为性能指标更直观些，而以同时发请求用户数作为性能指标更准确些。 QPS每秒查询率(Query Per Second)每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。对应fetches/sec，即每秒的响应请求数，也即是最大吞吐能力。 从以上概念来看吞吐量和响应时间是衡量系统性能的重要指标，QPS虽然和吞吐量的计量单位不同，但应该是成正比的，任何一个指标都可以含量服务器的并行处理能力。当然Throughput更关心数据量，QPS更关心处理笔数。 CPU利用率CPU Load Average &lt; CPU个数 核数 0.7 Context Switch Rate就是Process（Thread）的切换，如果切换过多，会让CPU忙于切换，也会导致影响吞吐量。《高性能服务器架构 》这篇文章的第2节就是说的是这个问题的。究竟多少算合适？google了一大圈，没有一个确切的解释。Context Switch大体上由两个部分组成：中断和进程(包括线程)切换，一次中断（Interrupt）会引起一次切换，进程（线程）的创建、激活之类的也会引起一次切换。CS的值也和TPS（Transaction Per Second）相关的，假设每次调用会引起N次CS，那么就可以得出 Context Switch Rate = Interrupt Rate + TPS* N CSR减掉IR，就是进程/线程的切换，假如主进程收到请求交给线程处理，线程处理完毕归还给主进程，这里就是2次切换。也可以用CSR、IR、TPS的值代入公式中，得出每次事物导致的切换数。因此，要降低CSR，就必须在每个TPS引起的切换上下功夫，只有N这个值降下去，CSR就能降低，理想情况下N=0，但是无论如何如果N &gt;= 4，则要好好检查检查。另外网上说的CSR&lt;5000，我认为标准不该如此单一。 这三个指标在 LoadRunner 中可以监控到；另外，在 linux 中，也可以用 vmstat 查看r（Load Arerage），in（Interrupt）和cs（Context Switch） 工具 uptime 1234567uptime 08:21:34 up 36 min, 2 users, load average: 0.00, 0.00, 0.00 #当前服务器时间： 08:21:34#当前服务器运行时长 36 min#当前用户数 2 users#当前的负载均衡 load average 0.00, 0.00, 0.00，分别取1min,5min,15min的均值 dmesg dmesg命令用于显示开机信息。 kernel会将开机信息存储在ring buffer中。您若是开机时来不及查看信息，可利用dmesg来查看。开机信息亦保存在/var/log目录中，名称为dmesg的文件里。 语法 1dmesg [-cn][-s &lt;缓冲区大小&gt;] 参数说明： -c 显示信息后，清除ring buffer中的内容。 -s&lt;缓冲区大小&gt; 预设置为8196，刚好等于ring buffer的大小。 -n 设置记录信息的层级。 top查看进程活动状态以及一些系统状况 vmstat查看系统状态、硬件和系统信息等 iostat查看CPU 负载，硬盘状况 sar综合工具，查看系统状况 mpstat查看多处理器状况 netstat查看网络状况 iptraf实时网络状况监测 tcpdump抓取网络数据包，详细分析 mpstat查看多处理器状况 tcptrace数据包分析工具 netperf网络带宽工具 dstat综合工具，综合了 vmstat, iostat, ifstat, netstat 等多个信息 系统负载说明Load 就是对计算机干活多少的度量（WikiPedia：the system Load is a measure of the amount of work that a compute system is doing）简单的说是进程队列的长度。Load Average 就是一段时间（1分钟、5分钟、15分钟）内平均Load。 分析工具 工具 描述 top 查看系统负载情况 uptime 查看系统负载情况 strace 统计跟踪内核态信息 vmstat 查看负载情况 dmesg 查看内核日志信息 使用方式123456789101112131415//查看负载情况uptimetopvmstat//统计系统调用耗时情况strace -c -p pid//跟踪指定的系统操作例如epoll_waitstrace -T -e epoll_wait -p pid//查看内核日志信息dmesg Reference http://tmq.qq.com/2016/07/it-is-necessary-to-know-the-background-performance-test/ https://www.ibm.com/developerworks/java/library/j-nativememory-linux/ http://www.oracle.com/technetwork/java/javase/index-137495.html http://www.hollischuang.com/archives/303 https://www.jianshu.com/p/0bbac570fa4c","categories":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/tags/Linux/"},{"name":"异常处理","slug":"异常处理","permalink":"https://vincentruan.github.io/tags/异常处理/"},{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/tags/Java/"}]},{"title":"操作系统基础概念简述","slug":"操作系统基础概念简述","date":"2020-02-11T13:35:14.000Z","updated":"2020-02-21T03:03:52.519Z","comments":true,"path":"2020/02/11/操作系统基础概念简述/","link":"","permalink":"https://vincentruan.github.io/2020/02/11/操作系统基础概念简述/","excerpt":"","text":"操作系统概念大部分操作系统提供了特定的基础概念和抽象，例如进程、地址空间、文件等，它们是需要理解的核心内容。下面我们会简要介绍一些基本概念，为了说明这些概念，我们会不时的从 UNIX 中提出示例，相同的示例也会存在于其他系统中，我们后面会进行介绍。 进程操作系统一个很关键的概念就是 进程(Process)。进程的本质就是操作系统执行的一个程序。与每个进程相关的是地址空间(address space)，这是从某个最小值的存储位置(通常是零)到某个最大值的存储位置的列表。在这个地址空间中，进程可以进行读写操作。地址空间中存放有可执行程序，程序所需要的数据和它的栈。与每个进程相关的还有资源集，通常包括寄存器(registers)（寄存器一般包括程序计数器(program counter)和堆栈指针(stack pointer)）、打开文件的清单、突发的报警、有关的进程清单和其他需要执行程序的信息。你可以把进程看作是容纳运行一个程序所有信息的一个容器。 对进程建立一种直观感觉的方式是考虑建立一种多程序的系统。考虑下面这种情况：用户启动一个视频编辑程序，指示它按照某种格式转换视频，然后再去浏览网页。同时，一个检查电子邮件的后台进程被唤醒并开始运行，这样，我们目前就会有三个活动进程：视频编辑器、Web 浏览器和电子邮件接收程序。操作系统周期性的挂起一个进程然后启动运行另一个进程，这可能是由于过去一两秒钟程序用完了 CPU 分配的时间片，而 CPU 转而运行另外的程序。 像这样暂时中断进程后，下次应用程序在此启动时，必须要恢复到与中断时刻相同的状态，这在我们用户看起来是习以为常的事情，但是操作系统内部却做了巨大的事情。这就像和足球比赛一样，一场完美精彩的比赛是可以忽略裁判的存在的。这也意味着在挂起时该进程的所有信息都要被保存下来。例如，进程可能打开了多个文件进行读取。与每个文件相关联的是提供当前位置的指针（即下一个需要读取的字节或记录的编号）。当进程被挂起时，必须要保存这些指针，以便在重新启动进程后执行的 read调用将能够正确的读取数据。在许多操作系统中，与一个进程有关的所有信息，除了该进程自身地址空间的内容以外，均存放在操作系统的一张表中，称为 进程表(process table)，进程表是数组或者链表结构，当前存在每个进程都要占据其中的一项。 所以，一个挂起的进程包括：进程的地址空间（往往称作磁芯映像， core image，纪念过去的磁芯存储器），以及对应的进程表项（其中包括寄存器以及稍后启动该进程所需要的许多其他信息）。 与进程管理有关的最关键的系统调用往往是决定着进程的创建和终止的系统调用。考虑一个典型的例子，有一个称为 命令解释器(command interpreter) 或 shell 的进程从终端上读取命令。此时，用户刚键入一条命令要求编译一个程序。shell 必须先创建一个新进程来执行编译程序，当编译程序结束时，它执行一个系统调用来终止自己的进程。 如果一个进程能够创建一个或多个进程（称为子进程），而且这些进程又可以创建子进程，则很容易找到进程数，如下所示 上图表示一个进程树的示意图，进程 A 创建了两个子进程 B 和进程 C，子进程 B 又创建了三个子进程 D、E、F。 合作完成某些作业的相关进程经常需要彼此通信来完成作业，这种通信称为进程间通信(interprocess communication)。我们在后面会探讨进程间通信。 其他可用的进程系统调用包括：申请更多的内存（或释放不再需要的内存），等待一个子进程结束，用另一个程序覆盖该程序。 有时，需要向一个正在运行的进程传递信息，而该进程并没有等待接收信息。例如，一个进程通过网络向另一台机器上的进程发送消息进行通信。为了保证一条消息或消息的应答不丢失。发送者要求它所在的操作系统在指定的若干秒后发送一个通知，这样如果对方尚未收到确认消息就可以进行重新发送。在设定该定时器后，程序可以继续做其他工作。 在限定的时间到达后，操作系统会向进程发送一个 警告信号(alarm signal)。这个信号引起该进程暂时挂起，无论该进程正在做什么，系统将其寄存器的值保存到堆栈中，并开始重新启动一个特殊的信号处理程，比如重新发送可能丢失的消息。这些信号是软件模拟的硬件中断，除了定时器到期之外，该信号可以通过各种原因产生。许多由硬件检测出来的陷阱，如执行了非法指令或使用了无效地址等，也被转换成该信号并交给这个进程。 系统管理器授权每个进程使用一个给定的 UID(User IDentification)。每个启动的进程都会有一个操作系统赋予的 UID，子进程拥有与父进程一样的 UID。用户可以是某个组的成员，每个组也有一个 GID(Group IDentification)。 在 UNIX 操作系统中，有一个 UID 是 超级用户(superuser)，或者 Windows 中的管理员(administrator)，它具有特殊的权利，可以违背一些保护规则。在大型系统中，只有系统管理员掌握着那些用户可以称为超级用户。 地址空间每台计算机都有一些主存用来保存正在执行的程序。在一个非常简单的操作系统中，仅仅有一个应用程序运行在内存中。为了运行第二个应用程序，需要把第一个应用程序移除才能把第二个程序装入内存。 复杂一些的操作系统会允许多个应用程序同时装入内存中运行。为了防止应用程序之间相互干扰（包括操作系统），需要有某种保护机制。虽然此机制是在硬件中实现，但却是由操作系统控制的。 上述观点涉及对计算机主存的管理和保护。另一种同等重要并与存储器有关的内容是管理进程的地址空间。通常，每个进程有一些可以使用的地址集合，典型值从 0 开始直到某个最大值。一个进程可拥有的最大地址空间小于主存。在这种情况下，即使进程用完其地址空间，内存也会有足够的内存运行该进程。 但是，在许多 32 位或 64 位地址的计算机中，分别有 2^32 或 2^64 字节的地址空间。如果一个进程有比计算机拥有的主存还大的地址空间，而且该进程希望使用全部的内存，那该怎么处理？在早期的计算机中是无法处理的。但是现在有了一种虚拟内存的技术，正如前面讲到过的，操作系统可以把部分地址空间装入主存，部分留在磁盘上，并且在需要时来回交换它们。 文件几乎所有操作系统都支持的另一个关键概念就是文件系统。如前所述，操作系统的一项主要功能是屏蔽磁盘和其他 I/O 设备的细节特性，给程序员提供一个良好、清晰的独立于设备的抽象文件模型。创建文件、删除文件、读文件和写文件 都需要系统调用。在文件可以读取之前，必须先在磁盘上定位和打开文件，在文件读过之后应该关闭该文件，有关的系统调用则用于完成这类操作。 为了提供保存文件的地方，大多数个人计算机操作系统都有目录(directory) 的概念，从而可以把文件分组。比如，学生可以给每个课程都创建一个目录，用于保存该学科的资源，另一个目录可以存放电子邮件，再有一个目录可以存放万维网主页。这就需要系统调用创建和删除目录、将已有文件放入目录中，从目录中删除文件等。目录项可以是文件或者目录，目录和目录之间也可以嵌套，这样就产生了文件系统 进程和文件层次都是以树状的结构组织，但这两种树状结构有不少不同之处。一般进程的树状结构层次不深（很少超过三层），而文件系统的树状结构要深一些，通常会到四层甚至五层。进程树层次结构是暂时的，通常最多存在几分钟，而目录层次则可能存在很长时间。进程和文件在权限保护方面也是有区别的。一般来说，父进程能控制和访问子进程，而在文件和目录中通常存在一种机制，使文件所有者之外的其他用户也能访问该文件。 目录层结构中的每一个文件都可以通过从目录的顶部即 根目录(Root directory) 开始的路径名(path name) 来确定。绝对路径名包含了从根目录到该文件的所有目录清单，它们之间用斜杠分隔符分开，在上面的大学院系文件系统中，文件 CS101 的路径名是 /Faculty/Prof.Brown/Courses/CS101。最开始的斜杠分隔符代表的是根目录 /，也就是文件系统的绝对路径。 出于历史原因，Windows 下面的文件系统以 \\ 来作为分隔符，但是 Linux 会以 / 作为分隔符。 在上面的系统中，每个进程会有一个 工作目录(working directory)，对于没有以斜线开头给出绝对地址的路径，将在这个工作目录下寻找。如果 /Faculty/Prof.Brown 是工作目录，那么 /Courses/CS101 与上面给定的绝对路径名表示的是同一个文件。进程可以通过使用系统调用指定新的工作目录，从而变更其工作目录。 在读写文件之前，首先需要打开文件，检查其访问权限。若权限许可，系统将返回一个小整数，称作文件描述符(file descriptor)，供后续操作使用。若禁止访问，系统则返回一个错误码。 在 UNIX 中，另一个重要的概念是 特殊文件(special file)。提供特殊文件是为了使 I/O 设备看起来像文件一般。这样，就像使用系统调用读写文件一样，I/O 设备也可以通过同样的系统调用进行读写。特殊文件有两种，一种是块儿特殊文件(block special file) 和 字符特殊文件(character special file)。块特殊文件指那些由可随机存取的块组成的设备，如磁盘等。比如打开一个块特殊文件，然后读取第4块，程序可以直接访问设备的第4块而不必考虑存放在该文件的文件系统结构。类似的，字符特殊文件用于打印机、调制解调器和其他接受或输出字符流的设备。按照惯例，特殊文件保存在 /dev 目录中。例如，/devv/lp 是打印机。 还有一种与进程和文件相关的特性是管道，管道(pipe) 是一种虚文件，他可以连接两个进程 如果 A 和 B 希望通过管道对话，他们必须提前设置管道。当进程 A 相对进程 B 发送数据时，它把数据写到管道上，相当于管道就是输出文件。这样，在 UNIX 中两个进程之间的通信就非常类似于普通文件的读写了。 保护计算机中含有大量的信息，用户希望能够对这些信息中有用而且重要的信息加以保护，这些信息包括电子邮件、商业计划等，管理这些信息的安全性完全依靠操作系统来保证。例如，文件提供授权用户访问。 比如 UNIX 操作系统，UNIX 操作系统通过对每个文件赋予一个 9 位二进制保护代码，对 UNIX 中的文件实现保护。该保护代码有三个位子段，一个用于所有者，一个用于与所有者同组（用户被系统管理员划分成组）的其他成员，一个用于其他人。每个字段中有一位用于读访问，一位用于写访问，一位用于执行访问。这些位就是著名的 rwx位。例如，保护代码rwxr-x--x 的含义是所有者可以读、写或执行该文件，其他的组成员可以读或执行（但不能写）此文件、而其他人可以执行（但不能读和写）该文件。 shell操作系统是执行系统调用的代码。编辑器、编译器、汇编程序、链接程序、使用程序以及命令解释符等，尽管非常重要，非常有用，但是它们确实不是操作系统的组成部分。下面我们着重介绍一下 UNIX 下的命令提示符，也就是 shell，shell 虽然有用，但它也不是操作系统的一部分，然而它却能很好的说明操作系统很多特性，下面我们就来探讨一下。 shell 有许多种，例如 sh、csh、ksh 以及 bash等，它们都支持下面这些功能，最早起的 shell 可以追溯到 sh 用户登录时，会同时启动一个 shell，它以终端作为标准输入和标准输出。首先显示提示符(prompt)，它可能是一个美元符号($)，提示用户 shell 正在等待接收命令，假如用户输入 1date shell 会创建一个子进程，并运行 date 做为子进程。在该子进程运行期间，shell 将等待它结束。在子进程完成时，shell 会显示提示符并等待下一行输入。 用户可以将标准输出重定向到一个文件中，例如 1date &gt; file 同样的，也可以将标准输入作为重定向 1sort &lt;file1&gt; file2 这会调用 sort 程序来接收 file1 的内容并把结果输出到 file2。 可以将一个应用程序的输出通过管道作为另一个程序的输入，因此有 1cat file1 file2 file3 | sort &gt; /dev/lp 这会调用 cat 应用程序来合并三个文件，将其结果输送到 sort 程序中并按照字典进行排序。sort 应用程序又被重定向到 /dev/lp ，显然这是一个打印操作。 系统调用我们已经可以看到操作系统提供了两种功能：为用户提供应用程序抽象和管理计算机资源。对于大部分在应用程序和操作系统之间的交互主要是应用程序的抽象，例如创建、写入、读取和删除文件。计算机的资源管理对用户来说基本上是透明的。因此，用户程序和操作系统之间的接口主要是处理抽象。为了真正理解操作系统的行为，我们必须仔细的分析这个接口。 多数现代操作系统都有功能相同但是细节不同的系统调用，引发操作系统的调用依赖于计算机自身的机制，而且必须用汇编代码表达。任何单 CPU 计算机一次执行执行一条指令。如果一个进程在用户态下运行用户程序，例如从文件中读取数据。那么如果想要把控制权交给操作系统控制，那么必须执行一个异常指令或者系统调用指令。操作系统紧接着需要参数检查找出所需要的调用进程。操作系统紧接着进行参数检查找出所需要的调用进程。然后执行系统调用，把控制权移交给系统调用下面的指令。大致来说，系统调用就像是执行了一个特殊的过程调用，但是只有系统调用能够进入内核态而过程调用则不能进入内核态。 为了能够了解具体的调用过程，下面我们以 read 方法为例来看一下调用过程。像上面提到的那样，会有三个参数，第一个参数是指定文件、第二个是指向缓冲区、第三个参数是给定需要读取的字节数。就像几乎所有系统调用一样，它通过使用与系统调用相同的名称来调用一个函数库，从而从C程序中调用：read。 1count = read(fd,buffer,nbytes); 系统调用在 count 中返回实际读出的字节数。这个值通常与 nbytes 相同，但也可能更小。比如在读过程中遇到了文件尾的情况。 如果系统调用不能执行，不管是因为无效的参数还是磁盘错误，count 的值都会被置成 -1，然后在全局变量 errno 中放入错误信号。程序应该进场检查系统调用的结果以了解是否出错。 系统调用是通过一系列的步骤实现的，为了更清楚的说明这个概念，我们还以 read 调用为例，在准备系统调用前，首先会把参数压入堆栈，如下所示 C 和 C++ 编译器使用逆序（必须把第一个参数赋值给 printf(格式字符串)，放在堆栈的顶部）。第一个参数和第三个参数都是值调用，但是第二个参数通过引用传递，即传递的是缓冲区的地址（由 &amp; 指示），而不是缓冲的内容。然后是 C 调用系统库的 read 函数，这也是第四步。 在由汇编语言写成的库过程中，一般把系统调用的编号放在操作系统所期望的地方，如寄存器（第五步）。然后执行一个 TRAP 指令，将用户态切换到内核态，并在内核中的一个固定地址开始执行第六步。TRAP 指令实际上与过程调用指令非常相似，它们后面都跟随一个来自远处位置的指令，以及供以后使用的一个保存在栈中的返回地址。 TRAP 指令与过程调用指令存在两个方面的不同 TRAP 指令会改变操作系统的状态，由用户态切换到内核态，而过程调用不改变模式 其次，TRAP 指令不能跳转到任意地址上。根据机器的体系结构，要么跳转到一个单固定地址上，或者指令中有一 8 位长的字段，它给定了内存中一张表格的索引，这张表格中含有跳转地址，然后跳转到指定地址上。 跟随在 TRAP 指令后的内核代码开始检查系统调用编号，然后dispatch给正确的系统调用处理器，这通常是通过一张由系统调用编号所引用的、指向系统调用处理器的指针表来完成第七步。此时，系统调用处理器运行第八步，一旦系统调用处理器完成工作，控制权会根据 TRAP 指令后面的指令中返回给函数调用库第九步。这个过程接着以通常的过程调用返回的方式，返回到客户应用程序，这是第十步。然后调用完成后，操作系统还必须清除用户堆栈，然后增加堆栈指针(increment stackpointer)，用来清除调用 read 之前压入的参数。从而完成整个 read 调用过程。 在上面的第九步中我们说道，控制可能返回 TRAP 指令后面的指令，把控制权再移交给调用者这个过程中，系统调用会发生阻塞，从而避免应用程序继续执行。这么做是有原因的。例如，如果试图读键盘，此时并没有任何输入，那么调用者就必须被阻塞。在这种情形下，操作系统会检查是否有其他可以运行的进程。这样，当有用户输入 时候，进程会提醒操作系统，然后返回第 9 步继续运行。 下面，我们会列出一些常用的 POSIX 系统调用，POSIX 系统调用大概有 100 多个，它们之中最重要的一些调用见下表 进程管理 调用 说明 pid = fork() 创建与父进程相同的子进程 pid = waitpid(pid, &amp;statloc,options) 等待一个子进程终止 s = execve(name,argv,environp) 替换一个进程的核心映像 exit(status) 终止进程执行并返回状态 文件管理 调用 说明 fd = open(file, how,…) 打开一个文件使用读、写 s = close(fd) 关闭一个打开的文件 n = read(fd,buffer,nbytes) 把数据从一个文件读到缓冲区中 n = write(fd,buffer,nbytes) 把数据从缓冲区写到一个文件中 position = iseek(fd,offset,whence) 移动文件指针 s = stat(name,&amp;buf) 取得文件状态信息 目录和文件系统管理 调用 说明 s = mkdir(nname,mode) 创建一个新目录 s = rmdir(name) 删去一个空目录 s = link(name1,name2) 创建一个新目录项 name2,并指向 name1 s = unlink(name) 删去一个目录项 s = mount(special,name,flag) 安装一个文件系统 s = umount(special) 卸载一个文件系统 其他 调用 说明 s = chdir(dirname) 改变工作目录 s = chmod(name,mode) 修改一个文件的保护位 s = kill(pid, signal) 发送信号给进程 seconds = time(&amp;seconds) 获取从 1970 年1月1日至今的时间 上面的系统调用参数中有一些公共部分，例如 pid 系统进程 id，fd 是文件描述符，n 是字节数，position 是在文件中的偏移量、seconds 是流逝时间。 从宏观角度上看，这些系统调所提供的服务确定了多数操作系统应该具有的功能，下面分别来对不同的系统调用进行解释 用于进程管理的系统调用在 UNIX 中，fork 是唯一可以在 POSIX 中创建进程的途径，它创建一个原有进程的副本，包括所有的文件描述符、寄存器等内容。在 fork 之后，原有进程以及副本（父与子）就分开了。在 fork 过程中，所有的变量都有相同的值，虽然父进程的数据通过复制给子进程，但是后续对其中任何一个进程的修改不会影响到另外一个。fork 调用会返回一个值，在子进程中该值为 0 ，并且在父进程中等于子进程的 进程标识符(Process IDentified,PID)。使用返回的 PID，就可以看出来哪个是父进程和子进程。 在多数情况下， 在 fork 之后，子进程需要执行和父进程不一样的代码。从终端读取命令，创建一个子进程，等待子进程执行命令，当子进程结束后再读取下一个输入的指令。为了等待子进程完成，父进程需要执行 waitpid 系统调用，父进程会等待直至子进程终止（若有多个子进程的话，则直至任何一个子进程终止）。waitpid 可以等待一个特定的子进程，或者通过将第一个参数设为 -1 的方式，等待任何一个比较老的子进程。当 waitpid 完成后，会将第二个参数 statloc 所指向的地址设置为子进程的退出状态（正常或异常终止以及退出值）。有各种可使用的选项，它们由第三个参数确定。例如，如果没有已经退出的子进程则立刻返回。 那么 shell 该如何使用 fork 呢？在键入一条命令后，shell 会调用 fork 命令创建一个新的进程。这个子进程会执行用户的指令。通过使用 execve系统调用可以实现系统执行，这个系统调用会引起整个核心映像被一个文件所替代，该文件由第一个参数给定。下面是一个简化版的例子说明 fork、waitpid 和 execve 的使用 12345678910111213#define TRUE 1while(TRUE)&#123; /* 一直循环下去 */ type_prompt(); /* 在屏幕上显示提示符 */ read_command(command,parameters) /* 从终端读取输入 */ if(fork() != 0)&#123; /* fork 子进程 */ /* 父代码 */ waitpid(-1, &amp;status, 0); /* 等待子进程执行完毕 */ &#125;else&#123; /* 子代码 */ execve(command,parameters,0) /* 执行命令 */ &#125;&#125; 一般情况下，execve 有三个参数：将要执行的文件名称，一个指向变量数组的指针，以及一个指向环境数组的指针。这里对这些参数做一个简要的说明。 先看一个 shell 指令 1cp file1 file2 此命令把 file1 复制到 file2 文件中，在 shell 执行 fork 之后，子进程定位并执行文件拷贝，并将源文件和目标文件的名称传递给它。 cp 的主程序（以及包含其他大多数 C 程序的主程序）包含声明 1main(argc,argv,envp) 其中 argc 是命令行中参数数目的计数，包括程序名称。对于上面的例子，argc 是3。第二个参数argv 是数组的指针。该数组的元素 i 是指向该命令行第 i 个字符串的指针。在上面的例子中，argv[0] 指向字符串 cp，argv[1] 指向字符串 file1，argv[2] 指向字符串 file2。main 的第三个参数是指向环境的指针，该环境是一个数组，含有 name = value 的赋值形式，用以将诸如终端类型以及根目录等信息传送给程序。这些变量通常用来确定用户希望如何完成特定的任务（例如，使用默认打印机）。在上面的例子中，没有环境参数传递给 execve ，所以环境变量是 0 ，所以 execve 的第三个参数为 0 。 可能你觉得 execve 过于复杂，这时候我要鼓励一下你，execve 可能是 POSIX 的全部系统调用中最复杂的一个了，其他都比较简单。作为一个简单的例子，我们再来看一下 exit ，这是进程在执行完成后应执行的系统调用。这个系统调用有一个参数，它的退出状态是 0 - 255 之间，它通过 waitpid 系统调用中的 statloc 返回给父级。 UNIX 中的进程将内存划分成三个部分：text segment,文本区，例如程序代码，data segment，数据区，例如变量，stack segment，栈区域。数据向上增长而堆栈向下增长，如下图所示 上图能说明三个部分的内存分配情况，夹在中间的是空闲区，也就是未分配的区域，堆栈在需要时自动的挤压空闲区域，不过数据段的扩展是显示地通过系统调用 brk 进行的，在数据段扩充后，该系统调用指向一个新地址。但是，这个调用不是 POSIX 标准中定义的，对于存储器的动态分配，鼓励程序员使用 malloc 函数，而 malloc 的内部实现则不是一个适合标准化的主题，因为几乎没有程序员直接使用它。 用于文件管理的系统调用许多系统调用都与文件系统有关，要读写一个文件，必须先将其打开。这个系统调用通过绝对路径名或指向工作目录的相对路径名指定要打开文件的名称，而代码 O_RDONLY、 O_WRONLY 或 O_RDWR 的含义分别是只读、只写或者两者都可以，为了创建一个新文件，使用 O_CREATE参数。然后可使用返回的文件描述符进行读写操作。接着，可以使用 close 关闭文件，这个调用使得文件描述符在后续的 open 中被再次使用。 最常用的调用还是 read 和 write，我们再前面探讨过 read 调用，write 具有与 read 相同的参数。 尽管多数程序频繁的读写文件，但是仍有一些应用程序需要能够随机访问一个文件的任意部分。与每个文件相关的是一个指向文件当前位置的指针。在顺序读写时，该指针通常指向要读出（写入）的下一个字节。Iseek 调用可以改变该位置指针的值，这样后续的 read 或 write 调用就可以在文件的任何地方开始。 Iseek 有三个参数，position = iseek(fd,offset,whence)，第一个是文件描述符，第二个是文件位置，第三个是说明该文件位置是相对于文件起始位置，当前位置还是文件的结尾。在修改了指针之后，Iseek 所返回的值是文件中的绝对位置。 UNIX 为每个文件保存了该文件的类型（普通文件、特殊文件、目录等）、大小，最后修改时间以及其他信息，程序可以通过 stat 系统调用查看这些信息。s = stat(name,&amp;buf)，第一个参数指定了被检查的文件；第二个参数是一个指针，该指针指向存放这些信息的结构。对于一个打开的文件而言，fstat 调用完成同样的工作。 用于目录管理的系统调用下面我们探讨目录和整个文件系统的系统调用，上面探讨的是和某个文件有关的系统调用。mkdir 和 rmdir 分别用于创建s = mkdir(nname,mode)和删除 s = rmdir(name) 空目录，下一个调用是 s = link(name1,name2) 它的作用是允许同一个文件以两个或者多个名称出现，多数情况下是在不同的目录中使用 link ，下面我们探讨一下 link 是如何工作的 图中有两个用户 ast 和 jim，每个用户都有他自己的一个目录和一些文件，如果 ast 要执行一个包含下面系统调用的应用程序 1link(\"/usr/jim/memo\", \"/usr/ast/note\"); jim 中的 memo 文件现在会进入到 ast 的目录中，在 note 名称下。此后，/usr/jim/memo和 /usr/ast/note 会有相同的名称。 用户目录是保存在 /usr，/user，/home 还是其他位置，都是由本地系统管理员决定的。 要理解 link 是如何工作的需要清楚 link 做了什么操作。UNIX 中的每个文件都有一个独一无二的版本，也称作 i - number，i-编号，它标示着不同文件的版本。这个 i - 编号是 i-nodes,i-节点 表的索引。每个文件都会表明谁拥有这个文件，这个磁盘块的位置在哪，等等。目录只是一个包含一组（i编号，ASCII名称）对应的文件。UNIX 中的第一个版本中，每个目录项都会有 16 个字节，2 个字节对应 i - 编号和 14 个字节对应其名称。现在需要一个更复杂的结构需要支持长文件名，但是从概念上讲一个目录仍是一系列（i-编号，ASCII 名称）的集合。在上图中，mail 的 i-编号为 16，依此类推。link 只是利用某个已有文件的 i-编号，创建一个新目录项（也许用一个新名称）。在上图 b 中，你会发现有两个相同的 70 i-编号的文件，因此它们需要有相同的文件。如果其中一个使用了 unlink 系统调用的话，其中一个会被移除，另一个将保留。如果两个文件都移除了，则 UNIX 会发现该文件不存在任何没有目录项（i-节点中的一个域记录着指向该文件的目录项），就会把该文件从磁盘中移除。 就像我们上面提到过的那样，mount 系统 s = mount(special,name,flag)调用会将两个文件系统合并为一个。通常的情况是将根文件系统分布在硬盘（子）分区上，并将用户文件分布在另一个（子）分区上，该根文件系统包含常用命令的二进制（可执行）版本和其他使用频繁的文件。然后，用户就会插入可读取的 USB 硬盘。 通过执行 mount 系统调用，USB 文件系统可以被添加到根文件系统中， 图 a 是安装前的系统文件，图 b 是安装后的系统文件。 如果用 C 语言来执行那就是 1mount(\"/dev/sdb0\",\"/mnt\",0) 这里，第一个参数是 USB 驱动器 0 的块特殊文件名称，第二个参数是被安装在树中的位置，第三个参数说明将要安装的文件系统是可读写的还是只读的。 当不再需要一个文件系统时，可以使用 umount 移除之。 其他系统调用除了进程、文件、目录系统调用，也存在其他系统调用的情况，下面我们来探讨一下。我们可以看到上面其他系统调用只有四种，首先来看第一个 chdir，chdir 调用更改当前工作目录，在调用 1chdir(\"/usr/ast/test\"); 后，打开 xyz 文件，会打开 /usr/ast/test/xyz 文件，工作目录的概念消除了总是需要输入长文件名的需要。 在 UNIX 系统中，每个文件都会有保护模式，这个模式会有一个读-写-执行位，它用来区分所有者、组和其他成员。chmod 系统调用提供改变文件模式的操作。例如，要使一个文件除了对所有者之外的用户可读，你可以执行 1chmod(\"file\",0644); kill 系统调用是用户和用户进程发送信号的方式，如果一个进程准备好捕捉一个特定的信号，那么在信号捕捉之前，会运行一个信号处理程序。如果进程没有准备好捕捉特定的信号，那么信号的到来会杀掉该进程（此名字的由来）。 POSIX 定义了若干时间处理的进程。例如，time 以秒为单位返回当前时间，0 对应着 1970 年 1月 1日。在一台 32 位字的计算机中，time 的最大值是 (2^32) - 1秒，这个数字对应 136 年多一点。所以在 2106 年，32 位的 UNIX 系统会发飙。如果读者现在有 32 位 UNIX 系统，建议在 2106 年更换位 64 位操作系统（偷笑～）。 Win 32 API上面我们提到的都是 UNIX 系统调用，现在我们来聊聊 Win 32 中的系统调用。Windows 和 UNIX 在各自的编程方式上有着根本的不同。UNIX 程序由执行某些操作或执行其他操作的代码组成，进行系统调用以执行某些服务。Windows 系统则不同，Windows 应用程序通常是由事件驱动的。主程序会等待一些事件发生，然后调用程序去处理。最简单的事件处理是键盘敲击和鼠标滑过，或者是鼠标点击，或者是插入 USB 驱动，然后操作系统调用处理器去处理事件，更新屏幕和更新程序内部状态。这是与 UNIX 不同的设计风格。 当然，Windows 也有系统调用。在 UNIX 中，系统调用（比如 read）和系统调用所使用的调用库（例如 read）几乎是一对一的关系。而在 Windows 中，情况则大不相同。首先，函数库的调用和实际的系统调用几乎是不对应的。微软定义了一系列过程，称为 Win32应用编程接口(Application Programming Interface)，程序员通过这套标准的接口来实现系统调用。这个接口支持从 Windows 95 版本以来所有的 Windows 版本。 Win32 API 调用的数量是非常巨大的，有数千个多。但这些调用并不都是在内核态的模式下运行时，有一些是在用户态的模型下运行。Win32 API 有大量的调用，用来管理视窗、几何图形、文本、字体、滚动条、对话框、菜单以及 GUI 的其他功能。为了使图形子系统在内核态下运行，需要系统调用，否则就只有函数库调用。 我们把关注点放在和 Win32 系统调用中来，我们可以简单看一下 Win32 API 中的系统调用和 UNIX 中有什么不同（并不是所有的系统调用） UNIX Win32 说明 fork CreateProcess 创建一个新进程 waitpid WaitForSingleObject 等待一个进程退出 execve none CraeteProcess = fork + servvice exit ExitProcess 终止执行 open CreateFile 创建一个文件或打开一个已有的文件 close CloseHandle 关闭文件 read ReadFile 从单个文件中读取数据 write WriteFile 向单个文件写数据 lseek SetFilePointer 移动文件指针 stat GetFileAttributesEx 获得不同的文件属性 mkdir CreateDirectory 创建一个新的目录 rmdir RemoveDirectory 移除一个空的目录 link none Win32 不支持 link unlink DeleteFile 销毁一个已有的文件 mount none Win32 不支持 mount umount none Win32 不支持 mount，所以也不支持mount chdir SetCurrentDirectory 切换当前工作目录 chmod none Win32 不支持安全 kill none Win32 不支持信号 time GetLocalTime 获取当前时间 上表中是 UNIX 调用大致对应的 Win32 API 系统调用，简述一下上表。CreateProcess 用于创建一个新进程，它把 UNIX 中的 fork 和 execve 两个指令合成一个，一起执行。它有许多参数用来指定新创建进程的性质。Windows 中没有类似 UNIX 中的进程层次，所以不存在父进程和子进程的概念。在进程创建之后，创建者和被创建者是平等的。WaitForSingleObject 用于等待一个事件，等待的事件可以是多种可能的事件。如果有参数指定了某个进程，那么调用者将等待指定的进程退出，这通过 ExitProcess 来完成。 然后是6个文件操作，在功能上和 UNIX 的调用类似，然而在参数和细节上是不同的。和 UNIX 中一样，文件可以打开，读取，写入，关闭。SetFilePointer 和 GetFileAttributesEx 设置文件的位置并取得文件的属性。 Windows 中有目录，目录分别用 CreateDirectory 以及 RemoveDirectoryAPI 调用创建和删除。也有对当前的目录的标记，这可以通过 SetCurrentDirectory 来设置。使用GetLocalTime 可获得当前时间。 Win32 接口中没有文件的链接、文件系统的 mount、umount 和 stat ，当然， Win32 中也有大量 UNIX 中没有的系统调用，特别是对 GUI 的管理和调用。 操作系统结构下面我们会探讨操作系统的几种结构，主要包括单体结构、分层系统、微内核、客户-服务端系统、虚拟机和外核等。下面以此来探讨一下 单体系统到目前为止，在大多数系统中，整个系统在内核态以单一程序的方式运行。整个操作系统是以程序集合来编写的，链接在一块形成一个大的二进制可执行程序。使用此技术时，如果系统中的每个过程都提供了前者所需的一些有用的计算，则它可以自由调用任何其他过程。在单体系统中，调用任何一个所需要的程序都非常高效，但是上千个不受限制的彼此调用往往非常臃肿和笨拙，而且单体系统必然存在单体问题，那就是只要系统发生故障，那么任何系统和应用程序将不可用，这往往是灾难性的。 在单体系统中构造实际目标程序时，会首先编译所有单个过程（或包含这些过程的文件），然后使用系统链接器将它们全部绑定到一个可执行文件中 对于单体系统，往往有下面几种建议 需要有一个主程序，用来调用请求服务程序 需要一套服务过程，用来执行系统调用 需要一套服务程序，用来辅助服务过程调用 在单体系统中，对于每个系统调用都会有一个服务程序来保障和运行。需要一组实用程序来弥补服务程序需要的功能，例如从用户程序中获取数据。可将各种过程划分为一个三层模型 除了在计算机初启动时所装载的核心操作系统外，许多操作系统还支持额外的扩展。比如 I/O 设备驱动和文件系统。这些部件可以按需装载。在 UNIX 中把它们叫做 共享库(shared library)，在 Windows 中则被称为 动态链接库(Dynamic Link Library,DLL)。他们的扩展名为 .dll，在 C:\\Windows\\system32 目录下存在 1000 多个 DLL 文件，所以不要轻易删除 C 盘文件，否则可能就炸了哦。 分层系统分层系统使用层来分隔不同的功能单元。每一层只与该层的上层和下层通信。每一层都使用下面的层来执行其功能。层之间的通信通过预定义的固定接口通信。 分层系统是由 E.W.Dijkstar 和他的学生在荷兰技术学院所开发的 THE 系统。 把上面单体系统进一步通用化，就变为了一个层次式结构的操作系统，它的上层软件都是在下层软件的基础之上构建的。该系统分为六层，如下所示 层号 功能 5 操作员 4 用户程序 3 输入/输出管理 2 操作员-进程通信 1 存储器和磁鼓管理 0 处理器分配和多道程序编程 处理器在 0 层运行，当中断发生或定时器到期时，由该层完成进程切换；在第 0 层之上，系统由一些连续的进程组成，编写这些进程时不用再考虑在单处理器上多进程运行的细节。内存管理在第 1 层，它分配进程的主存空间。第 1 层软件保证一旦需要访问某一页面，该页面必定已经在内存中，并且在页面不需要的时候将其移出。 第 2 层处理进程与操作员控制台（即用户）之间的通信。第 3 层管理 I/O 设备和相关的信息流缓冲区。第 4 层是用户程序层，用户程序不用考虑进程、内存、控制台或 I/O 设备管理等细节。系统操作员在第 5 层。 微内核在分层方式中，设计者要确定在哪里划分 内核-用户 的边界。传统上，所有的层都在内核中，但是这样做没有必要。事实上，尽可能减少内核态中功能可能是更好的做法。因为内核中的错误很难处理，一旦内核态中出错误会拖累整个系统。 所以，为了实现高可靠性，将操作系统划分成小的、层级之间能够更好定义的模块是很有必要的，只有一个模块 — 微内核 — 运行在内核态，其余模块可以作为普通用户进程运行。由于把每个设备驱动和文件系统分别作为普通用户进程，这些模块中的错误虽然会使这些模块崩溃，但是不会使整个系统死机。 MINIX 3 是微内核的代表作，它的具体结构如下 在内核的外部，系统的构造有三层，它们都在用户态下运行，最底层是设备驱动器。由于它们都在用户态下运行，所以不能物理的访问 I/O 端口空间，也不能直接发出 I/O 命令。相反，为了能够对 I/O 设备编程，驱动器构建一个结构，指明哪个参数值写到哪个 I/O 端口，并声称一个内核调用，这样就完成了一次调用过程。 位于用户态的驱动程序上面是服务器层，包含有服务器，它们完成操作系统的多数工作。由一个或多个文件服务器管理着文件系统，进程管理器创建、销毁和管理进程。服务器中有一个特殊的服务器称为 再生服务器(reincarnation server)，它的任务就是检查服务器和驱动程序的功能是否正确，一旦检查出来错误，它就会补上去，无需用户干预。这种方式使得系统具有可恢复性，并具有较高的可靠性。 微内核中的内核还具有一种 机制 与 策略 分离的思想。比如系统调度，一个比较简单的调度算法是，对每个进程赋予一个优先级，并让内核执行具有最高优先级的进程。这里，内核机制就是寻找最高的优先级进程并运行。而策略（赋予进程优先级）可以在用户态中的进程完成。在这种模式中，策略和机制是分离的，从而使内核变得更小。 客户-服务器模式微内核思想的策略是把进程划分为两类：服务器，每个服务器用来提供服务；客户端，使用这些服务。这个模式就是所谓的 客户-服务器模式。 客户-服务器模式会有两种载体，一种情况是一台计算机既是客户又是服务器，在这种方式下，操作系统会有某种优化；但是普遍情况下是客户端和服务器在不同的机器上，它们通过局域网或广域网连接。 客户通过发送消息与服务器通信，客户端并不需要知道这些消息是在本地机器上处理，还是通过网络被送到远程机器上处理。对于客户端而言，这两种情形是一样的：都是发送请求并得到回应。 越来越多的系统，包括家里的 PC，都成为客户端，而在某地运行的大型机器则成为服务器。许多 web 就是以这种方式运行的。一台 PC 向某个服务器请求一个 Web 页面，服务器把 Web 页面返回给客户端，这就是典型的客服-服务器模式 文章参考 《现代操作系统》 《Modern Operating System》forth edition http://faculty.cs.niu.edu/~hutchins/csci360/hchnotes/psw.htm https://www.computerhope.com/jargon/c/clockcyc.htm","categories":[{"name":"架构","slug":"架构","permalink":"https://vincentruan.github.io/categories/架构/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://vincentruan.github.io/tags/操作系统/"}]},{"title":"14个Java并发容器","slug":"14个Java并发容器","date":"2020-02-11T09:00:26.000Z","updated":"2020-02-17T02:40:44.573Z","comments":true,"path":"2020/02/11/14个Java并发容器/","link":"","permalink":"https://vincentruan.github.io/2020/02/11/14个Java并发容器/","excerpt":"","text":"并发容器介绍 ConcurrentHashMap：并发版HashMap CopyOnWriteArrayList：并发版ArrayList CopyOnWriteArraySet：并发Set ConcurrentLinkedQueue：并发队列(基于链表) ConcurrentLinkedDeque：并发队列(基于双向链表) ConcurrentSkipListMap：基于跳表的并发Map ConcurrentSkipListSet：基于跳表的并发Set ArrayBlockingQueue：阻塞队列(基于数组) LinkedBlockingQueue：阻塞队列(基于链表) LinkedBlockingDeque：阻塞队列(基于双向链表) PriorityBlockingQueue：线程安全的优先队列 SynchronousQueue：读写成对的队列 LinkedTransferQueue：基于链表的数据交换队列 DelayQueue：延时队列 1.ConcurrentHashMap 并发版HashMap最常见的并发容器之一，可以用作并发场景下的缓存。底层依然是哈希表，但在JAVA 8中有了不小的改变，而JAVA 7和JAVA 8都是用的比较多的版本，因此经常会将这两个版本的实现方式做一些比较（比如面试中） 一个比较大的差异就是，JAVA 7中采用分段锁来减少锁的竞争，JAVA 8中放弃了分段锁，采用CAS，同时为了防止哈希冲突严重时退化成链表（冲突时会在该位置生成一个链表，哈希值相同的对象就链在一起），会在链表长度达到阈值（8）后转换成红黑树（比起链表，树的查询效率更稳定）。 2.CopyOnWriteArrayList 并发版ArrayList并发版ArrayList，底层结构也是数组，和ArrayList不同之处在于：当新增和删除元素时会创建一个新的数组，在新的数组中增加或者排除指定对象，最后用新增数组替换原来的数组。 适用场景：由于读操作不加锁，写（增、删、改）操作加锁，因此适用于读多写少的场景。 局限：由于读的时候不会加锁（读的效率高，就和普通ArrayList一样），读取的当前副本，因此可能读取到脏数据。如果介意，建议不用。 看看源码感受下： 123456789101112131415161718192021222324public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; final transient ReentrantLock lock = new ReentrantLock(); private transient volatile Object[] array; // 添加元素，有锁 public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); // 修改时加锁，保证并发安全 try &#123; Object[] elements = getArray(); // 当前数组 int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); // 创建一个新数组，比老的大一个空间 newElements[len] = e; // 要添加的元素放进新数组 setArray(newElements); // 用新数组替换原来的数组 return true; &#125; finally &#123; lock.unlock(); // 解锁 &#125; &#125; // 读元素，不加锁，因此可能读取到旧数据 public E get(int index) &#123; return get(getArray(), index); &#125;&#125; 3.CopyOnWriteArraySet 并发Set基于CopyOnWriteArrayList实现（内含一个CopyOnWriteArrayList成员变量），也就是说底层是一个数组，意味着每次add都要遍历整个集合才能知道是否存在，不存在时需要插入（加锁）。 适用场景：在CopyOnWriteArrayList适用场景下加一个，集合别太大（全部遍历伤不起）。 4.ConcurrentLinkedQueue 并发队列(基于链表)基于链表实现的并发队列，使用乐观锁(CAS)保证线程安全。因为数据结构是链表，所以理论上是没有队列大小限制的，也就是说添加数据一定能成功。 5.ConcurrentLinkedDeque 并发队列(基于双向链表)基于双向链表实现的并发队列，可以分别对头尾进行操作，因此除了先进先出(FIFO)，也可以先进后出（FILO），当然先进后出的话应该叫它栈了。 6.ConcurrentSkipListMap 基于跳表的并发MapSkipList即跳表，跳表是一种空间换时间的数据结构，通过冗余数据，将链表一层一层索引，达到类似二分查找的效果 7.ConcurrentSkipListSet 基于跳表的并发Set类似HashSet和HashMap的关系，ConcurrentSkipListSet里面就是一个ConcurrentSkipListMap，就不细说了。 8.ArrayBlockingQueue 阻塞队列(基于数组)基于数组实现的可阻塞队列，构造时必须制定数组大小，往里面放东西时如果数组满了便会阻塞直到有位置（也支持直接返回和超时等待），通过一个锁ReentrantLock保证线程安全。 用offer操作举个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; /** * 读写共用此锁，线程间通过下面两个Condition通信 * 这两个Condition和lock有紧密联系（就是lock的方法生成的） * 类似Object的wait/notify */ final ReentrantLock lock; /** 队列不为空的信号，取数据的线程需要关注 */ private final Condition notEmpty; /** 队列没满的信号，写数据的线程需要关注 */ private final Condition notFull; // 一直阻塞直到有东西可以拿出来 public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) notEmpty.await(); return dequeue(); &#125; finally &#123; lock.unlock(); &#125; &#125; // 在尾部插入一个元素，队列已满时等待指定时间，如果还是不能插入则返回 public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; checkNotNull(e); long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); // 锁住 try &#123; // 循环等待直到队列有空闲 while (count == items.length) &#123; if (nanos &lt;= 0) return false;// 等待超时，返回 // 暂时放出锁，等待一段时间（可能被提前唤醒并抢到锁，所以需要循环判断条件） // 这段时间可能其他线程取走了元素，这样就有机会插入了 nanos = notFull.awaitNanos(nanos); &#125; enqueue(e);//插入一个元素 return true; &#125; finally &#123; lock.unlock(); //解锁 &#125; &#125;&#125; 乍一看会有点疑惑，读和写都是同一个锁，那要是空的时候正好一个读线程来了不会一直阻塞吗？ 答案就在notEmpty、notFull里，这两个出自lock的小东西让锁有了类似synchronized + wait + notify的功能。 9.LinkedBlockingQueue 阻塞队列(基于链表)基于链表实现的阻塞队列，想比与不阻塞的ConcurrentLinkedQueue，它多了一个容量限制，如果不设置默认为int最大值。 10.LinkedBlockingDeque 阻塞队列(基于双向链表)类似LinkedBlockingQueue，但提供了双向链表特有的操作。 11.PriorityBlockingQueue 线程安全的优先队列构造时可以传入一个比较器，可以看做放进去的元素会被排序，然后读取的时候按顺序消费。某些低优先级的元素可能长期无法被消费，因为不断有更高优先级的元素进来。 12.SynchronousQueue 数据同步交换的队列一个虚假的队列，因为它实际上没有真正用于存储元素的空间，每个插入操作都必须有对应的取出操作，没取出时无法继续放入。 一个简单的例子感受一下： 1234567891011121314151617181920212223242526272829303132333435363738import java.util.concurrent.*;public class Main &#123; public static void main(String[] args) &#123; SynchronousQueue&lt;Integer&gt; queue = new SynchronousQueue&lt;&gt;(); new Thread(() -&gt; &#123; try &#123; // 没有休息，疯狂写入 for (int i = 0; ; i++) &#123; System.out.println(\"放入: \" + i); queue.put(i); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); new Thread(() -&gt; &#123; try &#123; // 咸鱼模式取数据 while (true) &#123; System.out.println(\"取出: \" + queue.take()); Thread.sleep((long) (Math.random() * 2000)); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125;/* 输出:放入: 0取出: 0放入: 1取出: 1放入: 2取出: 2放入: 3取出: 3*/ 可以看到，写入的线程没有任何sleep，可以说是全力往队列放东西，而读取的线程又很不积极，读一个又sleep一会。输出的结果却是读写操作成对出现。 JAVA中一个使用场景就是Executors.newCachedThreadPool()，创建一个缓存线程池。 1234567public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor( 0, // 核心线程为0，没用的线程都被无情抛弃 Integer.MAX_VALUE, // 最大线程数理论上是无限了，还没到这个值机器资源就被掏空了 60L, TimeUnit.SECONDS, // 闲置线程60秒后销毁 new SynchronousQueue&lt;Runnable&gt;()); // offer时如果没有空闲线程取出任务，则会失败，线程池就会新建一个线程&#125; 13.LinkedTransferQueue 基于链表的数据交换队列实现了接口TransferQueue，通过transfer方法放入元素时，如果发现有线程在阻塞在取元素，会直接把这个元素给等待线程。如果没有人等着消费，那么会把这个元素放到队列尾部，并且此方法阻塞直到有人读取这个元素。和SynchronousQueue有点像，但比它更强大。 14.DelayQueue 延时队列可以使放入队列的元素在指定的延时后才被消费者取出，元素需要实现Delayed接口。 总结上面简单介绍了JAVA并发包下的一些容器类，知道有这些东西，遇到合适的场景时就能想起有个现成的东西可以用了。想要知其所以然，后续还得再深入探索一番。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/tags/JAVA/"},{"name":"并发","slug":"并发","permalink":"https://vincentruan.github.io/tags/并发/"}]},{"title":"Java8开发的4个小技巧","slug":"Java8开发的4个小技巧","date":"2020-02-11T08:48:32.000Z","updated":"2020-02-17T02:40:44.634Z","comments":true,"path":"2020/02/11/Java8开发的4个小技巧/","link":"","permalink":"https://vincentruan.github.io/2020/02/11/Java8开发的4个小技巧/","excerpt":"","text":"1.OptionalOptional是一个严重被低估的功能，并且有潜力删除很多困扰我们的NullPointerExceptions。这在代码边界中（要么是正在使用的API，要么是正在暴露的API）特别有用，因为它允许你和你的调用代码来推理所期待的东西。 然而，不加思考和设计就应用Optional可能会导致影响大量的类，并可能导致可读性更差。下面是一些关于如何高效使用Optional的技巧。 Optional应该只用于返回类型……不是参数，也不是字段。幸运的是，IntelliJ IDEA的让你打开检查来查看是是否遵循这些建议。 Optional值应在遇到它们的地方中处理。IntelliJ IDEA的建议会防止代码Optional泄漏，所以请记得在你发现Optional的地方处理它，迅速采取行动。 不应该简单调用get()Optional的功能是表达这个值可能是空的，并让你应对这种情况。因此，在对它做任何事情之前一定要检查是否有一个值。只是简单得调用get()而不先检查isPresent()在某些时候可能会导致空指针。幸运的是，IntelliJ IDEA也有检查可以提醒你这一点。 可能有更优雅的方式结合了get()的isPresent()当然会很赞… 但也有更优雅的解决方案。你可以使用orElse在万一是空值的情况下给一个替代方案。 或者你可以使用orElseGet说明在值为空的情况下调用哪个方法。这似乎与上面的例子相同，但supplier方法将只在需要的时候调用，因此，如果这是一种昂贵的方法，那么使用lambda会有更佳性能。 2.使用Lambda表达式Lambda表达式是Java 8的主要特点之一。即使你还没有使用Java 8，你现在可能已经对它们有了基本的了解。它们是用Java编程的一种新的方式，并且什么是“最佳实践”还不明显。下面是我喜欢遵循的一些指引。 保持简短函数式程序员与较长的lambda表达式相处会更愉快，但那些淫浸于Java多年的人会发现保持lambda表达式为区区几行代码更容易。你甚至可能更愿意将其限制到一行代码，并且你可以轻松重构较长的表达式为一个方法。 这些甚至可能会成为方法引用。方法引用一开始会觉得有点陌生，但实际上坚持方法引用是有价值的，因为它们在某些情况下有助于可读性，后面我会讨论到这一点。 明确类型信息缺少lambda表达式，所以你可能会觉得包含类型信息用于参数会很有用。 正如你所见，这回变得相当笨拙。所以我更喜欢给参数取一个有用的名字。当然，不管你有没有这么做，IntelliJ IDEA可以让你看到参数得类型信息。 甚至是lambda所代表的函数式接口： 3.针对Lambda表达式设计 我认为lambda表达式有点像泛型——和泛型一起，我们经常使用它们（例如，添加类型信息到List&lt; &gt;），但最好我们可以设计一种方法或一个具有泛型类型（例如Person&lt; T &gt;）的类。 同样的，当使用类似于Streams API的东西时，我们会传递lambda表达式，但更好的是创造一个需要lambda参数的方法。 但是，如果你发现自己处于这类情况下，下面有一些超棒的技巧。 IntelliJ IDEA可以帮你引进函数式参数 这让你可以在有人将传递一个lambda而非Object的地方创建一个参数。此功能的好处是，它表明，现有函数式接口匹配规格说明。 这会导致… 使用现有的函数式接口 随着开发人员越来越熟悉Java 8代码，我们就能知道当使用如Supplier和 Consumer的接口时，会发生什么，以及创建一个本地的ErrorMessageCreator（举个例子）可能会造成混乱，而且浪费。看看这个函数包了解一下哪些已经是可用的。 添加@FunctionalInterface到函数式接口 如果你确实需要创建自己的函数式接口，那么就这样用此注释标记。这似乎没有太大的作用，但IntelliJ IDEA会告诉你，在你的接口不能匹配用于函数式接口的异常的时候。当你没有指定要覆盖的方法时，它会标志： 当你指定了太多方法的时候，它会标志： 并且如果你应用它到一个类而不是接口时，它会警告你： lambda表达式可用于带有一个单一抽象方法的任何接口，但它们不能用于符合相同标准的抽象类。似乎不合逻辑，但就是这样。 4.Stream Stream API是Java 8另一个大特点，并且我认为我们还真的不知道这对我们的编码方式会产生多大的改变。下面是我发现的一些有用的东西 排队点操作符 我个人更喜欢排队我的流操作。当然，你没有必要这样，当我发现这样做对我有帮助： 一目了然地看到我有哪些操作 调试更容易（虽然IntelliJ IDEA确实提供了对一行中的任意多个lambda表达式设置断点的能力，但是拆分到不同的行会变得更简单） 当我测试东西的时候注释操作 轻松插入peek()用于调试或测试 此外，在我看来，它更整洁。如果我们按照这个模式，在减少代码行数方面我们并没有增加很多。 你可能需要调整格式设置以排列点操作符。 使用方法引用 是的，确实需要一段时间来适应这个奇怪的语法。但是，如果使用得当，它确实可以增加可读性。请看： 与（相对）新的Objects类上的辅助方法相比较： 后者的代码对于哪些值是要保存的更加明确。当lambda可以被折叠到方法参考的时候，IntelliJ IDEA通常会让你知道。 当遍历一个集合时，在可行的情况下使用Streams API …或者新的集合方法，如forEach。IntelliJ IDEA给你建议是： 一般使用Streams API比循环和if语句的组合更加明确。例如： IntelliJ IDEA建议这可重构为： 我所做的性能测试表明这种重构令人惊讶——并不总是可预测性能是保持不变，改善还是变得更糟。与往常一样，如果性能在应用程序中是关键，那么在交付一种风格到另一种之前衡量它。 遍历数组时使用循环 但是，使用Java 8并不一定意味着你必须到处使用流和新的集合方法。IntelliJ IDEA会建议转换成流，但是，这并不意味着你必须回答“yes”（记得检查是可以抑制或关闭的）。 特别是，遍历原始类型的小型数组几乎肯定会用，以获得更好的性能循环，很可能（至少对于Java开发人员是新的流）更具可读性。 与任何技巧一样，规则并不是一成不变的，但你应该决定是尽可能地使用Streams API，还是依然对一些操作使用循环。总之，要一致。 附录Lambda表达式 Lambda语法一行执行语句的写法： 1(parameters) -&gt; expression 如果有多行执行语句，可以加上 {} 1(parameters) -&gt; &#123; statements; &#125; 如： 1public int add(int x, int y) &#123; return x + y;&#125; 转换成Lambda表达式有以下几种写法： 123456// 指定参数类型及return(int x, int y) -&gt; &#123; return x + y; &#125;// 指定参数类型，不指定return(int x, int y) -&gt; x + y;// 不指定参数类型和return，编译器会自动推断(x, y) -&gt; x + y; Lambda用途1、只有一个抽象方法的函数式接口Lambda表达式的目标类型是函数式接口，什么是函数式接口之后会讲。 下面拿创建线程来举例，用lambda表达式可以有以下几种写法。 1234567891011121314151617181920public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"t1\"); &#125; &#125;).start(); Runnable runnable = () -&gt; System.out.println(\"t2\"); new Thread(runnable).start(); new Thread(() -&gt; System.out.println(\"t3\")).start(); new Thread(() -&gt; run(\"t4\")).start(); new Thread(() -&gt; &#123; String str = \"t5\"; System.out.println(str); &#125;).start();&#125;private static void run(String str) &#123; System.out.println(str);&#125; 最后输出： 1t1t2t3t4t5 2、集合批量操作下面打印list集合的两种写法是等价的。 12345List&lt;String&gt; list = Arrays.asList(\"a\",\"b\",\"c\");for(String str : list) &#123; System.out.println(str);&#125;list.forEach((e) -&gt; System.out.println(e)); 3、流操作下面是流查询list集合中等于 &quot;a&quot;的数量。 1list.stream().filter((e) -&gt; \"a\".equals(e)).count();","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA8","slug":"JAVA8","permalink":"https://vincentruan.github.io/tags/JAVA8/"}]},{"title":"如何提高服务器的并发处理能力","slug":"如何提高服务器的并发处理能力","date":"2020-02-11T07:22:05.000Z","updated":"2020-02-17T02:40:44.888Z","comments":true,"path":"2020/02/11/如何提高服务器的并发处理能力/","link":"","permalink":"https://vincentruan.github.io/2020/02/11/如何提高服务器的并发处理能力/","excerpt":"","text":"以下内容为入门级介绍，意在对老技术作较全的总结而不是较深的研究。主要参考《构建高性能Web站点》一书。 什么是服务器并发处理能力一台服务器在单位时间里能处理的请求越多，服务器的能力越高，也就是服务器并发处理能力越强 有什么方法衡量服务器并发处理能力1. 吞吐率吞吐率，单位时间里服务器处理的最大请求数，单位req/s 从服务器角度，实际并发用户数的可以理解为服务器当前维护的代表不同用户的文件描述符总数，也就是并发连接数。 服务器一般会限制同时服务的最多用户数，比如apache的MaxClents参数。 这里再深入一下，对于服务器来说，服务器希望支持高吞吐率，对于用户来说，用户只希望等待最少的时间，显然，双方不能满足，所以双方利益的平衡点，就是我们希望的最大并发用户数。 2. 压力测试有一个原理一定要先搞清楚，假如100个用户同时向服务器分别进行10个请求，与1个用户向服务器连续进行1000次请求，对服务器的压力是一样吗？ 实际上是不一样的，因对每一个用户，连续发送请求实际上是指发送一个请求并接收到响应数据后再发送下一个请求。 这样对于1个用户向服务器连续进行1000次请求, 任何时刻服务器的网卡接收缓冲区中只有1个请求，而对于100个用户同时向服务器分别进行10个请求，服务器的网卡接收缓冲区最多有100个等待处理的请求，显然这时的服务器压力更大。 压力测试前提考虑的条件 并发用户数: 指在某一时刻同时向服务器发送请求的用户总数(HttpWatch) 总请求数 请求资源描述 请求等待时间(用户等待时间) 用户平均请求的等待时间 服务器平均请求处理的时间 硬件环境 压力测试中关心的时间又细分以下2种: 用户平均请求等待时间（这里暂不把数据在网络的传输时间，还有用户PC本地的计算时间计算入内） 服务器平均请求处理时间 用户平均请求等待时间主要用于衡量服务器在一定并发用户数下，单个用户的服务质量；而服务器平均请求处理时间就是吞吐率的倒数。 一般来说，用户平均请求等待时间 = 服务器平均请求处理时间 * 并发用户数 怎么提高服务器的并发处理能力1. 提高CPU并发计算能力服务器之所以可以同时处理多个请求，在于操作系统通过多执行流体系设计使得多个任务可以轮流使用系统资源。 这些资源包括CPU，内存以及I/O. 这里的I/O主要指磁盘I/O, 和网络I/O。 多进程 &amp; 多线程多执行流的一般便是进程，多进程的好处可以对CPU时间的轮流使用，对CPU计算和IO操作重叠利用。这里的IO主要是指磁盘IO和网络IO，相对CPU而言，它们慢的可怜。 而实际上，大多数进程的时间主要消耗在I/O操作上。 现代计算机的DMA技术可以让CPU不参与I/O操作的全过程，比如进程通过系统调用，使得CPU向网卡或者磁盘等I/O设备发出指令，然后进程被挂起，释放出CPU资源，等待I/O设备完成工作后通过中断来通知进程重新就绪。 对于单任务而言，CPU大部分时间空闲，这时候多进程的作用尤为重要。 多进程不仅能够提高CPU的并发度。其优越性还体现在独立的内存地址空间和生命周期所带来的稳定性和健壮性，其中一个进程崩溃不会影响到另一个进程。 但是进程也有如下缺点： fork()系统调用开销很大: prefork 进程间调度和上下文切换成本: 减少进程数量 庞大的内存重复：共享内存 IPC编程相对比较麻烦 减少进程切换当硬件上下文频繁装入和移出时，所消耗的时间是非常可观的。可用Nmon工具监视服务器每秒的上下文切换次数。 为了尽量减少上下文切换次数，最简单的做法就是减少进程数，尽量使用线程并配合其它I/O模型来设计并发策略。 还可以考虑使用进程绑定CPU技术，增加CPU缓存的命中率。若进程不断在各CPU上切换，这样旧的CPU缓存就会失效。 减少使用不必要的锁服务器处理大量并发请求时，多个请求处理任务时存在一些资源抢占竞争，这时一般采用“锁”机制来控制资源的占用。到底什么是重入锁附录内容推荐大家看下。 当一个任务占用资源时，我们锁住资源，这时其它任务都在等待锁的释放，这个现象称为锁竞争。 通过锁竞争的本质，我们要意识到尽量减少并发请求对于共享资源的竞争。 比如在允许情况下关闭服务器访问日志，这可以大大减少在锁等待时的延迟时间。要最大程度减少无辜的等待时间。 这里说下无锁编程，就是由内核完成这个锁机制，主要是使用原子操作替代锁来实现对共享资源的访问保护。 使用原子操作时，在进行实际的写操作时，使用了lock指令，这样就可以阻止其他任务写这块内存，避免出现数据竞争现象。原子操作速度比锁快，一般要快一倍以上。 例如fwrite(), fopen()，其是使用append方式写文件，其原理就是使用了无锁编程，无锁编程的复杂度高，但是效率快，而且发生死锁概率低。 考虑进程优先级进程调度器会动态调整运行队列中进程的优先级，通过top观察进程的PR值 考虑系统负载可在任何时刻查看/proc/loadavg, top中的load average也可看出 考虑CPU使用率除了用户空间和内核空间的CPU使用率以外，还要关注I/O wait,它是指CPU空闲并且等待I/O操作完成的时间比例（top中查看wa的值）。 2. 考虑减少内存分配和释放服务器的工作过程中，需要大量的内存，使得内存的分配和释放工作尤为重要。 可以通过改善数据结构和算法复制度来适当减少中间临时变量的内存分配及数据复制时间，而服务器本身也使用了各自的策略来提高效率。 例如Apache,在运行开始时一次申请大片的内存作为内存池，若随后需要时就在内存池中直接获取，不需要再次分配，避免了频繁的内存分配和释放引起的内存整理时间。 再如Nginx使用多线程来处理请求，使得多个线程之间可以共享内存资源，从而令它的内存总体使用量大大减少。 另外，Nginx分阶段的内存分配策略，按需分配，及时释放，使得内存使用量保持在很小的数量范围。 另外，还可以考虑共享内存。 共享内存指在多处理器的计算机系统中，可以被不同中央处理器（CPU）访问的大容量内存，也可以由不同进程共享，是非常快的进程通信方式。 但是使用共享内存也有不好的地方，就是对于多机器时数据不好统一。 shell命令ipcs可用来显示系统下共享内存的状态，函数shmget可以创建或打开一块共享内存区，函数shmat将一个存在的共享内存段连接到本进程空间, 函数shmctl可以对共享内存段进行多种操作，函数shmdt函数分离该共享内存。 3. 考虑使用持久连接持久连接也为长连接，它本身是TCP通信的一种普通方式，即在一次TCP连接中持续发送多分数据而不断开连接。 与它相反的方式称为短连接，也就是建立连接后发送一份数据就断开，然后再次建立连接发送下一份数据， 周而复始。 是否采用持久连接，完全取决于应用特点。 从性能角度看，建立TCP连接的操作本身是一项不小的开销，在允许的情况下，连接次数越少，越有利于性能的提升; 尤其对于密集型的图片或网页等小数据请求处理有明显的加速所用。 HTTP长连接需要浏览器和web服务器的共同协作，目前浏览器普遍支持长连接，表现在其发出的HTTP请求数据头中包含关于长连接的声明，如下：Connection: Keep-Alive 主流的web服务器都支持长连接，比如apache中，可以用KeepAlive off关闭长连接。 对于长连接的有效使用，还有关键一点在于长连接超时时间的设置，即长连接在什么时候关闭吗？ Apache的默认设置为5s, 若这个时间设置过长，则可能导致资源无效占有，维持大量空闲进程，影响服务器性能。 4. 改进I/O 模型I/O操作根据设备的不同分为很多类型，比如内存I/O, 网络I/O, 磁盘I/O。 对于网络I/O和磁盘I/O, 它们的速度要慢很多，尽管使用RAID磁盘阵列可通过并行磁盘磁盘来加快磁盘I/O速度，购买大连独享网络带宽以及使用高带宽网络适配器可以提高网络I/O的速度。 但这些I/O操作需要内核系统调用来完成，这些需要CPU来调度，这使得CPU不得不浪费宝贵的时间来等待慢速I/O操作。 我们希望让CPU足够少的时间在i/O操作的调度上，如何让高速的CPU和慢速的I/O设备更好地协调工作，是现代计算机一直探讨的话题。各种I/O模型的本质区别在于CPU的参与方式。 DMA技术I/O设备和内存之间的数据传输方式由DMA控制器完成。在DMA模式下，CPU只需向DMA下达命令，让DMA控制器来处理数据的传送，这样可以大大节省系统资源。 异步I/O异步I/O指主动请求数据后便可以继续处理其它任务，随后等待I/O操作的通知，这样进程在数据读写时不发生阻塞。 异步I/O是非阻塞的，当函数返回时，真正的I/O传输已经完成，这让CPU处理和I/O操作达到很好的重叠。 I/O多路复用epoll服务器同时处理大量的文件描述符是必不可少的，若采用同步非阻塞I/O模型，若同时接收TCP连接的数据，就必须轮流对每个socket调用接收数据的方法，不管这些socket有没有可接收的数据，都要询问一次。 假如大部分socket并没有数据可以接收，那么进程便会浪费很多CPU时间用于检查这些socket有没有可以接收的数据。 多路I/O就绪通知的出现，提供了对大量文件描述符就绪检查的高性能方案，它允许进程通过一种方法同时监视所有文件描述符，并可以快速获得所有就绪的文件描述符，然后只针对这些文件描述符进行数据访问。 epoll可以同时支持水平触发和边缘触发，理论上边缘触发性能更高，但是代码实现复杂，因为任何意外的丢失事件都会造成请求处理错误。 epoll主要有2大改进： epoll只告知就绪的文件描述符，而且当调用epoll_wait()获得文件描述符时，返回并不是实际的描述符，而是一个代表就绪描述符数量的值，然后只需去epoll指定的一个数组中依次取得相应数量的文件描述符即可。 这里使用了内存映射(mmap)技术，这样彻底省掉了这些文件描述符在系统调用时复制的开销。 epoll采用基于事件的就绪通知方式。其事先通过epoll_ctrl()注册每一个文件描述符，一旦某个文件描述符就绪时，内核会采用类似callback的回调机制，当进程调用epoll_wait()时得到通知 关于IO模型，可以参考笔者前面写的相关文章Java NIO.2；关于epoll，可以参考笔者前面写的文章select、poll和epoll简介。 Sendfile大多数时候，我们都向服务器请求静态文件，比如图片，样式表等。 在处理这些请求时，磁盘文件的数据先经过内核缓冲区，然后到用户内存空间，不需经过任何处理，其又被送到网卡对应的内核缓冲区，接着再被送入网卡进行发送。 Linux提供sendfile()系统调用，可以讲磁盘文件的特定部分直接传送到代表客户端的socket描述符，加快了静态文件的请求速度，同时减少CPU和内存的开销。 适用场景：对于请求较小的静态文件，sendfile发挥的作用不那么明显，因发送数据的环节在整个过程中所占时间的比例相比于大文件请求时小很多。 内存映射Linux内核提供一种访问磁盘文件的特殊方式，它可以将内存中某块地址空间和我们指定的磁盘文件相关联，从而对这块内存的访问转换为对磁盘文件的访问。这种技术称为内存映射。 多数情况下，内存映射可以提高磁盘I/O的性能，无须使用read()或write()等系统调用来访问文件，而是通过mmap()系统调用来建立内存和磁盘文件的关联，然后像访问内存一样自由访问文件。 缺点：在处理较大文件时，内存映射会导致较大的内存开销，得不偿失。 直接I/O在linux 2.6中，内存映射和直接访问文件没有本质差异，因为数据需要经过2次复制，即在磁盘与内核缓冲区之间以及在内核缓冲区与用户态内存空间。 引入内核缓冲区的目的在于提高磁盘文件的访问性能，然而对于一些复杂的应用，比如数据库服务器，它们为了进一步提高性能，希望绕过内核缓冲区，由自己在用户态空间实现并管理I/O缓冲区，比如数据库可根据更加合理的策略来提高查询缓存命中率。 另一方面，绕过内核缓冲区也可以减少系统内存的开销，因内核缓冲区本身就在使用系统内存。 Linux在open()系统调用中增加参数选项O_DIRECT,即可绕过内核缓冲区直接访问文件,实现直接I/O。 在Mysql中，对于Innodb存储引擎，自身进行数据和索引的缓存管理，可在my.cnf配置中分配raw分区跳过内核缓冲区，实现直接I/O。 5. 改进服务器并发策略服务器并发策略的目的，是让I/O操作和CPU计算尽量重叠进行，一方面让CPU在I/O等待时不要空闲，另一方面让CPU在I/O调度上尽量花最少的时间。 一个进程处理一个连接，非阻塞I/O这样会存在多个并发请求同时到达时，服务器必然要准备多个进程来处理请求。其进程的开销限制了它的并发连接数。 但从稳定性和兼容性的角度，则其相对安全，任何一个子进程的崩溃不会影响服务器本身，父进程可以创建新的子进程；这种策略典型的例子就是Apache的fork和prefork模式。 对于并发数不高（如150以内）的站点同时依赖Apache其它功能时的应用选择Apache还是可以的。 一个线程处理一个连接，非阻塞IO这种方式允许在一个进程中通过多个线程来处理多个连接，一个线程处理一个连接。Apache的worker模式就是这种典型例子，使其可支持更多的并发连接。不过这种模式的总体性能还不如prefork，所以一般不选用worker模式。 一个进程处理多个连接，异步I/O一个线程同时处理多个连接，潜在的前提条件就是使用IO多路复用就绪通知。 这种情况下，将处理多个连接的进程叫做worker进程或服务进程。worker的数量可以配置，如Nginx中的worker_processes 4。 一个线程处理多个连接，异步IO即使有高性能的IO多路复用就绪通知，但磁盘IO的等待还是无法避免的。更加高效的方法是对磁盘文件使用异步IO，目前很少有Web服务器真正意义上支持这种异步IO。 6. 改进硬件环境还有一点要提及的是硬件环境，服务器的硬件配置对应用程序的性能提升往往是最直接，也是最简单的方式，这就是所谓的scale up。这里不做论述。 附录什么是重入锁 java.util.concurrent.locks.ReentrantLock 这个是 JDK @since 1.5 添加的一种颗粒度更小的锁，它完全可以替代 synchronized 关键字来实现它的所有功能，而且 ReentrantLock 锁的灵活度要远远大于 synchronized 关键字。 从类结构图看出，ReentrantLock 实现了 Lock 接口，ReentrantLock 只是 Lock 接口的一个实现而已。 java.util.concurrent.locks.Lock 它们都是 java.util.concurrent 包里面的内容（俗称 JUC、并发包），也都是 JDK 1.5 开始加入的。 为什么叫重入锁呢？ReentrantLock，我们把它拆开来看就明了了。 Re-Entrant-Lock：即表示可重新反复进入的锁，但仅限于当前线程； 12345678910public void m() &#123; lock.lock(); lock.lock(); try &#123; // ... method body &#125; finally &#123; lock.unlock() lock.unlock() &#125;&#125; 如示例代码所示，当前线程可以反复加锁，但也需要释放同样加锁次数的锁，即重入了多少次，就要释放多少次，不然也会导入锁不被释放。 试想一下，如果不设计成可重入锁，那自己如果反复给自己加锁，不是会把自己加死锁了吗？所以，到现在，重入锁的概念大概应该清楚了吧？ 重入锁最重要的几个方法这几个方法都是 Lock 接口中定义的： 1）lock() 获取锁，有以下三种情况： 锁空闲：直接获取锁并返回，同时设置锁持有者数量为：1； 当前线程持有锁：直接获取锁并返回，同时锁持有者数量递增1； 其他线程持有锁：当前线程会休眠等待，直至获取锁为止； 2）lockInterruptibly() 获取锁，逻辑和 lock() 方法一样，但这个方法在获取锁过程中能响应中断。 3）tryLock() 从关键字字面理解，这是在尝试获取锁，获取成功返回：true，获取失败返回：false, 这个方法不会等待，有以下三种情况： 锁空闲：直接获取锁并返回：true，同时设置锁持有者数量为：1； 当前线程持有锁：直接获取锁并返回：true，同时锁持有者数量递增1； 其他线程持有锁：获取锁失败，返回：false； 4）tryLock(long timeout, TimeUnit unit) 逻辑和 tryLock() 差不多，只是这个方法是带时间的。 5）unlock() 释放锁，每次锁持有者数量递减 1，直到 0 为止。所以，现在知道为什么 lock 多少次，就要对应 unlock 多少次了吧。 6）newCondition 返回一个这个锁的 Condition 实例，可以实现 synchronized 关键字类似 wait/ notify 实现多线程通信的功能，不过这个比 wait/ notify 要更灵活，更强大！ 重入锁大概的用法12345678910111213141516class X &#123; private final ReentrantLock lock = new ReentrantLock(); // ... public void m() &#123; lock.lock(); // block until condition holds try &#123; // ... method body &#125; finally &#123; lock.unlock() &#125; &#125;&#125;&#125; 看见没有，加锁和释放锁都在方法里面进行，可以自由控制，比 synchronized 更灵活，更方便。但要注意的是，释放锁操作必须在 finally 里面，不然如果出现异常导致锁不能被正常释放，进而会卡死后续所有访问该锁的线程。 synchronized 是重入锁吗？那么问题来了，synchronized 是重入锁吗？ 你可能会说不是，因为 ReentrantLock 既然是重入锁，根据推理，相反，那 synchronized 肯定就不是重入锁，那你就错了。 答案是：yes，为什么？看下面的例子： 1234567public synchronized void operation()&#123; add();&#125;public synchronized void add()&#123;&#125; operation 方法调用了 add 方法，两个方法都是用 synchronized 修饰的，add() 方法可以成功获取当前线程 operation() 方法已经获取到的锁，说明 synchronized 就是可重入锁。","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/categories/架构设计/"}],"tags":[{"name":"分布式架构","slug":"分布式架构","permalink":"https://vincentruan.github.io/tags/分布式架构/"},{"name":"资源管理","slug":"资源管理","permalink":"https://vincentruan.github.io/tags/资源管理/"},{"name":"转载","slug":"转载","permalink":"https://vincentruan.github.io/tags/转载/"}]},{"title":"分布式基础要点","slug":"分布式基础要点","date":"2020-02-06T12:20:12.000Z","updated":"2020-02-17T02:40:44.865Z","comments":true,"path":"2020/02/06/分布式基础要点/","link":"","permalink":"https://vincentruan.github.io/2020/02/06/分布式基础要点/","excerpt":"","text":"1 概念1.1 模型节点在具体的工程项目中，一个节点往往是一个操作系统上的进程。在本文的模型中，认为节点是一个完整的、不可分的整体，如果某个程序进程实际上由若干相对独立部分构成，则在模型中可以将一个进程划分为多个节点。 异常 机器宕机：机器宕机是最常见的异常之一。在大型集群中每日宕机发生的概率为千分之一左右，在实践中，一台宕机的机器恢复的时间通常认为是24 小时，一般需要人工介入重启机器。 网络异常：消息丢失，两片节点之间彼此完全无法通信，即出现了“网络分化”；消息乱序，有一定的概率不是按照发送时的顺序依次到达目的节点，考虑使用序列号等机制处理网络消息的乱序问题，使得无效的、过期的网络消息不影响系统的正确性；数据错误；不可靠的TCP，TCP 协议为应用层提供了可靠的、面向连接的传输服务，但在分布式系统的协议设计中不能认为所有网络通信都基于TCP 协议则通信就是可靠的。TCP协议只能保证同一个TCP 链接内的网络消息不乱序，TCP 链接之间的网络消息顺序则无法保证。 分布式三态：如果某个节点向另一个节点发起RPC(Remote procedure call)调用，即某个节点A 向另一个节点B 发送一个消息，节点B 根据收到的消息内容完成某些操作，并将操作的结果通过另一个消息返回给节点A，那么这个RPC 执行的结果有三种状态：“成功”、“失败”、“超时（未知）”，称之为分布式系统的三态。 存储数据丢失:对于有状态节点来说，数据丢失意味着状态丢失，通常只能从其他节点读取、恢复存储的状态。 异常处理原则\\：被大量工程实践所检验过的异常处理黄金原则是：任何在设计阶段考虑到的异常情况一定会在系统实际运行中发生，但在系统实际运行遇到的异常却很有可能在设计时未能考虑，所以，除非需求指标允许，在系统设计时不能放过任何异常情况。 1.2 副本副本（replica/copy）指在分布式系统中为数据或服务提供的冗余。对于数据副本指在不同的节点上持久化同一份数据，当出现某一个节点的存储的数据丢失时，可以从副本上读到数据。数据副本是分布式系统解决数据丢失异常的唯一手段。另一类副本是服务副本，指数个节点提供某种相同的服务，这种服务一般并不依赖于节点的本地存储，其所需数据一般来自其他节点。 副本协议是贯穿整个分布式系统的理论核心。 副本一致性分布式系统通过副本控制协议，使得从系统外部读取系统内部各个副本的数据在一定的约束条件下相同，称之为副本一致性(consistency)。副本一致性是针对分布式系统而言的，不是针对某一个副本而言。 强一致性(strong consistency)：任何时刻任何用户或节点都可以读到最近一次成功更新的副本数据。强一致性是程度最高的一致性要求，也是实践中最难以实现的一致性。 单调一致性(monotonic consistency)：任何时刻，任何用户一旦读到某个数据在某次更新后的值，这个用户不会再读到比这个值更旧的值。单调一致性是弱于强一致性却非常实用的一种一致性级别。因为通常来说，用户只关心从己方视角观察到的一致性，而不会关注其他用户的一致性情况。 会话一致性(session consistency)：任何用户在某一次会话内一旦读到某个数据在某次更新后的值，这个用户在这次会话过程中不会再读到比这个值更旧的值。会话一致性通过引入会话的概念，在单调一致性的基础上进一步放松约束，会话一致性只保证单个用户单次会话内数据的单调修改，对于不同用户间的一致性和同一用户不同会话间的一致性没有保障。实践中有许多机制正好对应会话的概念，例如php 中的session 概念。 最终一致性(eventual consistency)：最终一致性要求一旦更新成功，各个副本上的数据最终将达 到完全一致的状态，但达到完全一致状态所需要的时间不能保障。对于最终一致性系统而言，一个用户只要始终读取某一个副本的数据，则可以实现类似单调一致性的效果，但一旦用户更换读取的副本，则无法保障任何一致性。 弱一致性(week consistency)：一旦某个更新成功，用户无法在一个确定时间内读到这次更新的值，且即使在某个副本上读到了新的值，也不能保证在其他副本上可以读到新的值。弱一致性系统一般很难在实际中使用，使用弱一致性系统需要应用方做更多的工作从而使得系统可用。 1.3 衡量分布式系统的指标 性能：系统的吞吐能力，指系统在某一时间可以处理的数据总量，通常可以用系统每秒处理的总的数据量来衡量；系统的响应延迟，指系统完成某一功能需要使用的时间；系统的并发能力，指系统可以同时完成某一功能的能力，通常也用QPS(query per second)来衡量。上述三个性能指标往往会相互制约，追求高吞吐的系统，往往很难做到低延迟；系统平均响应时间较长时，也很难提高QPS。 可用性：系统的可用性(availability)指系统在面对各种异常时可以正确提供服务的能力。系统的可用性可以用系统停服务的时间与正常服务的时间的比例来衡量，也可以用某功能的失败次数与成功次数的比例来衡量。可用性是分布式的重要指标，衡量了系统的鲁棒性，是系统容错能力的体现。 可扩展性：系统的可扩展性(scalability)指分布式系统通过扩展集群机器规模提高系统性能（吞吐、延迟、并发）、存储容量、计算能力的特性。好的分布式系统总在追求“线性扩展性”，也就是使得系统的某一指标可以随着集群中的机器数量线性增长。 一致性：分布式系统为了提高可用性，总是不可避免的使用副本的机制，从而引发副本一致性的问题。越是强的一致的性模型，对于用户使用来说使用起来越简单。 2 分布式系统原理2.1 数据分布方式所谓分布式系统顾名思义就是利用多台计算机协同解决单台计算机所不能解决的计算、存储等问题。单机系统与分布式系统的最大的区别在于问题的规模，即计算、存储的数据量的区别。将一个单机问题使用分布式解决，首先要解决的就是如何将问题拆解为可以使用多机分布式解决，使得分布式系统中的每台机器负责原问题的一个子集。由于无论是计算还是存储，其问题输入对象都是数据，所以如何拆解分布式系统的输入数据成为分布式系统的基本问题。 哈希方式 哈希分布数据的缺点同样明显，突出表现为可扩展性不高，一旦集群规模需要扩展，则几乎所有的数据需要被迁移并重新分布。工程中，扩展哈希分布数据的系统时，往往使得集群规模成倍扩展，按照数据重新计算哈希，这样原本一台机器上的数据只需迁移一半到另一台对应的机器上即可完成扩展。 针对哈希方式扩展性差的问题，一种思路是不再简单的将哈希值与机器做除法取模映射，而是将对应关系作为元数据由专门的元数据服务器管理.同时，哈希值取模个数往往大于机器个数，这样同一台机器上需要负责多个哈希取模的余数。但需要以较复杂的机制维护大量的元数据。哈希分布数据的另一个缺点是，一旦某数据特征值的数据严重不均，容易出现“数据倾斜”（data skew）问题。 哈希分布数据的另一个缺点是，一旦某数据特征值的数据严重不均，容易出现“数据倾斜”（data skew）问题 按数据范围分布按数据范围分布是另一个常见的数据分布式，将数据按特征值的值域范围划分为不同的区间，使得集群中每台（组）服务器处理不同区间的数据。 工程中，为了数据迁移等负载均衡操作的方便，往往利用动态划分区间的技术，使得每个区间中服务的数据量尽量的一样多。当某个区间的数据量较大时，通过将区间“分裂”的方式拆分为两个区间，使得每个数据区间中的数据量都尽量维持在一个较为固定的阈值之下。 一般的，往往需要使用专门的服务器在内存中维护数据分布信息，称这种数据的分布信息为一种元信息。甚至对于大规模的集群，由于元信息的规模非常庞大，单台 计算机无法独立维护，需要使用多台机器作为元信息服务器。 按数据量分布数据量分布数据与具体的数据特征无关，而是将数据视为一个顺序增长的文件，并将这个文件按照某一较为固定的大小划分为若干数据块（chunk），不同的数据块分布到不同的服务器上。与按数据范围分布数据的方式类似的是，按数据量分布数据也需要记录数据块的具体分布情况，并将该分布信息作为元数据使用元数据服务器管理。 由于与具体的数据内容无关，按数据量分布数据的方式一般没有数据倾斜的问题，数据总是被均匀切分并分布到集群中。当集群需要重新负载均衡时，只需通过迁移数据块即可完成。集群扩容也没有太大的限制，只需将部分数据库迁移到新加入的机器上即可以完成扩容。按数据量划分数据的缺点是需要管理较为复杂的元信息，与按范围分布数据的方式类似，当集群规模较大时，元信息的数据量也变得很大，高效的管理元信息成为新的课题。 一致性哈希一致性哈希（consistent hashing）是另一个种在工程中使用较为广泛的数据分布方式。一致性哈希最初在P2P 网络中作为分布式哈希表（DHT）的常用数据分布算法。一致性哈希的基本方式是使用一个哈希函数计算数据或数据特征的哈希值，令该哈希函数的输出值域为一个封闭的环，即哈希函数输出的最大值是最小值的前序。将节点随机分布到这个环上，每个节点负责处理从自己开始顺时针至下一个节点的全部哈希值域上的数据。 使用一致性哈希的方式需要将节点在一致性哈希环上的位置作为元信息加以管理，这点比直接使用哈希分布数据的方式要复杂。然而，节点的位置信息只于集群中的机器规模相关，其元信息的量通常比按数据范围分布数据和按数据量分布数据的元信息量要小很多。 为此一种常见的改进算法是引入虚节点（virtual node）的概念，系统初始时就创建许多虚节点，虚节点的个数一般远大于未来集群中机器的个数，将虚节点均匀分布到一致性哈希值域环上，其功能与基本一致性哈希算法中的节点相同。为每个节点分配若干虚节点。操作数据时，首先通过数据的哈希值在环上找到对应的虚节点，进而查找元数据找到对应的真实节点。使用虚节点改进有多个优点。首先，一旦某个节点不可用，该节点将使得多个虚节点不可用，从而使得多个相邻的真实节点负载失效节点的压里。同理，一旦加入一个新节点，可以分配多个虚节点，从而使得新节点可以 负载多个原有节点的压力，从全局看，较容易实现扩容时的负载均衡。 副本与数据分布分布式系统容错、提高可用性的基本手段就是使用副本。对于数据副本的分布方式主要影响系统的可扩展性。一种基本的数据副本策略是以机器为单位，若干机器互为副本，副本机器之间的数据完全相同。这种策略适用于上述各种数据分布方式。其优点是非常简单，其缺点是恢复数据的效率不高、可扩展性也不高。 更合适的做法不是以机器作为副本单位，而是将数据拆为较合理的数据段，以数据段为单位作为副本。实践中，常常使得每个数据段的大小尽量相等且控制在一定的大小以内。数据段有很多不同的称谓，segment，fragment，chunk，partition 等等。数据段的选择与数据分布方式直接相关。对于哈希分数据的方式，每个哈希分桶后的余数可以作为一个数据段，为了控制数据段的大小，常常使得分桶个数大于集群规模。一旦将数据分为数据段，则可以以数据段为单位管理副本，从而副本与机器不再硬相关，每台机器都可以负责一定数据段的副本。 一旦副本分布与机器无关，数据丢失后的恢复效率将非常高。这是因为，一旦某台机器的数据丢失，其上数据段的副本将分布在整个集群的所有机器中，而不是仅在几个副本机器中，从而可以从整个集群同时拷贝恢复数据，而集群中每台数据源机器都可以以非常低的资源做拷贝。作为恢复数据源的机器即使都限速1MB/s，若有100 台机器参与恢复，恢复速度也能达到100MB/s。再者，副本分布与机器无关也利于集群容错。如果出现机器宕机，由于宕机机器上的副本分散于整个集群，其压力也自然分散到整个集群。最后，副本分布与机器无关也利于集群扩展。理论上，设集群规模 为N 台机器，当加入一台新的机器时，只需从各台机器上迁移1/N – 1/N+1 比例的数据段到新机器即实现了新的负载均衡。由于是从集群中各机器迁移数据，与数据恢复同理，效率也较高。工程中，完全按照数据段建立副本会引起需要管理的元数据的开销增大，副本维护的难度也相应增大。一种折中的做法是将某些数据段组成一个数据段分组，按数据段分组为粒度进行副本管理。这样做可以将副本粒度控制在一个较为合适的范围内。 本地化计算在分布式系统中，数据的分布方式也深深影响着计算的分布方式。在分布式系统中计算节点和保存计算数据的存储节点可以在同一台物理机器上，也可以位于不同的物理机器。如果计算节点和存储节点位于不同的物理机器则计算的数据需要通过网络传输，此种方式的开销很大，甚至网络带宽会成为系统的总体瓶颈。另一种思路是，将计算尽量调度到与存储节点在同一台物理机器上的计算节点上进行，这称之为本地化计算。本地化计算是计算调度的一种重要优化，其体现了一种重要的分布式调度思想：“移动数据不如移动计算”。 数据分布方式的选择在实际工程实践中，可以根据需求及实施复杂度合理选择数据分布方式。另外，数据分布方式是可以灵活组合使用的，往往可以兼备各种方式的优点，收到较好的综合效果。 例：数据倾斜问题，在按哈希分数据的基础上引入按数据量分布数据的方式，解决该数据倾斜问题。按用户id 的哈希值分数据，当某个用户id 的数据量特别大时，该用户的数据始终落在某一台机器上。此时，引入按数据量分布数据的方式，统计用户的数据量，并按某一阈值将用户的数据切为多个均匀的数据段，将这些数据段分布到集群中去。由于大部分用户的数据量不会超过阈值，所以元数据中仅仅保存超过阈值的用户的数据段分布信息，从而可以控制元数据的规模。这种哈希分布数据方式与按数据量分布数据方式组合使用的方案，在某真实系统中使用，取得了较好的效果。 2.2 基本副本协议副本控制协议指按特定的协议流程控制副本数据的读写行为，使得副本满足一定的可用性和一致性要求的分布式协议。副本控制协议要具有一定的对抗异常状态的容错能力，从而使得系统具有一定的可用性，同时副本控制协议要能提供一定一致性级别。由CAP 原理（在2.9 节详细分析）可知，要设计一种满足强一致性，且在出现任何网络异常时都可用的副本协议是不可能的。为此，实际中的副本控制协议总是在可用性、一致性与性能等各要素之间按照具体需求折中。 副本控制协议可以分为两大类：“中心化(centralized)副本控制协议”和“去中心化(decentralized)副本控制协议”。 中心化副本控制协议中心化副本控制协议的基本思路是由一个中心节点协调副本数据的更新、维护副本之间的一致性。图给出了中心化副本协议的通用架构。中心化副本控制协议的优点是协议相对较为简单，所有的副本相关的控制交由中心节点完成。并发控制将由中心节点完成，从而使得一个分布式并发控制问题，简化为一个单机并发控制问题。所谓并发控制，即多个节点同时需要修改副本数据时，需要解决“写写”、“读写”等并发冲突。单机系统上常用加锁等方式进行并发控制。对于分布式并发控制，加锁也是一个常用的方法，但如果没有中心节点统一进行锁管理，就需要完全分布式化的锁系统，会使得协议非常复杂。中心化副本控制协议的缺点是系统的可用性依赖于中心化节点，当中心节点异常或与中心节点通信中断时，系统将失去某些服务（通常至少失去更新服务），所以中心化副本控制协议的缺点正是存在一定的停服务时间。 primary-secondary 协议在primary-secondary 类型的协议中，副本被分为两大类，其中有且仅有一个副本作为primary 副本，除primary 以外的副本都作为secondary 副本。维护primary 副本的节点作为中心节点，中心节点负责维护数据的更新、并发控制、协调副本的一致性。 Primary-secondary 类型的协议一般要解决四大类问题：数据更新流程、数据读取方式、Primary 副本的确定和切换、数据同步（reconcile）。 数据更新基本流程 数据更新都由primary 节点协调完成。 外部节点将更新操作发给primary 节点 primary 节点进行并发控制即确定并发更新操作的先后顺序 primary 节点将更新操作发送给secondary 节点 primary 根据secondary 节点的完成情况决定更新是否成功并将结果返回外部节点 在工程实践中，如果由primary 直接同时发送给其他N 个副本发送数据，则每个 secondary 的更新吞吐受限于primary 总的出口网络带宽，最大为primary 网络出口带宽的1/N。为了解决这个问题，有些系统（例如，GFS），使用接力的方式同步数据，即primary 将更新发送给第一 个secondary 副本，第一个secondary 副本发送给第二secondary 副本，依次类推。 数据读取方式数据读取方式也与一致性高度相关。如果只需要最终一致性，则读取任何副本都可以满足需求。如果需要会话一致性，则可以为副本设置版本号，每次更新后递增版本号，用户读取副本时验证版本号，从而保证用户读到的数据在会话范围内单调递增。使用primary-secondary 比较困难的是实现强一致性。 由于数据的更新流程都是由primary 控制的，primary 副本上的数据一定是最新的，所以 如果始终只读primary 副本的数据，可以实现强一致性。如果只读primary 副本，则secondary 副本将不提供读服务。实践中，如果副本不与机器绑定，而是按照数据段为单位维护副本，仅有primary 副本提供读服务在很多场景下并不会造出机器资源浪费。 将副本分散到集群中个，假设primary 也是随机的确定的，那么每台机器上都有一些数据的primary 副本，也有另一些数据段的secondary 副本。从而某台服务器实际都提供读写服务。 由primary 控制节点secondary 节点的可用性。当primary 更新某个secondary 副本不成功时，primary 将该secondary 副本标记为不可用，从而用户不再读取该不可用的副本。不可用的 secondary 副本可以继续尝试与primary 同步数据，当与primary 完成数据同步后，primary 可以副本标记为可用。这种方式使得所有的可用的副本，无论是primary 还是secondary 都是可读的，且在一个确定的时间内，某secondary 副本要么更新到与primary 一致的最新状态，要么被标记为不可用，从而符合较高的一致性要求。这种方式依赖于一个中心元数据管理系统，用于记录哪些副本可用，哪些副本不可用。某种意义上，该方式通过降低系统的可用性来提高系统的一致性。 primary 副本的确定与切换在primary-secondary 类型的协议中，另一个核心的问题是如何确定primary 副本，尤其是在原primary 副本所在机器出现宕机等异常时，需要有某种机制切换primary 副本，使得某个secondary 副本成为新的primary 副本。 通常的，在primary-secondary 类型的分布式系统中，哪个副本是primary 这一信息都属于元信息，由专门的元数据服务器维护。执行更新操作时，首先查询元数据服务器获取副本的primary 信息，从而进一步执行数据更新流程。 由于分布式系统中可靠的发现节点异常是需要一定的探测时间的，这样的探测时间通常是10 秒级别，这也意味着一旦primary 异常，最多需要10 秒级别的发现时间，系统才能开始primary 的切换，在这10 秒时间内，由于没有primary，系统不能提供更 新服务，如果系统只能读primary 副本，则这段时间内甚至不能提供读服务。从这里可以看到，primary-backup 类副本协议的最大缺点就是由于primary 切换带来的一定的停服务时间。 数据同步不一致的secondary 副本需要与primary 进行同步（reconcile）。 通常不一致的形式有三种：一、由于网络分化等异常，secondary 上的数据落后于primary 上的数据。二、在某些协议下，secondary 上的数据有可能是脏数据，需要被丢弃。所谓脏数据是由于primary 副本没有进行某一更新操作，而secondary 副本上反而进行的多余的修改操作，从而造成secondary 副本数据错误。三、secondary 是一个新增加的副本，完全没有数据，需要从其他副本上拷贝数据。 对于第一种secondary 数据落后的情况，常见的同步方式是回放primary 上的操作日志（通常是redo 日志），从而追上primary 的更新进度。对于脏数据的情况，较好的做法是设计的分布式协议不产生脏数据。如果协议一定有产生脏数据的可能，则也应该使得产生脏数据的概率降到非常低得情况，从而一旦发生脏数据的情况可以简单的直接丢弃有脏数据的副本，这样相当于副本没有数据。另外，也可以设计一些基于undo 日志的方式从而可以删除脏数据。如果secondary 副本完全没有数据，则常见的做法是直接拷贝primary 副本的数据，这种方法往往比回放日志追更新进度的方法快很多。但拷贝数据时primary 副本需要能够继续提供更新服务，这就要求primary 副本支持快照(snapshot)功能。即对某一刻的副本数据形成快照，然后拷贝快照，拷贝完成后使用回放日志的方式追快照形成后的更新操作。 去中心化副本控制协议去中心化副本控制协议没有中心节点，协议中所有的节点都是完全对等的，节点之间通过平等协商达到一致。从而去中心化协议没有因为中心化节点异常而带来的停服务等问题。 去中心化协议的最大的缺点是协议过程通常比较复杂。尤其当去中心化协议需要实现强一致性时，协议流程变得复杂且不容易理解。由于流程的复杂，去中心化协议的效率或者性能一般也较中心化协议低。一个不恰当的比方就是，中心化副本控制协议类似专制制度，系统效率高但高度依赖于中心节点，一旦中心节点异常，系统受到的影响较大；去中心化副本控制协议类似民主制度，节点集体协商，效率低下，但个别节点的异常不会对系统总体造成太大影响。 2.3 Lease 机制Lease 机制是最重要的分布式协议，广泛应用于各种实际的分布式系统中。 基于lease 的分布式cache 系统基本的问题背景如下：在一个分布式系统中，有一个中心服务器节点，中心服务器存储、维护着一些数据，这些数据是系统的元数据。系统中其他的节点通过访问中心服务器节点读取、修改其上的元数据。由于系统中各种操作都依赖于元数据，如果每次读取元数据的操作都访问中心服务器 节点，那么中心服务器节点的性能成为系统的瓶颈。为此，设计一种元数据cache，在各个节点上 cache 元数据信息，从而减少对中心服务器节点的访问，提高性能。另一方面，系统的正确运行严格依赖于元数据的正确，这就要求各个节点上cache 的数据始终与中心服务器上的数据一致，cache 中的数据不能是旧的脏数据。最后，设计的cache 系统要能最大可能的处理节点宕机、网络中断等异常，最大程度的提高系统的可用性。 为此，利用lease 机制设计一套cache 系统，其基本原理为如下。中心服务器在向各节点发送数据时同时向节点颁发一个lease。每个lease 具有一个有效期，和信用卡上的有效期类似，lease 上的 有效期通常是一个明确的时间点，例如12:00:10，一旦真实时间超过这个时间点，则lease 过期失效。这样lease 的有效期与节点收到lease 的时间无关，节点可能收到lease 时该lease 就已经过期失效。这里首先假设中心服务器与各节点的时钟是同步的，在下节中讨论时钟不同步对lease 的影响。中心服务器发出的lease 的含义为：在lease 的有效期内，中心服务器保证不会修改对应数据的值。因此，节点收到数据和lease 后，将数据加入本地Cache，一旦对应的lease 超时，节点将对应的本地cache 数据删除。中心服务器在修改数据时，首先阻塞所有新的读请求，并等待之前为该数据发出的所有lease 超时过期，然后修改数据的值。 基于lease 的cache，客户端节点读取元数据 判断元数据是否已经处于本地cache 且lease 处于有效期内1.1 是：直接返回cache 中的元数据1.2 否：向中心服务器节点请求读取元数据信息1.2.1 服务器收到读取请求后，返回元数据及一个对应的lease 1.2.2 客户端是否成功收到服务器返回的数据 1.2.2.1 失败或超时：退出流程，读取失败，可重试1.2.2.2 成功：将元数据与该元数据的lease 记录到内存中，返回元数据 基于lease 的cache，客户端节点修改元数据流程2.1 节点向服务器发起修改元数据请求。2.2 服务器收到修改请求后，阻塞所有新的读数据请求，即接收读请求，但不返回数据。2.3 服务器等待所有与该元数据相关的lease 超时。2.4 服务器修改元数据并向客户端节点返回修改成功。 上述机制可以保证各个节点上的cache 与中心服务器上的中心始终一致。这是因为中心服务器节点在发送数据的同时授予了节点对应的lease，在lease 有效期内，服务器不会修改数据，从而客户端节点可以放心的在lease 有效期内cache 数据。上述lease 机制可以容错的关键是：服务器一旦 发出数据及lease，无论客户端是否收到，也无论后续客户端是否宕机，也无论后续网络是否正常，服务器只要等待lease 超时，就可以保证对应的客户端节点不会再继续cache 数据，从而可以放心的修改数据而不会破坏cache 的一致性。 上述基础流程有一些性能和可用性上的问题，但可以很容易就优化改性。优化点一：服务器在修改元数据时首先要阻塞所有新的读请求，造成没有读服务。这是为了防止发出新的lease 从而引起不断有新客户端节点持有lease 并缓存着数据，形成“活锁”。优化的方法很简单，服务器在进入修改数据流程后，一旦收到读请求则只返回数据但不颁发lease。从而造成在修改流程执行的过程中，客户端可以读到元数据，只是不能缓存元数据。进一步的优化是，当进入修改流程，服务器颁发的lease 有效期限选择为已发出的lease 的最大有效期限。这样做，客户端可以继续在服务器进入修改流程后继续缓存元数据，但服务器的等待所有lease 过期的时间也不会因为颁发新的lease 而不断延长。 最后，cache 机制与多副本机制的区别。Cache 机制与多副本机制的相似之处都 是将一份数据保存在多个节点上。但Cache 机制却要简单许多，对于cache 的数据，可以随时删除丢弃，并命中cache 的后果仅仅是需要访问数据源读取数据；然而副本机制却不一样，副本是不能随意丢弃的，每失去一个副本，服务质量都在下降，一旦副本数下降到一定程度，则往往服务将不再可用。 lease 机制的分析lease 的定义：Lease 是由颁发者授予的在某一有效期内的承诺。颁发者一旦发出lease，则无论接受方是否收到，也无论后续接收方处于何种状态，只要lease 不过期，颁发者一定严守承诺；另一方面，接收方在lease 的有效期内可以使用颁发者的承诺，但一旦lease 过期，接收方一定不能继续使用颁发者的承诺。 Lease 机制具有很高的容错能力。首先，通过引入有效期，Lease 机制能否非常好的容错网络异常。Lease 颁发过程只依赖于网络可以单向通信，即使接收方无法向颁发者发送消息，也不影响lease 的颁发。由于lease 的有效期是一个确定的时间点，lease 的语义与发送lease 的具体时间无关，所以 同一个lease 可以被颁发者不断重复向接受方发送。即使颁发者偶尔发送lease 失败，颁发者也可以 简单的通过重发的办法解决。一旦lease 被接收方成功接受，后续lease 机制不再依赖于网络通信，即使网络完全中断lease 机制也不受影响。再者，Lease 机制能较好的容错节点宕机。如果颁发者宕机，则宕机的颁发者通常无法改变之前的承诺，不会影响lease 的正确性。在颁发者机恢复后，如果颁发者恢复出了之前的lease 信息，颁发者可以继续遵守lease 的承诺。如果颁发者无法恢复lease 信息，则只需等待一个最大的lease 超时时间就可以使得所有的lease 都失效，从而不破坏lease机制。 例如上节中的cache 系统的例子中，一旦服务器宕机，肯定不会修改元数据，重新恢复后，只需等待一个最大的lease 超时时间，所有节点上的缓存信息都将被清空。对于接受方宕机的情况，颁发者 不需要做更多的容错处理，只需等待lease 过期失效，就可以收回承诺，实践中也就是收回之前赋予的权限、身份等。最后，lease 机制不依赖于存储。颁发者可以持久化颁发过的lease 信息，从而在 宕机恢复后可以使得在有效期的lease 继续有效。但这对于lease 机制只是一个优化，如之前的分析，即使颁发者没有持久化lease 信息，也可以通过等待一个最大的lease 时间的方式使得之前所有颁发 的lease 失效，从而保证机制继续有效。 Lease 机制依赖于有效期，这就要求颁发者和接收者的时钟是同步的。一方面，如果颁发者的 时钟比接收者的时钟慢，则当接收者认为lease 已经过期的时候，颁发者依旧认为lease 有效。接收者可以用在lease 到期前申请新的lease 的方式解决这个问题。另一方面，如果颁发者的时钟比接收 者的时钟快，则当颁发者认为lease 已经过期的时候，接收者依旧认为lease 有效，颁发者可能将lease 颁发给其他节点，造成承诺失效，影响系统的正确性。对于这种时钟不同步，实践中的通常做法是将颁发者的有效期设置得比接收者的略大，只需大过时钟误差就可以避免对lease 的有效性的影响。 基于lease 机制确定节点状态分布式协议依赖于对节点状态认知的全局一致性，即一旦节点Q 认为某个节点 A 异常，则节点A 也必须认为自己异常，从而节点A 停止作为primary，避免“双主”问题的出现。解决这种问题有两种思路，第一、设计的分布式协议可以容忍“双主”错误，即不依赖于对节点状 态的全局一致性认识，或者全局一致性状态是全体协商后的结果；第二、利用lease 机制。对于第一 种思路即放弃使用中心化的设计，而改用去中心化设计，超过本节的讨论范畴。下面着重讨论利用 lease 机制确定节点状态。 由中心节点向其他节点发送lease，若某个节点持有有效的lease，则认为该节点正常可以提供服 务。用于例2.3.1 中，节点A、B、C 依然周期性的发送heart beat 报告自身状态，节点Q 收到heart beat 后发送一个lease，表示节点Q 确认了节点A、B、C 的状态，并允许节点在lease 有效期内正常工 作。节点Q 可以给primary 节点一个特殊的lease，表示节点可以作为primary 工作。一旦节点Q 希望切换新的primary，则只需等前一个primary 的lease 过期，则就可以安全的颁发新的lease 给新的 primary 节点，而不会出现“双主”问题。 在实际系统中，若用一个中心节点发送lease 也有很大的风险，一旦该中心节点宕机或网络异常，则所有的节点没有lease，从而造成系统高度不可用。为此，实际系统总是使用多个中心节点互为副本，成为一个小的集群，该小集群具有高可用性，对外提供颁发lease 的功能。chubby 和zookeeper 都是基于这样的设计。 lease 的有效期时间选择工程中，常选择的lease 时长是10 秒级别，这是一个经过验证的经验值，实践中可以作为参考并综合选择合适的时长。 2.4 Quorum 机制先做这样的约定：更新操作（write）是一系列顺序的过程，通过其他机制确定更新操作的顺序（例如primary-secondary 架构中由primary 决定顺序），每个更新操作记为wi， i 为更新操作单调递增的序号，每个wi 执行成功后副本数据都发生变化，称为不同的数据版本，记 作vi。假设每个副本都保存了历史上所有版本的数据。 write-all-read-oneWrite-all-read-one（简称WARO）是一种最简单的副本控制规则，顾名思义即在更新时写所有的副本，只有在所有的副本上更新成功，才认为更新成功，从而保证所有的副本一致，这样在读取数据时可以读任一副本上的数据。 由于更新操作需要在所有的N 个副本上都成功，更新操作才能成 功，所以一旦有一个副本异常，更新操作失败，更新服务不可用。对于更新服务，虽然有N 个副本， 但系统无法容忍任何一个副本异常。另一方面，N 个副本中只要有一个副本正常，系统就可以提供读服务。对于读服务而言，当有N 个副本时，系统可以容忍N-1 个副本异常。从上述分析可以发现WARO 读服务的可用性较高，但更新服务的可用性不高，甚至虽然使用了副本，但更新服务的可用性等效于没有副本。 Quorum 定义在Quorum 机制下，当某次更新操作wi 一旦在所有N 个副本中的W 个副本上都成功，则就称 该更新操作为“成功提交的更新操作”，称对应的数据为“成功提交的数据”。令R&gt;N-W，由于更新 操作wi 仅在W 个副本上成功，所以在读取数据时，最多需要读取R 个副本则一定能读到wi 更新后 的数据vi 。如果某次更新wi 在W 个副本上成功，由于W+R&gt;N，任意R 个副本组成的集合一定与 成功的W个副本组成的集合有交集，所以读取R 个副本一定能读到wi 更新后的数据vi。如图 2-10， Quorum 机制的原理可以文森图表示。 某系统有5 个副本，W=3，R=3，最初5 个副本的数据一致，都是v1，某次更新操作 w2 在前3 副本上成功，副本情况变成（v2 v2 v2 v1 v1）。此时，任意3 个副本组成的集合中一定包括 v2。在上述定义中，令W=N，R=1，就得到WARO，即WARO 是Quorum 机制的一种特例。与分析WARO 相似，分析Quorum 机制的可用性。限制Quorum 参数为W+R=N+1。由于更新 操作需要在W 个副本上都成功，更新操作才能成功，所以一旦N-W+1 个副本异常，更新操作始终无法在W 个副本上成功，更新服务不可用。另一方面，一旦N-R+1 个副本异常，则无法保证一定可以读到与W 个副本有交集的副本集合，则读服务的一致性下降。 再次强调：仅仅依赖quorum 机制是无法保证强一致性的。因为仅有quorum 机制时无法确定最新已成功提交的版本号，除非将最新已提交的版本号作为元数据由特定的元数据服务器或元数据集群管理，否则很难确定最新成功提交的版本号。在下一节中，将讨论在哪些情况下，可以仅仅 通过quorum 机制来确定最新成功提交的版本号。 Quorum 机制的三个系统参数N、W、R 控制了系统的可用性，也是系统对用户的服务承诺：数据最多有N 个副本，但数据更新成功W 个副本即返回用户成功。对于一致性要求较高的Quorum 系统，系统还应该承诺任何时候不读取未成功提交的数据，即读取到的数据都是曾经在W 个副本上成功的数据。 读取最新成功提交的数据Quorum 机制只需成功更新N 个副本中的W 个，在读取R 个副本时，一定可以读到最新的成功提交的数据。但由于有不成功的更新情况存在，仅仅读取R 个副本却不一定能确定哪个版本的数据 是最新的已提交的数据。对于一个强一致性Quorum 系统，若存在个数据少于W 个，假设为X 个，则继续读取其他副本，直若成功读取到W 个 该版本的副本，则该数据为最新的成功提交的数据；如果在所有副本中该数据的个数肯定不满 足W 个，则R 中版本号第二大的为最新的成功提交的副本。例：在读取到（v2 v1 v1）时，继续读取剩余的副本，若读到剩余两个副本 为（v2 v2）则v2 是最新的已提交的副本；若读到剩余的两个副本为（v2 v1）或（v1 v1）则v1 是最新成功提交的版本；若读取后续两个副本有任一超时或失败，则无法判断哪个版本是最新的成功提交的版本。 可以看出，在单纯使用Quorum 机制时，若要确定最新的成功提交的版本，最多需要读取R+ （W-R-1）=N 个副本，当出现任一副本异常时，读最新的成功提交的版本这一功能都有可能不可用。实际工程中，应该尽量通过其他技术手段，回避通过Quorum 机制读取最新的成功提交的版本。例如，当quorum 机制与primary-secondary 控制协议结合使用时，可以通过读取primary 的方式读取到最新的已提交的数据。 基于Quorum 机制选择primary副本读取数据时依照一致性要求的不同可以有不同的做法：如果需要强一致性的立刻读取到最新的成功提交的数据，则可以简单的只读取primary 副本上的数据即可，也可以通过上节的方式读取；如果需要会话一致性，则可以根据之前已经读到的数据版本号在各个副本上进行选择性读取；如果只需要弱一致性，则可以选择任意副本读取。 在primary-secondary 协议中，当primary 异常时，需要选择出一个新的primary，之后secondary 副本与primary 同步数据。通常情况下，选择新的primary 的工作是由某一中心节点完成的，在引入 quorum 机制后，常用的primary 选择方式与读取数据的方式类似，即中心节点读取R 个副本，选择 R 个副本中版本号最高的副本作为新的primary。新primary 与至少W 个副本完成数据同步后作为新的primary 提供读写服务。首先，R 个副本中版本号最高的副本一定蕴含了最新的成功提交的数据。再者，虽然不能确定最高版本号的数是一个成功提交的数据，但新的primary 在随后与secondary 同 步数据，使得该版本的副本个数达到W，从而使得该版本的数据成为成功提交的数据。 例：在N=5，W=3，R=3 的系统中，某时刻副本最大版本号为（v2 v2 v1 v1 v1），此时v1 是系统的最新的成功提交的数据，v2 是一个处于中间状态的未成功提交的数据。假设此刻原primary 副本异常，中心节点进行primary 切换工作。这类“中间态”数据究竟作为“脏数据”被删除，还是作为新的数据被同步后成为生效的数据，完全取决于这个数据能否参与新primary 的选举。下面分别分析这两种情况。 第一、如图 2-12，若中心节点与其中3 个副本通信成功，读取到的版本号为（v1 v1 v1），则任 选一个副本作为primary，新primary 以v1 作为最新的成功提交的版本并与其他副本同步，当与第1、第2 个副本同步数据时，由于第1、第2 个副本版本号大于primary，属于脏数据，可以按照2.2.2.4 节中介绍的处理脏数据的方式解决。实践中，新primary 也有可能与后两个副本完成同步后就提供数据服务，随后自身版本号也更新到v2，如果系统不能保证之后的v2 与之前的v2 完全一样，则新 primary 在与第1、2 个副本同步数据时不但要比较数据版本号还需要比较更新操作的具体内容是否一样。 第二、若中心节点与其他3 个副本通信成功，读取到的版本号为（v2 v1 v1），则选取版本号为 v2 的副本作为新的primary，之后，一旦新primary 与其他2 个副本完成数据同步，则符合v2 的副 本个数达到W 个，成为最新的成功提交的副本，新primary 可以提供正常的读写服务。 2.5 日志技术日志技术是宕机恢复的主要技术之一。日志技术最初使用在数据库系统中。严格来说日志技术不是一种分布式系统的技术，但在分布式系统的实践中，却广泛使用了日志技术做宕机恢复，甚 至如BigTable 等系统将日志保存到一个分布式系统中进一步增强了系统容错能力。 Redo Log 与Check point设计一个高速的单机查询系统，将数据全部存放在内存中以实现高速的数据查询，每次更新操作更新一小部分数据（例如 key-value 中的某一个key）。现在问题为利用日志技术实现该内存查询系统的宕机恢复。与数据库的事务不同的是，这个问题模型中的每个成功的更新操作都会生效。这也等效为数据库的每个事务只有一个更新操作，且每次更新操作都可以也必须立即提交（Auto commit）。 Redo Log 将更新操作的结果（例如Set K1=1，则记录K1=1）以追加写（append）的方式写入磁盘的 日志文件 按更新操作修改内存中的数据 返回更新成功 从Redo Log 的流程可以看出，Redo 写入日志的是更新操作完成后的结果（虽然本文不讨论Undo Log，这点是与Undo Log 的区别之一），且由于是顺序追加写日志文件，在磁盘等对顺序写有力的 存储设备上效率较高。 用Redo Log 进行宕机恢复非常简单，只需要“回放”日志即可。 流程2.5.2：Redo Log 的宕机恢复 从头读取日志文件中的每次更新操作的结果，用这些结果修改内存中的数据。 从Redo Log 的宕机恢复流程也可以看出，只有写入日志文件的更新结果才能在宕机后恢复。这也是为什么在Redo Log 流程中需要先更新日志文件再更新内存中的数据的原因。假如先更新内存中的数据，那么用户立刻就能读到更新后的数据，一旦在完成内存修改与写入日志之间发生宕机，那么最后一次更新操作无法恢复，但之前用户可能已经读取到了更新后的数据，从而引起不一致的问题。 Check point 。在简化的模型下，check point 技术的过程即将内存中的数据以某种易于重新加载的数据组织方式完整的dump 到磁盘，从而减少宕机恢复时需要回放的日志数据。 流程：check point 向日志文件中记录“Begin Check Point” 将内存中的数据以某种易于重新加载的数据组织方式dump 到磁盘上 向日志文件中记录“End Check Point” 在check point 流程中，数据可以继续按照流程2.5.1 被更新，这段过程中新更新的数据可以dump 到磁盘也可以不dump 到磁盘，具体取决于实现。例如，check point 开始时k1=v1，check point 过程 中某次更新为k1 = v2，那么dump 到磁盘上的k1 的值可以是v1 也可以是v2。 流程：基于check point 的宕机恢复流程 将dump 到磁盘的数据加载到内存。 从后向前扫描日志文件，寻找最后一个“End Check Point”日志。 从最后一个“End Check Point”日志向前找到最近的一个“Begin Check Point”日志，并回 放该日志之后的所有更新操作日志。 No Undo/No Redo log 若数据维护在磁盘中，某批更新由若干个更新操作组成，这些更新操作需要原子生效，即要么同时生效，要么都不生效。 0/1 目录技术中有两个目录结构，称为目录0(Directory 0)和目录1(Directory 1)。另有一个结构称为主记录（Master record）记录当前正在使用的目录称为活动目录。主记录中要么记录使用目录0，要么记录使用目录1。目录0 或目录1 中记录了各个数据的在日志文件中的位置。0/1 目录的数据更新过程始终在非活动目录上进行，只是在数据生效前，将主记录中的0、1 值反转，从而切换主记录。 流程：0/1 目录数据更新流程 将活动目录完整拷贝到非活动目录。 对于每个更新操作，新建一个日志项纪录操作后的值，并在非活动目录中将相应数据的位置修改为新建的日志项的位置。 原子性修改主记录：反转主记录中的值，使得非活动目录生效。 0/1 目录的更新流程非常简单，通过0、1 目录的主记录切换使得一批修改的生效是原子的。0/1 目录将批量事务操作的原子性通过目录手段归结到主记录的原子切换。由于多条记录的原子修改一般较难实现而单条记录的原子修改往往可以实现，从而降低了问题实现的难度。在工程中0/1 目录的思想运用非常广泛，其形式也不局限在上述流程中，可以是内存中的两个数据结构来回切换，也可以是磁盘上的两个文件目录来回生效切换。 2.6 两阶段提交协议两阶段提交协议是一种经典的强一致性中心化副本控制协议。虽然在工程中该协议有较多的问题，但研究该协议能很好的理解分布式系统的几个典型问题。 流程描述两阶段提交协议是一种典型的“中心化副本控制”协议。在该协议中，参与的节点分为两类：一个中心化协调者节点（coordinator）和N 个参与者节点（participant）。每个参与者节点即上文背景介绍中的管理数据库副本的节点。 两阶段提交的思路比较简单，在第一阶段，协调者询问所有的参与者是否可以提交事务（请参与者投票），所有参与者向协调者投票。在第二阶段，协调者根据所有参与者的投票结果做出是否事务可以全局提交的决定，并通知所有的参与者执行该决定。在一个两阶段提交流程中，参与者不能改变自己的投票结果。两阶段提交协议的可以全局提交的前提是所有的参与者都同意提交事务，只要有一个参与者投票选择放弃(abort)事务，则事务必须被放弃。 流程：两阶段提交协调者流程 写本地日志“begin_commit”，并进入WAIT 状态； 向所有参与者发送“prepare 消息”； 等待并接收参与者发送的对“prepare 消息”的响应；3.1 若收到任何一个参与者发送的“vote-abort 消息”；3.1.1 写本地“global-abort”日志，进入ABORT；3.1.2 向所有的参与者发送“global-abort 消息”；3.1.3 进入ABORT 状态；3.2 若收到所有参与者发送的“vote-commit”消息；3.2.1 写本地“global-commit”日志，进入COMMIT 状态；3.1.2 向所有的参与者发送“global-commit 消息”； 等待并接收参与者发送的对“global-abort 消息”或“global-commit 消息”的确认响应消息，一旦收到所有参与者的确认消息，写本地“end_transaction” 日志流程结束。 流程：两阶段提交协调者流程 写本地日志“init”记录，进入INIT 状态 等待并接受协调者发送的“prepare 消息”，收到后 2.1 若参与者可以提交本次事务 2.1.1 写本地日志“ready”，进入READY 状态 2.1.2 向协调者发送“vote-commit”消息 2.1.4 等待协调者的消息2.1.4.1 若收到协调者的“global-abort”消息2.1.4.1.1 写本地日志“abort”，进入ABORT 状态2.1.4.1.2 向协调者发送对“global-abort”的确认消息 2.1.4.2 若收到协调者的“global-commit”消息2.1.4.1.1 写本地日志“commit”，进入COMMIT 状态 2.1.4.1.2 向协调者发送对“global-commit”的确认消息 2.2 若参与者无法提交本次事务 2.2.1 写本地日志“abort”，进入ABORT 状态 2.2.2 向协调者发送“vote-abort”消息 2.2.3 流程对该参与者结束 2.2.4 若后续收到协调者的“global-abort”消息可以响应 即使流程结束，但任何时候收到协调者发送的“global-abort”消息或“global-commit”消息也都要发送一个对应的确认消息。 异常处理宕机恢复 协调者宕机恢复 协调者宕机恢复后，首先通过日志查找到宕机前的状态。如果日志中最后是“begin_commit”记录，说明宕机前协调者处于WAIT 状态，协调者可能已经发送过“prepare 消息”也可能还没发送，但协调者一定还没有发送过“global-commit 消息”或“global-abort 消息”，即事务的全局状态还没有确定。此时，协调者可以重新发送“prepare 消息” 继续两阶段提交流程，即使参与者已经发送过对“prepare 消息”的响应，也不过是再次重传之前的响应而不会影响协议的一致性。如果日志中最后是“global-commit”或“global-abort”记录，说明宕机前协调者处于COMMIT 或ABORT 状态。此时协调者只需重新向所有的参与者发送“global-commit 消息”或“global-abort 消息”就可以继续两阶段提交流程。 参与者宕机恢复参与者宕机恢复后，首先通过日志查找宕机前的状态。如果日志中最后是“init”记录，说明参与者处于INIT 状态，还没有对本次事务做出投票选择，参与者可以继续流程等待协调者发送的“prepare 消息”。如果日志中最后是“ready”记录，说明参与者处于REDAY 状态，此时说明参与者已经就本次 事务做出了投票选择，但宕机前参与者是否已经向协调者发送“vote-commit”消息并不可知。所以此时参与者可以向协调者重发“vote-commit”，并继续协议流程。如果日志中最后是“commit”或“abort”记录，说明参与者已经收到过协调者的“global-commit 消息”（处于COMMIT 状态）或者“global-abort 消息”（处于ABORT 状态）。至于是否向协调者发 送过对“global-commit”或“global-abort”的确认消息则未知。但即使没有发送过确认消息，由于协调者会不断重发“global-commit”或“global-abort”，只需在收到这些消息时发送确认消息既可，不影响协议的全局一致性。 协议分析两阶段提交协议在工程实践中真正使用的较少，主要原因有以下几点： 两阶段提交协议的容错能力较差。从上文的分析可以看出，两阶段提交协议在某些情况下存在流程无法执行下去的情况，且也无法判断流程状态。在工程中好的分布式协议往往总是可以在即使发生异常的情况下也能执行下去。例如，回忆Lease 机制（2.3 ），一旦lease 发出，无论出现任何异常，Lease 服务器节点总是可以通过时间判定出Lease 是否有效，也可以用等待Lease 超时的方法收回Lease 权限，整个Lease 协议的流程不存在任何流程被阻塞而无法执行下去的情况。与Lease 机制的简单有效相比，两阶段提交的协议显得较为复杂且容错能力差。 两阶段提交协议的性能较差。一次成功的两阶段提交协议流程中，协调者与每个参与者 之间至少需要两轮交互4 个消息“prepare”、“vote-commit”、“global-commit”、“确认global-commit”。过多的交互次数会降低性能。另一方面，协调者需要等待所有的参与者的投票结果，一旦存在较慢的参与者，会影响全局流程执行速度。 虽然存在一些改进的两阶段提交协议可以提高容错能力和性能，然而这类协议依旧是在工程中使用较少的一类协议，其理论价值大于实践意义。 2.7 MVCCMVCC(Multi-version Cocurrent Control，多版本并发控制)技术。MVCC 技术最初也是在数据库系统中被提出，但这种思想并不局限于单机的分布式系统，在分布式系统中同样有效。 MVCC 即多个不同版本的数据实现并发控制的技术，其基本思想是为每次事务生成 一个新版本的数据，在读数据时选择不同版本的数据即可以实现对事务结果的完整性读取。在使用MVCC 时，每个事务都是基于一个已生效的基础版本进行更新，事务可以并行进行，从而可以产生一种图状结构。 基础数据的版本为1，同时产生了两个事务：事务A 与事务B。这两个事务都各自对数据进行了一些本地修改（这些修改只有事务自己可见，不影响真正的数据），之后事务A 首先提交，生成数据版本2；基于数据版本2，又发起了事务C，事务C 继续提交，生成了数据版 本3；最后事务B 提交，此时事务B 的结果需要与事务C 的结果合并，如果数据没有冲突，即事务 B 没有修改事务A 与事务C 修改过的变量，那么事务B 可以提交，否则事务B 提交失败。MVCC 的流程过程非常类似于SVN 等版本控制系统的流程，或者说SVN 等版本控制系统就是 使用的MVCC 思想。事务在基于基础数据版本做本地修改时，为了不影响真正的数据，通常有两种做法，一是将基础数据版本中的数据完全拷贝出来再修改，SVN 即使用了这种方法，SVN check out 即是拷贝的过程；二是每个事务中只记录更新操作，而不记录完整的数据，读取数据时再将更新操作应用到用基础版本的数据从而计算出结果，这个过程也类似SVN 的增量提交。 2.8 Paxos协议Paxos 协议是少数在工程实践中证实的强一致性、高可用的去中心化分布式协议。Paxos 协议的流程较为复杂，但其基本思想却不难理解，类似于人类社会的投票过程。Paxos 协议中，有一组完全对等的参与节点（称为accpetor），这组节点各自就某一事件做出决议，如果某个决议获得了超过半数节点的同意则生效。Paxos 协议中只要有超过一半的节点正常，就可以工作，能很好对抗宕机、网络分化等异常情况。 角色Proposer：提案者。Proposer 可以有多个，Proposer 提出议案（value）。所谓value，在工程中可以是任何操作，例如“修改某个变量的值为某个值”、“设置当前primary 为某个节点”等等。Paxos 协议中统一将这些操作抽象为value。不同的Proposer 可以提出不同的甚至矛盾的value，例如某个Proposer 提议“将变量X 设置为1”，另一个Proposer 提议“将变量X 设置为2”，但对同一轮Paxos 过程，最多只有一个value 被批准。Acceptor：批准者。Acceptor 有N 个，Proposer 提出的value 必须获得超过半数(N/2+1)的Acceptor 批准后才能通过。Acceptor 之间完全对等独立。Learner：学习者。Learner 学习被批准的value。所谓学习就是通过读取各个Proposer 对value 的选择结果，如果某个value 被超过半数Proposer 通过，则Learner 学习到了这个value。回忆（2.4 ） 不难理解，这里类似Quorum 机制，某个value 需要获得W=N/2 + 1 的Acceptor 批准，从而学习者需要至少读取N/2+1 个Accpetor，至多读取N 个Acceptor 的结果后，能学习到一个通过的value。上述三类角色只是逻辑上的划分，实践中一个节点可以同时充当这三类角色。 流程Paxos 协议一轮一轮的进行，每轮都有一个编号。每轮Paxos 协议可能会批准一个value，也可 能无法批准一个value。如果某一轮Paxos 协议批准了某个value，则以后各轮Paxos 只能批准这个 value。上述各轮协议流程组成了一个Paxos 协议实例，即一次Paxos 协议实例只能批准一个value，这也是Paxos 协议强一致性的重要体现。每轮Paxos 协议分为阶段，准备阶段和批准阶段，在这两个阶段Proposer 和Acceptor 有各自的处理流程。 流程：Proposer 的流程 （准备阶段） 向所有的Acceptor 发送消息“Prepare(b)”；这里b 是Paxos 的轮数，每轮递增 如果收到任何一个Acceptor 发送的消息“Reject(B)”，则对于这个Proposer 而言本轮Paxos 失败，将轮数b 设置为B+1 后重新步骤1；（批准阶段，根据收到的Acceptor 的消息作出不同选择） 如果接收到的Acceptor 的“Promise(b, v_i)”消息达到N/2+1 个（N 为Acceptor 总数，除法取整， 下同）；v_i 表示Acceptor 最近一次在i 轮批准过value v。3.1 如果收到的“Promise(b, v)”消息中，v 都为空，Proposer 选择一个value v，向所有Acceptor 广播Accept(b, v)；3.2 否则，在所有收到的“Promise(b, v_i)”消息中，选择i 最大的value v，向所有Acceptor 广播消息Accept(b，v)； 如果收到Nack(B)，将轮数b 设置为B+1 后重新步骤1； 流程：Accpetor 流程 （准备阶段） 接受某个Propeser 的消息Prepare(b)。参数B 是该Acceptor 收到的最大Paxos 轮数编号；V 是Acceptor 批准的value，可以为空 1.1 如果b&gt;B，回复Promise(b, V_B)，设置B=b; 表示保证不再接受编号小于b 的提案。1.2 否则，回复Reject(B) （批准阶段） 接收Accept(b, v)， 2.1 如果b &lt; B, 回复Nack(B)，暗示proposer 有一个更大编号的提案被这个Acceptor 接收了 2.2 否则设置V=v。表示这个Acceptor 批准的Value 是v。广播Accepted 消息。 例子基本例子里有5 个Acceptor，1 个Proposer，不存在任何网络、宕机异常。我们着重考察各个Accpetor 上变量B 和变量V 的变化，及Proposer 上变量b 的变化。 初始状态 Proposer 向所有Accpetor 发送“Prepare(1)”，所有Acceptor 正确处理，并回复Promise(1, NULL) Proposer 收到5 个Promise(1, NULL)，满足多余半数的Promise 的value 为空，此时发送 Accept(1, v1)，其中v1 是Proposer 选择的Value。 此时，v1 被超过半数的Acceptor 批准，v1 即是本次Paxos 协议实例批准的Value。如果Learner 学习value，学到的只能是v1 在同一个Paxos 实例中，批准的Value 是无法改变的，即使后续Proposer 以更高的序号发起Paxos 协议也无法改变value。Paxos 协议的核心就在于“批准的value 无法改变”，这也是整个协议正确性的基础。 Paxos 协议是被人为设计出来，其设计过程也是协议的推导过程。Paxos 协议利用了Quorom 机 制，选择的W=R=N/2+1。简单而言，协议就是Proposer 更新Acceptor 的过程，一旦某个Acceptor 成功更新了超过半数的Acceptor，则更新成功。Learner 按Quorum 去读取Acceptor，一旦某个value 在超过半数的Proposer 上被成功读取，则说明这是一个被批准的value。协议通过引入轮次，使得高轮次的提议抢占低轮次的提议来避免死锁。协议设计关键点是如何满足“在一次Paxos 算法实例过程中只批准一个Value”这一约束条件。 2.9 CAPCAP 理论的定义很简单，CAP 三个字母分别代表了分布式系统中三个相互矛盾的属性： Consistency (一致性)：CAP 理论中的副本一致性特指强一致性（1.3.4 ）； Availiablity(可用性)：指系统在出现异常时已经可以提供服务； Tolerance to the partition of network (分区容忍)：指系统可以对网络分区（1.1.4.2 ）这种异常情 况进行容错处理； CAP 理论指出：无法设计一种分布式协议，使得同时完全具备CAP 三个属性，即1)该种协议下的副本始终是强一致性，2)服务始终是可用的，3)协议可以容忍任何网络分区异常；分布式系统协议只能在CAP 这三者间所有折中。 热力学第二定律说明了永动机是不可能存在的，不要去妄图设计永动机。与之类似，CAP 理论的意义就在于明确提出了不要去妄图设计一种对CAP 三大属性都完全拥有的完美系统，因为这种系统在理论上就已经被证明不存在。 Lease 机制: Lease 机制牺牲了部分异常情况下的A，从而获得了完全的C 与很好的P。 Quorum 机制: Quorum 机制，在CAP 三大因素中都各做了折中，有一定的C，有较好 的A，也有较好的P，是一种较为平衡的分布式协议。 两阶段提交协议: 两阶段提交系统具有完全的C，很糟糕的A，很糟糕的P。 Paxos 协议：同样是强一致性协议，Paxos 在CAP 三方面较之两阶段提交协议要优秀得多。Paxos 协议具有 完全的C，较好的A，较好的P。Paxos 的A 与P 的属性与Quorum 机制类似，因为Paxos 的协议本 身就具有Quorum 机制的因素。","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/categories/架构设计/"}],"tags":[{"name":"分布式架构","slug":"分布式架构","permalink":"https://vincentruan.github.io/tags/分布式架构/"}]},{"title":"HTTP协议要点","slug":"HTTP协议要点","date":"2020-02-06T06:22:39.000Z","updated":"2020-02-17T02:40:44.576Z","comments":true,"path":"2020/02/06/HTTP协议要点/","link":"","permalink":"https://vincentruan.github.io/2020/02/06/HTTP协议要点/","excerpt":"","text":"以下文章来源于Java建设者 ，作者cxuan HTTP 内容协商什么是内容协商在 HTTP 中，内容协商是一种用于在同一 URL 上提供资源的不同表示形式的机制。内容协商机制是指客户端和服务器端就响应的资源内容进行交涉，然后提供给客户端最为适合的资源。内容协商会以响应资源的语言、字符集、编码方式等作为判断的标准。 内容协商的种类内容协商主要有以下3种类型： 服务器驱动协商（Server-driven Negotiation） 这种协商方式是由服务器端进行内容协商。服务器端会根据请求首部字段进行自动处理 客户端驱动协商（Agent-driven Negotiation） 这种协商方式是由客户端来进行内容协商。 透明协商（Transparent Negotiation） 是服务器驱动和客户端驱动的结合体，是由服务器端和客户端各自进行内容协商的一种方法。 内容协商的分类有很多种，主要的几种类型是 Accept、Accept-Charset、Accept-Encoding、Accept-Language、Content-Language。 一般来说，客户端用 Accept 头告诉服务器希望接收什么样的数据，而服务器用 Content 头告诉客户端实际发送了什么样的数据。 为什么需要内容协商我们为什么需要内容协商呢？在回答这个问题前我们先来看一下 TCP 和 HTTP 的不同。 在 TCP / IP 协议栈里，传输数据基本上都是 header+body 的格式。但 TCP、UDP 因为是传输层的协议，它们不会关心 body 数据是什么，只要把数据发送到对方就算是完成了任务。 而 HTTP 协议则不同，它是应用层的协议，数据到达之后需要告诉应用程序这是什么数据。当然不告诉应用这是哪种类型的数据，应用也可以通过不断尝试来判断，但这种方式无疑十分低效，而且有很大几率会检查不出来文件类型。 所以鉴于此，浏览器和服务器需要就数据的传输达成一致，浏览器需要告诉服务器自己希望能够接收什么样的数据，需要什么样的压缩格式，什么语言，哪种字符集等；而服务器需要告诉客户端自己能够提供的服务是什么。 所以我们就引出了内容协商的几种概念，下面依次来进行探讨 内容协商标头Accept接受请求 HTTP 标头会通告客户端自己能够接受的 MIME 类型 那么什么是 MIME 类型呢？在回答这个问题前你应该先了解一下什么是 MIME MIME: MIME (Multipurpose Internet Mail Extensions) 是描述消息内容类型的因特网标准。MIME 消息能包含文本、图像、音频、视频以及其他应用程序专用的数据。 也就是说，MIME 类型其实就是一系列消息内容类型的集合。那么 MIME 类型都有哪些呢？ 文本文件：text/html、text/plain、text/css、application/xhtml+xml、application/xml 图片文件：image/jpeg、image/gif、image/png 视频文件：video/mpeg、video/quicktime 应用程序二进制文件：application/octet-stream、application/zip 比如，如果浏览器不支持 PNG 图片的显示，那 Accept 就不指定image/png，而指定可处理的 image/gif 和 image/jpeg 等图片类型。 一般 MIME 类型也会和 q 这个属性一起使用，q 是什么？q 表示的是权重，来看一个例子 1Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 这是什么意思呢？若想要给显示的媒体类型增加优先级，则使用 q= 来额外表示权重值，没有显示权重的时候默认值是1.0 ，我给你列个表格你就明白了 q MIME 1.0 text/html 1.0 application/xhtml+xml 0.9 application/xml 0.8 / 也就是说，这是一个放置顺序，权重高的在前，低的在后，application/xml;q=0.9 是不可分割的整体。 Accept-CharsetAccept-charset 属性规定服务器处理表单数据所接受的字符编码；Accept-charset 属性允许你指定一系列字符集，服务器必须支持这些字符集，从而得以正确解释表单中的数据。 Accept-Charset 没有对应的标头，服务器会把这个值放在 Content-Type中用charset=xxx来表示， 例如，浏览器请求 GBK 或 UTF-8 的字符集，然后服务器返回的是 UTF-8 编码，就是下面这样 12Accept-Charset: gbk, utf-8Content-Type: text/html; charset=utf-8 Accept-Language首部字段 Accept-Language 用来告知服务器用户代理能够处理的自然语言集（指中文或英文等），以及自然语言集的相对优先级。可一次指定多种自然语言集。和 Accept 首部字段一样，按权重值 q= 来表示相对优先级。 1Accept-Language: en-US,en;q=0.5 Accept-Encoding表示 HTTP 标头会标明客户端希望服务端返回的内容编码，这通常是一种压缩算法。Accept-Encoding 也是属于内容协商 的一部分，使用并通过客户端选择 Content-Encoding 内容进行返回。 即使客户端和服务器都能够支持相同的压缩算法，服务器也可能选择不压缩并返回，这种情况可能是由于这两种情况造成的: 要发送的数据已经被压缩了一次，第二次压缩并不会导致发送的数据更小 服务器过载，无法承受压缩带来的性能开销，通常，如果服务器使用 CPU 超过 80% ，Microsoft 则建议不要使用压缩 下面是 Accept-Encoding 的使用方式 1234567Accept-Encoding: gzipAccept-Encoding: compressAccept-Encoding: deflateAccept-Encoding: brAccept-Encoding: identityAccept-Encoding: *Accept-Encoding: deflate, gzip;q=1.0, *;q=0.5 上面的几种表述方式就已经把 Accept-Encoding 的属性列全了 gzip: 由文件压缩程序 gzip 生成的编码格式，使用 Lempel-Ziv编码（LZ77）和32位CRC的压缩格式，感兴趣的同学可以读一下 （https://en.wikipedia.org/wiki/LZ77_and_LZ78#LZ77） compress: 使用Lempel-Ziv-Welch（LZW）算法的压缩格式，有兴趣的同学可以读 （https://en.wikipedia.org/wiki/LZW） deflate: 使用 zlib 结构和 deflate 压缩算法的压缩格式，参考 （https://en.wikipedia.org/wiki/Zlib） 和 （https://en.wikipedia.org/wiki/DEFLATE） br: 使用 Brotli 算法的压缩格式，参考 （https://en.wikipedia.org/wiki/Brotli） 不执行压缩或不会变化的默认编码格式 * : 匹配标头中未列出的任何内容编码，如果没有列出 Accept-Encoding ，这就是默认值，并不意味着支 持任何算法，只是表示没有偏好 ;q= 采用权重 q 值来表示相对优先级，这点与首部字段 Accept 相同。 Content-TypeContent-Type 实体标头用于指示资源的 MIME 类型。作为响应，Content-Type 标头告诉客户端返回的内容的内容类型实际上是什么。Content-type 有两种值 : MIME 类型和字符集编码，例如 1Content-Type: text/html; charset=UTF-8 在某些情况下，浏览器将执行 MIME 嗅探，并且不一定遵循此标头的值；为防止此行为，可以将标头 X-Content-Type-Options 设置为 nosniff。 Content-EncodingContent-Encoding 实体标头用于压缩媒体类型，它让客户端知道如何进行解码操作，从而使客户端获得 Content-Type 标头引用的 MIME 类型。表示如下 1234567Content-Encoding: gzipContent-Encoding: compressContent-Encoding: deflateContent-Encoding: identityContent-Encoding: brContent-Encoding: gzip, identityContent-Encoding: deflate, gzip Content-LanguageContent-Language 实体标头用于描述面向受众的语言，以便使用户根据用户自己的首选语言进行区分。例如 123Content-Language: de-DEContent-Language: en-USContent-Language: de-DE, en-CA 下面根据内容协商对应的请求/响应标头，我列了一张图供你参考，注意其中 Accept-Charset 没有对应的 Content-Charset ，而是通过 Content-Type 来表示。 HTTP 认证 HTTP 提供了用于访问控制和身份认证的功能，下面就对 HTTP 的权限和认证功能进行介绍 通用 HTTP 认证框架RFC 7235 定义了 HTTP 身份认证框架，服务器可以根据其文档的定义来检查客户端请求。客户端也可以根据其文档定义来提供身份验证信息。 请求/响应的工作流程如下：服务器以401(未授权) 的状态响应客户端告诉客户端服务器需要认证信息，客户端提供至少一个 www-Authenticate 的响应标头进行授权信息的认证。想要通过服务器进行身份认证的客户端可以在请求标头字段中添加认证标头进行身份认证，一般的认证过程如下 首先客户端发起一个 HTTP 请求，不带有任何认证标头，服务器对此 HTTP 请求作出响应，发现此 HTTP 信息未带有认证凭据，服务器通过 www-Authenticate标头返回 401 告诉客户端此请求未通过认证。然后客户端进行用户认证，认证完毕后重新发起 HTTP 请求，这次 HTTP 请求带有用户认证凭据（注意，整个身份认证的过程必须通过 HTTPS 连接保证安全），到达服务器后服务器会检查认证信息，如果不符合服务器认证信息，会返回 403 Forbidden 表示用户认证失败，如果满足认证信息，则返回 200 OK。 我们知道，客户端和服务器之间的 HTTP 连接可以被代理缓存重新发送，所以认证信息也适用于代理服务器。 代理认证由于资源认证和代理认证可以共存，因此需要不同的头和状态码，在代理的情况下，会返回状态码 407(需要代理认证)， Proxy-Authenticate 响应头包含至少一个适用于代理的情况，Proxy-Authorization请求头用于将证书提供给代理服务器。下面分别来认识一下这两个标头 Proxy-AuthenticateHTTP Proxy-Authenticate 响应标头定义了身份验证方法，应使用该身份验证方法来访问代理服务器后面的资源。它将请求认证到代理服务器，从而允许它进一步发送请求。例如 12Proxy-Authenticate: BasicProxy-Authenticate: Basic realm=&quot;Access to the internal site&quot; Proxy-Authorization这个 HTTP 请求标头和上面的 Proxy-Authenticate 拼接很相似，但是概念不同，这个标头用于向代理服务器提供凭据，例如 1Proxy-Authorization: Basic YWxhZGRpbjpvcGVuc2VzYW1l 下面是代理服务器的请求/响应认证过程 这个过程和通用的过程类似，我们就不再详细展开描述了。 禁止访问如果代理服务器收到的有效凭据不足以获取对给定资源的访问权限，则服务器应使用403 Forbidden状态代码进行响应。与 401 Unauthorized 和 407 Proxy Authorization Required 不同，该用户无法进行身份验证。 WWW-Authenticate 和 Proxy-Authenticate 头WWW-Authenticate 和 Proxy-Authenticate 响应头定义了获得对资源访问权限的身份验证方法。他们需要指定使用哪种身份验证方案，以便希望授权的客户端知道如何提供凭据。它们的一般表示形式如下 12WWW-Authenticate: &lt;type&gt; realm=&lt;realm&gt;Proxy-Authenticate: &lt;type&gt; realm=&lt;realm&gt; 我想你从上面看到这里一定会好奇 和 realm是什么东西，现在就来解释下。 是认证协议，Basic 是下面协议中最普遍使用的 RFC 7617 中定义了Basic HTT P身份验证方案，该方案将凭据作为用户ID /密码对传输，并使用 base64 进行编码。(感兴趣的同学可以看看 https://tools.ietf.org/html/rfc7617) 其他的认证协议主要有 认证协议 参考来源 Basic 查阅 RFC 7617，base64编码的凭据 Bearer 查阅 RFC 6750，承载令牌来访问受 OAuth 2.0保护的资源 Digest 查阅 RFC 7616，Firefox仅支持md5哈希，请参见错误bug 472823以获得SHA加密支持 HOBA 查阅 RFC 7486 Mutual 查阅 RFC 8120 AWS4-HMAC-SHA256 查阅 AWS docs realm 用于描述保护区或指示保护范围，这可能是诸如 Access to the staging site(访问登陆站点) 或者类似的，这样用户就可以知道他们要访问哪个区域。 Authorization 和 Proxy-Authorization 标头Authorization 和 Proxy-Authorization 请求标头包含用于通过代理服务器对用户代理进行身份验证的凭据。在此，再次需要类型，其后是凭据，取决于使用哪种身份验证方案，可以对凭据进行编码或加密。一般表示如下 12Authorization: Basic YWxhZGRpbjpvcGVuc2VzYW1lProxy-Authorization: Basic YWxhZGRpbjpvcGVuc2VzYW1l HTTP 缓存通过把请求/响应缓存起来有助于提升系统的性能，Web 缓存减少了延迟和网络传输量，因此减少资源获取锁需要的时间。由于链路漫长，网络时延不可控，浏览器使用 HTTP 获取资源的成本较高。所以，非常有必要把数据缓存起来，下次再请求的时候尽可能地复用。当 Web 缓存在其存储中具有请求的资源时，它将拦截该请求并直接返回资源，而不是到达源服务器重新下载并获取。这样做可以实现两个小目标 减轻服务器负载 提升系统性能 下面我们就一起来探讨一下 HTTP 缓存都有哪些 不同类型的缓存HTTP 缓存有几种不同的类型，这些可以分为两个主要类别：私有缓存 和 共享缓存。 共享缓存：共享缓存是一种缓存，它可以存储多个用户重复使用的请求/响应。 私有缓存：私有缓存也称为专用缓存，它只适用于单个用户。 不缓存过期资源：所有的请求都会直接到达服务器，由服务器来下载资源并返回。 我们主要探讨浏览器缓存和代理缓存，但真实情况不只有这两种缓存，还有网关缓存，CDN，反向代理缓存和负载平衡器，把它们部署在 Web 服务器上，可以提高网站和 Web 应用程序的可靠性，性能和可伸缩性。 不缓存过期资源不缓存过期资源即浏览器和代理不会缓存过期资源，客户端发起的请求会直接到达服务器，可以使用 no-cache 标头代表不缓存过期资源。 no-cache 属于 Cache-Control 通用标头，其一般的表示方法如下 1Cache-Control: no-cache 也可以使用 max-age = 0 来实现不缓存的效果。 1Cache-Control: max-age=0 私有缓存私有缓存只用来缓存单个用户，你可能在浏览器设置中看到了 缓存，浏览器缓存包含服务器通过 HTTP 下载下来的所有文档。这个高速缓存用于使访问的文档可以进行前进/后退，保存操作而无需重新发送请求到源服务器。 可以使用 private 来实现私有缓存，这与 public 的用法相反，缓存服务器只对特定的客户端进行缓存，其他客户端发送过来的请求，缓存服务器则不会返回缓存。它的一般表示方法如下 1Cache-Control: private 共享缓存共享缓存是一种用于存储要由多个用户重用的响应缓存。共享缓存一般使用 public 来表示，public 属性只出现在客户端响应中，表示响应可以被任何缓存所缓存。一般表示方法如下 1Cache-Control: public 缓存控制HTTP/1.1 中的 Cache-Control 常规标头字段用于执行缓存控制，使用此标头可通过其提供的各种指令来定义缓存策略。下面我们依次介绍一下这些属性 不缓存no-store 才是真正意义上的不缓存，每次服务器接受到客户端的请求后，都会返回最新的资源给客户端。 1Cache-Control: no-store 缓存但需要验证同上面的 不缓存过期资源 私有和共享缓存同上 缓存过期缓存中一个很重要的指令就是max-age，这是资源被视为新鲜的最长时间 ，与 Expires相反，此指令是相对于请求时间的。对于应用程序中不会更改的文件，通常可以添加主动缓存。下面是 mag-age 的表示 1Cache-Control: max-age=31536000 缓存验证must-revalidate 表示缓存必须在使用之前验证过时资源的状态，并且不应使用过期的资源。 1Cache-Control: must-revalidate 下面是一个缓存验证图 什么是新鲜的数据 一旦资源存储在缓存中，理论上就可以永远被缓存使用。但是不管是浏览器缓存还是代理缓存，其存储空间是有限的，所以缓存会定期进行清除，这个过程叫做 缓存回收(cache eviction) （自译）。另一方面，服务器上的缓存也会定期进行更新，HTTP 作为应用层的协议，它是一种客户-服务器模式，HTTP 是无状态的协议，因此当资源发生更改时，服务器无法通知缓存和客户端。因此服务器必须通过某种方式告知客户端缓存已经被更新。服务器会提供过期时间这个概念，告知客户端在此到期时间之前，资源是新鲜的，也就是未更改过的。在此到期时间的范围之外，资源已过时。过期算法(Eviction algorithms) 通常会将新资源优先于陈旧资源使用。 这里需要注意一下，过期的资源并不会被回收或忽略，当高速缓存接收到过期资源时，它会使用 If-None-Match 转发此请求，以检查它是否仍然有效。如果有效，服务器会返回 304 Not Modified响应头并且没有任何响应体，从而节省了一些带宽。 下面是使用共享缓存代理的过程 这个图应该比较好理解，只说一下 Age 的作用，Age 是 HTTP 响应标头告诉客户端源服务器在多久之前创建了响应，它的单位为秒，Age 标头通常接近于0，如果是0则可能是从源服务器获取的，如果不是表示可能是由代理服务器创建，那么 Age 的值表示的是缓存后的响应再次发起认证到认证完成的时间值。 缓存的有效性是由多个标头来共同决定的，而并非某一个标头来决定。如果指定了Cache-control:max-age=N ，那么缓存会保存 N 秒。如果这个通用标头不存在的话，则会检查是否存在 Expires 标头。如果 Exprires 标头存在，那么它的值减去 Date 标头的值就可以确定其有效性。最后，如果max-age 和 expires 都不存在，就去寻找 Last-Modified 标头，如果存在此标头，则高速缓存的有效性等于 Date 标头的值减去 Last-modified 标头的值除以10。 缓存验证当到达缓存资源的有效期时，将对其进行验证或再次获取。仅当服务器提供了强验证器或弱验证器时，才可以进行验证。 当用户按下重新加载按钮时，将触发重新验证。如果缓存的响应包含 Cache-control：must-revalidate标头，则在正常浏览下也会触发该事件。另一个因素是 高级 -&gt; 缓存首选项 面板中的缓存验证首选项。有一个选项可在每次加载文档时强制进行验证。 Etag我们上面提到了强验证器和弱验证器，实现验证器功能的标头正式 Etag 的作用，这意味着 HTTP 用户代理（例如浏览器）不知道该字符串表示什么，并且无法预测其值。如果 Etag 标头是资源响应的一部分，则客户端可以在未来请求的标头中发出 If-None-Match，以验证缓存的资源。 Last-Modified响应标头可以用作弱验证器，因为它只有1秒可以分辨的时间。如果响应中存在 Last-Modified标头，则客户端可以发出 If-Modified-Since请求标头来验证缓存资源。（关于 Etag 更多我们会在条件请求介绍） 避免碰撞通过使用 Etag 和 If-Match 标头，你可以检测避免碰撞。 例如，在编辑 MDN 时，将对当前 Wiki 内容进行哈希处理并将其放入响应中的 Etag 中 1Etag: &quot;33a64df551425fcc55e4d42a148795d9f25f89d4&quot; 当将更改保存到 Wiki 页面（发布数据）时，POST 请求将包含 If-Match 标头，其中包含 Etag 值以检查有效性。 1If-Match: &quot;33a64df551425fcc55e4d42a148795d9f25f89d4&quot; 如果哈希值不匹配，则表示文档已在中间进行了编辑，并返回 412 Precondition Failed错误。 缓存未占用资源Etag 标头的另一个典型用法是缓存未更改的资源，如果用户再次访问给定的 URL（已设置Etag），并且该 URL过时，则客户端将在 If-None-Match 标头字段中发送其 Etag 的值 1If-None-Match: &quot;33a64df551425fcc55e4d42a148795d9f25f89d4&quot; 服务器将客户端的 Etag（通过 If-None-Match 发送）与 Etag 进行比较，以获取其当前资源版本，如果两个值都匹配（即资源未更改），则服务器会发回 304 Not Modified状态，没有主体，它告诉客户端响应的缓存仍然可以使用。 HTTP CROS 跨域CROS 的全称是 Cross-Origin Resource Sharing(CROS)，中文译为 跨域资源共享，它是一种机制。是一种什么机制呢？它是一种让运行在一个域(origin)上的 Web 应用被准许访问来自不同源服务器上指定资源的机制。在搞懂这个机制前，你需要线了解什么是 域(origin) OriginWeb 概念中域(Origin) 的内容由scheme(protocol) - 协议，host(domain) - 主机和用于访问它的 URL port - 端口定义。仅仅当 scheme 、host、port 都匹配时，两个对象才有相同的来源。这种协议相同，域名相同，端口相同的安全策略也被称为 同源策略（Same Origin Policy)。某些操作仅限于具有相同来源的内容，可以使用 CORS 取消此限制。 跨域的特点 下面是跨域问题的例子，看看你是否清楚什么是跨域了 12(1) http://example.com/app1/index.html(2) http://example.com/app2/index.html 上面这两个 URL 是否具有跨域问题呢？ 上面两个 URL 是不具有跨域问题的，因为这两个 URL 具有相同的协议(scheme)和主机(host) 那么下面这两个是否具有跨域问题呢？ 12http://Example.com:80http://example.com 这两个 URL 也不具有跨域问题，为什么不具有，端口不一样啊。其实它们两个端口是一样的。 或许你会认为这两个 URL 是不一样的，放心，关于一样不一样的论据我给你抛出来了 协议和域名部分是不区分大小写的，但是路径部分则根据服务器平台而定。Windows 和 Mac OS X 系统是不区分大小写的，而采用UNIX和Linux系的服务器系统是区分大小写的， 也就是说上面的 Example.com 和 example.com 其实是一个网址，并且由于两个地址具有相同的 scheme 和 host ，默认情况下服务器通过端口80传递 HTTP 内容，所以上面这两个地址也是相同的。 下面这两个 URL 地址是否具有跨域问题？ 12http://example.com/app1https://example.com/app2 这两个 URL 的 scheme 不同，所以这两个 URL 具有跨域问题 再看下面这三个 URL 是否具有跨域问题 123http://example.comhttp://www.example.comhttp://myapp.example.com 这三个 URL 也是具有跨域问题的，因为它们隶属于不通服务器的主机 host。 下面这两个 URL 是否具有跨域问题 12http://example.comhttp://example.com:8080 这两个 URL 也是具有跨域问题，因为这两个 URL 的默认端口不一样。 同源策略处于安全的因素，浏览器限制了从脚本发起跨域的 HTTP 请求。XMLHttpRequest 和其他 Fetch 接口 会遵循 同源策略(same-origin policy)。也就是说使用这些 API 的应用程序想要请求相同的资源，那么他们应该具有相同的来源，除非来自其他来源的响应包括正确的 CORS 标头也可以。 同源策略是一种很重要的安全策略，它限制了从一个来源加载的文档或脚本如何与另一个来源的资源进行交互。它有助于隔离潜在的恶意文档，减少可能的攻击媒介。 我们上面提到，如果两个 URL 具有相同的协议、主机和端口号（如果指定）的话，那么两个 URL 具有相同的来源。下面有一些实例，你判断一下是不是具有相同的来源 目标来源 http://store.company.com/dir/page.html 现在我带你认识了两遍不同的源，现在你应该知道如何区分两个 URL 是否属于同一来源了吧！ 好，你现在知道了什么是跨域问题，现在我要问你，哪些请求会产生跨域请求呢？这是我们下面要讨论的问题 跨域请求跨域请求可能会从下面这几种请求中发出： 调用 XMLHttpRequest 或者 Fetch api。 XMLHttpRequest 是什么？（我是后端程序员，前端不太懂，简单解释下，如果解释的不好，还请前端大佬们不要胖揍我） 所有的现代浏览器都有一个内置的 XMLHttpReqeust 对象，这个对象可以用于从服务器请求数据。 XMLHttpReqeust 对于开发人员来说很重要，XMLHttpReqeust 对象可以用来做下面这些事情 更新网页无需重新刷新页面 页面加载后从服务器请求数据 页面加载后从服务端获取数据 在后台将数据发送到服务器 使用 XMLHttpRequest(XHR) 对象与服务器进行交互，你可以从 URL 检索数据从而不必刷新整个页面，这使网页可以更新页面的一部分，而不会中断用户的操作。XMLHttpRequest 在 AJAX 异步编程中使用很广泛。 再来说一下 Fetch API 是什么，Fetch 提供了请求和响应对象（以及其他网络请求）的通用定义。它还提供了相关概念的定义，例如 CORS 和 HTTP Origin 头语义，并在其他地方取代了它们各自的定义。 Web 字体（用于 CSS 中@ font-face中的跨域字体使用），以便服务器可以部署 TrueType 字体，这些字体只能由允许跨站点加载和使用的网站使用。 WebGL 纹理 使用 drawImage() 绘制到画布上的图像/视频帧 图片的 CSS 形状 跨域功能概述跨域资源共享标准通过添加新的 HTTP 标头来工作，这些标头允许服务器描述允许哪些来源从 Web 浏览器读取信息。另外，对于可能导致服务器数据产生副作用的 HTTP 请求方法（尤其是 GET 或者具有某些 MIME 类型 POST 方法以外 HTTP 方法），该规范要求浏览器预检请求，使用 HTTP OPTIONS 请求方法从服务器请求受支持的方法，然后在服务器批准后发送实际请求。服务器还可以通知客户端是否应与请求一起发送凭据（例如 Cookies 和 HTTP 身份验证）。 注意：CORS 故障会导致错误，但是出于安全原因，该错误的详细信息不适用于 JavaScript。所有代码都知道发生了错误。确定具体出问题的唯一方法是查看浏览器的控制台以获取详细信息。 访问控制下面我会和大家探讨三种方案，这些方案都演示了跨域资源共享的工作方式。所有这些示例都使用XMLHttpRequest，它可以在任何支持的浏览器中发出跨站点请求。 简单请求一些请求不会触发 CORS预检（关于预检我们后面再介绍）。简单请求是满足一下所有条件的请求 允许以下的方法：GET、HEAD和 POST 除了由用户代理自动设置的标头（例如 Connection、User-Agent 或者在 Fetch 规范中定义为禁止标头名称的其他标头）外，唯一允许手动设置的标头是那些 Fetch 规范将其定义为 CORS安全列出的请求标头 ，它们是： Accept Accept-Language Content-Language Content-Type（下面会介绍） DPR Downlink Save-Data Viewport-Width Width Content-Type 标头的唯一允许的值是 application/x-www-form-urlencoded multipart/form-data text/plain 没有在请求中使用的任何 XMLHttpRequestUpload 对象上注册事件侦听器；这些可以使用XMLHttpRequest.upload 属性进行访问。 请求中未使用 ReadableStream对象。 例如，假定 web 内容 https://foo.example 想要获取 https://bar.other 域的资源，那么 JavaScript 中的代码可能会像下面这样写 123456const xhr = new XMLHttpRequest();const url = &apos;https://bar.other/resources/public-data/&apos;; xhr.open(&apos;GET&apos;, url);xhr.onreadystatechange = someHandler;xhr.send(); 这使用 CORS 标头来处理特权，从而在客户端和服务器之间执行某种转换。 让我们看看在这种情况下浏览器将发送到服务器的内容，并让我们看看服务器如何响应： 12345678GET /resources/public-data/ HTTP/1.1Host: bar.otherUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: en-us,en;q=0.5Accept-Encoding: gzip,deflateConnection: keep-aliveOrigin: https://foo.example 注意请求的标头 Origin ，它表明调用来自于 https://foo.example。让我们看看服务器是如何响应的 12345678910HTTP/1.1 200 OKDate: Mon, 01 Dec 2008 00:23:53 GMTServer: Apache/2Access-Control-Allow-Origin: *Keep-Alive: timeout=2, max=100Connection: Keep-AliveTransfer-Encoding: chunkedContent-Type: application/xml[…XML Data…] 服务端发送 Access-Control-Allow-Origin 作为响应。使用 Origin 标头和 Access-Control-Allow-Origin 展示了最简单的访问控制协议。在这个事例中，服务端使用Access-Control-Allow-Origin 作为响应，也就说明该资源可以被任何域访问。 如果位于https://bar.other的资源所有者希望将对资源的访问限制为仅来自https://foo.example的请求，他们应该发送如下响应 1Access-Control-Allow-Origin: https://foo.example 现在除了 https://foo.example 之外的任何域都无法以跨域方式访问到 https://bar.other的资源。 预检请求和上面探讨的简单请求不同，预检请求首先通过 OPTIONS 方法向另一个域上的资源发送 HTTP 请求，用来确定实际请求是否可以安全的发送。跨站点这样被预检，因为它们可能会影响用户数据。 下面是一个预检事例 123456const xhr = new XMLHttpRequest();xhr.open(&apos;POST&apos;, &apos;https://bar.other/resources/post-here/&apos;);xhr.setRequestHeader(&apos;X-PINGOTHER&apos;, &apos;pingpong&apos;);xhr.setRequestHeader(&apos;Content-Type&apos;, &apos;application/xml&apos;);xhr.onreadystatechange = handler;xhr.send(&apos;&lt;person&gt;&lt;name&gt;Arun&lt;/name&gt;&lt;/person&gt;&apos;); 上面的事例创建了一个 XML 请求体用来和 POST 请求一起发送。此外，设置了非标准请求头 X-PINGOTHER ，这个标头不是 HTTP/1.1 的一部分，但通常对 Web 程序很有用。由于请求的 Content-Type 使用 application/xml，并且设置了自定义标头，因此该请求被预检。如下图所示 如下所述，实际的 POST 请求不包含 Access-Control-Request- * 标头；只有 OPTIONS 请求才需要它们。 下面我们来看一下完整的客户端/服务器交互，首先是预检请求/响应 1234567891011121314151617181920OPTIONS /resources/post-here/ HTTP/1.1Host: bar.otherUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: en-us,en;q=0.5Accept-Encoding: gzip,deflateConnection: keep-aliveOrigin: http://foo.exampleAccess-Control-Request-Method: POSTAccess-Control-Request-Headers: X-PINGOTHER, Content-TypeHTTP/1.1 204 No ContentDate: Mon, 01 Dec 2008 01:15:39 GMTServer: Apache/2Access-Control-Allow-Origin: https://foo.exampleAccess-Control-Allow-Methods: POST, GET, OPTIONSAccess-Control-Allow-Headers: X-PINGOTHER, Content-TypeAccess-Control-Max-Age: 86400Vary: Accept-Encoding, OriginKeep-Alive: timeout=2, max=100Connection: Keep-Alive 上面的1 -11 行代表预检请求，预检请求使用 OPYIIONS 方法，浏览器根据上面的 JavaScript 代码段所使用的请求参数确定是否需要发送此请求，以便服务器可以响应是否可以使用实际请求参数发送请求。OPTIONS 是一种 HTTP / 1.1方法，用于确定来自服务器的更多信息，并且是一种安全的方法，这意味着它不能用于更改资源。请注意，与 OPTIONS 请求一起，还发送了另外两个请求标头（分别是第9行和第10行） 12Access-Control-Request-Method: POSTAccess-Control-Request-Headers: X-PINGOTHER, Content-Type Access-Control-Request-Method 标头作为预检请求的一部分通知服务器，当发送实际请求时，将使用POST 请求方法发送该请求。 Access-Control-Request-Headers 标头通知服务器，当发送请求时，它将与X-PINGOTHER 和 Content-Type 自定义标头一起发送。服务器可以确定这种情况下是否接受请求。 下面的 1 - 11行是服务器发回的响应，表示POST 请求和 X-PINGOTHER 是可以接受的，我们着重看一下下面这几行 1234Access-Control-Allow-Origin: http://foo.exampleAccess-Control-Allow-Methods: POST, GET, OPTIONSAccess-Control-Allow-Headers: X-PINGOTHER, Content-TypeAccess-Control-Max-Age: 86400 服务器完成响应表明源 http://foo.example 是可以接受的 URL，能够允许 POST、GET、OPTIONS 进行请求，允许自定义标头 X-PINGOTHER, Content-Type。最后，Access-Control-Max-Age 以秒为单位给出一个值，这个值表示对预检请求的响应可以缓存多长时间，在此期间内无需发送其他预检请求。 完成预检请求后，将发送实际请求： 12345678910111213141516171819202122232425262728POST /resources/post-here/ HTTP/1.1Host: bar.otherUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: en-us,en;q=0.5Accept-Encoding: gzip,deflateConnection: keep-aliveX-PINGOTHER: pingpongContent-Type: text/xml; charset=UTF-8Referer: https://foo.example/examples/preflightInvocation.htmlContent-Length: 55Origin: https://foo.examplePragma: no-cacheCache-Control: no-cache&lt;person&gt;&lt;name&gt;Arun&lt;/name&gt;&lt;/person&gt;HTTP/1.1 200 OKDate: Mon, 01 Dec 2008 01:15:40 GMTServer: Apache/2Access-Control-Allow-Origin: https://foo.exampleVary: Accept-Encoding, OriginContent-Encoding: gzipContent-Length: 235Keep-Alive: timeout=2, max=99Connection: Keep-AliveContent-Type: text/plain[Some GZIP&apos;d payload] 正式响应中很多标头我们在之前的文章已经探讨过了，本篇不再做详细的介绍，读者可以参考你还在为 HTTP 的这些概念头疼吗？ 查阅 带凭证的请求XMLHttpRequest 或 Fetch 和 CORS 最有趣的功能就是能够发出知道 HTTP Cookie 和 HTTP 身份验证的 凭证 请求。默认情况下，在跨站点 XMLHttpRequest 或 Fetch 调用中，浏览器将不发送凭据。调用 XMLHttpRequest对象或 Request 构造函数时必须设置一个特定的标志。 在下面这个例子中，最初从 http://foo.example 加载的内容对设置了 Cookies 的http://bar.other 上的资源进行了简单的 GET 请求， foo.example 上可能的代码如下 1234567891011const invocation = new XMLHttpRequest();const url = &apos;http://bar.other/resources/credentialed-content/&apos;; function callOtherDomain() &#123; if (invocation) &#123; invocation.open(&apos;GET&apos;, url, true); invocation.withCredentials = true; invocation.onreadystatechange = handler; invocation.send(); &#125;&#125; 第7行显示 XMLHttpRequest 上的标志，必须设置该标志才能使用 Cookie 进行调用。默认情况下，调用是不在使用 Cookie 的情况下进行的。由于这是一个简单的 GET 请求，因此不会进行预检，但是浏览器将拒绝任何没有 Access-Control-Allow-Credentials 的响应：标头为true，指的是响应不会返回 web 页面的内容。 上面的请求用下图可以表示 这是客户端和服务器之间的示例交换： 123456789101112131415161718192021222324252627GET /resources/access-control-with-credentials/ HTTP/1.1Host: bar.otherUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: en-us,en;q=0.5Accept-Encoding: gzip,deflateConnection: keep-aliveReferer: http://foo.example/examples/credential.htmlOrigin: http://foo.exampleCookie: pageAccess=2HTTP/1.1 200 OKDate: Mon, 01 Dec 2008 01:34:52 GMTServer: Apache/2Access-Control-Allow-Origin: https://foo.exampleAccess-Control-Allow-Credentials: trueCache-Control: no-cachePragma: no-cacheSet-Cookie: pageAccess=3; expires=Wed, 31-Dec-2008 01:34:53 GMTVary: Accept-Encoding, OriginContent-Encoding: gzipContent-Length: 106Keep-Alive: timeout=2, max=100Connection: Keep-AliveContent-Type: text/plain[text/plain payload] 上面第10行包含指向http://bar.other 上的内容 Cookie，但是如果 bar.other 没有以Access-Control-Allow-Credentials:true 响应（下面第五行），响应将被忽略，并且不能使用网站返回的内容。 请求凭证和通配符 当回应凭证请求时，服务器必须在 Access-Control-Allow-Credentials 中指定一个来源，而不能直接写* 通配符 因为上面示例代码中的请求标头包含 Cookie 标头，如果 Access-Control-Allow-Credentials 中是指定的通配符 * 的话，请求会失败。 注意上面示例中的 Set-Cookie 响应标头还设置了另外一个值，如果发生故障，将引发异常（取决于所使用的API）。 HTTP 响应标头下面会列出一些服务器跨域共享规范定义的 HTTP 标头，上面简单概述了一下，现在一起来认识一下，主要会介绍下面这些 Access-Control-Allow-Origin Access-Control-Allow-Credentials Access-Control-Allow-Headers Access-Control-Allow-Methods Access-Control-Expose-Headers Access-Control-Max-Age Access-Control-Request-Headers Access-Control-Request-Method Origin Access-Control-Allow-OriginAccess-Control-Allow-Origin 是 HTTP 响应标头，指示响应是否能够和给定的源共享资源。Access-Control-Allow-Origin 指定单个资源会告诉浏览器允许指定来源访问资源。对于没有凭据的请求 *通配符，告诉浏览器允许任何源访问资源。 例如，如果要允许源 https://mozilla.org 的代码访问资源，可以使用如下的指定方式 12Access-Control-Allow-Origin: https://mozilla.orgVary: Origin 如果服务器指定单个来源而不是*通配符，则服务器还应在 Vary 响应标头中包含该来源。 Access-Control-Allow-CredentialsAccess-Control-Allow-Credentials 是 HTTP 的响应标头，这个标头告诉浏览器，当包含凭证请求（Request.credentials）时是否将响应公开给前端 JavaScript 代码。 这时候你会问到 Request.credentials 是什么玩意？不要着急，来给你看一下，首先来看 Request 是什么玩意， 实际上，Request 是 Fetch API 的一类接口代表着资源请求。一般创建 Request 对象有两种方式 使用 Request() 构造函数创建一个 Request 对象 还可以通过 FetchEvent.request api 操作来创建 再来说下 Request.credentials 是什么意思，Request 接口的凭据只读属性指示在跨域请求的情况下，用户代理是否应从其他域发送 cookie。（其他 Request 对象的方法详见 https://developer.mozilla.org/en-US/docs/Web/API/Request） 当发送的是凭证模式的请求包含 （Request.credentials）时，如果 Access-Control-Allow-Credentials 值为 true，浏览器将仅向前端 JavaScript 代码公开响应。 1Access-Control-Allow-Credentials: true 凭证一般包括 cookie、认证头和 TLS 客户端证书 当用作对预检请求响应的一部分时，这表明是否可以使用凭据发出实际请求。注意简单的GET 请求不会进行预检。 可以参考一个实际的例子 https://www.jianshu.com/p/ea485e5665b3 Access-Control-Allow-HeadersAccess-Control-Allow-Headers 是一个响应标头，这个标头用来响应预检请求，它发出实际请求时可以使用哪些HTTP标头。 示例 自定义标头 这是 Access-Control-Allow-Headers 标头的示例。它表明除了像 CROS 安全列出的请求标头外，对服务器的 CROS 请求还支持名为 X-Custom-Header 的自定义标头。 1Access-Control-Allow-Headers: X-Custom-Header 多个标头 这个例子展示了 Access-Control-Allow-Headers 如何使用多个标头 1Access-Control-Allow-Headers: X-Custom-Header, Upgrade-Insecure-Requests 绕过其他限制 尽管始终允许使用 CORS 安全列出的请求标头，并且通常不需要在 Access-Control-Allow-Headers 中列出这些标头，但是无论如何列出它们都将绕开适用的其他限制。 1Access-Control-Allow-Headers: Accept 这里你可能会有疑问，哪些是 CORS 列出的安全标头？（别嫌累，就是这么麻烦） 有下面这些 Accep、Accept-Language、Content-Language、Content-Type ，当且仅当包含这些标头时，无需在 CORS 上下文中发送预检请求。 Access-Control-Allow-MethodsAccess-Control-Allow-Methods 也是响应标头，它指定了哪些访问资源的方法可以使用预检请求。例如 12Access-Control-Allow-Methods: POST, GET, OPTIONSAccess-Control-Allow-Methods: * Access-Control-Expose-HeadersAccess-Control-Expose-Headers 响应标头表明哪些标头可以作为响应的一部分公开。默认情况下，仅公开6个CORS安全列出的响应标头，分别是 Cache-Control Content-Language Content-Type Expires Last-Modified Pragma 如果希望客户端能够访问其他标头，则必须使用 Access-Control-Expose-Headers 标头列出它们。下面是示例 要公开非 CORS 安全列出的请求标头，可以像如下这样指定 1Access-Control-Expose-Headers: Content-Length 要另外公开自定义标头，例如 X-Kuma-Revision，可以指定多个标头，并用逗号分隔 1Access-Control-Expose-Headers: Content-Length, X-Kuma-Revision 在不是凭证请求中，你还可以使用通配符 1Access-Control-Expose-Headers: * 但是，这不会通配 Authorization 标头，因此如果需要公开它，则需要明确列出 1Access-Control-Expose-Headers: *, Authorization Access-Control-Max-AgeAccess-Control-Max-Age 响应头表示预检请求的结果可以缓存多长时间，例如 1Access-Control-Max-Age: 600 表示预检请求可以缓存10分钟 Access-Control-Request-Headers浏览器在发出预检请求时使用 Access-Control-Request-Headers 请求标头，使服务器知道在发出实际请求时客户端可能发送的 HTTP 标头。 1Access-Control-Request-Headers: X-PINGOTHER, Content-Type Access-Control-Request-Method同样的，Access-Control-Request-Method 响应标头告诉服务器发出预检请求时将使用那种 HTTP 方法。此标头是必需的，因为预检请求始终是 OPTIONS，并且使用的方法与实际请求不同。 1Access-Control-Request-Method: POST OriginOrigin 请求标头表明匹配的来源，它不包含任何信息，仅仅包含服务器名称，它与 CORS 请求以及 POST 请求一起发送，它类似于 Referer 标头，但与此标头不同，它没有公开整个路径。例如 1Origin: https://developer.mozilla.org HTTP 条件请求HTTP 具有条件请求的概念，通过比较资源更新生成的值与验证器的值进行比较，来确定资源是否进行过更新。这样的请求对于验证缓存的内容、条件请求、验证资源的完整性来说非常重要。 原则HTTP 条件请求是根据特定标头的值执行不同的请求，这些标头定义了一个前提条件，如果前提条件匹配或不匹配，则请求的结果将有所不同。 对于 安全 的方法，像是 GET、用于请求文档的资源，仅当条件请求的条件满足时发回文档资源，所以，这种方式可以节约带宽。 什么是安全的方法，对于 HTTP 来说，安全的方法是不会改变服务器状态的方法，换句话说，如果方法只是只读操作，那么它肯定是安全的方法，比如说 GET 请求，它肯定是安全的方法，因为它只是请求资源。几种常见的方法肯定是安全的，它们是 GET、HEAD和 OPTIONS。所有安全的方法都是幂等的（这他妈幂等又是啥意思？）但不是所有幂等的方法都是安全的，例如 PUT 和 DELETE 都是幂等的，但不安全。 幂等性：如果相同的客户端发起一次或者多次 HTTP 请求会得到相同的结果，则说明 HTTP 是幂等的。（我们这次不深究幂等性） 对于 非安全 的方法，像是 PUT，只有原始文档与服务器上存储的资源相同时，才可以使用条件请求来传输文档。（PUT 方法通常用来传输文件，就像 FTP 协议的文件上传一样） 验证所有的条件请求都会尝试检查服务器上存储的资源是否与某个特定版本的资源相匹配。为了满足这种情况，条件请求需要指示资源的版本。由于无法和整个文件逐个字符进行比较，因此需要把整个文件描绘成一个值，然后把此值和服务器上的资源进行比较，这种方式称为比较器，比较器有两个条件 文档的最后修改日期 一个不透明的字符串，用于唯一标识每个版本，称为实体标签或 Etag。 比较两个资源是否时相同的版本有些复杂，根据上下文，有两种相等性检查 当期望的是字节对字节进行比较时，例如在恢复下载时，使用强 Etag进行验证 当用户代理需要比较两个资源是否具有相同的内容时，使用若 Etag 进行验证 HTTP 协议默认使用 强验证，它指定何时进行弱验证 强验证强验证保证的是字节 级别的验证，严格的验证非常严格，可能在服务器级别难以保证，但是它能够保证任何时候都不会丢失数据，但这种验证丢失性能。 要使用 Last-Modified 很难实现强验证，通常，这是通过使用带有资源的 MD5 哈希值的Etag 来完成的。 弱验证弱验证不同于强验证，因为如果内容相等，它将认为文档的两个版本相同，例如，一个页面与另一个页面的不同之处仅在于页脚的日期不同，因此该页面被认为与其他页面相同。而使用强验证时则被认为这两个版本是不同的。构建一个若验证的 Etag 系统可能会非常复杂，因为这需要了解每个页面元素的重要性，但是对于优化缓存性能非常有用。 下面介绍一下 Etag 如何实现强弱验证。 Etag 响应头是特定版本的标识，它能够使缓存变得更高效并能够节省带宽，因为如果缓存内容未发生变更，Web 服务器则不需要重新发送完整的响应。除此之外，Etag 能够防止资源同时更新互相覆盖。 如果给定 URL 上的资源发生变更，必须生成一个新的 Etag 值，通过比较它们可以确定资源的两个表示形式是否相同。 Etag 值有两种，一种是强 Etag，一种是弱 Etag； 强 Etag 值，无论实体发生多么细微的变化都会改变其值，一般的表示如下 1Etag: &quot;33a64df551425fcc55e4d42a148795d9f25f89d4&quot; 弱 Etag 值，弱 Etag 值只用于提示资源是否相同。只有资源发生了根本改变，产生差异时才会改变 Etag 值。这时，会在字段值最开始处附加 W/。 1Etag: W/&quot;0815&quot; 下面就来具体探讨一下条件请求的标头和 Etag 的关系 条件请求条件请求主要包含的标头如下 If-Match If-None-Match If-Modified-Since If-Unmodified-Since If-Range If-Match对于 GET 和 POST 方法，服务器仅在与列出的 Etag（响应标头） 之一匹配时才返回请求的资源。这里又多了一个新词 Etag，我们稍后再说 Etag 的用法。对于像是 PUT和其他非安全的方法，在这种情况下，它仅仅将上传资源。 下面是两种常见的案例 对于 GET 和 POST 方法，会结合使用 Range 标头，它可以确保新发送请求的范围与上一个请求的资源相同，如果不匹配的话，会返回 416 响应。 对于其他方法，特别是 PUT 方法，If-Match 可以防止丢失更新，服务器会比对 If-Match 的字段值和资源的 Etag 值，仅当两者一致时，才会执行请求。反之，则返回状态码 412 Precondition Failed 的响应。例如 12If-Match: &quot;bfc13a64729c4290ef5b2c2730249c88ca92d82d&quot;If-Match: * If-None-Match条件请求，它与 If-Match 的作用相反，仅当 If-None-Match 的字段值与 Etag 值不一致时，可处理该请求。对于GET 和 HEAD ，仅当服务器没有与给定资源匹配的 Etag 时，服务器将返回 200 OK作为响应。对于其他方法，仅当最终现有资源的 Etag 与列出的任何值都不匹配时，才会处理请求。 当 GET 和 POST 发送的 If-None-Match与 Etag 匹配时，服务器会返回 304。 123If-None-Match: &quot;bfc13a64729c4290ef5b2c2730249c88ca92d82d&quot;If-None-Match: W/&quot;67ab43&quot;, &quot;54ed21&quot;, &quot;7892dd&quot;If-None-Match: * If-Modified-SinceIf-Modified-Since 是 HTTP 条件请求的一部分，只有在给定日期之后，服务端修改了请求所需要的资源，才会返回 200 OK 的响应。如果在给定日期之后，服务端没有修改内容，响应会返回 304 并且不带任何响应体。If-Modified-Since 只能使用 GET 和 HEAD请求。 If-Modified-Since 与 If-None-Match 结合使用时，它将被忽略，除非服务器不支持 If-None-Match。一般表示如下 1If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT 注意：这是格林威治标准时间。HTTP 日期始终以格林尼治标准时间表示，而不是本地时间。 If-RangeIf-Range 也是条件请求，如果满足条件（If-Range 的值和 Etag 值或者更新的日期时间一致），则会发出范围请求，否则将会返回全部资源。它的一般表示如下 12If-Range: Wed, 21 Oct 2015 07:28:00 GMTIf-Range: bfc13a64729c4290ef5b2c2730249c88ca92d82d If-Unmodified-SinceIf-Unmodified-Since HTTP 请求标头也是一个条件请求，服务器只有在给定日期之后没有对其进行修改时，服务器才返回请求资源。如果在指定日期时间后发生了更新，则以状态码 412 Precondition Failed 作为响应返回。 1If-Unmodified-Since: Wed, 21 Oct 2015 07:28:00 GMT 条件请求示例缓存更新条件请求最常见的示例就是更新缓存，如果缓存是空或没有缓存，则以200 OK的状态发送回请求的资源。如下图所示 客户端第一次发送请求没有，缓存为空并且没有条件请求，服务器在收到客户端请求后，设置验证器 Last-Modified 和 Etag 标签，并把这两个标签随着响应一起发送回客户端。 下一次客户端再发送相同的请求后，会直接从缓存中提取，只要缓存没有过期，就不会有任何新的请求到达服务器重新下载资源。但是，一旦缓存过期，客户端不会直接使用缓存的值，而是发出条件请求。验证器的值用作 If-Modified-Since 和If-Match标头的参数。 缓存过期后客户端重新发起请求，服务器收到请求后发现如果资源没有更改，服务器会发回 304 Not Modified响应，这使缓存再次刷新，并让客户端使用缓存的资源。尽管有一个响应/请求往返消耗一些资源，但是这比再次通过有线传输整个资源更有效。 如果资源已经发生更改，则服务器仅使用新版本的资源返回 200 OK 响应，就像没有条件请求，并且客户端会重新使用新的资源，从这个角度来讲，缓存是条件请求的前置条件。 断点续传HTTP 可以支持文件的部分下载，通过保留已获得的信息，此功能允许恢复先前的操作，从而节省带宽和时间。 支持断点续传的服务器通过发送 Accept-Ranges 标头广播此消息，一旦发生这种情况，客户端可以通过发送缺少范围的 Ranges标头来恢复下载 这里你可能有疑问 Ranges 和 Content-Range是什么，来解释一下 Range Range HTTP 请求标头指示服务器应返回文档指定部分的资源，可以一次请求一个 Range 来返回多个部分，服务器会将这些资源返回各个文档中。如果服务器成功返回，那么将返回 206 响应；如果 Range 范围无效，服务器返回416 Range Not Satisfiable错误；服务器还可以忽略 Range 标头，并且返回 200 作为响应。 1Range: bytes=200-1000, 2000-6576, 19000- 还有一种表示是 1Range: bytes=0-499, -500 它们分别表示请求前500个字节和最后500个字节，如果范围重叠，则服务器可能会拒绝该请求。 Content-Range HTTP 的 Content-Range 响应标头是针对范围请求而设定的，返回响应时使用首部字段Content-Range，能够告知客户端响应实体的哪部分是符合客户端请求的，字段以字节为单位。它的一般表示如下 1Content-Range: bytes 200-1000/67589 上段代码表示从所有 67589 个字节中返回 200-1000 个字节的内容 那么上面的 Content-Range你也应该知道是什么意思了 断点续传的原理比较简单，但是这种方式存在潜在的问题：如果在两次下载资源的期间进行了资源更新，那么获得的范围将对应于资源的两个不同版本，并且最终文档将被破坏。 为了阻止这种情况的出现，就会使用条件请求。对于范围来说，有两种方法可以做到这一点。一种方法是使用 If-Modified-Since和If-Match，如果前提条件失败，服务器将返回错误；然后客户端从头开始重新下载。 即使此方法有效，当文档资源发生改变时，它也会添加额外的 响应/请求 交换。这会降低性能，并且 HTTP 具有特定的标头来避免这种情况 If-Range。 该解决方案效率更高，但灵活性稍差一些，因为在这种情况下只能使用一个 Etag。 通过乐观锁避免丢失更新Web 应用程序中最普遍的操作是资源更新。这在任何文件系统或应用程序中都很常见，但是任何允许存储远程资源的应用程序都需要这种机制。 使用 put 方法，你可以实现这一点，客户端首先读取原始文件对其进行修改，然后把它们发送到服务器。 上面这种请求响应存在问题，一旦考虑到并发性，事情就会变得不准确。当客户端在本地修改资源打算重新发送之前，第二个客户端可以获取相同的资源并对资源进行修改操作，这样就会造成问题。当它们重新发送请求到服务器时，第一个客户端所做的修改将被第二次客户端的修改所覆盖，因为第二次客户端修改并不知道第一次客户端正在修改。资源提交并更新的一方不会传达给另外一方，所以要保留哪个客户的更改，将随着他们提交的速度而变化；这取决于客户端，服务器的性能，甚至取决于人工在客户端编辑文档的性能。例如下面这个流程 如果没有两个用户同时操作服务器，也就不存在这个问题。但是，现实情况是不可能只有单个用户出现的，所以为了规避或者避免这个问题，我们希望客户端资源在更新时进行提示或者修改被拒绝时收到通知。 条件请求允许实现乐观锁算法。这个概念是允许所有的客户端获取资源的副本，然后让他们在本地修改资源，并成功通过允许第一个客户端提交更新来控制并发，基于此服务端的后面版本的更新都将被拒绝。 这是使用 If-Match 或 If-Unmodified-Since标头实现的。如果 Etag 与原始文件不匹配，或者自获取以来已对文件进行了修改，则更改为拒绝更新，并显示412 Precondition Failed错误。 HTTP CookiesHTTP 协议中的 Cookie 包括 Web Cookie 和浏览器 Cookie，它是服务器发送到 Web 浏览器的一小块数据。服务器发送到浏览器的 Cookie，浏览器会进行存储，并与下一个请求一起发送到服务器。通常，它用于判断两个请求是否来自于同一个浏览器，例如用户保持登录状态。 HTTP Cookie 机制是 HTTP 协议无状态的一种补充和改良 Cookie 主要用于下面三个目的 会话管理 登陆、购物车、游戏得分或者服务器应该记住的其他内容 个性化 用户偏好、主题或者其他设置 追踪 记录和分析用户行为 Cookie 曾经用于一般的客户端存储。虽然这是合法的，因为它们是在客户端上存储数据的唯一方法，但如今建议使用现代存储 API。Cookie 随每个请求一起发送，因此它们可能会降低性能（尤其是对于移动数据连接而言）。客户端存储的现代 API 是 Web 存储 API（localStorage 和 sessionStorage）和 IndexedDB。 创建 Cookie当接收到客户端发出的 HTTP 请求时，服务器可以发送带有响应的 Set-Cookie 标头，Cookie 通常由浏览器存储，然后将 Cookie 与 HTTP 标头一同向服务器发出请求。可以指定到期日期或持续时间，之后将不再发送Cookie。此外，可以设置对特定域和路径的限制，从而限制 cookie 的发送位置。 Set-Cookie 和 Cookie 标头Set-Cookie HTTP 响应标头将 cookie 从服务器发送到用户代理。下面是一个发送 Cookie 的例子 123456HTTP/2.0 200 OKContent-type: text/htmlSet-Cookie: yummy_cookie=chocoSet-Cookie: tasty_cookie=strawberry[page content] 此标头告诉客户端存储 Cookie 现在，随着对服务器的每个新请求，浏览器将使用 Cookie 头将所有以前存储的 cookie 发送回服务器。 123GET /sample_page.html HTTP/2.0Host: www.example.orgCookie: yummy_cookie=choco; tasty_cookie=strawberry Cookie 主要分为三类，它们是 会话Cookie、永久Cookie 和 Cookie的 Secure 和 HttpOnly 标记，下面依次来介绍一下 会话 Cookies上面的示例创建的是会话 Cookie ，会话 Cookie 有个特征，客户端关闭时 Cookie 会删除，因为它没有指定Expires 或 Max-Age 指令。这两个指令你看到这里应该比较熟悉了。 但是，Web 浏览器可能会使用会话还原，这会使大多数会话 Cookie 保持永久状态，就像从未关闭过浏览器一样 永久性 Cookies永久性 Cookie 不会在客户端关闭时过期，而是在特定日期（Expires）或特定时间长度（Max-Age）外过期。例如 1Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Cookie的 Secure 和 HttpOnly 标记安全的 Cookie 需要经过 HTTPS 协议通过加密的方式发送到服务器。即使是安全的，也不应该将敏感信息存储在cookie 中，因为它们本质上是不安全的，并且此标志不能提供真正的保护。 HttpOnly 的作用 会话 cookie 中缺少 HttpOnly 属性会导致攻击者可以通过程序(JS脚本、Applet等)获取到用户的 cookie 信息，造成用户cookie 信息泄露，增加攻击者的跨站脚本攻击威胁。 HttpOnly 是微软对 cookie 做的扩展，该值指定 cookie 是否可通过客户端脚本访问。 如果在 Cookie 中没有设置 HttpOnly 属性为 true，可能导致 Cookie 被窃取。窃取的 Cookie 可以包含标识站点用户的敏感信息，如 ASP.NET 会话 ID 或 Forms 身份验证票证，攻击者可以重播窃取的 Cookie，以便伪装成用户或获取敏感信息，进行跨站脚本攻击等。 Cookie 的作用域Domain 和 Path 标识定义了 Cookie 的作用域：即 Cookie 应该发送给哪些 URL。 Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前主机(不包含子域名）。如果指定了Domain，则一般包含子域名。 例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如developer.mozilla.org）。 例如，设置 Path=/docs，则以下地址都会匹配： 123/docs/docs/Web//docs/Web/HTTP","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://vincentruan.github.io/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://vincentruan.github.io/tags/HTTP/"}]},{"title":"Mermaid 实用教程","slug":"Mermaid-实用教程","date":"2020-02-04T13:40:12.000Z","updated":"2020-02-17T02:40:44.658Z","comments":true,"path":"2020/02/04/Mermaid-实用教程/","link":"","permalink":"https://vincentruan.github.io/2020/02/04/Mermaid-实用教程/","excerpt":"","text":"相关文档官方文档 Github地址 语句末尾分号是可选的。%% 行注释。 流程图语法说明图表方向Mermaid 支持多种图表的方向，语法如下： 12graph 方向描述 图表中的其他语句... 其中“方向描述”为 用词 含义 TB 从上到下 BT 从下到上 RL 从右到左 LR 从左到右 节点定义即流程图中每个文本块，包括开始、结束、处理、判断等。Mermaid 中每个节点都有一个 id，以及节点的文字。 表述 说明 id[文字] 矩形节点 id(文字) 圆角矩形节点 id((文字)) 圆形节点 id&gt;文字] 右向旗帜状节点 id{文字} 菱形节点 需要注意的是，如果节点的文字中包含标点符号，需要时用双引号包裹起来。另外如果希望在文字中使用换行，请使用替换换行 节点间的连线 表述 说明 &gt; 添加尾部箭头 - 不添加尾部箭头 -- 单线 --text-- 单线上加文字 == 粗线 ==text== 粗线加文字 -.- 虚线 -.text.- 虚线加文字 子图表使用以下语法添加子图表 123subgraph 子图表名称 子图表中的描述语句...end123 对 font awesome 的支持使用 fa: #图表名称# 的语法添加 fontawesome。 12345graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D; 方向 TB/TD - top bottom BT - bottom top RL - right left LR - left right 12graph TB Start --&gt; Stop 节点12graph LR id 12graph LR id[带文字节点] 12graph LR id(圆角节点) 12graph LR id((圆形节点)) 12graph LR id&gt;不对称节点] 12graph LR id&#123;菱形节点&#125; 连接线实线，箭头，无文字12graph LR A--&gt;B 实线，无箭头，无文字12graph LR A---B 实线，无箭头，文字前面两个 -，后面三个 - 12graph LR A-- 文字 ---B 或 12graph LR A--- |文字| B 实线，箭头，文字12graph LR A-- 文字 --&gt;B 或 12graph LR A--&gt; |文字| B 虚线，箭头，无文字12graph LR; A-.-&gt;B; 虚线，箭头，文字12graph LR A-. text .-&gt; B 大箭头，无文字12graph LR A ==&gt; B 大箭头，文字12graph LR A == text ==&gt; B 特殊语法引号文字里用引号避免一些特殊字符的错误。比如矩形节点里有 () 时就无法渲染，所以加上引号。 12graph LR id1[\"This is the (text) in the box\"] 实体字符可以使用 HTML 中的实体字符。 12graph LR A[\"A double quote:#quot;\"] --&gt;B[\"A dec char:#9829;\"] 子图1234567891011graph TB c1--&gt;a2 subgraph one a1--&gt;a2 end subgraph two b1--&gt;b2 end subgraph three c1--&gt;c2 end 样式linkStyle 后面的数字表示第几根线，从 0 开始。可以指定颜色和粗细。 1234567graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D; linkStyle 0 stroke:#0ff,stroke-width:2px; linkStyle 3 stroke:#ff3,stroke-width:4px; 可以设置节点背景，边框颜色，粗细，实线还是虚线 1234graph LR id1(Start)--&gt;id2(Stop) style id1 fill:#f9f,stroke:#333,stroke-width:4px style id2 fill:#ccf,stroke:#f66,stroke-width:2px,stroke-dasharray: 5, 5 样式类12345678graph LR A--&gt;B %% 定义样式类 classDef className fill:#f9f,stroke:#333,stroke-width:4px; %% 应用样式类，markdown里没效果 class A className 1classDef default fill:#f9f,stroke:#333,stroke-width:4px; 定义一个名为 default 的类，节点没有指定特定样式类时，将都会应用这个样式类。 图标可以使用 Font Awesome 图标。语法 fa:icon class name。 12345graph TD B[\"fa:fa-twitter for peace\"] B--&gt;C[fa:fa-ban forbidden] B--&gt;D(fa:fa-spinner); B--&gt;E(A fa:fa-camera-retro perhaps?); 时序图1234567891011sequenceDiagram participant Alice participant Bob Alice-&gt;John: Hello John, how are you? loop Healthcheck John-&gt;John: Fight against hypochondria end Note right of John: Rational thoughts &lt;br/&gt;prevail... John--&gt;Alice: Great! John-&gt;Bob: How about you? Bob--&gt;John: Jolly good! 参与者如果不显示声明，参与者将根据第一次出现的顺序排列，如： 123sequenceDiagram Alice-&gt;&gt;John: Hello John, how are you? John--&gt;&gt;Alice: Great! 第一条语句出现了两个参与者角色，而在这条语句中，Alice 在 John 之前，所以图中也是这个顺序。如果不想根据第一次出现的顺序来排，可以主动声明以定义顺序： 12345sequenceDiagram participant John participant Alice Alice-&gt;&gt;John: Hello John, how are you? John--&gt;&gt;Alice: Great! 别名可以给角色写一个简短的别名以方便书写。 12345sequenceDiagram participant A as Alice participant J as John A-&gt;&gt;J: Hello John, how are you? J-&gt;&gt;A: Great! 消息消息连线有六种样式。 有一个-是实线，两个-是虚线。 1234567sequenceDiagram A-&gt;B: 无箭头实线 A--&gt;B: 无箭头虚线(点线) A-&gt;&gt;B: 有箭头实线 A--&gt;&gt;B: 有箭头实线 A-x B: 有箭头实线，加上叉 A--x B: 有箭头虚线，加上叉 活动期1234567sequenceDiagram Alice-&gt;&gt;John: Hello John, how are you? %% activate 角色名 表示激活控制焦点 activate John John--&gt;&gt;Alice: Great! %% deactivate 角色名 表示控制焦点结束 deactivate John 使用 +/- 的更方便的写法： 123sequenceDiagram Alice-&gt;&gt;+John: Hello John, how are you? John--&gt;&gt;-Alice: Great! 可以嵌套： 12345sequenceDiagram Alice-&gt;&gt;+John: Hello John, how are you? Alice-&gt;&gt;+John: John, can you hear me? John--&gt;&gt;-Alice: Hi Alice, I can hear you! John--&gt;&gt;-Alice: I feel great! 备注语法：Note [ right of | left of | over ] [Actor]。 表述 含义 right of 右侧 left of 左侧 over 在当中，可以横跨多个参与者 123sequenceDiagram participant John Note right of John: Text in note over 可用于单独一个角色上，也可以用于相邻两个角色间： 123sequenceDiagram Alice-&gt;John: Hello John, how are you? Note over Alice,John: A typical interaction 循环语法： 12345678910loop Loop text... statements ...endsequenceDiagram Alice-&gt;John: Hello John, how are you? %% loop 后跟循环体说明文字 loop Every minute John--&gt;Alice: Great! %% 标记循环结束 end 选择语法： 12345alt Describing text... statements ...else... statements ...end 可选条件，比如在没有 else 分支的情况下使用，有点类似 java 中的 switch 的 default 分支，代表剩下所有情况。 12345678910111213opt Describing text... statements ...endsequenceDiagram Alice-&gt;&gt;Bob: Hello Bob, how are you? alt is sick Bob-&gt;&gt;Alice: Not so good :( else is well Bob-&gt;&gt;Alice: Feeling fresh like a daisy end opt Extra response Bob-&gt;&gt;Alice: Thanks for asking end","categories":[{"name":"mermaid","slug":"mermaid","permalink":"https://vincentruan.github.io/categories/mermaid/"}],"tags":[{"name":"mermaid","slug":"mermaid","permalink":"https://vincentruan.github.io/tags/mermaid/"}]},{"title":"使用Apache Bench和Gnuplot产生性能测试图","slug":"使用Apache-Bench-和-Gnuplot产生性能测试图","date":"2020-02-04T13:13:26.000Z","updated":"2020-02-17T02:40:44.861Z","comments":true,"path":"2020/02/04/使用Apache-Bench-和-Gnuplot产生性能测试图/","link":"","permalink":"https://vincentruan.github.io/2020/02/04/使用Apache-Bench-和-Gnuplot产生性能测试图/","excerpt":"","text":"Apache Beach (ab)是Apache自带的一个性能测试工具，专门用来测试网站的性能， 不仅限于Apache web服务器。 它可以同时模拟多个并发请求，测试Web服务器的最大承载压力，同时也可以根据Apache Bench提供的测试结果对服务器性能参数进行调整。它可以记录测试数据，其它工具比如Gnuplot可以利用测试数据进行分析。它也可以提供一个summary，可以直观显示当前测试的web服务器的性能。 安装ab ab是Apache httpd的一部分。不同的发行版提供了不同的安装方法。 比如在笔者使用的redhat 6.4上可以查看此工具在哪个包里： 12345678#yum provides /usr/bin/ab......httpd-tools-2.2.15-30.el6.centos.x86_64 : Tools for use with the Apache HTTP : ServerRepo : updatesMatched from:Filename : /usr/bin/ab...... 它被打包在httpd-tools包里，安装httpd-tools: 1yum install httpd-tools 安装成功后查看帮助： 1ab -h 或 1man ab 运行ab 一个最简单的ab例子就是： 1# ab -n 100 -c 10 http://www.google.com/ 注意网址后面要加”/“或者明确的path如”https://www.google.com/?gfe_rd=cr&amp;ei=_BvfU77ZGMeL8QfugIHAAw&quot;.“-c”是并发数，可以模拟同时有多少个clients并发访问。“-n”表示总的请求数。每个client发送的请求数为此数字除以client数（上面的数字）。“-t”可以指定测试的最大时间，如果还不到此数请求已经发完，那么测试也会结束。当使用-t参数时，ab内部默认最大的请求数为50000，为了同时使用”-n”指定的参数，可以将”-t”参数放在”-n”参数之前， 如果想了解更多的信息， 可以查看这篇文章. 实际运行ab 我使用apache ab要测试的是一个tomcat搭建的集群，上面跑着CPU密集型的一个应用程序，前面使用nginx作为load balancer。 此应用的一个主要的服务通过RESTful service提供， 并且是POST类型的。 Request body是一个XML。 我想随机的替换body中的一个属性，以便测试动态请求对服务器的影响。 但是Apache ab只能提供静态的数据，所以我下载了它的代码并改造了一下。 首先创建了一个request.xml， 并将其中的那个属性改为占位符 修改ab.c文件，将发送请求中的占位符用随机数代替 修改的代码可重用性不高，在这里就不贴了。 写了一个脚本，可以测试不同的并发数： 12345for var in &#123;4,20,50,100,150,200,300&#125;do ab -g plot/biz$var.dat -r -c $&#123;var&#125; -n $&#123;total&#125; -H 'Accept:application/xml' -p request.xml -T 'application/xml' http://localhost:8080/app/bizdone 使用Gnuplot生成图表 在上一步中生成了测试数据，我们可以通过Gnuplot这一强大的工具生成漂亮的图表了。 在生成图表之前，我们还需要处理一下获得的数据， 如果直接使用测试生成报表，我们可能得到这样一个图表： 相应的Gnuplot文件为： 123456789101112131415161718192021222324252627282930#output as png imageset terminal png size 1000,560#save file to \"domain.png\"set output \"biz.png\"#graph titleset title \"Biz Performance\"set key invert reverse Left outside#nicer aspect ratio for image size#set size 1,0.7# y-axis gridset grid y#x-axis labelset xlabel \"requests\"#y-axis labelset ylabel \"response time (ms)\"#plot data from \"biz.dat\" using column 9 with smooth sbezier lines#and title of \"Biz Performance\" for the given dataplot \"biz4.dat\" using 9 smooth sbezier with lines title \"concurrency 4\", \\\"biz20.dat\" using 9 smooth sbezier with lines title \"concurrency 20\", \\\"biz50.dat\" using 9 smooth sbezier with lines title \"concurrency 50\", \\\"biz100.dat\" using 9 smooth sbezier with lines title \"concurrency 100\", \\\"biz150.dat\" using 9 smooth sbezier with lines title \"concurrency 150\", \\\"biz200.dat\" using 9 smooth sbezier with lines title \"concurrency 200\", \\\"biz300.dat\" using 9 smooth sbezier with lines title \"concurrency 300\" 这张图有参考价值，我们可以看到大部分的请求的相应时间落在那个数值段中，但是不能以时间序列显示服务器的性能。 它是以”总用时“ (ttime) 进行排序，所以一般它会一条上升的曲线来显示。这篇文章中指出了一种按照时间序列显示数据的方法。 Apapche ab生成的测试数据中已经包含了时间戳，可以修改Gnuplot生成按时间序列显示的响应时间图：[ Gnuplot文件为： 123456789101112131415161718192021222324252627# Let's output to a jpeg fileset terminal jpeg size 500,500# This sets the aspect ratio of the graphset size 1, 1# The file we'll write toset output \"graphs/timeseries.jpg\"# The graph titleset title \"Benchmark testing\"# Where to place the legend/keyset key left top# Draw gridlines oriented on the y axisset grid y# Specify that the x-series data is time dataset xdata time# Specify the *input* format of the time dataset timefmt \"%s\"# Specify the *output* format for the x-axis tick labelsset format x \"%S\"# Label the x-axisset xlabel 'seconds'# Label the y-axisset ylabel \"response time (ms)\"# Tell gnuplot to use tabs as the delimiter instead of spaces (default)set datafile separator '\\t'# Plot the dataplot \"data/testing.tsv\" every ::2 using 2:5 title 'response time' with pointsexit 为了得到按时间序列显示的吞吐率图表，我们可以处理一下得到的测试数据： 12345for var in &#123;4,20,50,100,150,200,300&#125;do start_time=`awk '&#123;print $6&#125;' plot/biz$var.dat | grep -v 'wait' | sort | uniq -c|head -1|awk '&#123;print $2&#125;'` awk '&#123;print $6&#125;' plot/biz$var.dat | grep -v 'wait' | sort | uniq -c|awk -v t=$start_time '&#123;print $2-t,$1&#125;' &gt; plot/epochtime$var.datdone 然后根据一下的Gnuplot配置生成图表。 1234567891011121314151617181920212223242526272829#output as png imageset terminal png size 1000,560set output \"throughput.png\"#graph titleset title \"Throughput\"set key invert reverse Left outside#nicer aspect ratio for image size#set size 1,0.6# y-axis gridset grid y#x-axis labelset xlabel \"time\"#y-axis labelset ylabel \"responses per second\"plot \"epochtime4.dat\" using 1:2 with lines title \"concurrency 4\", \\\"epochtime20.dat\" using 1:2 with lines title \"concurrency 20\", \\\"epochtime50.dat\" using 1:2 with lines title \"concurrency 50\", \\\"epochtime100.dat\" using 1:2 with lines title \"concurrency 100\", \\\"epochtime150.dat\" using 1:2 with lines title \"concurrency 150\", \\\"epochtime200.dat\" using 1:2 with lines title \"concurrency 200\", \\\"epochtime300.dat\" using 1:2 with lines title \"concurrency 300\"","categories":[{"name":"性能测试","slug":"性能测试","permalink":"https://vincentruan.github.io/categories/性能测试/"}],"tags":[{"name":"Apache Beach","slug":"Apache-Beach","permalink":"https://vincentruan.github.io/tags/Apache-Beach/"},{"name":"Gnuplot","slug":"Gnuplot","permalink":"https://vincentruan.github.io/tags/Gnuplot/"}]},{"title":"12个Git高级命令","slug":"12个Git高级命令","date":"2020-02-04T13:03:00.000Z","updated":"2020-02-17T02:40:44.563Z","comments":true,"path":"2020/02/04/12个Git高级命令/","link":"","permalink":"https://vincentruan.github.io/2020/02/04/12个Git高级命令/","excerpt":"","text":"使用Git时常用的命令有pull、commit、push等，貌似很简单。不过，有时你会遇到合并冲突的情况，Git这时会将冲突标记出来，需要你手工来解决。有时，你会不小心将代码提交到错误的分支上，并且又推送到了远程仓库。还有些时候，你需要切换到不同的分支，但Git却不让你这么做，因为还有未保存的修改。如果需要通过另一个分支的提交来为代码打补丁该怎么做呢？本文就将介绍12个Git高级命令，合理使用这些命令可以大大提升应用Git的效率。 1. 使用rebase而非merge来拉取上游修改分支合并会被记录为一次合并提交，这种做法是很有意义的。比如说，可以通过这种方式来标识一个新特性被合并到了发布分支中。不过，当多个团队成员工作在一个项目中并使用常规的git pull来同步分支时，提交时间线就会被不必要的合并提交所污染。更好的做法则是使用git rebase将一个feature分支变基到master分支： 12$ git checkout feature$ git rebase master 这么做会将整个feature分支移动到master分支的起点，它会合并master分支上所有新的提交。不过，相比于使用合并提交来说，变基会通过在原来的分支中为每次提交创建全新提交来重写项目历史。变基的主要好处在于你会得到一个更加整洁的项目历史。此外，这里还有关于变基的陷阱的一些讨论。 2. 在执行git rebase后解决合并冲突正如能力越大责任就越大一样。在执行git rebase时，你可能会遇到合并冲突的情况。合并冲突表示两个提交修改了同一个文件的同一行，Git不知道该应用哪一个修改。 Git会为你提供3个选择来修复导致冲突的提交（fa39187）： 可以运行git rebase –abort来完全取消变基。这么做会取消变基修改，并将分支置回到执行git rebase之前的状态。 可以运行git rebase –skip来完全忽略该提交。这样，有问题的提交所引入的变化就不会被添加到历史中。 可以使用与合并冲突相同的标准步骤来解决冲突。 3. 临时性保存修改在工作进行中时，有些东西常常会处于凌乱的状态。如果这时需要切换到不同的分支该怎么办呢？Git是不允许你这么做的，因为还有尚未保存的修改。坦率地说，你并不想将半成品提交上去，后面再来修改。这个问题的解决之道就是使用git stash命令。Stash会接收工作目录的当前状态（比如说，修改了的追踪文件与暂存区的修改等），并将其保存到未完成的修改栈中，这样后面随时可以再来修改。可以通过如下命令来暂存你的工作： 123$ git stashSaved working directory and index state WIP on feature: 3fc175f fix race conditionHEAD is now at 3fc175f fix race condition 现在，工作目录就是干净的了： 123$ git status# On branch featurenothing to commit, working directory clean 这时就可以安全地切换分支做别的事情了。不过不必担心，暂存的提交依旧还在： 12$ git stash liststash@&#123;0&#125;: WIP on feature: 3fc175f fix race condition 稍后，在回到feature分支后，你就可以取回所有暂存的变更了： 1234567$ git stash popOn branch featureChanges not staged for commit: (use \"git add ...\" to update what will be committed) modified: index.htmlDropped refs/stash@&#123;0&#125; (ac2321cc3a33ba712b8e50c99a99d3c20da9d6b8) 关于暂存，还有其他一些选项可用，如下所示： 123$ git stash save \"describe it\" # give the stash a name$ git stash clear # delete a stashed commit$ git stash save --keep-index # stash only unstaged files 4. 克隆一个特定的远程分支如果想要从远程仓库中克隆一个特定的分支该怎么做呢？通常你会使用git clone，不过这么做会将所有其他分支都一并克隆下来。一个便捷的方式是使用git remote add： 123$ git init $ git remote add -t -f origin $ git checkout 5. 将cherry-pick远程提交合并到自己的分支中更有甚者，如果只想将远程仓库的一个特定提交合并到自己的分支中该怎么做呢？可以使用git cherry-pick 来选择给定SHA值的提交，然后将其合并到当前分支中： 1$ git cherry-pick 6. 应用来自于不相关的本地仓库的补丁如果需要将另一个不相关的本地仓库的提交补丁应用到当前仓库该怎么做呢？答案就是下面这条命令： 1$ git --git-dir=/.git format-patch -k -1 --stdout | git am -3 -k 7. 忽略追踪文件中的变更如果你和你的同事操纵的是相同分支，那么很有可能需要频繁执行git merge或是git rebase。不过，这么做可能会重置一些与环境相关的配置文件，这样在每次合并后都需要修改。与之相反，你可以通过如下命令永久性地告诉Git不要管某个本地文件： 1$ git update-index --assume-unchanged 8. 每隔X秒运行一次git pull通常，合并冲突出现的原因在于你正在工作的本地仓库不再反映远程仓库的当前状态。这正是我们为什么每天早晨要首先执行一次git pull的缘故。此外，你还可以在后台通过脚本（或是使用GNU Screen）每隔X秒调用一次git pull： 12$ screen$ for((i=1;i&lt;=10000;i+=1)); do sleep X &amp;&amp; git pull; done 9. 将子目录分隔为新的仓库有时，你可能需要将Git仓库中某个特定的目录转换为一个全新的仓库。这可以通过git filter-branch来实现： 1234$ git filter-branch --prune-empty --subdirectory-filter master# Filter the master branch to your directory and remove empty commitsRewrite 48dc599c80e20527ed902928085e7861e6b3cbe6 (89/89)Ref 'refs/heads/master' was rewritten 现在，仓库会包含指定子目录中的所有文件。虽然之前的所有文件都会被删除，但他们依旧存在于Git历史中。现在可以将新的本地仓库推送到远程了。 10. 清理有时，Git会提示“untracked working tree files”会“overwritten by checkout”。造成这种情况的原因有很多。不过通常来说，我们可以使用如下命令来保持工作树的整洁，从而防止这种情况的发生： 123$ git clean -f # remove untracked files$ git clean -fd # remove untracked files/directories$ git clean -nfd # list all files/directories that would be removed 11. 将项目文件打成tar包，并且排除.git目录有时，你需要将项目副本提供给无法访问GitHub仓库的外部成员。最简单的方式就是使用tar或zip来打包所有的项目文件。不过，如果不小心，隐藏的.git目录就会包含到tar文件中，这会导致文件体积变大；同时，如果里面的文件与接收者自己的Git仓库弄混了，那就更加令人头疼了。轻松的做法则是自动从tar文件中排除掉.git目录： 1$ tar cJf .tar.xz / --exclude-vcs 12. 查找修改者最后，如果出现混乱的情况，你一定想要找出是谁造成的。如果生产服务器宕机，那么找到罪魁祸首是比较容易的事情：只需执行git blame。该命令会显示出文件中每一行的作者，提交hash则会找出该行的上一次修改，还能看到提交的时间戳： 1$ git blame","categories":[{"name":"git","slug":"git","permalink":"https://vincentruan.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://vincentruan.github.io/tags/git/"}]},{"title":"在CentOS上安装Git","slug":"在CentOS上安装Git","date":"2020-02-04T13:00:57.000Z","updated":"2020-02-17T02:40:44.883Z","comments":true,"path":"2020/02/04/在CentOS上安装Git/","link":"","permalink":"https://vincentruan.github.io/2020/02/04/在CentOS上安装Git/","excerpt":"","text":"CentOS的yum源中没有git，只能自己编译安装，现在记录下编译安装的内容，留给自己备忘。 确保已安装了依赖的包 12345678yum install curlyum install curl-develyum install zlib-develyum install openssl-develyum install perlyum install cpioyum install expat-develyum install gettext-devel yum install perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker 下载最新的git包 1234567wget http://www.codemonkey.org.uk/projects/git-snapshots/git/git-latest.tar.gztar xzvf git-latest.tar.gzcd git-2011-11-30 ＃你的目录可能不是这个autoconf./configuremakesudo make install 检查下安装的版本，大功告成 1git --version","categories":[{"name":"git","slug":"git","permalink":"https://vincentruan.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://vincentruan.github.io/tags/git/"},{"name":"centos","slug":"centos","permalink":"https://vincentruan.github.io/tags/centos/"}]},{"title":"大规模网站架构的缓存机制和几何分形学","slug":"大规模网站架构的缓存机制和几何分形学","date":"2020-02-04T09:42:42.000Z","updated":"2020-02-17T02:40:44.883Z","comments":true,"path":"2020/02/04/大规模网站架构的缓存机制和几何分形学/","link":"","permalink":"https://vincentruan.github.io/2020/02/04/大规模网站架构的缓存机制和几何分形学/","excerpt":"","text":"缓存机制在我们的实际研发工作中，被极其广泛地应用，通过这些缓存机制来提升系统交互的效率。简单的总结来说，就是在两个环节或者系统之间，会引入一个cache/buffer做为提升整体效率的角色。 而 有趣的是，这种缓存机制令人惊奇并且优美的遵循着“几何分形”的规律，也就是几何分形学中的“自相似性”：从整体上看遵循某种组成规律或者特性，同时从每 一个局部看，仍然遵循某种组成的规律或者特性。我们的这些系统，从整体上看遵循了缓存机制，每一个组成的局部也遵循缓存机制。 等同类比的一个概念，我们常常说的“空间换时间”，牺牲一部分空间代价，来换取整体效率的提升。 graph LR A[A] ==> B(Cache) ==> C[B] C[B] ==> B(Cache) ==> A[A] 例如A和B两者之间的数据交换，为了提升整体的效率，引入角色C，而C被用于当做热点数据的存储，或者是某种中间处理的机制。 我们先从web前端层面开始，看看有哪些比较关键的缓存机制？它们又是怎样协调工作的呢？ 一、前端Cache机制1. 域名转为IP地址（域名服务器DNS缓存）我们知道域名其实只是一个别名，真实的服务器请求地址，实际上是一个IP地址。获得IP地址的方式，就是查询DNS映射表。虽然这是一个非常简单的查询， 但如果每次用户访问一个url都去查询DNS一次，未免显得太频繁，会产生一个可怕的访问量级。DNS服务器会告诉你，你别老是经常过来，万一我挂了，我们就无法愉快地玩耍了。 各个浏览器的缓存时间，会有一定的差别。例如，在chrome浏览器中查看dns的缓存时间的方式是：chrome://net-internals/#dns。 浏览器一般会在本地会建立一个DNS缓存，在一段比较长的时间里，都是使用本地的缓存映射。例如，在Win7系统的cmd里，可以通过“ipconfig /flushdns ”的方式来立刻刷新本地DNS。 graph LR A[浏览器] ==> B(Cache) ==> C[DNS] C[DNS] ==> B(Cache) ==> A[浏览器] 优点：域名映射为IP非常快。 成本：消耗一定的浏览器空间来存储映射关系 2. 访问服务器，获取静态内容（地理位置分布式服务CDN）可能有人会觉得，这个CDN不是缓存。其实，CDN的原理就是将离你很远的东西，放在离你很近的地方，通过这种方式提高用户的访问速度。从这个角 度，它也可以理解为牺牲空间成本换取了时间，本质上也是一种特殊的中间cache。腾讯、阿里等这些大的一线互联网公司一般倾向于自己建立CDN系统，中 小型企业也经常使用第三方的CDN服务。 graph LR A[浏览器] ==> B(CDN) ==> C[很远的服务器] C[很远的服务器] ==> B(Cache) ==> A[浏览器] 优点：解决用户离服务器太远的时候，网络路由中跳来跳去的严重耗时。 成本：全国各地部署多套静态存储服务，管理成本比较高，发布新文件的时候，需要等待全国节点的更新等。 3. 浏览器本地缓存（无网络交互类型）在前端优化原则中，其中一条就是尽量消灭请求，以达到降低服务器压力和提升用户体验的效果。静态文件，例如Js、html、css、图片等内容，很多内容可以1次请求，然后未来就直接访问本地，不再请求web服务器。 常用的实现方法是通过Http协议头中的expire和max-age来控制，这两者的使用方法和区别，我这里就不赘叙了。还有一种HTML5中很热的方式，则是localStorage，尤其在移动端也被做为一个强大的缓存，甚至当做一种本地存储来广泛使用。 graph LR A[浏览器] ==> B(本地缓存localStore) ==> C[web服务器] C[web服务器] ==> B(本地缓存localStore) ==> A[浏览器] 优点：减少网络传输，加快页面内容展示速度，提升用户体验。 成本：占用客户端的部分内存和磁盘，影响实时性。 4. 浏览器和web服务协议缓存（有网络交互类型）浏览器的本地缓存是存在过期时间的，一旦过期，就必须重新向服务器请求。这个时候，会有两种情形： 服务器的文件或者内容没有更新，可以继续使用浏览器本地缓存。 服务器的文件或者内容已经更新，需要重新请求，通过网络传输新的文件或者内容。 这里的协商方式也可以通过Http协议来控制，Last-Modified和Etag，这个时候请求服务器，如果是内容没有发生变更的情况，服务器会返回 304 Not Modified。这样的话，就不需要每次访问服务器都通过网络传输一个比较大的文件或者数据包，只要简单的http应答就可以达到相同的请求文件效果。 graph LR A[浏览器] ==> B(Last-MofifiedEtag机制) ==> C[web服务器] C[web服务器] ==> B(Last-MofifiedEtag机制) ==> A[浏览器] 下图中的例子，是腾讯的自建CDN（imgcache.gtime.cn）： ![image-20200204180300749](大规模网站架构的缓存机制和几何分形学/image-20200204180300749.png) 优点：减少频繁的网络大数据包传输，节约带宽，提升用户体验。 成本：增加了服务器处理的步骤，消耗更多的CPU资源。 ## **5. 浏览器中间代理** 上面的几种cache机制，实际上都是非常常见。但是，在移动互联网时代，流量昂贵是很多用户心中深深的痛。于是，又出现了一种新型的中间cache， 也就是在浏览器和web服务器再架设一个中间代理。这个代理服务器会帮助手机浏览器去请求web页面，然后将web页面进行处理和压缩（例如压缩文件和图片），使页面变小，然后再传输给手机端的浏览器。 graph LR A[手机浏览器] ==> B(浏览器商的中间代理服务器) ==> C[压缩后的Html和图片] ==> A[手机浏览器] B(浏览器商的中间代理服务器) ==> D[www.qq.com的web服务器] D[www.qq.com的web服务器] ==> B(浏览器商的中间代理服务器) 部分手机浏览器（例如Chrome）号称可以节省流量，提升访问速度，实际上就是上述做法。但是，也分为两种情况： - 用户的网络和手机配置都比较差，因为页面被压缩变小，加载和传输速度变快，并且节约了流量。 - 用户的网络和手机配置都比较好，本身直连速度已经很快了，反而因为设置了中间代理，加载速度变慢，也可节约流量。 下图是chrome手机浏览器中，开启和不开启中间代理的对比图： ![image-20200204180713768](大规模网站架构的缓存机制和几何分形学/image-20200204180713768.png) 优点：节约用户流量，大部分情况下提升了加载速度。 成本：需要架设中间代理服务器，对各种文件进行压缩，有比较高的服务器维护成本。 ## **6. 预加载缓存机制** 这种加载方式主要流行在移动端，为了解决手机网速慢和浏览器加载性能问题，浏览器会判断页面的关联内容，进行“预加载”。 也就是说，在用户浏览A页面的时候，就提前下载并且加载B页面的内容。给用户的体验就是，B页面一瞬间就出现了，中间没有任何延迟的感觉，从而带来更好的 极佳的用户体验。 这种实现机制，往往由浏览器来实现，当然，手机页面本身，也可以通过JS来自身实现。而这种机制也存在一些问题，浏览器需要预判用户的浏览行为，在一些场景下，这个预判算法本身不一定准确，如果不准确则带来一定的流量、内存和系统资源的浪费。 graph LR A[浏览器] ==> C[页面内容A] A[浏览器] -.- B(预加载) -.-> D[页面内容B] A[浏览器] -.- E(预加载) -.-> F[页面内容C/D/E/...] 优点：给用户带来极佳的页面展示体验。 缺点：预判实现比较复杂，占据一定的内存和手机系统资源，可能产生流量和资源浪费。 前端的cache当然不仅仅如此简单，如果细致到每一个小环节和组成部分，我们会发现实际上是无处不在的，例如浏览器的渲染行为、网络网卡的传输环节，小环节和小环节之间也有无数这种类型的cache角色。 这个就如同几何分形学中的自相似性：从整体上看符合某种组成规律或者特性，同时，从局部看，仍然符合某种组成的规律或者特性。 几何分形的现象在我们生活中，也是非常常见的，例如： 人体中的几何分形例子，例如：人体有1个头部+4肢，局部上看人的手指也是1个手指头+4个手指；人体无论整体或者局部，都大致遵循黄金分割点0.618的比例来生长（五官按照这个比例越多，越好看）。 例如下图中的叶子，每个局部都和主干组成结构相似。 二、Web系统和几何分形学1. Web系统中的缓存机制看完上面的前端cache，我们会感觉到缓存机制在前端中的确无处不在，那么它在其他地方和环节，是否也无处不在？ 可以看看这张图： graph TB A[浏览器] ==> C[前端cache机制] ==> D[web服务器] D[web服务器] ==> C[前端cache机制] ==> A[浏览器] D[web服务器] ==放大web服务器==> B(memcache缓存) ==> E[MySQL] B(memcache缓存) ==> F[Apache] E[MySQL] ==> B(memcache缓存) F[Apache] ==> B(memcache缓存) E[MySQL] ==放大MySQL==> G(innodb_buffer_pool存放热点数据) ==> H[MySQL内部数据] G(innodb_buffer_pool存放热点数据) ==> I[外界请求] H[MySQL内部数据] ==> G(innodb_buffer_pool存放热点数据) I[外界请求] ==> G(innodb_buffer_pool存放热点数据) 实际上，每一个环节本身是可以又再次被放大的，放大以后，我们又看见了更多缓存机制的“特性”存在。从一个整体来看，符合该规律，从组成部分来看，仍然符合该规律。 每一个组成缓存机制的“成员”的内部，又存在着更多的缓存机制。 Apache内部的一些“缓存机制”： url映射缓存mod_cache（有mode_disk_cache和mod_mem_cache，后者官方已不推荐） 缓存热点文件打开描述符mod_file_cache（对于静态文件的情况，减少打开文件中open行为的耗时） 启动的时候，通过prefork模式设置的StartServers服务进程池，牺牲内存空间。 MySQL内的一些“缓存机制”： 数据库的索引，牺牲磁盘空间（组合索引等会占据很大的磁盘空间） innodb_buffer_pool_size，热点数据的缓存，牺牲内存空间 innodb_flush_method写入磁盘的机制，可以配置成缓冲写入的方式 query_cache_size查询缓存，牺牲内存空间 thread_cache_size数据库连接池的缓存个数，牺牲内存空间 2. 接近硬件层面的“空间换时间”那我们再来看更细小的一个环节，计算机写的操作。我们会发现，在内存和物理磁盘之间，还有一个磁盘缓冲区（页高速缓存）的存在，这个是内存和磁盘之间的“缓存”。当然，读取的操作也是同理。 下图是“放大”MySQL中的写入磁盘： graph LR A[外界请求] ==> C[innodb_buffer_pool存放热点数据] ==> B[MySQL内部数据] B[MySQL内部数据] ==> C[innodb_buffer_pool存放热点数据] ==> A[外界请求] B[MySQL内部数据] ==放大写入数据==> D[磁盘写入缓冲区在内存中] ==> E[MySQL] ==队列满或超时==> F[物理磁盘] G[内存] ==> D[磁盘写入缓冲区在内存中] 实际上，更进一步看，CPU和内存之间也存在缓存机制（常用指令会存在放在寄存器中，因为CPU访问寄存器会远快于访问内存，中间为了缓冲它们之间差距，设置了多级高速缓存）。 graph LR A[Mem] ==Bus总线==> B[L3 Cache] ==> C[L2 Cache] ==> D[L1 Cache] ==> E[CPU core] E[CPU core] ==> D[L1 Cache] ==> C[L2 Cache] ==> B[L3 Cache] ==Bus总线==> A[Mem] 例如下图是Intel i7 920的各级缓存大小： 这个时候，我们可以看出来，计算机系统从大的系统层面看，是遵循“缓存机制”的规律的，同时，在每个局部成员的层面，同样遵循该规律。 3. 现实世界中的“缓存机制”我们现在喝水通常使用的是杯子，杯子实际上也扮演着一个特殊的Cache角色。举个例子：一个人离饮水机比较远，他渴了，他有如下两种“喝水”的方式： 不用杯子，每次渴了直接去饮水机喝（这个比较霸气侧漏，不要在意细节）。结果：频繁跑动，耗费体力。 使用杯子，渴了先喝杯子（Cache）上的水，如果杯子没有，带上杯子去装水，再喝。结果：比较少跑动，节省体力。 这样看不直观，简化为一个流程图如下： graph LR A((人)) -.口渴则过去喝.-> B[比较远的饮水机] A((人)) ==> D[杯子 Cache] --杯子空则过去--> B[比较远的饮水机] 这虽然是个人尽皆知的道理，但是，这个方法本身是“进化”出来的。百万年前的原始人类和其他大自然的动物一样的，喝水遵循了第一种方式，只是随着人类的发展，“进化”出第二种喝水的方式。 这里也存在一个缓存机制，就是用杯子的空间获取喝水效率的时间。 还有一个更为典型的例子，就是坐车/运输，假设我们从深圳去广州，我们会去坐客运车。而客运车（假设上面有40个 座位）实际上相当于一个40个座位的“队列”。遵循着网络传输的相同的规律“队列满或者超时则发送”。客车本身的40个位置，就像一个“发送缓冲区”。使 用和不使用这个大的缓冲区，客车也可以有两者运作方式： 车站发现来一个人，用只能容纳一个人的小车，不等待直接送一个人去广州。 车站发现来一个人，先放进客车buffer中，等待人满或者达到班车约定时间（队列超时）再出发。 graph LR A(深圳车站) -.1.来一个立刻用车运走.-> B(广州车站) A(深圳车站) ==2==> D[40座客车buffer] --> B(广州车站) 显而易见，第一种是太浪费资源了。 除此之外，还有很多各种各样的例子，如江河上的大坝、我们桌面上的一些东西（它们占据宝贵的桌面空间）、我们公司附近小店里的商品、离我们近的东西等等。 看到这里，很多人会渐渐发觉，计算机的一些原理，竟然在现实世界里有无处不在的“映射和影子”。 几何分形学是个非常有趣的东西，某些规律，实际上还贯穿在整个宏观和微观世界中。 例如“绕转”的现象： graph LR A[电子围绕原子核转] ==> B[月球自转] ==> C[月球围绕地球转] ==> D[地月系围绕太阳转] ==> E[太阳系围绕银河系中心转] 4. 现实世界和计算机“缓存机制”原理的关系，为什么遵循“几何分形”？实际上，计算机的原理来源于数学，而数学是日常生活现象和规律的高度抽象，源于生活，高于生活。 graph LR A[现实世界] -.高度抽象.-> B[数学] -.应用实现.-> C[计算机原理] 同时，不仅仅“缓存机制”，还有很多其他技术的原理，也能找到这种遵循“几何分形学”的样子。","categories":[{"name":"缓存","slug":"缓存","permalink":"https://vincentruan.github.io/categories/缓存/"}],"tags":[{"name":"cache","slug":"cache","permalink":"https://vincentruan.github.io/tags/cache/"},{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/tags/架构设计/"}]},{"title":"electron-vue开发入门指南","slug":"electron-vue开发入门指南","date":"2020-01-31T04:48:08.000Z","updated":"2020-02-17T02:40:44.764Z","comments":true,"path":"2020/01/31/electron-vue开发入门指南/","link":"","permalink":"https://vincentruan.github.io/2020/01/31/electron-vue开发入门指南/","excerpt":"","text":"Electron概述 GitHub 官网不翻墙太卡，本着能偷懒就偷懒，GayHub就够了，不用翻官网了 中文文档 W3C教程 VUE概述 GitHub VUE官网 官网资料齐全，中英文档都齐备，基本看完够搞个工程了 Electron + Vue 联合使用安装Nodejs安装成功之后node -v，会显示版本，版本可以不用这么新，看心情安装。 12$ node -vv12.14.0 搭建Vue开发环境直接使用脚手架工具vue-cli，因为在国内的npm非常慢，所以需要重新设置npm镜像，设置为淘宝的镜像 1npm config set registry https://registry.npm.taobao.org/ 我们可以看一下镜像地址是： 12vue npm config get registry https://registry.npm.taobao.org/ 如果不想修改默认npm地址，也可以设置cnpm(因为自带翻墙光环，考虑到后面可能不方便翻墙，后面全程优先使用墙内网络操作。) 123npm install -g cnpm --registry=https://registry.npm.taobao.org//输入命令,查看是否安装成功cnpm 安装脚手架工具： 1npm install --global vue-cli 安装web-pack： 1npm install -g webpack yarn 使用国内镜像 12yarn config set registry https://registry.npm.taobao.orgyarn config list npm更新package.json将package.json中的依赖更新为最新版 安装 1npm install -g npm-check-updates 显示当前目录下项目中所有新的依赖包 1ncu 更新项目package文件 1ncu -u npm-check-updates更多参数 什么是Yarn和NPM?Yarn:Yet Another Resource Negotiator，是一个快速、可靠、安全的依赖管理工具，一款新的JavaScript包管理工具。 Yarn工作流： Yarn使用方法：https://yarn.bootcss.com/docs/usage/ Yarn使用方法-如图： Yarn是什么：https://yarn.bootcss.com Npm是什么 :https://www.npmjs.cn/ yarn和npm命令对比一、命令对比 yarn npm 命令功能 yarn install npm install 根据pack.json安装项目所需的依赖包 yarn install --flat -- 注释1 yarn install --no-lockfile npm install --no-package-lock 不读取或生成yarn.lock锁文件 yarn install --pure-lockfile -- 不要生成yarn.lock锁文件 yarn add [package] npm install [package] 安装需要的依赖包 yarn add [package] --dev npm install [package] --save-dev 注释2 yarn add [package] --D npm install [package] --save-dev 同上 yarn add [package] --peer -- 注释3 yarn add [package] --P -- 同上 yarn add [package] --optional npm install [package] --save-optional 注释4 yarn add [package] --O npm install [package] --save-optional 同上 yarn add [package] --exact npm install [package] --save-exact 注释5 yarn add [package] --E npm install [package] --save-exact 同上 yarn global add [package] npm install [package] --global 全局安装依赖包 yarn global upgrade npm update --global 全局更新依赖包 yarn add --force npm rebuild 更改包内容后进行重建 yarn remove [package] npm uninstall [package] 卸载已经安装的依赖包 yarn cache clean [package] npm cache clean 注释6 yarn upgrade rm -rf node_modules &amp;&amp; npm install 更新依赖包 yarn version --major npm version major 更新依赖包的版本 yarn version --minor npm version minor 更新依赖包的版本 yarn version --patch npm version patch 更新依赖包的版本 二、命令注释 注释1 ：安装所有依赖项，但每个依赖项只允许一个版本。在第一次运行时，这将提示你为多版本的依赖包选择一个版本，进行安装。这些将添加到您package.json的 resolutions字段下。 12345\"resolutions\": &#123; \"package-a\": \"2.0.0\", \"package-b\": \"5.0.0\", \"package-c\": \"1.5.2\"&#125; 注释2 ：安装所需的依赖包，并将该包的记录写到package.json文件的 devDependencies 选项中。 1234567\"devDependencies\": &#123; \"autoprefixer\": \"^7.1.2\", \"babel-core\": \"^6.22.1\", \"babel-helper-vue-jsx-merge-props\": \"^2.0.3\", \"babel-loader\": \"^7.1.1\", \"babel-plugin-syntax-jsx\": \"^6.18.0\",&#125; 注释3 ：安装所需的依赖包，并将该包的记录写到package.json文件的 peerDependencies 选项中。 注释4 ：安装所需的依赖包，并将该包的记录写到package.json文件的 optionalDependencies 选项中。 注释5 ：安装依赖包的确切版本，默认设置是使用依赖包的最新版本。例如， yarn add foo@1.2.3将接受版本1.9.1，但 yarn add foo@1.2.3 --exact 只接受版本1.2.3。 注释6 ：运行此命令将清除全局缓存依赖包。当再次yarn或yarn install运行，进行下载依赖包 安装Electron1cnpm install -g electron 验证 123&gt;electron -v v7.1.10 搭建electron-vue项目simulatedgreg/electron-vue用的vue-cli2，不建议再使用，如果vue-cli用的3或者4，建议直接跳到下面的章节 相关文档 electron-vue文档 使用electron-vue脚手架工具初始化项目可能会比较慢，可以通过webpack方式初始化vue项目，然后在引入electron方式，这个会快很多 1234567891011121314151617181920212223242526272829$ vue init simulatedgreg/electron-vue alistar? Application Name alistar? Application Id org.evue.alistar? Application Version 0.0.1? Project description 哞利斯塔, 快乐辅助? Use Sass / Scss? Yes? Select which Vue plugins to install axios, vue-electron, vue-router, vuex, vuex-electron? Use linting with ESLint? Yes? Which ESLint config would you like to use? Standard? Set up unit testing with Karma + Mocha? Yes? Set up end-to-end testing with Spectron + Mocha? Yes? What build tool would you like to use? builder? author vincentruan &lt;rzw0813@gmail.com&gt; vue-cli · Generated \"alistar\".---All set. Welcome to your new electron-vue project!Make sure to check out the documentation for this boilerplate athttps://simulatedgreg.gitbooks.io/electron-vue/content/.Next Steps: $ cd alistar $ yarn (or `npm install`) $ yarn run dev (or `npm run dev`) 上面已经有提示下一步做什么了，cd alistar目录下，之后对照执行，如果用yarn记得设置代理或者用国内镜像。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374$ cnpm install| [22/67] Installing get-stdin@^4.0.1platform unsupported babel-loader@7.1.5 › webpack@4.41.5 › watchpack@1.6.0 › chokidar@2.1.8 › fsevents@^1.2.7 Package require os(darwin) not compatible with your platform(win32)[fsevents@^1.2.7] optional install error: Package require os(darwin) not compatible with your platform(win32)√ Installed 67 packages√ Linked 1218 latest versions[1/7] scripts.postinstall babel-core@6.26.3 › babel-register@6.26.0 › core-js@^2.5.0 run \"node -e \\\"try&#123;require('./postinstall')&#125;catch(e)&#123;&#125;\\\"\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_core-js@2.6.11@core-js\"Thank you for using core-js ( https://github.com/zloirock/core-js ) for polyfilling JavaScript standard library!The project needs your help! Please consider supporting of core-js on Open Collective or Patreon:&gt; https://opencollective.com/core-js&gt; https://www.patreon.com/zloirockAlso, the author of core-js ( https://github.com/zloirock ) is looking for a good job -)[1/7] scripts.postinstall babel-core@6.26.3 › babel-register@6.26.0 › core-js@^2.5.0 finished in 2s[2/7] scripts.postinstall electron-builder@20.44.4 › app-builder-lib@20.44.4 › ejs@^2.6.2 run \"node ./postinstall.js\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_ejs@2.7.4@ejs\"Thank you for installing EJS: built with the Jake JavaScript build tool (https://jakejs.com/)[2/7] scripts.postinstall electron-builder@20.44.4 › app-builder-lib@20.44.4 › ejs@^2.6.2 finished in 2s[3/7] scripts.postinstall electron@^2.0.4 run \"node install.js\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_electron@2.0.18@electron\"Downloading SHASUMS256.txt[============================================&gt;] 100.0% of 5.39 kB (5.39 kB/s)[3/7] scripts.postinstall electron@^2.0.4 finished in 17s[4/7] scripts.install spectron@3.8.0 › electron-chromedriver@~1.8.0 run \"node ./download-chromedriver.js\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_electron-chromedriver@1.8.0@electron-chromedriver\"Downloading tmp-2644-1-SHASUMS256.txt-1.8.0[============================================&gt;] 100.0% of 8.02 kB (8.02 kB/s)successfully dowloaded and extracted![4/7] scripts.install spectron@3.8.0 › electron-chromedriver@~1.8.0 finished in 5s[5/7] scripts.install karma@2.0.5 › socket.io@2.0.4 › engine.io@3.1.5 › uws@~9.14.0 run \"node-gyp rebuild &gt; build_log.txt 2&gt;&amp;1 || exit 0\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_uws@9.14.0@uws\"[5/7] scripts.install karma@2.0.5 › socket.io@2.0.4 › engine.io@3.1.5 › uws@~9.14.0 finished in 3s[6/7] scripts.install node-sass@^4.9.2 run \"node scripts/install.js\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_node-sass@4.13.1@node-sass\"Downloading binary from https://cdn.npm.taobao.org/dist/node-sass/v4.13.1/win32-x64-72_binding.nodeDownload completeBinary saved to D:\\gitspace\\alistar\\node_modules\\_node-sass@4.13.1@node-sass\\vendor\\win32-x64-72\\binding.nodeCaching binary to C:\\Users\\vincentruan\\.npminstall_tarball\\node-sass\\4.13.1\\win32-x64-72_binding.node[6/7] scripts.install node-sass@^4.9.2 finished in 4s[6/7] scripts.postinstall node-sass@^4.9.2 run \"node scripts/build.js\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_node-sass@4.13.1@node-sass\"Binary found at D:\\gitspace\\alistar\\node_modules\\_node-sass@4.13.1@node-sass\\vendor\\win32-x64-72\\binding.nodeTesting binaryBinary is fine[6/7] scripts.postinstall node-sass@^4.9.2 finished in 2s[7/7] scripts.postinstall alistar@0.0.1 run \"npm run lint:fix\", root: \"D:\\\\gitspace\\\\alistar\"&gt; alistar@0.0.1 lint:fix D:\\gitspace\\alistar&gt; eslint --ext .js,.vue -f ./node_modules/eslint-friendly-formatter --fix src test[7/7] scripts.postinstall alistar@0.0.1 finished in 11s√ Run 7 scriptspeerDependencies link ajv@5.5.2 in D:\\gitspace\\alistar\\node_modules\\_ajv-keywords@2.1.1@ajv-keywords unmet with D:\\gitspace\\alistar\\node_modules\\ajv(6.11.0)peerDependencies WARNING karma-webpack@^3.0.0 requires a peer of webpack@^2.0.0 || ^3.0.0 but webpack@4.41.5 was installeddeprecate css-loader@0.28.11 › cssnano@3.10.0 › autoprefixer@6.7.7 › browserslist@^1.7.6 Browserslist 2 could fail on reading Browserslist &gt;3.0 config used in other tools.deprecate babel-core@6.26.3 › babel-register@6.26.0 › core-js@^2.5.0 core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3.deprecate eslint@4.19.1 › file-entry-cache@2.0.0 › flat-cache@1.3.4 › circular-json@^0.3.1 CircularJSON is in maintenance only, flatted is its successor.deprecate karma-coverage@1.1.2 › istanbul@^0.4.0 This module is no longer maintained, try this instead: npm i nycVisit https://istanbul.js.org/integrations for other alternatives.deprecate karma@2.0.5 › log4js@2.11.0 › circular-json@^0.5.4 CircularJSON is in maintenance only, flatted is its successor.deprecate karma@2.0.5 › log4js@2.11.0 › nodemailer@^2.5.0 All versions below 4.0.1 of Nodemailer are deprecated. See https://nodemailer.com/status/deprecate karma@2.0.5 › log4js@2.11.0 › nodemailer@2.7.2 › socks@1.1.9 If using 2.x branch, please upgrade to at least 2.1.6 to avoid a serious bug with socket data flow and an import issue introduced in 2.1.0deprecate karma@2.0.5 › log4js@2.11.0 › nodemailer@2.7.2 › mailcomposer@4.0.1 This project is unmaintaineddeprecate karma@2.0.5 › log4js@2.11.0 › loggly@1.1.1 › request@2.75.0 › node-uuid@~1.4.7 Use uuid module insteaddeprecate karma@2.0.5 › log4js@2.11.0 › loggly@1.1.1 › request@2.75.0 › hawk@~3.1.3 This module moved to @hapi/hawk. Please make sure to switch over as this distribution is no longer supported and may contain bugs and critical security issues.deprecate karma@2.0.5 › log4js@2.11.0 › nodemailer@2.7.2 › mailcomposer@4.0.1 › buildmail@4.0.1 This project is unmaintaineddeprecate karma@2.0.5 › log4js@2.11.0 › loggly@1.1.1 › request@2.75.0 › hawk@3.1.3 › cryptiles@2.x.x This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).deprecate karma@2.0.5 › log4js@2.11.0 › loggly@1.1.1 › request@2.75.0 › hawk@3.1.3 › sntp@1.x.x This module moved to @hapi/sntp. Please make sure to switch over as this distribution is no longer supported and may contain bugs and critical security issues.deprecate karma@2.0.5 › log4js@2.11.0 › loggly@1.1.1 › request@2.75.0 › hawk@3.1.3 › hoek@2.x.x This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).deprecate karma@2.0.5 › log4js@2.11.0 › loggly@1.1.1 › request@2.75.0 › hawk@3.1.3 › boom@2.x.x This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).deprecate spectron@3.8.0 › webdriverio@^4.8.0 outdated version, please use @nextdeprecate karma@2.0.5 › socket.io@2.0.4 › engine.io@3.1.5 › uws@~9.14.0 New code is available at github.com/uNetworking/uWebSockets.jsRecently updated (since 2020-01-23): 10 packages (detail see file D:\\gitspace\\alistar\\node_modules\\.recently_updates.txt) Today: → babel-preset-env@1.7.0 › browserslist@3.2.8 › electron-to-chromium@^1.3.47(1.3.342) (09:02:31) → webpack-dev-server@3.10.1 › del@4.1.1 › @types/glob@7.1.1 › @types/node@*(13.5.2) (05:51:42)√ All packages installed (1560 packages installed from npm registry, used 1m(network 27s), speed 2.23MB/s, json 1285(3.12MB), tarball 58.05MB) 编译完成后run dev， 1$ cnpm run dev 问题收集与处理修复问题前先将项目初始化提交github 问题一：ERROR in Template execution failed: ReferenceError: process is not defined高版本的node，大于12的版本时候。使用electron-vue项目时候会报错！Webpack ReferenceError: process is not defined! 123456789101112131415ReferenceError: process is not defined - index.ejs:11 eval [.]/[_html-webpack-plugin@3.2.0@html-webpack-plugin]/lib/loader.js!./src/index.ejs:11:2 - index.ejs:16 module.exports [.]/[_html-webpack-plugin@3.2.0@html-webpack-plugin]/lib/loader.js!./src/index.ejs:16:3 - index.js:284 [alistar]/[_html-webpack-plugin@3.2.0@html-webpack-plugin]/index.js:284:18 - runMicrotasks - task_queues.js:93 processTicksAndRejections internal/process/task_queues.js:93:5 修改 .electron-vue/webpack.renderer.config.js 和 .electron-vue/webpack.web.config.js如下 webpack.renderer.config.js：L125 123456789101112131415161718192021222324new HtmlWebpackPlugin(&#123; filename: 'index.html', template: path.resolve(__dirname, '../src/index.ejs'), minify: &#123; collapseWhitespace: true, removeAttributeQuotes: true, removeComments: true &#125;, templateParameters(compilation, assets, options) &#123; return &#123; compilation: compilation, webpack: compilation.getStats().toJson(), webpackConfig: compilation.options, htmlWebpackPlugin: &#123; files: assets, options: options &#125;, process, &#125;; &#125;, nodeModules: process.env.NODE_ENV !== 'production' ? path.resolve(__dirname, '../node_modules') : false&#125;), webpack.web.config.js: L97 12345678910111213141516171819202122new HtmlWebpackPlugin(&#123; filename: 'index.html', template: path.resolve(__dirname, '../src/index.ejs'), templateParameters(compilation, assets, options) &#123; return &#123; compilation: compilation, webpack: compilation.getStats().toJson(), webpackConfig: compilation.options, htmlWebpackPlugin: &#123; files: assets, options: options &#125;, process, &#125;; &#125;, minify: &#123; collapseWhitespace: true, removeAttributeQuotes: true, removeComments: true &#125;, nodeModules: false&#125;), 重新执行run dev 问题二： Unable to install vue-devtoolselectron-devtools-installer无法安装远程的vue-devtool，采用手动安装方式。 从本地浏览器已安装的插件中拷贝到项目路径，在项目目录下创建文件夹devTools\\vue-devtools，拷贝 C:\\Users\\${userName}\\AppData\\Local\\Google\\Chrome\\User Data\\Default\\Extensions\\nhdogjmejiglipccpnnnanhbledajbpd\\5.1.1_0文件夹内容devTools\\vue-devtools下， 修改src/main/index.dev.js 1234567891011121314151617181920212223242526272829303132/** * This file is used specifically and only for development. It installs * `electron-debug` &amp; `vue-devtools`. There shouldn't be any need to * modify this file, but it can be used to extend your development * environment. *//* eslint-disable */// Install `electron-debug` with `devtron`require('electron-debug')(&#123; showDevTools: true &#125;)// 新增变量定义import &#123; BrowserWindow &#125; from 'electron';import path from 'path';// Install `vue-devtools`require('electron').app.on('ready', () =&gt; &#123; // 注释掉的这部分是 Electron-Vue 中预装devtool的代码，没有用 // let installExtension = require('electron-devtools-installer') // installExtension.default(installExtension.VUEJS_DEVTOOLS) // .then(() =&gt; &#123;&#125;) // .catch(err =&gt; &#123; // console.log('Unable to install `vue-devtools`: \\n', err) // &#125;) // 安装vue-devtools BrowserWindow.addDevToolsExtension(path.resolve(__dirname, '../../devTools/vue-devtools'));&#125;)// Require `main` process to boot apprequire('./index') 应用自动重启，注意首次启动vue插件被&gt;&gt;这个隐藏了，需要手动拖动一下 问题三：ERROR in Error: .\\node_modules\\html-webpack-plugin\\node_modules\\clean-css\\index.js:1 SyntaxError: Invalid or unexpected token找到这个文件发现下载的是一串ASII乱码，尝试删除重新安装，发现用yarn install下载的这个文件总有问题，改为cnpm下载就行了 问题四： ERROR in TypeError: compilation.templatesPlugin is not a functionwebpack不是最新版 解决方法： 1.删除node_modules，重新安装 1npm install 2.安装最新webpack 1npm add webpack@latest 知识库vue项目转换为electron-vue 把原有项目package.json的dependencies，devDependencies中不同的配置项，添加到 my-project 的package.json中 把vue项目src的内容全部拷贝到 my-project/src/renderer 中 安装依赖 npm install 运行 npm run dev 就可以看到跑起来的客户端 打包 npm run build 项目的安装文件放进build里面，执行.exe文件就可以安装了（build文件有点大） electron-vue使用electron-builder指定打包32位//package.json 1234567891011\"win\": &#123; \"icon\": \"build/icons/icon.ico\", \"target\": [ &#123; \"target\": \"nsis\", \"arch\": [ \"ia32\" ] &#125; ]&#125;, electron-vue开发环境跨域代理设置//.electron-vue/dev-runner.js 1234567891011121314function startRenderer()&#123;... proxy: &#123; '/api': &#123; target: 'http://192.168.74.222:6019', // secure: false, // 如果是https接口，需要配置这个参数 changeOrigin: true, // 如果接口跨域，需要进行这个参数配置 pathRewrite: &#123; '^/api': '' &#125; &#125; &#125; ...&#125; 通过BrowserWindow新窗口打开项目内页面123456789101112const BrowserWindow = require('electron').remote.BrowserWindowconst winURL = process.env.NODE_ENV === 'development' ? `http://localhost:9080/#/new` : `file://$&#123;__dirname&#125;/index.html#new`let newWindow = new BrowserWindow(&#123; height: 600, width: 800&#125;)newWindow.loadURL(winURL)newWindow.on('closed', () =&gt; &#123; newWindow = null&#125;) 放弃SimulatedGREG/electron-vueSimulatedGREG/electron-vue已经很久没有更新了，而且其生成的工程结构并不是vue-cli3，在尝试升级vue-cli3过程中，发现简直是无底洞，直接放弃治疗，重头升级！！！ electron-vue3/4从0单排安装/升级vue-cli3/4先执行以下命令，确认下本地安装的vue-cli版本： 1vue -V 如果本地使用的是vue-cli2.x或者更早版本，可先卸载： 1cnpm uninstall vue-cli -g ※注：vue-cli3和vue-cli4使用了新的npm包名，与旧版本不一样。 如果还没有安装vue-cli3/4，先执行以下命令安装： 1cnpm install @vue/cli -g 如果你已安装vue-cli3/4，但不是最新版本，可执行以下命令升级： 1cnpm update @vue/cli -g 直接安装vue-cli4 创建vue项目找个喜欢的目录，执行以下命令，创建vue项目： （这里把项目名称定为alistar） 1vue create alistar 会出现以下选项（如果熟悉此步骤可跳过本节内容）：这里建议直接选择default一步搞定，后续有需要插件自己在package.json选配，刚创建项目没必要折腾 1234Vue CLI v3.8.4? Please pick a preset: (Use arrow keys) default (babel, eslint) &gt; Manually select features 选择“Manually select features” (自定义安装)。 1234567891011? Check the features needed for your project: (Press &lt;space&gt; to select, &lt;a&gt; to toggle all, &lt;i&gt; to invert selection)❯◉ Babel ◯ TypeScript ◯ Progressive Web App (PWA) Support ◉ Router ◉ Vuex ◉ CSS Pre-processors ◉ Linter / Formatter ◯ Unit Testing ◯ E2E Testing 这里选择了常用的模块，请根据实际需求进行选择。 12? Use history mode for router? (Requires proper server setup for index fallback in production) (Y/n) n 如果选择了router，这里会询问是否使用history模式。 vue-router 默认使用hash模式（即通过url#hash来跳转页面），使用URL的hash来模拟一个完整的 URL，当URL改变时，页面不会重新加载。 如果使用history，URL就像正常的url，比较好看。但是还需要后台配置支持。 这里我们选择“n”。 123456? Pick a CSS pre-processor (PostCSS, Autoprefixer and CSS Modules are supported by default): (Use arrow keys) Sass/SCSS (with dart-sass) Sass/SCSS (with node-sass) Less ❯ Stylus 选择CSS预处理模块，这里我们使用“Stylus”。 12345? Pick a linter / formatter config: (Use arrow keys) ESLint with error prevention only ESLint + Airbnb config ❯ ESLint + Standard config ESLint + Prettier 选择ESLint代码格式检查工具的配置，选择“ESLint + Standard config”，标准配置。 1234? Pick additional lint features: (Press &lt;space&gt; to select, &lt;a&gt; to toggle all, &lt;i&gt; to invert selection)❯◉ Lint on save ◯ Lint and fix on commit Line on save表示在保存代码的时候，进行格式检查。 Lint and fix on commit表示在git commit的时候自动纠正格式。 这里只选择“Lint on save”。 123? Where do you prefer placing config for Babel, PostCSS, ESLint, etc.? In dedicated config files ❯ In package.json 这里问把 babel, postcss, eslint 这些配置文件放哪？ In dedicated config files 表示独立文件 In package.json 表示放在package.json里 这里选择“In package.json”。 1? Save this as a preset for future projects? (y/N) N 是否为以后的项目保留这些设置？选择“N”。 然后耐心等待项目安装完成。 自动安装electron使用electron-builder安装 进入到项目根目录，执行： 1vue add electron-builder 在安装过程中，很可能会卡在这一步不动了： 1node ./download-chromedriver.js 没关系，我们先强制结束掉。再执行一次vue add electron-builder，然后就可以顺利通过了。 接下来出现配置选项： 1234? Choose Electron Version ^4.0.0&gt; ^5.0.0 ^6.0.0 选择Electron版本为5.0.0 Electron5.0和6.0的语法变化不大 选用5.0是因为node-ffi第三方修改版也只能支持到5.0 然后耐心等待安装完成。出现报错，跟上面安装的一样VueDevtools不翻墙安装不了，不理他，直接用本地方案开搞 1234567891011- Running completion hooks...error: Unexpected console statement (no-console) at src\\background.js:64:3: 62 | await installVueDevtools() 63 | &#125; catch (e) &#123;&gt; 64 | console.error('Vue Devtools failed to install:', e.toString()) | ^ 65 | &#125; 66 | 67 | &#125;1 error found. 安装完成后会自动在src目录下生成background.js并修改了package.json。 安装依赖包在项目根目录执行，安装全部依赖包： 1yarn 如果安装过程中报错：Error: post install error, please remove node_modules before retry!可以忽略，不影响后续使用。 编译并启动APP执行以下命令，开始编译APP，并启动开发环境APP： 1yarn electron:serve 首次启动可能会等待很久，出现以下信息： 12345INFO Launching Electron...Failed to fetch extension, trying 4 more timesFailed to fetch extension, trying 3 more timesFailed to fetch extension, trying 2 more times... 这是因为在请求安装vuejs devtools插件。需要科学上网才能安装成功。如果不能科学上网也没关系，耐心等待5次请求失败后会自动跳过(可以本地安装）。编译成功后，就会出现开发环境的APP了。 配置ESLint代码格式检查工具ESlint可以高效的检查代码格式，让参与项目的所有工程师都能保持统一的代码风格。其检测精度甚至可以精确到是否多一个空格或者少一个空格。代码格式的统一对提高团队的协同开发效率有很大的帮助，特别是对有代码洁癖的工程师。 在项目根目录下创建.eslintrc.js （注意文件名前面有个“.”） 请粘贴以下代码： 123456789101112131415161718192021222324module.exports = &#123; root: true, env: &#123; node: true &#125;, 'extends': [ 'plugin:vue/essential', '@vue/standard' ], rules: &#123; 'no-debugger': process.env.NODE_ENV === 'production' ? 'error' : 'off', // 不检测语句末尾的分号 'semi': ['off', 'always'], // 强制缩进为2个空格 'indent': ['error', 2], // 关闭函数名称跟括号之间的空格检测 'space-before-function-paren': 0, // 忽略大括号内的空格 'object-curly-spacing': 0 &#125;, parserOptions: &#123; parser: 'babel-eslint' &#125;&#125; 这里说明下关于indent缩进的配置，要配合项目根目录下的.editorconfig 12345[*.&#123;js,jsx,ts,tsx,vue&#125;]indent_style = space &lt;--这里定义缩进类型是空格还是tabindent_size = 2 &lt;--这里需要与.eslintrc.js的indent对应trim_trailing_whitespace = trueinsert_final_newline = true .editorconfig 用于IDE自动格式化代码 .eslintrc.js 用于ESlint检测 以上是常用的配置。如果你有更多的配置需求，可参阅： https://cloud.tencent.com/developer/doc/1078 配置vue在项目根目录下创建vue.config.js，粘贴以下代码： 123456789101112131415161718192021const path = require('path');function resolve (dir) &#123; return path.join(__dirname, dir);&#125;module.exports = &#123; publicPath: './', devServer: &#123; // can be overwritten by process.env.HOST host: '0.0.0.0', port: 8080 &#125;, chainWebpack: config =&gt; &#123; config.resolve.alias .set('@', resolve('src')) .set('src', resolve('src')) .set('common', resolve('src/common')) .set('components', resolve('src/components')); &#125;&#125;; devServer 用于设置开发环境的服务，这里表示在本地8080端口启动web服务。 chainWebpack 我们给项目目录起了“别名(alias)”，在代码中，我们可以直接用“别名”访问资源，省去了每次输入完整相对路径的麻烦。 ※注： ◉ 在js代码中可直接使用别名，例如： @/common/js/xxx.js 等价于 src/common/js/xxx.js common/js/xxx.js 等价于 src/common/js/xxx.js ◉ 在css或者html中使用别名，需要在别名前加“~”，例如： @import “~common/stylus/font.styl”; 项目基本设定主进程和渲染进程简介在开始下面的步骤之前，很有必要简单了解下Electron的应用架构。 主进程Electron 运行 package.json 的 main 脚本（background.js）的进程被称为主进程。 在主进程中运行的脚本通过创建web页面来展示用户界面。 一个 Electron 应用总是有且只有一个主进程。 渲染进程由于 Electron 使用了 Chromium 来展示 web 页面，所以 Chromium 的多进程架构也被使用到。 每个 Electron 中的 web 页面运行在它自己的渲染进程中。 在普通的浏览器中，web页面通常在一个沙盒环境中运行，不被允许去接触原生的资源。 然而 Electron 的用户在 Node.js 的 API 支持下可以在页面中和操作系统进行一些底层交互。 主进程与渲染进程的关系主进程使用 BrowserWindow 实例创建页面。 每个 BrowserWindow 实例都在自己的渲染进程里运行页面。 当一个 BrowserWindow 实例被销毁后，相应的渲染进程也会被终止。 主进程管理所有的web页面和它们对应的渲染进程。 每个渲染进程都是独立的，它只关心它所运行的 web 页面。 具体可参阅官方文档： https://electronjs.org/docs/tutorial/application-architecture#main-and-renderer-processes APP窗口大小修改background.js： 123456789 function createWindow () &#123; // Create the browser window. win = new BrowserWindow(&#123;M width: 1200,M height: 620, webPreferences: &#123; nodeIntegration: true &#125; &#125;) 取消跨域限制修改background.js： 12345678910 function createWindow () &#123; // Create the browser window. win = new BrowserWindow(&#123; width: 1200, height: 620, webPreferences: &#123;+ webSecurity: false, nodeIntegration: true &#125; &#125;) 取消菜单栏在我们生成的桌面APP中，我们可以看到默认的菜单栏。 在windows中，菜单栏在APP窗口内的顶部；在macOS中，菜单栏位于电脑屏幕顶部。 为了方便项目将来也能直接生成纯web应用，尽量把APP的全部功能都做到渲染进程里，这里我们取消菜单栏。 由于macOS的特殊性，顶部菜单栏无法删除，所以我们针对macOS特殊处理，把菜单栏只保留“关于”和“退出”。 修改background.js： 123456789101112131415161718192021222324252627282930313233M import &#123; app, protocol, BrowserWindow, Menu &#125; from &apos;electron&apos; ... function createWindow () &#123; ... win.on(&apos;closed&apos;, () =&gt; &#123; win = null &#125;) + createMenu() &#125; + // 设置菜单栏+ function createMenu() &#123;+ // darwin表示macOS，针对macOS的设置+ if (process.platform === &apos;darwin&apos;) &#123;+ const template = [+ &#123;+ label: &apos;App Demo&apos;,+ submenu: [+ &#123;+ role: &apos;about&apos;+ &#125;,+ &#123;+ role: &apos;quit&apos;+ &#125;]+ &#125;]+ let menu = Menu.buildFromTemplate(template)+ Menu.setApplicationMenu(menu)+ &#125; else &#123;+ // windows及linux系统+ Menu.setApplicationMenu(null)+ &#125;+ &#125; macOS菜单栏名称label的“App Demo”会在build版本生效，dev版本会显示“Electron” 更多关于菜单栏设置，请参阅：https://electronjs.org/docs/api/menu 设置APP窗口图标准备windows和macOS两版图标。 windows: app.ico 最小尺寸：256x256 macOS: app.png或app.icns 最小尺寸：512x512 把图标文件放到public/目录下，项目结构如下： 1234567891011121314151617|- /dist_electron （略）|- /public |- app.icns &lt;-- 本教程暂时未使用icns |- app.ico |- app.png |- favicon.ico |- index.html|- /src （略）|- .editorconfig |- .eslintrc.js|- .gitignore|- babel.config.js|- package.json|- package-lock.json|- README.md 可以顺便把favicon.ico也修改一下，但是在桌面版APP上是用不到的。如果以后生成纯web项目才会用到。 修改background.js，让APP窗口应用图标： 1234567891011 function createWindow () &#123; // Create the browser window. win = new BrowserWindow(&#123; width: 1200, height: 620, webPreferences: &#123; nodeIntegration: true &#125;,+ // eslint-disable-next-line no-undef+ icon: `$&#123;__static&#125;/app.ico` &#125;) 这里的${__static}对应的是public目录 现在，Windows系统上可以看到开发环境的APP窗口图标已经生效了。 macOS图标请参照相关章节，并且需要在build后才能生效。 设置APP窗口标题栏名称修改public/index.html: 我们把electron-vue-demo改为App Demo。 1234567 &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0\"&gt; &lt;link rel=\"icon\" href=\"&lt;%= BASE_URL %&gt;favicon.ico\"&gt;M &lt;title&gt;App Demo&lt;/title&gt; &lt;/head&gt; build最终产品这里我们已经集成了electron-builder工具，官方文档可以参阅：https://www.electron.build/ 设置APP及安装包图标在窗口图标章节，我们的图标生效于运行APP的窗口。本小节将生效于最终生成的可执行文件和安装包图标。需要准备的图标文件请回看对应章节。 修改vue.config.js 1234567891011121314 chainWebpack: config =&gt; &#123;...&#125;,+ pluginOptions: &#123;+ electronBuilder: &#123;+ builderOptions: &#123;+ win: &#123;+ icon: './public/app.ico'+ &#125;,+ mac: &#123;+ icon: './public/app.png'+ &#125;+ &#125;+ &#125;+ &#125; ... 运行build后的mac版本，可以看到图标都已生效了。 安装包和可执行文件的截图就不再放出了。 更多详细介绍，可参阅： https://www.electron.build/icons.html 设置APP名称APP名称包括安装包中APP的名称、可执行文件的文件名。 修改vue.config.js: 12345678910111213 pluginOptions: &#123; electronBuilder: &#123; builderOptions: &#123; win: &#123; icon: './public/app.ico' &#125;, mac: &#123; icon: './public/app.png' &#125;,+ productName: 'AppDemo' &#125; &#125; &#125; 打包APP执行以下命令，可以build工程： 1npm run electron:build 最终在dist_electron目录下生成build后的产品。 windows版本目录如下： 123456789/dist_electron|- /bundled （略）|- /win-unpacked &lt;-- 绿色版 （略）|- AppDemo Setup 0.1.0.exe &lt;-- 安装文件|- AppDemo Setup 0.1.0.exe.blockmap|- builder-effective-config.yaml|- index.js 这里其实就win-unpacked和AppDemo Setup 0.1.0.exe有用。 ※注：在32位环境下打包生成的是32位APP，在64位环境下打包生成的是64位APP。 mac版本12345678910/dist_electron|- /bundled （略）|- /mac |- AppDemo &lt;-- 绿色版|- AppDemo-0.1.0-mac.zip &lt;-- 绿色版压缩包|- AppDemo-0.1.0-mac.dmg &lt;-- 安装包|- AppDemo-0.1.0.dmg.blockmap|- builder-effective-config.yaml|- index.js 可能出现的错误我曾经在Win10 64bit 1809版本上build失败，保存信息中提示： 123Error output:Can't open output fileError - aborting creation process 与此同时，在win7和win10 1803版本build正常。经研究，无果。后来把windows升级到1903版本，问题解决了。应该是vue-cli-plugin-electron-builder插件与系统之间的问题导致。 关于项目开发的一些经验在完成以上章节后，后面基本可以完全按照web方式开发了。这里简单分享下一些小经验。 src目录结构参考1234567891011121314151617181920/src|- /common |- /fonts |- /images |- /js |- api |- libs |- /stylus |- /components |- /base |- /modules |- /moduleA |- /moduleB ... |- /views |- App.vue |- background.js |- main.js |- router.js |- store.js 下面对部分重要目录简要说明： 1234567891011common/ - 项目公用库common/fonts/ - 字体文件common/images/ - 公用图片common/js/ - 公用js目录common/js/api/ - 把api按类别封装成函数，并export出去，减少业务逻辑中的重复代码common/js/lib/ - 存放一些公用函数库、定义的常量库等common/stylus/ - Stylus样式文件components/ - vue组件目录component/base/ - vue基础组件，例如自定义的CheckBox、日期选择器、Dialog、Toaster、分页组件等component/modules/ - vue模块views/ - vue页面 换肤功能的实现很多项目都有实时换肤的需求，在实际开发中，虽然我们使用了Sass、Less、Stylus等高端样式工具，但最终经过编译还是要回归到最原始的CSS。换肤的本质还是实时替换皮肤样式文件。 失败案例以Stylus为例，抽象出皮肤文件skin.styl: 12$color-bg = #fff$color-text = #333 在业务样式中引用： 12345@import 'skin.styl'body background: $color-bg color: $color-text 当经过编译后，生成的css为： 1body &#123;background: #fff; color: #333;&#125; 样式已经写死了，无法换肤。 那么应该怎么做呢？ 成功案例项目根目录下的public目录是静态目录，也就是说在build最终产品的时候，它里面的文件将原封不动保留。所以，可以将皮肤文件放在这里。 1234567891011|- /public+ |- /skin+ |- /skin01+ |- skin.css+ |- /skin02+ |- skin.css |- app.icns |- app.ico |- app.png |- favicon.ico |- index.html 由于Electron的是基于chromium内核，所以不用担心代码的浏览器兼容问题。接下来就是发挥CSS3变量var(–*)的时候了。 public/skin/skin01/skin.css： 1234:root &#123; --color-bg: #fff; --color-text: #333;&#125; public/skin/skin02/skin.css： 1234:root &#123; --color-bg: #263238; --color-text: #b2ccd6;&#125; 修改src/App.vue： 1234567891011121314151617181920 ... &lt;style lang=\"stylus\"&gt;+ body+ background: var(--color-bg)+ color: var(--color-text) #app font-family 'Avenir', Helvetica, Arial, sans-serif -webkit-font-smoothing antialiased -moz-osx-font-smoothing grayscale text-align centerM color: var(--color-text) #nav padding 30px a font-weight boldM color: var(--color-text) &amp;.router-link-exact-active color #42b983 &lt;/style&gt; 在public/index.html引入皮肤样式，注意加上id=”app-skin”： 12345678 &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0\"&gt; &lt;link rel=\"icon\" href=\"&lt;%= BASE_URL %&gt;favicon.ico\"&gt;+ &lt;link rel=\"stylesheet\" href=\"&lt;%= BASE_URL %&gt;skin/skin01/skin.css\" id=\"app-skin\"&gt; &lt;title&gt;App Demo&lt;/title&gt; &lt;/head&gt; 篇幅有限，这里就不写通过js修改皮肤的代码了。通过调试工具手动修改skin的css路径，可看到换肤效果 从Electron4.x升级到5.x如果你之前用的是Electron4.x，升级到5.x很简单。 修改package.json中electron的版本(写作本文时是5.0.6)： 123 ...M \"electron\": \"^5.0.6\", ... 修改background.js中的这部分： 1234567891011// Scheme must be registered before the app is ready// Electron 4.x代码// protocol.registerStandardSchemes(['app'], &#123;secure: true&#125;)// Electron 5.x代码protocol.registerSchemesAsPrivileged([&#123; scheme: 'app', privileges: &#123; secure: true, standard: true &#125;&#125;]) 然后执行，等待升级安装完成： 1yarn","categories":[{"name":"vue","slug":"vue","permalink":"https://vincentruan.github.io/categories/vue/"}],"tags":[{"name":"electron","slug":"electron","permalink":"https://vincentruan.github.io/tags/electron/"},{"name":"vue","slug":"vue","permalink":"https://vincentruan.github.io/tags/vue/"},{"name":"nodejs","slug":"nodejs","permalink":"https://vincentruan.github.io/tags/nodejs/"}]},{"title":"JVM 性能调优监控工具 jps、jstack、jmap、jhat、jstat、hprof 使用详解","slug":"JVM-性能调优监控工具-jps、jstack、jmap、jhat、jstat、hprof-使用详解","date":"2020-01-27T04:51:30.000Z","updated":"2020-02-24T06:46:36.634Z","comments":true,"path":"2020/01/27/JVM-性能调优监控工具-jps、jstack、jmap、jhat、jstat、hprof-使用详解/","link":"","permalink":"https://vincentruan.github.io/2020/01/27/JVM-性能调优监控工具-jps、jstack、jmap、jhat、jstat、hprof-使用详解/","excerpt":"","text":"Java应用开发、维护中，有时候我们会碰到下面这些问题： OutOfMemoryError，内存不足 内存泄露 线程死锁 锁争用（Lock Contention） Java进程消耗CPU过高 …… 这些问题在日常开发、维护中可能被很多人忽视（比如有的人遇到上面的问题只是重启服务器或者调大内存，而不会深究问题根源），但能够理解并解决这些问题是Java程序员进阶的必备要求。本文将对一些常用的JVM性能调优监控工具进行介绍，希望能起抛砖引玉之用。 一、jps(Java Virtual Machine Process Status Tool) ： 基础工具jps主要用来输出JVM中运行的进程状态信息。语法格式如下： 1jps [options] [hostid] 如果不指定hostid就默认为当前主机或服务器。 命令行参数选项说明如下： 1234567-q 不输出类名、Jar名和传入main方法的参数-m 输出传入main方法的参数-l 输出main类或Jar的全限名-v 输出传入JVM的参数 比如下面：12345678root@ubuntu:/# jps -m -l2458 org.artifactory.standalone.main.Main /usr/local/artifactory-2.2.5/etc/jetty.xml29920 com.sun.tools.hat.Main -port 9998 /tmp/dump.dat3149 org.apache.catalina.startup.Bootstrap start30972 sun.tools.jps.Jps -m -l8247 org.apache.catalina.startup.Bootstrap start25687 com.sun.tools.hat.Main -port 9999 dump.dat21711 mrf-center.jar 二、 jstackjstack主要用来查看某个Java进程内的线程堆栈信息。语法格式如下：123jstack [option] pidjstack [option] executable corejstack [option] [server-id@]remote-hostname-or-ip 命令行参数选项说明如下：1-l long listings，会打印出额外的锁信息，在发生死锁时可以用jstack -l pid来观察锁持有情况-m mixed mode，不仅会输出Java堆栈信息，还会输出C/C++堆栈信息（比如Native方法） jstack可以定位到线程堆栈，根据堆栈信息我们可以定位到具体代码，所以它在JVM性能调优中使用得非常多。下面我们来一个实例找出某个Java进程中最耗费CPU的Java线程并定位堆栈信息，用到的命令有ps、top、printf、jstack、grep。第一步先找出Java进程ID，我部署在服务器上的Java应用名称为mrf-center： 12root@ubuntu:/# ps -ef | grep mrf-center | grep -v greproot 21711 1 1 14:47 pts/3 00:02:10 java -jar mrf-center.jar 得到进程ID为21711，第二步找出该进程内最耗费CPU的线程，可以使用ps -Lfp pid或者ps -mp pid -o THREAD, tid, time或者top -Hp pid，我这里用第三个，输出如下： TIME列就是各个Java线程耗费的CPU时间，CPU时间最长的是线程ID为21742的线程，用 1printf \"%x\" 21742 得到21742的十六进制值为54ee，下面会用到。OK，下一步终于轮到jstack上场了，它用来输出进程21711的堆栈信息，然后根据线程ID的十六进制值grep，如下：12root@ubuntu:/# jstack 21711 | grep 54ee\"PollIntervalRetrySchedulerThread\" prio=10 tid=0x00007f950043e000 nid=0x54ee in Object.wait() [0x00007f94c6eda000] 可以看到CPU消耗在PollIntervalRetrySchedulerThread这个类的Object.wait()，我找了下我的代码，定位到下面的代码：12345678910111213// Idle waitgetLog().info(\"Thread [\" + getName() + \"] is idle waiting...\");schedulerThreadState = PollTaskSchedulerThreadState.IdleWaiting;long now = System.currentTimeMillis();long waitTime = now + getIdleWaitTime();long timeUntilContinue = waitTime - now;synchronized(sigLock) &#123;try &#123; if(!halted.get()) &#123; sigLock.wait(timeUntilContinue); &#125; &#125; catch (InterruptedException ignore) &#123; &#125;&#125; 它是轮询任务的空闲等待代码，上面的sigLock.wait(timeUntilContinue)就对应了前面的Object.wait()。 三、jmap（Memory Map）和 jhat（Java Heap Analysis Tool）jmap导出堆内存，生产上使用曾经导致过进程hang住的情况(JDK1.7)，分析可能存在侵入内存区间读取时，有一定概率造成影响，建议如果机器有重要任务在运行或者不能立刻重启的进程谨慎使用！然后使用jhat来进行分析jmap语法格式如下：123jmap [option] pidjmap [option] executable corejmap [option] [server-id@]remote-hostname-or-ip 如果运行在64位JVM上，可能需要指定-J-d64命令选项参数。1jmap -permstat pid 打印进程的类加载器和类加载器加载的持久代对象信息，输出：类加载器名称、对象是否存活（不可靠）、对象地址、父类加载器、已加载的类大小等信息，如下图： 使用jmap -heap pid查看进程堆内存使用情况，包括使用的GC算法、堆配置参数和各代中堆内存使用情况。比如下面的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849root@ubuntu:/# jmap -heap 21711Attaching to process ID 21711, please wait...Debugger attached successfully.Server compiler detected.JVM version is 20.10-b01using thread-local object allocation.Parallel GC with 4 thread(s)Heap Configuration:MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 2067791872 (1972.0MB)NewSize = 1310720 (1.25MB)MaxNewSize = 17592186044415 MBOldSize = 5439488 (5.1875MB)NewRatio = 2 SurvivorRatio = 8 PermSize = 21757952 (20.75MB)MaxPermSize = 85983232 (82.0MB)Heap Usage:PS Young GenerationEden Space: capacity = 6422528 (6.125MB) used = 5445552 (5.1932830810546875MB) free = 976976 (0.9317169189453125MB) 84.78829520089286% usedFrom Space: capacity = 131072 (0.125MB) used = 98304 (0.09375MB) free = 32768 (0.03125MB) 75.0% usedTo Space: capacity = 131072 (0.125MB) used = 0 (0.0MB) free = 131072 (0.125MB) 0.0% usedPS Old Generation capacity = 35258368 (33.625MB) used = 4119544 (3.9287033081054688MB) free = 31138824 (29.69629669189453MB) 11.683876009235595% usedPS Perm Generation capacity = 52428800 (50.0MB) used = 26075168 (24.867218017578125MB) free = 26353632 (25.132781982421875MB) 49.73443603515625% used .... 使用jmap -histo[:live] pid查看堆内存中的对象数目、大小统计直方图，如果带上live则只统计活对象，如下：1234567891011121314151617181920212223242526272829303132333435root@ubuntu:/# jmap -histo:live 21711 | more num #instances #bytes class name---------------------------------------------- 1: 38445 5597736 &lt;constMethodKlass&gt; 2: 38445 5237288 &lt;methodKlass&gt; 3: 3500 3749504 &lt;constantPoolKlass&gt; 4: 60858 3242600 &lt;symbolKlass&gt; 5: 3500 2715264 &lt;instanceKlassKlass&gt; 6: 2796 2131424 &lt;constantPoolCacheKlass&gt; 7: 5543 1317400 [I 8: 13714 1010768 [C 9: 4752 1003344 [B 10: 1225 639656 &lt;methodDataKlass&gt; 11: 14194 454208 java.lang.String 12: 3809 396136 java.lang.Class 13: 4979 311952 [S 14: 5598 287064 [[I 15: 3028 266464 java.lang.reflect.Method 16: 280 163520 &lt;objArrayKlassKlass&gt; 17: 4355 139360 java.util.HashMap$Entry 18: 1869 138568 [Ljava.util.HashMap$Entry; 19: 2443 97720 java.util.LinkedHashMap$Entry 20: 2072 82880 java.lang.ref.SoftReference 21: 1807 71528 [Ljava.lang.Object; 22: 2206 70592 java.lang.ref.WeakReference 23: 934 52304 java.util.LinkedHashMap 24: 871 48776 java.beans.MethodDescriptor 25: 1442 46144 java.util.concurrent.ConcurrentHashMap$HashEntry 26: 804 38592 java.util.HashMap 27: 948 37920 java.util.concurrent.ConcurrentHashMap$Segment 28: 1621 35696 [Ljava.lang.Class; 29: 1313 34880 [Ljava.lang.String; 30: 1396 33504 java.util.LinkedList$Entry 31: 462 33264 java.lang.reflect.Field 32: 1024 32768 java.util.Hashtable$Entry 33: 948 31440 [Ljava.util.concurrent.ConcurrentHashMap$HashEntry; class name是对象类型，说明如下：123456789B byteC charD doubleF floatI intJ longZ boolean[ 数组，如[I表示int[][L+类名 其他对象 还有一个很常用的情况是：用jmap把进程内存使用情况dump到文件中，再用jhat分析查看。jmap进行dump命令格式如下：1jmap -dump:format=b,file=dumpFileName pid 我一样地对上面进程ID为21711进行Dump：123root@ubuntu:/# jmap -dump:format=b,file=/tmp/dump.dat 21711 Dumping heap to /tmp/dump.dat ...Heap dump file created dump出来的文件可以用MAT、VisualVM等工具查看，这里用jhat查看：12345678root@ubuntu:/# jhat -port 9998 /tmp/dump.datReading from /tmp/dump.dat...Dump file created Tue Jan 28 17:46:14 CST 2014Snapshot read, resolving...Resolving 132207 objects...Chasing references, expect 26 dots..........................Eliminating duplicate references..........................Snapshot resolved.Started HTTP server on port 9998Server is ready. 注意如果Dump文件太大，可能需要加上-J-Xmx512m这种参数指定最大堆内存，即jhat -J-Xmx512m -port 9998 /tmp/dump.dat。然后就可以在浏览器中输入主机地址:9998查看了： 上面红线框出来的部分大家可以自己去摸索下，最后一项支持OQL（Object Query Language对象查询语言）。 四、jstat（JVM统计监测工具）看看各个区内存和GC的情况语法格式如下：1jstat [ generalOption | outputOptions vmid [interval[s|ms] [count]] ] vmid是Java虚拟机ID，在Linux/Unix系统上一般就是进程ID。interval是采样时间间隔。count是采样数目。比如下面输出的是GC信息，采样时间间隔为250ms，采样数为4：123456root@ubuntu:/# jstat -gc 21711 250 4 S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT 192.0 192.0 64.0 0.0 6144.0 1854.9 32000.0 4111.6 55296.0 25472.7 702 0.431 3 0.218 0.649192.0 192.0 64.0 0.0 6144.0 1972.2 32000.0 4111.6 55296.0 25472.7 702 0.431 3 0.218 0.649192.0 192.0 64.0 0.0 6144.0 1972.2 32000.0 4111.6 55296.0 25472.7 702 0.431 3 0.218 0.649192.0 192.0 64.0 0.0 6144.0 2109.7 32000.0 4111.6 55296.0 25472.7 702 0.431 3 0.218 0.649 要明白上面各列的意义，先看JVM堆内存布局： 可以看出： 12堆内存 = 年轻代 + 年老代 + 永久代年轻代 = Eden区 + 两个Survivor区（From和To） 现在来解释各列含义： 1234567S0C、S1C、S0U、S1U：Survivor 0/1区容量（Capacity）和使用量（Used）EC、EU：Eden区容量和使用量OC、OU：年老代容量和使用量PC、PU：永久代容量和使用量YGC、YGT：年轻代GC次数和GC耗时FGC、FGCT：Full GC次数和Full GC耗时GCT：GC总耗时 五、hprof（Heap/CPU Profiling Tool）hprof能够展现CPU使用率，统计堆内存使用情况。语法格式如下：123java -agentlib:hprof[=options] ToBeProfiledClassjava -Xrunprof[:options] ToBeProfiledClassjavac -J-agentlib:hprof[=options] ToBeProfiledClass 完整的命令选项如下： 1234567891011121314151617Option Name and Value Description Default--------------------- ----------- -------heap=dump|sites|all heap profiling allcpu=samples|times|old CPU usage offmonitor=y|n monitor contention nformat=a|b text(txt) or binary output afile=&lt;file&gt; write data to file java.hprof[.txt]net=&lt;host&gt;:&lt;port&gt; send data over a socket offdepth=&lt;size&gt; stack trace depth 4interval=&lt;ms&gt; sample interval in ms 10cutoff=&lt;value&gt; output cutoff point 0.0001lineno=y|n line number in traces? ythread=y|n thread in traces? ndoe=y|n dump on exit? ymsa=y|n Solaris micro state accounting nforce=y|n force output to &lt;file&gt; yverbose=y|n print messages about dumps y 来几个官方指南上的实例。CPU Usage Sampling Profiling(cpu=samples)的例子：1java -agentlib:hprof=cpu=samples,interval=20,depth=3 Hello 上面每隔20毫秒采样CPU消耗信息，堆栈深度为3，生成的profile文件名称是java.hprof.txt，在当前目录。 CPU Usage Times Profiling(cpu=times)的例子，它相对于CPU Usage Sampling Profile能够获得更加细粒度的CPU消耗信息，能够细到每个方法调用的开始和结束，它的实现使用了字节码注入技术（BCI）： 1javac -J-agentlib:hprof=cpu=times Hello.java Heap Allocation Profiling(heap=sites)的例子：1javac -J-agentlib:hprof=heap=sites Hello.java Heap Dump(heap=dump)的例子，它比上面的Heap Allocation Profiling能生成更详细的Heap Dump信息：1javac -J-agentlib:hprof=heap=dump Hello.java 虽然在JVM启动参数中加入-Xrunprof:heap=sites参数可以生成CPU/Heap Profile文件，但对JVM性能影响非常大，不建议在线上服务器环境使用。","categories":[{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/categories/Java/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/tags/Linux/"},{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://vincentruan.github.io/tags/JVM/"}]},{"title":"Linux命令 - netstat","slug":"Linux命令-netstat","date":"2020-01-27T04:44:15.000Z","updated":"2020-02-17T02:40:44.655Z","comments":true,"path":"2020/01/27/Linux命令-netstat/","link":"","permalink":"https://vincentruan.github.io/2020/01/27/Linux命令-netstat/","excerpt":"","text":"概述netstat 是一个告诉我们系统中所有 tcp/udp/unix socket 连接状态的命令行工具。它会列出所有已经连接或者等待连接状态的连接。 该工具在识别某个应用监听哪个端口时特别有用，我们也能用它来判断某个应用是否正常的在监听某个端口。 netstat 命令还能显示其它各种各样的网络相关信息，例如路由表， 网卡统计信息， 虚假连接以及多播成员等。 1 - 检查所有的连接使用 a 选项可以列出系统中的所有连接， 1$ netstat -a 这会显示系统所有的 tcp、udp 以及 unix 连接。 2 - 检查所有的 tcp/udp/unix socket 连接使用 t 选项只列出 tcp 连接， 1$ netstat -at 类似的，使用 u 选项只列出 udp 连接， 1$ netstat -au 使用 x 选项只列出 Unix socket 连接， 1$ netstat -ax 3 - 同时列出进程 ID/进程名称使用 p 选项可以在列出连接的同时也显示 PID 或者进程名称，而且它还能与其他选项连用， 1$ netstat -ap 4 - 列出端口号而不是服务名使用 n 选项可以加快输出，它不会执行任何反向查询（LCTT 译注：这里原文有误），而是直接输出数字。 由于无需查询，因此结果输出会快很多。 1$ netstat -an 5 - 只输出监听端口使用 l 选项只输出监听端口。它不能与 a 选项连用，因为 a 会输出所有端口， 1$ netstat -l 6 - 输出网络状态使用 s 选项输出每个协议的统计信息，包括接收/发送的包数量， 1$ netstat -s 7 - 输出网卡状态使用 I 选项只显示网卡的统计信息， 1$ netstat -i 8 - 显示多播组multicast group信息使用 g 选项输出 IPV4 以及 IPV6 的多播组信息， 1$ netstat -g 9 - 显示网络路由信息使用 r 输出网络路由信息， 1$ netstat -r 10 - 持续输出使用 c 选项持续输出结果 1$ netstat -c 11 - 过滤出某个端口与 grep 连用来过滤出某个端口的连接， 1$ netstat -anp | grep 3306 12 - 统计连接个数通过与 wc 和 grep 命令连用，可以统计指定端口的连接数量 1$ netstat -anp | grep 3306 | wc -l 这会输出 mysql 服务端口（即 3306端口）的连接数。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/tags/Linux/"},{"name":"netstat","slug":"netstat","permalink":"https://vincentruan.github.io/tags/netstat/"}]},{"title":"memcached与redis实现的对比","slug":"memcached与redis实现的对比","date":"2019-12-29T07:03:32.000Z","updated":"2020-02-17T02:40:44.790Z","comments":true,"path":"2019/12/29/memcached与redis实现的对比/","link":"","permalink":"https://vincentruan.github.io/2019/12/29/memcached与redis实现的对比/","excerpt":"","text":"memcached和redis，作为近些年最常用的缓存服务器，相信大家对它们再熟悉不过了。前两年还在学校时，我曾经读过它们的主要源码，如今写篇笔记从个人角度简单对比一下它们的实现方式，权当做复习，有理解错误之处，欢迎指正。 文中使用的架构类的图片大多来自于网络，有部分图与最新实现有出入，文中已经指出。 1. 综述 读一个软件的源码，首先要弄懂软件是用作干什么的，那memcached和redis是干啥的？众所周知，数据一般会放在数据库中，但是查询数据会相对比较慢，特别是用户很多时，频繁的查询，需要耗费大量的时间。怎么办呢？数据放在哪里查询快？那肯定是内存中。memcached和redis就是将数据存储在内存中，按照key-value的方式查询，可以大幅度提高效率。所以一般它们都用做缓存服务器，缓存常用的数据，需要查询的时候，直接从它们那儿获取，减少查询数据库的次数，提高查询效率。 2. 服务方式memcached和redis怎么提供服务呢？它们是独立的进程，需要的话，还可以让他们变成daemon进程，所以我们的用户进程要使用memcached和redis的服务的话，就需要进程间通信了。考虑到用户进程和memcached和redis不一定在同一台机器上，所以还需要支持网络间通信。因此，memcached和redis自己本身就是网络服务器，用户进程通过与他们通过网络来传输数据，显然最简单和最常用的就是使用tcp连接了。另外，memcached和redis都支持udp协议。而且当用户进程和memcached和redis在同一机器时，还可以使用unix域套接字通信。 3. 事件模型下面开始讲他们具体是怎么实现的了。首先来看一下它们的事件模型。 自从epoll出来以后，几乎所有的网络服务器全都抛弃select和poll，换成了epoll。redis也一样，只不多它还提供对select和poll的支持，可以自己配置使用哪一个，但是一般都是用epoll。另外针对BSD，还支持使用kqueue。而memcached是基于libevent的，不过libevent底层也是使用epoll的，所以可以认为它们都是使用epoll。epoll的特性这里就不介绍了，网上介绍文章很多。 它们都使用epoll来做事件循环，不过redis是单线程的服务器（redis也是多线程的，只不过除了主线程以外，其他线程没有event loop，只是会进行一些后台存储工作），而memcached是多线程的。 redis的事件模型很简单，只有一个event loop，是简单的reactor实现。不过redis事件模型中有一个亮点，我们知道epoll是针对fd的，它返回的就绪事件也是只有fd，redis里面的fd就是服务器与客户端连接的socket的fd，但是处理的时候，需要根据这个fd找到具体的客户端的信息，怎么找呢？通常的处理方式就是用红黑树将fd与客户端信息保存起来，通过fd查找，效率是lgn。不过redis比较特殊，redis的客户端的数量上限可以设置，即可以知道同一时刻，redis所打开的fd的上限，而我们知道，进程的fd在同一时刻是不会重复的（fd只有关闭后才能复用），所以redis使用一个数组，将fd作为数组的下标，数组的元素就是客户端的信息，这样，直接通过fd就能定位客户端信息，查找效率是O(1)，还省去了复杂的红黑树的实现（我曾经用c写一个网络服务器，就因为要保持fd和connect对应关系，不想自己写红黑树，然后用了STL里面的set，导致项目变成了c++的，最后项目使用g++编译，这事我不说谁知道？）。显然这种方式只能针对connection数量上限已确定，并且不是太大的网络服务器，像nginx这种http服务器就不适用，nginx就是自己写了红黑树。 而memcached是多线程的，使用master-worker的方式，主线程监听端口，建立连接，然后顺序分配给各个工作线程。每一个从线程都有一个event loop，它们服务不同的客户端。master线程和worker线程之间使用管道通信，每一个工作线程都会创建一个管道，然后保存写端和读端，并且将读端加入event loop，监听可读事件。同时，每个从线程都有一个就绪连接队列，主线程连接连接后，将连接的item放入这个队列，然后往该线程的管道的写端写入一个connect命令，这样event loop中加入的管道读端就会就绪，从线程读取命令，解析命令发现是有连接，然后就会去自己的就绪队列中获取连接，并进行处理。多线程的优势就是可以充分发挥多核的优势，不过编写程序麻烦一点，memcached里面就有各种锁和条件变量来进行线程同步。 4. 内存分配memcached和redis的核心任务都是在内存中操作数据，内存管理自然是核心的内容。首先看看他们的内存分配方式。memcached是有自己得内存池的，即预先分配一大块内存，然后接下来分配内存就从内存池中分配，这样可以减少内存分配的次数，提高效率，这也是大部分网络服务器的实现方式，只不过各个内存池的管理方式根据具体情况而不同。而redis没有自己得内存池，而是直接使用时分配，即什么时候需要什么时候分配，内存管理的事交给内核，自己只负责取和释放（redis既是单线程，又没有自己的内存池，是不是感觉实现的太简单了？那是因为它的重点都放在数据库模块了）。不过redis支持使用tcmalloc来替换glibc的malloc，前者是google的产品，比glibc的malloc快。 由于redis没有自己的内存池，所以内存申请和释放的管理就简单很多，直接malloc和free即可，十分方便。而memcached是支持内存池的，所以内存申请是从内存池中获取，而free也是还给内存池，所以需要很多额外的管理操作，实现起来麻烦很多，具体的会在后面memcached的slab机制讲解中分析。 5. 数据库实现接下来看看他们的最核心内容，各自数据库的实现。 5.1 memcached数据库实现memcached只支持key-value，即只能一个key对于一个value。它的数据在内存中也是这样以key-value对的方式存储，它使用slab机制。 首先看memcached是如何存储数据的，即存储key-value对。如下图，每一个key-value对都存储在一个item结构中，包含了相关的属性和key和value的值。 item是保存key-value对的，当item多的时候，怎么查找特定的item是个问题。所以memcached维护了一个hash表，它用于快速查找item。hash表适用开链法（与redis一样）解决键的冲突，每一个hash表的桶里面存储了一个链表，链表节点就是item的指针，如上图中的h_next就是指桶里面的链表的下一个节点。 hash表支持扩容（item的数量是桶的数量的1.5以上时扩容），有一个primary_hashtable，还有一个old_hashtable，其中正常适用primary_hashtable，但是扩容的时候，将old_hashtable = primary_hashtable，然后primary_hashtable设置为新申请的hash表（桶的数量乘以2），然后依次将old_hashtable 里面的数据往新的hash表里面移动，并用一个变量expand_bucket记录以及移动了多少个桶，移动完成后，再free原来的old_hashtable 即可（redis也是有两个hash表，也是移动，不过不是后台线程完成，而是每次移动一个桶）。扩容的操作，专门有一个后台扩容的线程来完成，需要扩容的时候，使用条件变量通知它，完成扩容后，它又考试阻塞等待扩容的条件变量。这样在扩容的时候，查找一个item可能会在primary_hashtable和old_hashtable的任意一个中，需要根据比较它的桶的位置和expand_bucket的大小来比较确定它在哪个表里。 item是从哪里分配的呢？从slab中。如下图，memcached有很多slabclass，它们管理slab，每一个slab其实是trunk的集合，真正的item是在trunk中分配的，一个trunk分配一个item。一个slab中的trunk的大小一样，不同的slab，trunk的大小按比例递增，需要新申请一个item的时候，根据它的大小来选择trunk，规则是比它大的最小的那个trunk。这样，不同大小的item就分配在不同的slab中，归不同的slabclass管理。 这样的缺点是会有部分内存浪费，因为一个trunk可能比item大，如图2，分配100B的item的时候，选择112的trunk，但是会有12B的浪费，这部分内存资源没有使用。 如上图，整个构造就是这样，slabclass管理slab，一个slabclass有一个slab_list，可以管理多个slab，同一个slabclass中的slab的trunk大小都一样。slabclass有一个指针slot，保存了未分配的item已经被free掉的item（不是真的free内存，只是不用了而已），有item不用的时候，就放入slot的头部，这样每次需要在当前slab中分配item的时候，直接取slot取即可，不用管item是未分配过的还是被释放掉的。 然后，每一个slabclass对应一个链表，有head数组和tail数组，它们分别保存了链表的头节点和尾节点。链表中的节点就是改slabclass所分配的item，新分配的放在头部，链表越往后的item，表示它已经很久没有被使用了。当slabclass的内存不足，需要删除一些过期item的时候，就可以从链表的尾部开始删除，没错，这个链表就是为了实现LRU。光靠它还不行，因为链表的查询是O（n）的，所以定位item的时候，使用hash表，这已经有了，所有分配的item已经在hash表中了，所以，hash用于查找item，然后链表有用存储item的最近使用顺序，这也是lru的标准实现方法。 每次需要新分配item的时候，找到slabclass对于的链表，从尾部往前找，看item是否已经过期，过期的话，直接就用这个过期的item当做新的item。没有过期的，则需要从slab中分配trunk，如果slab用完了，则需要往slabclass中添加slab了。 memcached支持设置过期时间，即expire time，但是内部并不定期检查数据是否过期，而是客户进程使用该数据的时候，memcached会检查expire time，如果过期，直接返回错误。这样的优点是，不需要额外的cpu来进行expire time的检查，缺点是有可能过期数据很久不被使用，则一直没有被释放，占用内存。 memcached是多线程的，而且只维护了一个数据库，所以可能有多个客户进程操作同一个数据，这就有可能产生问题。比如，A已经把数据更改了，然后B也更改了改数据，那么A的操作就被覆盖了，而可能A不知道，A任务数据现在的状态时他改完后的那个值，这样就可能产生问题。为了解决这个问题，memcached使用了CAS协议，简单说就是item保存一个64位的unsigned int值，标记数据的版本，每更新一次（数据值有修改），版本号增加，然后每次对数据进行更改操作，需要比对客户进程传来的版本号和服务器这边item的版本号是否一致，一致则可进行更改操作，否则提示脏数据。 以上就是memcached如何实现一个key-value的数据库的介绍。 5.2 redis数据库实现首先redis数据库的功能强大一些，因为不像memcached只支持保存字符串，redis支持string， list， set，sorted set，hash table 5种数据结构。例如存储一个人的信息就可以使用hash table，用人的名字做key，然后name super， age 24， 通过key 和 name，就可以取到名字super，或者通过key和age，就可以取到年龄24。这样，当只需要取得age的时候，不需要把人的整个信息取回来，然后从里面找age，直接获取age即可，高效方便。 为了实现这些数据结构，redis定义了抽象的对象redis object，如下图。每一个对象有类型，一共5种：字符串，链表，集合，有序集合，哈希表。 同时，为了提高效率，redis为每种类型准备了多种实现方式，根据特定的场景来选择合适的实现方式，encoding就是表示对象的实现方式的。然后还有记录了对象的lru，即上次被访问的时间，同时在redis 服务器中会记录一个当前的时间（近似值，因为这个时间只是每隔一定时间，服务器进行自动维护的时候才更新），它们两个只差就可以计算出对象多久没有被访问了。 然后redis object中还有引用计数，这是为了共享对象，然后确定对象的删除时间用的。最后使用一个void*指针来指向对象的真正内容。正式由于使用了抽象redis object，使得数据库操作数据时方便很多，全部统一使用redis object对象即可，需要区分对象类型的时候，再根据type来判断。而且正式由于采用了这种面向对象的方法，让redis的代码看起来很像c++代码，其实全是用c写的。 1234567891011121314151617181920212223242526//#define REDIS_STRING 0 // 字符串类型//#define REDIS_LIST 1 // 链表类型//#define REDIS_SET 2 // 集合类型(无序的)，可以求差集，并集等//#define REDIS_ZSET 3 // 有序的集合类型//#define REDIS_HASH 4 // 哈希类型//#define REDIS_ENCODING_RAW 0 /* Raw representation */ //raw 未加工//#define REDIS_ENCODING_INT 1 /* Encoded as integer *///#define REDIS_ENCODING_HT 2 /* Encoded as hash table *///#define REDIS_ENCODING_ZIPMAP 3 /* Encoded as zipmap *///#define REDIS_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list *///#define REDIS_ENCODING_ZIPLIST 5 /* Encoded as ziplist *///#define REDIS_ENCODING_INTSET 6 /* Encoded as intset *///#define REDIS_ENCODING_SKIPLIST 7 /* Encoded as skiplist *///#define REDIS_ENCODING_EMBSTR 8 /* Embedded sds string encoding */typedef struct redisObject &#123; unsigned type:4; // 对象的类型，包括 /* Object types */unsigned encoding:4; // 底部为了节省空间，一种type的数据， // 可以采用不同的存储方式unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */int refcount; // 引用计数void *ptr;&#125; robj; 说到底redis还是一个key-value的数据库，不管它支持多少种数据结构，最终存储的还是以key-value的方式，只不过value可以是链表，set，sorted set，hash table等。和memcached一样，所有的key都是string，而set，sorted set，hash table等具体存储的时候也用到了string。 而c没有现成的string，所以redis的首要任务就是实现一个string，取名叫sds（simple dynamic string），如下的代码， 非常简单的一个结构体，len存储改string的内存总长度，free表示还有多少字节没有使用，而buf存储具体的数据，显然len-free就是目前字符串的长度。 12345struct sdshdr &#123; int len; int free; char buf[];&#125;; 字符串解决了，所有的key都存成sds就行了，那么key和value怎么关联呢？key-value的格式在脚本语言中很好处理，直接使用字典即可，C没有字典，怎么办呢？自己写一个呗（redis十分热衷于造轮子）。看下面的代码，privdata存额外信息，用的很少，至少我们发现。 dictht是具体的哈希表，一个dict对应两张哈希表，这是为了扩容（包括rehashidx也是为了扩容）。dictType存储了哈希表的属性。redis还为dict实现了迭代器（所以说看起来像c++代码）。 哈希表的具体实现是和mc类似的做法，也是使用开链法来解决冲突，不过里面用到了一些小技巧。比如使用dictType存储函数指针，可以动态配置桶里面元素的操作方法。又比如dictht中保存的sizemask取size（桶的数量）-1，用它与key做&amp;操作来代替取余运算，加快速度等等。总的来看，dict里面有两个哈希表，每个哈希表的桶里面存储dictEntry链表，dictEntry存储具体的key和value。 前面说过，一个dict对于两个dictht，是为了扩容（其实还有缩容）。正常的时候，dict只使用dictht[0]，当dict[0]中已有entry的数量与桶的数量达到一定的比例后，就会触发扩容和缩容操作，我们统称为rehash，这时，为dictht[1]申请rehash后的大小的内存，然后把dictht[0]里的数据往dictht[1]里面移动，并用rehashidx记录当前已经移动万的桶的数量，当所有桶都移完后，rehash完成，这时将dictht[1]变成dictht[0], 将原来的dictht[0]变成dictht[1]，并变为null即可。不同于memcached，这里不用开一个后台线程来做，而是就在event loop中完成，并且rehash不是一次性完成，而是分成多次，每次用户操作dict之前，redis移动一个桶的数据，直到rehash完成。这样就把移动分成多个小移动完成，把rehash的时间开销均分到用户每个操作上，这样避免了用户一个请求导致rehash的时候，需要等待很长时间，直到rehash完成才有返回的情况。不过在rehash期间，每个操作都变慢了点，而且用户还不知道redis在他的请求中间添加了移动数据的操作，感觉redis太贱了 :-D 123456789101112131415161718192021222324252627282930313233typedef struct dict &#123; dictType *type; // 哈希表的相关属性void *privdata; // 额外信息 dictht ht[2]; // 两张哈希表，分主和副，用于扩容int rehashidx; /* rehashing not in progress if rehashidx == -1 */ // 记录当前数据迁移的位置，在扩容的时候用的int iterators; /* number of iterators currently running */ // 目前存在的迭代器的数量&#125; dict;typedef struct dictht &#123; dictEntry **table; // dictEntry是item，多个item组成hash桶里面的链表，table则是多个链表头指针组成的数组的指针unsigned long size; // 这个就是桶的数量 // sizemask取size - 1, 然后一个数据来的时候，通过计算出的hashkey, 让hashkey &amp; sizemask来确定它要放的桶的位置 // 当size取2^n的时候，sizemask就是1...111，这样就和hashkey % size有一样的效果，但是使用&amp;会快很多。这就是原因unsigned long sizemask; unsigned long used; // 已经数值的dictEntry数量&#125; dictht;typedef struct dictType &#123; unsigned int (*hashFunction)(const void *key); // hash的方法void *(*keyDup)(void *privdata, const void *key); // key的复制方法void *(*valDup)(void *privdata, const void *obj); // value的复制方法int (*keyCompare)(void *privdata, const void *key1, const void *key2); // key之间的比较void (*keyDestructor)(void *privdata, void *key); // key的析构void (*valDestructor)(void *privdata, void *obj); // value的析构&#125; dictType;typedef struct dictEntry &#123; void *key; union &#123; void *val; uint64_t u64; int64_t s64; &#125; v; struct dictEntry *next;&#125; dictEntry; 有了dict，数据库就好实现了。所有数据读存储在dict中，key存储成dictEntry中的key（string），用void* 指向一个redis object，它可以是5种类型中的任何一种。如下图，结构构造是这样，不过这个图已经过时了，有一些与redis3.0不符合的地方。 五种type的对象，每一个都至少有两种底层实现方式。string有3种：REDIS_ENCODING_RAW, REDIS_ENCIDING_INT, REDIS_ENCODING_EMBSTR， list有：普通双向链表和压缩链表，压缩链表简单的说，就是讲数组改造成链表，连续的空间，然后通过存储字符串的大小信息来模拟链表，相对普通链表来说可以节省空间，不过有副作用，由于是连续的空间，所以改变内存大小的时候，需要重新分配，并且由于保存了字符串的字节大小，所有有可能引起连续更新（具体实现请详细看代码）。set有dict和intset（全是整数的时候使用它来存储）， sorted set有：skiplist和ziplist， hashtable实现有压缩列表和dict和ziplist。skiplist就是跳表，它有接近于红黑树的效率，但是实现起来比红黑树简单很多，所以被采用（奇怪，这里又不造轮子了，难道因为这个轮子有点难？）。 hash table可以使用dict实现，则改dict中，每个dictentry中key保存了key（这是哈希表中的键值对的key），而value则保存了value，它们都是string。 而set中的dict，每个dictentry中key保存了set中具体的一个元素的值，value则为null。图中的zset（有序集合）有误，zset使用skiplist和ziplist实现，首先skiplist很好理解，就把它当做红黑树的替代品就行，和红黑树一样，它也可以排序。怎么用ziplist存储zset呢？首先在zset中，每个set中的元素都有一个分值score，用它来排序。所以在ziplist中，按照分值大小，先存元素，再存它的score，再存下一个元素，然后score。这样连续存储，所以插入或者删除的时候，都需要重新分配内存。所以当元素超过一定数量，或者某个元素的字符数超过一定数量，redis就会选择使用skiplist来实现zset（如果当前使用的是ziplist，会将这个ziplist中的数据取出，存入一个新的skiplist，然后删除改ziplist，这就是底层实现转换，其余类型的redis object也是可以转换的）。 另外，ziplist如何实现hashtable呢？其实也很简单，就是存储一个key，存储一个value，再存储一个key，再存储一个value。还是顺序存储，与zset实现类似，所以当元素超过一定数量，或者某个元素的字符数超过一定数量时，就会转换成hashtable来实现。各种底层实现方式是可以转换的，redis可以根据情况选择最合适的实现方式，这也是这样使用类似面向对象的实现方式的好处。 需要指出的是，使用skiplist来实现zset的时候，其实还用了一个dict，这个dict存储一样的键值对。为什么呢？因为skiplist的查找只是lgn的（可能变成n），而dict可以到O(1)， 所以使用一个dict来加速查找，由于skiplist和dict可以指向同一个redis object，所以不会浪费太多内存。另外使用ziplist实现zset的时候，为什么不用dict来加速查找呢？因为ziplist支持的元素个数很少（个数多时就转换成skiplist了），顺序遍历也很快，所以不用dict了。 这样看来，上面的dict，dictType，dictHt，dictEntry，redis object都是很有考量的，它们配合实现了一个具有面向对象色彩的灵活、高效数据库。不得不说，redis数据库的设计还是很厉害的。 与memcached不同的是，redis的数据库不止一个，默认就有16个，编号0-15。客户可以选择使用哪一个数据库，默认使用0号数据库。 不同的数据库数据不共享，即在不同的数据库中可以存在同样的key，但是在同一个数据库中，key必须是唯一的。 redis也支持expire time的设置，我们看上面的redis object，里面没有保存expire的字段，那redis怎么记录数据的expire time呢？ redis是为每个数据库又增加了一个dict，这个dict叫expire dict，它里面的dict entry里面的key就是数对的key，而value全是数据为64位int的redis object，这个int就是expire time。这样，判断一个key是否过期的时候，去expire dict里面找到它，取出expire time比对当前时间即可。为什么这样做呢？ 因为并不是所有的key都会设置过期时间，所以，对于不设置expire time的key来说，保存一个expire time会浪费空间，而是用expire dict来单独保存的话，可以根据需要灵活使用内存（检测到key过期时，会把它从expire dict中删除）。 redis的expire 机制是怎样的呢？ 与memcahed类似，redis也是惰性删除，即要用到数据时，先检查key是否过期，过期则删除，然后返回错误。单纯的靠惰性删除，上面说过可能会导致内存浪费，所以redis也有补充方案，redis里面有个定时执行的函数，叫servercron，它是维护服务器的函数，在它里面，会对过期数据进行删除，注意不是全删，而是在一定的时间内，对每个数据库的expire dict里面的数据随机选取出来，如果过期，则删除，否则再选，直到规定的时间到。即随机选取过期的数据删除，这个操作的时间分两种，一种较长，一种较短，一般执行短时间的删除，每隔一定的时间，执行一次长时间的删除。这样可以有效的缓解光采用惰性删除而导致的内存浪费问题。 以上就是redis的数据的实现，与memcached不同，redis还支持数据持久化，这个下面介绍。 5.4 redis数据库持久化redis和memcached的最大不同，就是redis支持数据持久化，这也是很多人选择使用redis而不是memcached的最大原因。 redis的持久化，分为两种策略，用户可以配置使用不同的策略。 5.4.1 RDB持久化用户执行save或者bgsave的时候，就会触发RDB持久化操作。RDB持久化操作的核心思想就是把数据库原封不动的保存在文件里。 那如何存储呢？如下图， 首先存储一个REDIS字符串，起到验证的作用，表示是RDB文件，然后保存redis的版本信息，然后是具体的数据库，然后存储结束符EOF，最后用检验和。关键就是databases，看它的名字也知道，它存储了多个数据库，数据库按照编号顺序存储，0号数据库存储完了，才轮到1，然后是2, 一直到最后一个数据库。 每一个数据库存储方式如下，首先一个1字节的常量SELECTDB，表示切换db了，然后下一个接上数据库的编号，它的长度是可变的，然后接下来就是具体的key-value对的数据了。 1234567891011121314int rdbSaveKeyValuePair(rio *rdb, robj *key, robj *val, long long expiretime, long long now)&#123; /* Save the expire time */if (expiretime != -1) &#123; /* If this key is already expired skip it */if (expiretime &lt; now) return 0; if (rdbSaveType(rdb,REDIS_RDB_OPCODE_EXPIRETIME_MS) == -1) return -1; if (rdbSaveMillisecondTime(rdb,expiretime) == -1) return -1; &#125; /* Save type, key, value */if (rdbSaveObjectType(rdb,val) == -1) return -1; if (rdbSaveStringObject(rdb,key) == -1) return -1; if (rdbSaveObject(rdb,val) == -1) return -1; return 1;&#125; 由上面的代码也可以看出，存储的时候，先检查expire time，如果已经过期，不存就行了，否则，则将expire time存下来，注意，及时是存储expire time，也是先存储它的类型为REDIS_RDB_OPCODE_EXPIRETIME_MS，然后再存储具体过期时间。接下来存储真正的key-value对，首先存储value的类型，然后存储key（它按照字符串存储），然后存储value，如下图。 在rdbsaveobject中，会根据val的不同类型，按照不同的方式存储，不过从根本上来看，最终都是转换成字符串存储，比如val是一个linklist，那么先存储整个list的字节数，然后遍历这个list，把数据取出来，依次按照string写入文件。对于hash table，也是先计算字节数，然后依次取出hash table中的dictEntry，按照string的方式存储它的key和value，然后存储下一个dictEntry。 总之，RDB的存储方式，对一个key-value对，会先存储expire time（如果有的话），然后是value的类型，然后存储key（字符串方式），然后根据value的类型和底层实现方式，将value转换成字符串存储。这里面为了实现数据压缩，以及能够根据文件恢复数据，redis使用了很多编码的技巧，有些我也没太看懂，不过关键还是要理解思想，不要在意这些细节。 保存了RDB文件，当redis再启动的时候，就根据RDB文件来恢复数据库。由于以及在RDB文件中保存了数据库的号码，以及它包含的key-value对，以及每个key-value对中value的具体类型，实现方式，和数据，redis只要顺序读取文件，然后恢复object即可。由于保存了expire time，发现当前的时间已经比expire time大了，即数据已经超时了，则不恢复这个key-value对即可。 保存RDB文件是一个很巨大的工程，所以redis还提供后台保存的机制。即执行bgsave的时候，redis fork出一个子进程，让子进程来执行保存的工作，而父进程继续提供redis正常的数据库服务。由于子进程复制了父进程的地址空间，即子进程拥有父进程fork时的数据库，子进程执行save的操作，把它从父进程那儿继承来的数据库写入一个temp文件即可。在子进程复制期间，redis会记录数据库的修改次数（dirty）。当子进程完成时，发送给父进程SIGUSR1信号，父进程捕捉到这个信号，就知道子进程完成了复制，然后父进程将子进程保存的temp文件改名为真正的rdb文件（即真正保存成功了才改成目标文件，这才是保险的做法）。然后记录下这一次save的结束时间。 这里有一个问题，在子进程保存期间，父进程的数据库已经被修改了，而父进程只是记录了修改的次数（dirty），被没有进行修正操作。似乎使得RDB保存的不是实时的数据库，有点不太高大上的样子。 不过后面要介绍的AOF持久化，就解决了这个问题。 除了客户执行sava或者bgsave命令，还可以配置RDB保存条件。即在配置文件中配置，在t时间内，数据库被修改了dirty次，则进行后台保存。redis在serve cron的时候，会根据dirty数目和上次保存的时间，来判断是否符合条件，符合条件的话，就进行bg save，注意，任意时刻只能有一个子进程来进行后台保存，因为保存是个很费io的操作，多个进程大量io效率不行，而且不好管理。 5.4.2 AOF持久化 首先想一个问题，保存数据库一定需要像RDB那样把数据库里面的所有数据保存下来么？有没有别的方法？ RDB保存的只是最终的数据库，它是一个结果。结果是怎么来的？是通过用户的各个命令建立起来的，所以可以不保存结果，而只保存建立这个结果的命令。 redis的AOF就是这个思想，它不同RDB保存db的数据，它保存的是一条一条建立数据库的命令。 我们首先来看AOF文件的格式，它里面保存的是一条一条的命令，首先存储命令长度，然后存储命令，具体的分隔符什么的可以自己深入研究，这都不是重点，反正知道AOF文件存储的是redis客户端执行的命令即可。 redis server中有一个sds aof_buf, 如果aof持久化打开的话，每个修改数据库的命令都会存入这个aof_buf（保存的是aof文件中命令格式的字符串），然后event loop没循环一次，在server cron中调用flushaofbuf，把aof_buf中的命令写入aof文件（其实是write，真正写入的是内核缓冲区），再清空aof_buf，进入下一次loop。这样所有的数据库的变化，都可以通过aof文件中的命令来还原，达到了保存数据库的效果。 需要注意的是，flushaofbuf中调用的write，它只是把数据写入了内核缓冲区，真正写入文件时内核自己决定的，可能需要延后一段时间。 不过redis支持配置，可以配置每次写入后sync，则在redis里面调用sync，将内核中的数据写入文件，这不过这要耗费一次系统调用，耗费时间而已。还可以配置策略为1秒钟sync一次，则redis会开启一个后台线程（所以说redis不是单线程，只是单eventloop而已），这个后台线程会每一秒调用一次sync。这里要问了，RDB的时候为什么没有考虑sync的事情呢？因为RDB是一次性存储的，不像AOF这样多次存储，RDB的时候调用一次sync也没什么影响，而且使用bg save的时候，子进程会自己退出（exit），这时候exit函数内会冲刷缓冲区，自动就写入了文件中。 再来看，如果不想使用aof_buf保存每次的修改命令，也可以使用aof持久化。redis提供aof_rewrite，即根据现有的数据库生成命令，然后把命令写入aof文件中。很奇特吧？对，就是这么厉害。进行aof_rewrite的时候，redis变量每个数据库，然后根据key-value对中value的具体类型，生成不同的命令，比如是list，则它生成一个保存list的命令，这个命令里包含了保存该list所需要的的数据，如果这个list数据过长，还会分成多条命令，先创建这个list，然后往list里面添加元素，总之，就是根据数据反向生成保存数据的命令。然后将这些命令存储aof文件，这样不就和aof append达到同样的效果了么？ aof格式也支持后台模式。执行aof_bgrewrite的时候，也是fork一个子进程，然后让子进程进行aof_rewrite，把它复制的数据库写入一个临时文件，然后写完后用新号通知父进程。父进程判断子进程的退出信息是否正确，然后将临时文件更名成最终的aof文件。好了，问题来了。在子进程持久化期间，可能父进程的数据库有更新，怎么把这个更新通知子进程呢？难道要用进程间通信么？是不是有点麻烦呢？你猜redis怎么做的？它根本不通知子进程。什么，不通知？那更新怎么办？ 在子进程执行aof_bgrewrite期间，父进程会保存所有对数据库有更改的操作的命令（增，删除，改等），把他们保存在aof_rewrite_buf_blocks中，这是一个链表，每个block都可以保存命令，存不下时，新申请block，然后放入链表后面即可，当子进程通知完成保存后，父进程将aof_rewrite_buf_blocks的命令append 进aof文件就可以了。多么优美的设计，想一想自己当初还考虑用进程间通信，别人直接用最简单的方法就完美的解决了问题，有句话说得真对，越优秀的设计越趋于简单，而复杂的东西往往都是靠不住的。 至于aof文件的载入，也就是一条一条的执行aof文件里面的命令而已。不过考虑到这些命令就是客户端发送给redis的命令，所以redis干脆生成了一个假的客户端，它没有和redis建立网络连接，而是直接执行命令即可。首先搞清楚，这里的假的客户端，并不是真正的客户端，而是存储在redis里面的客户端的信息，里面有写和读的缓冲区，它是存在于redis服务器中的。所以，如下图，直接读入aof的命令，放入客户端的读缓冲区中，然后执行这个客户端的命令即可。这样就完成了aof文件的载入。 123456789101112// 创建伪客户端fakeClient = createFakeClient();while(命令不为空) &#123; // 获取一条命令的参数信息 argc， argv ... // 执行 fakeClient-&gt;argc = argc; fakeClient-&gt;argv = argv; cmd-&gt;proc(fakeClient);&#125; 整个aof持久化的设计，个人认为相当精彩。其中有很多地方，值得膜拜。 5.5 redis的事务 redis另一个比memcached强大的地方，是它支持简单的事务。事务简单说就是把几个命令合并，一次性执行全部命令。对于关系型数据库来说，事务还有回滚机制，即事务命令要么全部执行成功，只要有一条失败就回滚，回到事务执行前的状态。redis不支持回滚，它的事务只保证命令依次被执行，即使中间一条命令出错也会继续往下执行，所以说它只支持简单的事务。 首先看redis事务的执行过程。首先执行multi命令，表示开始事务，然后输入需要执行的命令，最后输入exec执行事务。 redis服务器收到multi命令后，会将对应的client的状态设置为REDIS_MULTI，表示client处于事务阶段，并在client的multiState结构体里面保持事务的命令具体信息（当然首先也会检查命令是否能否识别，错误的命令不会保存），即命令的个数和具体的各个命令，当收到exec命令后，redis会顺序执行multiState里面保存的命令，然后保存每个命令的返回值，当有命令发生错误的时候，redis不会停止事务，而是保存错误信息，然后继续往下执行，当所有的命令都执行完后，将所有命令的返回值一起返回给客户。redis为什么不支持回滚呢？网上看到的解释出现问题是由于客户程序的问题，所以没必要服务器回滚，同时，不支持回滚，redis服务器的运行高效很多。在我看来，redis的事务不是传统关系型数据库的事务，要求CIAD那么非常严格，或者说redis的事务都不是事务，只是提供了一种方式，使得客户端可以一次性执行多条命令而已，就把事务当做普通命令就行了，支持回滚也就没必要了。 我们知道redis是单event loop的，在真正执行一个事物的时候（即redis收到exec命令后），事物的执行过程是不会被打断的，所有命令都会在一个event loop中执行完。但是在用户逐个输入事务的命令的时候，这期间，可能已经有别的客户修改了事务里面用到的数据，这就可能产生问题。所以redis还提供了watch命令，用户可以在输入multi之前，执行watch命令，指定需要观察的数据，这样如果在exec之前，有其他的客户端修改了这些被watch的数据，则exec的时候，执行到处理被修改的数据的命令的时候，会执行失败，提示数据已经dirty。 这是如何是实现的呢？ 原来在每一个redisDb中还有一个dict watched_keys，watched_kesy中dictentry的key是被watch的数据库的key，而value则是一个list，里面存储的是watch它的client。同时，每个client也有一个watched_keys，里面保存的是这个client当前watch的key。在执行watch的时候，redis在对应的数据库的watched_keys中找到这个key（如果没有，则新建一个dictentry），然后在它的客户列表中加入这个client，同时，往这个client的watched_keys中加入这个key。当有客户执行一个命令修改数据的时候，redis首先在watched_keys中找这个key，如果发现有它，证明有client在watch它，则遍历所有watch它的client，将这些client设置为REDIS_DIRTY_CAS，表面有watch的key被dirty了。当客户执行的事务的时候，首先会检查是否被设置了REDIS_DIRTY_CAS，如果是，则表明数据dirty了，事务无法执行，会立即返回错误，只有client没有被设置REDIS_DIRTY_CAS的时候才能够执行事务。 需要指出的是，执行exec后，该client的所有watch的key都会被清除，同时db中该key的client列表也会清除该client，即执行exec后，该client不再watch任何key（即使exec没有执行成功也是一样）。所以说redis的事务是简单的事务，算不上真正的事务。 以上就是redis的事务，感觉实现很简单，实际用处也不是太大。 5.6 redis的发布订阅频道 redis支持频道，即加入一个频道的用户相当于加入了一个群，客户往频道里面发的信息，频道里的所有client都能收到。 实现也很简单，也watch_keys实现差不多，redis server中保存了一个pubsub_channels的dict，里面的key是频道的名称（显然要唯一了），value则是一个链表，保存加入了该频道的client。同时，每个client都有一个pubsub_channels，保存了自己关注的频道。当用用户往频道发消息的时候，首先在server中的pubsub_channels找到改频道，然后遍历client，给他们发消息。而订阅，取消订阅频道不够都是操作pubsub_channels而已，很好理解。 同时，redis还支持模式频道。即通过正则匹配频道，如有模式频道p, 1, 则向普通频道p1发送消息时，会匹配p，1，除了往普通频道发消息外，还会往p，1模式频道中的client发消息。注意，这里是用发布命令里面的普通频道来匹配已有的模式频道，而不是在发布命令里制定模式频道，然后匹配redis里面保存的频道。实现方式也很简单，在redis server里面有个pubsub_patterns的list（这里为什么不用dict？因为pubsub_patterns的个数一般较少，不需要使用dict，简单的list就好了），它里面存储的是pubsubPattern结构体，里面是模式和client信息，如下所示，一个模式，一个client，所以如果有多个clint监听一个pubsub_patterns的话，在list面会有多个pubsubPattern，保存client和pubsub_patterns的对应关系。 同时，在client里面，也有一个pubsub_patterns list，不过里面存储的就是它监听的pubsub_patterns的列表（就是sds），而不是pubsubPattern结构体。 1234typedef struct pubsubPattern &#123; redisClient *client; // 监听的client robj *pattern; // 模式&#125; pubsubPattern; 当用户往一个频道发送消息的时候，首先会在redis server中的pubsub_channels里面查找该频道，然后往它的客户列表发送消息。然后在redis server里面的pubsub_patterns里面查找匹配的模式，然后往client里面发送消息。 这里并没有去除重复的客户，在pubsub_channels可能已经给某一个client发过message了，然后在pubsub_patterns中可能还会给用户再发一次（甚至更多次）。 估计redis认为这是客户程序自己的问题，所以不处理。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/* Publish a message */int pubsubPublishMessage(robj *channel, robj *message) &#123; int receivers = 0; dictEntry *de; listNode *ln; listIter li; /* Send to clients listening for that channel */ de = dictFind(server.pubsub_channels,channel); if (de) &#123; list *list = dictGetVal(de); listNode *ln; listIter li; listRewind(list,&amp;li); while ((ln = listNext(&amp;li)) != NULL) &#123; redisClient *c = ln-&gt;value; addReply(c,shared.mbulkhdr[3]); addReply(c,shared.messagebulk); addReplyBulk(c,channel); addReplyBulk(c,message); receivers++; &#125; &#125; /* Send to clients listening to matching channels */if (listLength(server.pubsub_patterns)) &#123; listRewind(server.pubsub_patterns,&amp;li); channel = getDecodedObject(channel); while ((ln = listNext(&amp;li)) != NULL) &#123; pubsubPattern *pat = ln-&gt;value; if (stringmatchlen((char*)pat-&gt;pattern-&gt;ptr, sdslen(pat-&gt;pattern-&gt;ptr), (char*)channel-&gt;ptr, sdslen(channel-&gt;ptr),0)) &#123; addReply(pat-&gt;client,shared.mbulkhdr[4]); addReply(pat-&gt;client,shared.pmessagebulk); addReplyBulk(pat-&gt;client,pat-&gt;pattern); addReplyBulk(pat-&gt;client,channel); addReplyBulk(pat-&gt;client,message); receivers++; &#125; &#125; decrRefCount(channel); &#125; return receivers;&#125; 6. 总结总的来看，redis比memcached的功能多很多，实现也更复杂。 不过memcached更专注于保存key-value数据（这已经能满足大多数使用场景了），而redis提供更丰富的数据结构及其他的一些功能。不能说redis比memcached好，不过从源码阅读的角度来看，redis的价值或许更大一点。","categories":[{"name":"缓存","slug":"缓存","permalink":"https://vincentruan.github.io/categories/缓存/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://vincentruan.github.io/tags/redis/"},{"name":"memcached","slug":"memcached","permalink":"https://vincentruan.github.io/tags/memcached/"}]},{"title":"[转载]从零开始：史上最详尽V2Ray搭建图文教程","slug":"转载-从零开始：史上最详尽V2Ray搭建图文教程","date":"2019-12-22T09:05:18.000Z","updated":"2019-12-22T09:16:39.439Z","comments":true,"path":"2019/12/22/转载-从零开始：史上最详尽V2Ray搭建图文教程/","link":"","permalink":"https://vincentruan.github.io/2019/12/22/转载-从零开始：史上最详尽V2Ray搭建图文教程/","excerpt":"","text":"本文转载自从零开始：史上最详尽V2Ray搭建图文教程，根据实际服务器配置做部分修改。 一、服务端安装以下所有操作都是使用root用户（普通用户自行sudo）进行操作的，服务器centos7。 1.安装wget 如提示没有安装wget，在登录完成的窗口输入下面命令并回车进行wget安装： 1yum -y install wget 2.下载脚本 安装完wget之后就可以进行下载安装v2ray的脚本了，输入如下命令并回车： 1wget https://install.direct/go.sh 3.安装unzip 因为centos不支持apt-get，我们需要安装unzip，详见官方说明： 1yum install -y zip unzip 4.执行安装 输入下面的命令并回车执行安装 123456789101112131415161718192021222324252627[michael@centos74 v2ray]$ bash go.sh Installing V2Ray v3.14 on x86_64Downloading V2Ray. % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 608 0 608 0 0 2229 0 --:--:-- --:--:-- --:--:-- 2235100 8482k 100 8482k 0 0 2501k 0 0:00:03 0:00:03 --:--:-- 2813kExtracting V2Ray package to /tmp/v2ray.Archive: /tmp/v2ray/v2ray.zip creating: /tmp/v2ray/v2ray-v3.14-linux-64/ inflating: /tmp/v2ray/v2ray-v3.14-linux-64/geoip.dat inflating: /tmp/v2ray/v2ray-v3.14-linux-64/geosite.dat inflating: /tmp/v2ray/v2ray-v3.14-linux-64/readme.md creating: /tmp/v2ray/v2ray-v3.14-linux-64/systemd/ inflating: /tmp/v2ray/v2ray-v3.14-linux-64/systemd/v2ray.service creating: /tmp/v2ray/v2ray-v3.14-linux-64/systemv/ inflating: /tmp/v2ray/v2ray-v3.14-linux-64/systemv/v2ray inflating: /tmp/v2ray/v2ray-v3.14-linux-64/v2ctl extracting: /tmp/v2ray/v2ray-v3.14-linux-64/v2ctl.sig inflating: /tmp/v2ray/v2ray-v3.14-linux-64/v2ray extracting: /tmp/v2ray/v2ray-v3.14-linux-64/v2ray.sig inflating: /tmp/v2ray/v2ray-v3.14-linux-64/vpoint_socks_vmess.json inflating: /tmp/v2ray/v2ray-v3.14-linux-64/vpoint_vmess_freedom.json PORT:13437UUID:f500ecf5-e135-49c6-9ce2-78eb490d0aa9Created symlink from /etc/systemd/system/multi-user.target.wants/v2ray.service to /etc/systemd/system/v2ray.service.V2Ray v3.14 is installed. 5.相关命令 在首次安装完成之后，V2Ray不会自动启动，需要手动运行上述启动命令。而在已经运行V2Ray的VPS上再次执行安装脚本，安装脚本会自动停止V2Ray 进程，升级V2Ray程序，然后自动运行V2Ray。在升级过程中，配置文件不会被修改。 1234567891011## 启动systemctl start v2ray## 停止systemctl stop v2ray## 重启systemctl restart v2ray## 开机自启systemctl enable v2ray 关于软件更新：更新 V2Ray 的方法是再次执行安装脚本！再次执行安装脚本！再次执行安装脚本！ 6.配置 如果你按照上面的命令执行安装完成之后，服务端其实是不需要再进行任何配置的，配置文件位于/etc/v2ray/config.json，使用cat /etc/v2ray/config.json查看配置信息。接下来进行客户端配置就行了。 说明： 配置文件中的id、端口、alterId需要和客户端的配置保持一致； 服务端使用脚本安装成功之后默认就是vmess协议； 配置完成之后重启v2ray。 9.防火墙开放端口 有的vps端口默认不开放，可能导致连接不成功，如果有这种情况，详细配置，见CentOs开放端口的方法—二、firewalld。部分服务器的防火墙配置只能在服务提供商的控制台操作，请注意。 12345## 查看已开放端口firewall-cmd --zone=public --list-ports## 添加开放端口firewall-cmd --zone=public --add-port=80/tcp --permanent 二、Windows 客户端1.下载 目前不支持水果系列，水果机只能自行走野路子解决。 1)下载【v2ray-windows-64.zip Github Release】;2)下载【v2rayN-v2rayN.exe-Github Release】； 对v2ray-windows-64.zip进行解压，然后将下载的V2RayN.exe复制到解压后的目录，即两个下载好的文件需要在同一目录。 2.配置 运行V2RayN.exe，然后进行配置，下图中的配置信息，需要和你VPS搭建的时候的配置信息对应，VPS的v2ray配置信息位于/etc/v2ray/config.json文件里。 如果采用上面的默认方式安装，服务端配置是协议vmess，则配置如下： 三、测试打开浏览器，访问www.google.com 四、进阶现在你已经学会使用v2ray了，为了更好的上网效果，建议继续了解一下下面文章： centos7基于nginx搭建v2ray服务端配置vmess+tls+websocket完全手册；【推荐】 使用Google BBR PLUS加速你的VPS网络； 如何以mkcp方式部署v2ray； 五、相关问题 使用v2ray访问谷歌提示异常流量； 启用cloudflare cdn之后v2ray报403错误；","categories":[],"tags":[{"name":"v2ray","slug":"v2ray","permalink":"https://vincentruan.github.io/tags/v2ray/"}]},{"title":"详解分布式协调服务 ZooKeeper","slug":"详解分布式协调服务-ZooKeeper","date":"2018-10-07T04:14:40.000Z","updated":"2020-02-17T02:40:44.899Z","comments":true,"path":"2018/10/07/详解分布式协调服务-ZooKeeper/","link":"","permalink":"https://vincentruan.github.io/2018/10/07/详解分布式协调服务-ZooKeeper/","excerpt":"","text":"作者 | Draveness 本文作者 Draveness，文章转载自 https://draveness.me/zookeeper-chubby， 对其内容进行过编辑。 这篇文章主要会介绍 Zookeeper 的实现原理以及常见的应用 在 2006 年，Google 发表了一篇名为 The Chubby lock service for loosely-coupled distributed systems 的论文，其中描述了一个分布式锁服务 Chubby 的设计理念和实现原理；作为 Google 内部的一个基础服务，虽然 Chubby 与 GFS、Bigtable 和 MapReduce 相比并没有那么大的名气，不过它在 Google 内部也是非常重要的基础设施。 相比于名不见经传的 Chubby，作者相信 Zookeeper 更被广大开发者所熟知，作为非常出名的分布式协调服务，Zookeeper 有非常多的应用，包括发布订阅、命名服务、分数是协调和分布式锁，这篇文章主要会介绍 Zookeeper 的实现原理以及常见的应用，但是在具体介绍 Zookeeper 的功能和原理之前，我们会简单介绍一下分布式锁服务 Chubby 以及它与 Zookeeper 之间的异同。 Chubby作为分布式锁服务，Chubby 的目的就是允许多个客户端对它们的行为进行同步，同时也能够解决客户端的环境相关信息的分发和粗粒度的同步问题，GFS 和 Bigtable 都使用了 Chubby 以解决主节点的选举等问题。在网络上你很难找到关于 Chubby 的相关资料，我们只能从 The Chubby lock service for loosely-coupled distributed systems 一文中窥见它的一些设计思路、技术架构等信息。 虽然 Chubby 和 Zookeeper 有着比较相似的功能，但是它们的设计理念却非常不同，Chubby 在论文的摘要中写道： We describe our experiences with the Chubby lock service, which is intended to provide coarse-grained locking as well as reliable (though low-volume) storage for a loosely-coupled distributed system. 从论文的摘要中我们可以看出 Chubby 首先被定义成一个 分布式的锁服务，它能够为分布式系统提供 松耦合、粗粒度 的分布式锁功能，然而我们并不能依赖于它来做一些重量的数据存储。 Chubby 在设计时做了两个重要的设计决定，一是提供完整、独立的分布式锁服务而非一个用于共识的库或者服务，另一个是选择提供小文件的的读写功能，使得主节点能够方便地发布自己的状态信息。 系统架构Chubby 总共由两部分组成，一部分是用于提供数据的读写接口并管理相关的配置数据的服务端，另一部分就是客户端使用的 SDK，为了提高系统的稳定性，每一个 Chubby 单元都由一组服务器组成，它会使用 共识算法 从集群中选举出主节点。 在一个 Chubby Cell 中，只有 主节点会对外提供读写服务，其他的节点其实都是当前节点的副本（Replica），它们只是维护一个数据的拷贝并会在主节点更新时对它们持有的数据库进行更新；客户端通过向副本发送请求获取主节点的位置，一旦它获取到了主节点的位置，就会向所有的读写请求发送给主节点，直到其不再响应为止。写请求都会通过一致性协议传播到所有的副本中，当集群中的多数节点都同步了请求时就会认为当前的写入已经被确认。 当主节点宕机时，副本会在其租约到期时重新进行选举，副本节点如果在宕机几小时还没有回复，那么系统就会从资源池中选择一个新的节点并在该节点上启动 Chubby 服务并更新 DNS 表。 主节点会不停地轮训 DNS 表获取集群中最新的配置，每次 DNS 表更新时，主节点都会将新的配置下发给 Chubby 集群中其他的副本节点。 Zookeeper很多人都会说 Zookeeper 是 Chubby 的一个开源实现，这其实是有问题的，它们两者只不过都提供了具有层级结构的命名空间： Chubby 和 Zookeeper 从最根本的设计理念上就有着非常明显的不同，在上文中我们已经提到了 Chubby 被设计成一个分布式的锁服务，它能够为分布式系统提供松耦合、粗粒度的分布式锁功能，然而我们并不能依赖于它来做一些重量的数据存储，而 Zookeeper 的论文在摘要中介绍到，它是一个能够为分布式系统提供协调功能的服务： In this paper, we describe ZooKeeper, a service for co- ordinating processes of distributed applications. Zookeeper 的目的是为客户端构建复杂的协调功能提供简单、高效的核心 API，相比于 Chubby 对外提供已经封装好的更上层的功能，Zookeeper 提供了更抽象的接口以便于客户端自行实现想要完成的功能。 Chubby 直接为用户提供封装好的锁和解锁的功能，内部完成了锁的实现，只是将 API 直接暴露给用户，而 Zookeeper 却需要用户自己实现分布式锁；总的来说，使用 Zookeeper 往往需要客户端做更多的事情，但是也享有更多的自由。 技术架构与 Chubby 集群中，多个节点只有一个能够对外提供服务不同，Zookeeper 集群中所有的节点都可以对外提供服务，但是集群中的节点也分为主从两种节点，所有的节点都能处理来自客户端的读请求，但是只有主节点才能处理写入操作： 这里所说的 Zookeeper 集群主从节点实际上分别是 Leader 和 Follower 节点。 客户端使用 Zookeeper 时会连接到集群中的任意节点，所有的节点都能够直接对外提供读操作，但是写操作都会被从节点路由到主节点，由主节点进行处理。 Zookeeper 在设计上提供了以下的两个基本的顺序保证，线性写和先进先出的客户端顺序： 其中线性写是指所有更新 Zookeeper 状态的请求都应该按照既定的顺序串行执行；而先进先出的客户端顺序是指，所有客户端发出的请求会按照发出的顺序执行。 Zab 协议在我们简单介绍 Zookeeper 的技术架构之后，这一节将谈及 Zookeeper 中的 Zab 协议，Zookeeper 的 Zab 协议是为了解决分布式一致性而设计出的一种协议，它的全称是 Zookeeper 原子广播协议，它能够在发生崩溃时快速恢复服务，达到高可用性。 如上一节提到的，客户端在使用 Zookeeper 服务时会随机连接到集群中的一个节点，所有的读请求都会由当前节点处理，而写请求会被路由给主节点并由主节点向其他节点广播事务，与 2PC 非常相似，如果在所有的节点中超过一半都返回成功，那么当前写请求就会被提交。 当主节点崩溃时，其他的 Replica 节点会进入崩溃恢复模式并重新进行选举，Zab 协议必须确保提交已经被 Leader 提交的事务提案，同时舍弃被跳过的提案，这也就是说当前集群中最新 ZXID 最大的服务器会被选举成为 Leader 节点；但是在正式对外提供服务之前，新的 Leader 也需要先与 Follower 中的数据进行同步，确保所有节点拥有完全相同的提案列表。 在上面提到 ZXID 其实就是 Zab 协议中设计的事务编号，它是一个 64 位的整数，其中最低的 32 位是一个计数器，每当客户端修改 Zookeeper 集群状态时，Leader 都会以当前 ZXID 值作为提案的编号创建一个新的事务，在这之后会将当前计数器加一；ZXID 中高的 32 位表示当前 Leader 的任期，每当发生崩溃进入恢复模式，集群的 Leader 重新选举之后都会将 epoch 加一。 Zab 和 PaxosZab 和 Paxos 协议在实现上其实有非常多的相似点，例如： 主节点会向所有的从节点发出提案； 主节点在接收到一组从节点中 50% 以上节点的确认后，才会认为当前提案被提交了； Zab 协议中的每一个提案都包含一个 epoch 值，与 Paxos 中的 Ballot 非常相似； 因为它们有一些相同的特点，所以有的观点会认为 Zab 是 Paxos 的一个简化版本，但是 Zab 和 Paxos 在设计理念上就有着比较大的不同，两者的主要区别就在于 Zab 主要是为构建高可用的主备系统设计的，而 Paxos 能够帮助工程师搭建具有一致性的状态机系统。 作为一个一致性状态机系统，它能够保证集群中任意一个状态机副本都按照客户端的请求执行了相同顺序的请求，即使来自客户端请求是异步的并且不同客户端的接收同一个请求的顺序不同，集群中的这些副本就是会使用 Paxos 或者它的变种对提案达成一致；在集群运行的过程中，如果主节点出现了错误导致宕机，其他的节点会重新开始进行选举并处理未提交的请求。 但是在类似 Zookeeper 的高可用主备系统中，所有的副本都需要对增量的状态更新顺序达成一致，这些状态更新的变量都是由主节点创建并发送给其他的从节点的，每一个从节点都会严格按照顺序逐一的执行主节点生成的状态更新请求，如果 Zookeeper 集群中的主节点发生了宕机，新的主节点也必须严格按照顺序对请求进行恢复。 总的来说，使用状态更新节点数据的主备系统相比根据客户端请求改变状态的状态机系统对于请求的执行顺序有着更严格的要求。 实现原理这一节会简单介绍 Zookeeper 的一些实现原理，重点会介绍以下几个部分的内容：文件系统、临时 / 持久节点和通知的实现原理。 文件系统了解或者使用 Zookeeper 或者其他分布式协调服务的读者对于使用类似文件系统的方式比较熟悉，与 Unix 中的文件系统份上相似的是，Zookeeper 中也使用文件系统组织系统中存储的资源。 Zookeeper 中其实并没有文件和文件夹的概念，它只有一个 Znode 的概念，它既能作为容器存储数据，也可以持有其他的 Znode 形成父子关系。 Znode 其实有 PERSISTENT、PERSISTENT_SEQUENTIAL、EPHEMERAL 和 EPHEMERAL_SEQUENTIAL 四种类型，它们是临时与持久、顺序与非顺序两个不同的方向组合成的四种类型。 临时节点是客户端在连接 Zookeeper 时才会保持存在的节点，一旦客户端和服务端之间的连接中断，当前连接持有的所有节点都会被删除，而持久的节点不会随着会话连接的中断而删除，它们需要被客户端主动删除；Zookeeper 中另一种节点的特性就是顺序和非顺序，如果我们使用 Zookeeper 创建了顺序的节点，那么所有节点就会在名字的末尾附加一个序列号，序列号是一个由父节点维护的单调递增计数器。 通知常见的通知机制往往都有两种，一种是客户端使用『拉』的方式从服务端获取最新的状态，这种方式获取的状态很有可能都是过期的，需要客户端不断地通过轮训的方式获取服务端最新的状态，另一种方式就是在客户端订阅对应节点后由服务端向所有订阅者推送该节点的变化，相比于客户端主动获取数据的方式，服务端主动推送更能够保证客户端数据的实时性。 作为分布式协调工具的 Zookeeper 就实现了这种服务端主动推送请求的机制，也就是 Watch，当客户端使用 getData 等接口获取 Znode 状态时传入了一个用于处理节点变更的回调，那么服务端就会主动向客户端推送节点的变更： 1public byte[] getData(final String path, Watcher watcher, Stat stat) 从这个方法中传入的 Watcher 对象实现了相应的 process 方法，每次对应节点出现了状态的改变，WatchManager 都会通过以下的方式调用传入 Watcher 的方法： 1234567891011Set&lt;Watcher&gt; triggerWatch(String path, EventType type, Set&lt;Watcher&gt; supress) &#123; WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path); Set&lt;Watcher&gt; watchers; synchronized (this) &#123; watchers = watchTable.remove(path); &#125; for (Watcher w : watchers) &#123; w.process(e); &#125; return watchers;&#125; Zookeeper 中的所有数据其实都是由一个名为 DataTree 的数据结构管理的，所有的读写数据的请求最终都会改变这颗树的内容，在发出读请求时可能会传入 Watcher 注册一个回调函数，而写请求就可能会触发相应的回调，由 WatchManager 通知客户端数据的变化。 通知机制的实现其实还是比较简单的，通过读请求设置 Watcher 监听事件，写请求在触发事件时就能将通知发送给指定的客户端。 会话在 Zookeeper 中一个非常重要的概念就是会话，客户端与服务器之间的任何操作都与 Zookeeper 中会话的概念有关，比如我们再上一节中提到的临时节点生命周期以及通知的机制等等，它们都是基于会话来实现的。 每当客户端与服务端建立连接时，其实创建了一个新的会话，在每一个会话的生命周期中，Zookeeper 会在不同的会话状态之间进行切换，比如说：CONNECTING、CONNECTED、RECONNECTING、RECONNECTED 和 CLOSE 等。 作为 Zookeeper 中最重要的概念之一，每一个 Session 都包含四个基本属性，会话的唯一 ID、会话超时时间、下次会话的超时时间点和表示会话是否被关闭的标记。 SessionTracker 是 Zookeeper 中的会话管理器，它负责所有会话的创建、管理以及清理工作，但是它本身只是一个 Java 的接口，定义了一系列用于管理会话的相关接口： 1234567891011121314151617181920public interface SessionTracker &#123; public static interface Session &#123; long getSessionId(); int getTimeout(); boolean isClosing(); &#125; public static interface SessionExpirer &#123; void expire(Session session); long getServerId(); &#125; long createSession(int sessionTimeout); boolean trackSession(long id, int to); boolean commitSession(long id, int to); boolean touchSession(long sessionId, int sessionTimeout); void setSessionClosing(long sessionId); void shutdown(); void removeSession(long sessionId);&#125; 与其他的长连接一样，Zookeeper 中的会话也需要客户端与服务端之间进行心跳检测，客户端会在超时时间内向服务端发送心跳请求来保证会话不会被服务端关闭，一旦服务端检测到某一个会话长时间没有收到心跳包就会中断当前会话释放服务器上的资源。 应用作为分布式协调服务，Zookeeper 能够为集群提供分布式一致性的保证，我们可以通过 Zookeeper 提供的最基本的 API 组合成更高级的功能： 12345678public class Zookeeper &#123; public String create(final String path, byte data[], List&lt;ACL&gt; acl, CreateMode createMode) public void delete(final String path, int version) throws InterruptedException, KeeperException public Stat exists(final String path, Watcher watcher) throws KeeperException, InterruptedException public byte[] getData(final String path, Watcher watcher, Stat stat) throws KeeperException, InterruptedException public Stat setData(final String path, byte data[], int version) throws KeeperException, InterruptedException public void sync(final String path, VoidCallback cb, Object ctx)&#125; 在这一节中，我们将介绍如何在生产环境中使用 Zookeeper 实现发布订阅、命名服务、分布式协调以及分布式锁等功能。 发布订阅通过 Zookeeper 进行数据的发布与订阅其实可以说是它提供的最基本功能，它能够允许多个客户端同时订阅某一个节点的变更并在变更发生时执行我们预先设置好的回调函数，在运行时改变服务的配置和行为： 123456789ZooKeeper zk = new ZooKeeper(\"localhost\", 3000, null);zk.getData(\"/config\", new Watcher() &#123; public void process(WatchedEvent watchedEvent) &#123; System.out.println(watchedEvent.toString()); &#125;&#125;, null);zk.setData(\"/config\", \"draven\".getBytes(), 0);// WatchedEvent state:SyncConnected type:NodeDataChanged path:/config 发布与订阅是 Zookeeper 提供的一个最基本的功能，它的使用非常的简单，我们可以在 getData 中传入实现 process 方法的 Watcher 对象，在每次改变节点的状态时，process 方法都会被调用，在这个方法中就可以对变更进行响应动态修改一些行为。 通过 Zookeeper 这个中枢，每一个客户端对节点状态的改变都能够推送给节点的订阅者，在发布订阅模型中，Zookeeper 的每一个节点都可以被理解成一个主题，每一个客户端都可以向这个主题推送详细，同时也可以订阅这个主题中的消息；只是 Zookeeper 引入了文件系统的父子层级的概念将发布订阅功能实现得更加复杂。 1234567public static enum EventType &#123; None(-1), NodeCreated(1), NodeDeleted(2), NodeDataChanged(3), NodeChildrenChanged(4);&#125; 如果我们订阅了一个节点的变更信息，那么该节点的子节点出现数量变更时就会调用 process 方法通知观察者，这也意味着更复杂的实现，同时和专门做发布订阅的中间件相比也没有性能优势，在海量推送的应用场景下，消息队列更能胜任，而 Zookeeper 更适合做一些类似服务配置的动态下发的工作。 命名服务除了实现服务配置数据的发布与订阅功能，Zookeeper 还能帮助分布式系统实现命名服务，在每一个分布式系统中，客户端应用都有根据指定名字获取资源、服务器地址的需求，在这时就要求整个集群中的全部服务有着唯一的名字。 在大型分布式系统中，有两件事情非常常见，一是不同服务之间的可能拥有相同的名字，另一个是同一个服务可能会在集群中部署很多的节点，Zookeeper 就可以通过文件系统和顺序节点解决这两个问题。 在上图中，我们创建了两个命名空间，/infrastructure 和 /business 分别代表架构和业务部门，两个部门中都拥有名为 metrics 的服务，而业务部门的 metrics 服务也部署了两个节点，在这里使用了命名空间和顺序节点解决唯一标志符的问题。 1234567ZooKeeper zk = new ZooKeeper(\"localhost\", 3000, null);zk.create(\"/metrics\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);zk.create(\"/metrics\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);List children = zk.getChildren(\"/\", null);System.out.println(children);// [metrics0000000001, metrics0000000002] 使用上面的代码就能在 Zookeeper 中创建两个带序号的 metrics 节点，分别是 metrics0000000001 和 metrics0000000002，也就是说 Zookeeper 帮助我们保证了节点的唯一性，让我们能通过唯一的 ID 查找到对应服务的地址等信息。 协调分布式事务Zookeeper 的另一个作用就是担任分布式事务中的协调者角色，在之前介绍 分布式事务 的文章中我们曾经介绍过分布式事务本质上都是通过 2PC 来实现的，在两阶段提交中就需要一个协调者负责协调分布式事务的执行。 123456789ZooKeeper zk = new ZooKeeper(\"localhost\", 3000, null);String path = zk.create(\"/transfer/tx\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);List ops = Arrays.asList( Op.create(path + \"/cohort\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL), Op.create(path + \"/cohort\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL), Op.create(path + \"/cohort\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL));zk.multi(ops); 当前节点作为协调者在每次发起分布式事务时都会创建一个 /transfer/tx 的持久顺序节点，然后为几个事务的参与者创建几个空白的节点，事务的参与者在收到事务时会向这些空白的节点中写入信息并监听这些节点中的内容。 所有的事务参与者会向当前节点中写入提交或者终止，一旦当前的节点改变了事务的状态，其他节点就会得到通知，如果出现一个写入终止的节点，所有的节点就会回滚对分布式事务进行回滚。 使用 Zookeeper 实现强一致性的分布式事务其实还是一件比较困难的事情，一方面是因为强一致性的分布式事务本身就有一定的复杂性，另一方面就是 Zookeeper 为了给客户端提供更多的自由，对外暴露的都是比较基础的 API，对它们进行组装实现复杂的分布式事务还是比较麻烦的，对于如何使用 Zookeeper 实现分布式事务，我们可以在 ZooKeeper Recipes and Solutions 一文中找到更为详细的内容。 分布式锁在数据库中，锁的概念其实是非常重要的，常见的关系型数据库就会对排他锁和共享锁进行支持，而 Zookeeper 提供的 API 也可以让我们非常简单的实现分布式锁。 1234567891011121314151617181920212223242526272829ZooKeeper zk = new ZooKeeper(\"localhost\", 3000, null);final String resource = \"/resource\";final String lockNumber = zk .create(\"/resource/lock-\", null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);List&lt;String&gt; locks = zk.getChildren(resource, false, null);Collections.sort(locks);if (locks.get(0).equals(lockNumber.replace(\"/resource/\", \"\"))) &#123; System.out.println(\"Acquire Lock\"); zk.delete(lockNumber, 0);&#125; else &#123; zk.getChildren(resource, new Watcher() &#123; public void process(WatchedEvent watchedEvent) &#123; try &#123; ZooKeeper zk = new ZooKeeper(\"localhost\", 3000, null); List locks = zk.getChildren(resource, null, null); Collections.sort(locks); if (locks.get(0).equals(lockNumber.replace(\"/resource/\", \"\"))) &#123; System.out.println(\"Acquire Lock\"); zk.delete(lockNumber, 0); &#125; &#125; catch (Exception e) &#123;&#125; &#125; &#125;, null);&#125; 如果多个服务同时要对某个资源进行修改，就可以使用上述的代码来实现分布式锁，假设集群中存在一个资源 /resource，几个服务需要通过分布式锁保证资源只能同时被一个节点使用，我们可以用创建临时顺序节点的方式实现分布式锁；当我们创建临时节点后，通过 getChildren 获取当前等待锁的全部节点，如果当前节点是所有节点中序号最小的就得到了当前资源的使用权限，在对资源进行处理后，就可以通过删除 /resource/lock-00000000x 来释放锁，如果当前节点不是最小值，就会注册一个 Watcher 等待 /resource 子节点的变化直到当前节点的序列号成为最小值。 上述代码在集群中争夺同一资源的服务器特别多的情况下会出现羊群效应，每次子节点改变时都会通知当前节点，造成资源的浪费，我们其实可以将 getChildren 换成 getData，让当前节点只监听前一个节点的删除事件： 1234567891011121314Integer number = Integer.parseInt(lockNumber.replace(\"/resource/lock-\", \"\")) + 1;String previousLock = \"/resource/lock-\" + String.format(\"%010d\", number);zk.getData(previousLock, new Watcher() &#123; public void process(WatchedEvent watchedEvent) &#123; try &#123; if (watchedEvent.getType() == Event.EventType.NodeDeleted) &#123; System.out.println(\"Acquire Lock\"); ZooKeeper zk = new ZooKeeper(\"localhost\", 3000, null); zk.delete(lockNumber, 0); &#125; &#125; catch (Exception e) &#123;&#125; &#125;&#125;, null); 在新的分布式锁实现中，我们减少了每一个服务需要关注的事情，只让它们监听需要关心的数据变更，减少 Zookeeper 发送不必要的通知影响效率。 分布式锁作为分布式系统中比较重要的一个工具，确实有着比较多的应用，同时也有非常多的实现方式，除了 Zookeeper 之外，其他服务例如 Redis 和 etcd 也能够实现分布式锁，为分布式系统的构建提供支持，不过在这篇文章中就不展开介绍了。 总结我们在这篇文章中简单介绍了 Google 的分布式锁服务 Chubby 以及同样能够提供分布式锁服务功能的 Zookeeper。 作为分布式协调服务，Zookeeper 的应用场景非常广泛，不仅能够用于服务配置的下发、命名服务、协调分布式事务以及分布式锁，还能够用来实现微服务治理中的服务注册以及发现等功能，这些其实都源于 Zookeeper 能够提供高可用的分布式协调服务，能够为客户端提供分布式一致性的支持，在后面的文章中作者也会介绍其他用于分布式协调的服务。 参考资料https://zookeeper.apache.org/doc/r3.4.4/recipes.html https://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/categories/架构设计/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://vincentruan.github.io/tags/zookeeper/"},{"name":"分布式","slug":"分布式","permalink":"https://vincentruan.github.io/tags/分布式/"}]},{"title":"Shadowsocks服务器代理","slug":"Shadowsocks服务器代理","date":"2018-07-13T14:58:47.000Z","updated":"2018-07-13T15:11:09.791Z","comments":true,"path":"2018/07/13/Shadowsocks服务器代理/","link":"","permalink":"https://vincentruan.github.io/2018/07/13/Shadowsocks服务器代理/","excerpt":"","text":"前言本文讲述如何安装配置Shadowsocks Server，并支持通过代理方式（http/sock v4/5)连接因特网. 这里主要阐述服务端通过proxy连接的解决方案，shadowsocks server直连网络的方式比较简单，网上这块资料也比较齐全，不做过多描述， ssserver代理安装配置安装Shadowsocks Server参考Install Shadowsocks Server on Windows， 客户端的安装方式参考Shadowsocks Client安装, 这里主要解决服务端通过代理解决shadowsocks server无法直连网络的问题，客户端这块不做过多描述。 更新代理脚本​ 这个问题的解决方案来自github的一个issue 通过猴子补丁的方式给ss添加了一个前置代理的功能 有兴趣深入了解的推荐star一下该作者的项目PySocket ​ 在上述步骤安装了python版的Shadowsocks Server之后，通过猴子补丁的方式给给 shadowsocks 服务端添加前置代理的功能（原则上也适用于客户端），支持 http、socks4、socks5 代理。并且通过 hook 的方式去掉了ss的dns查询，ss在接收到数据之后会直接把域名和请求一起发给代理。 使用的时候修改 socket.py 文件中 PROXY_TYPE、PROXY_ADDR、PROXY_PORT 等字段为你的代理地址，然后把 socket.py 文件放到 shadowsocks 根目录即可生效，不用修改任何源码。 通过pip安装的话要放到ssserver所在的目录，一般都在 Python27\\Scripts （python27上验证OK） 12pip install win_inet_pton --proxy=http://your-proxy-host:your-proxy-portpip install shadowsocks --proxy=http://your-proxy-host:your-proxy-port 配置部分： 1234# the proxy type. SOCKS5 SOCKS4 HTTPPROXY_TYPE = SOCKS5PROXY_ADDR = \"127.0.0.1\"PROXY_PORT = 1080 socket.py 文末部分，因为我选择 hook shadowsocks的代码，实际使用时在del module会报异常，因此将文末修改为 12345678910111213# hook shadowsocks's code remove the dns reqdef new_resolve(self, hostname, callback): callback((hostname, hostname), None)modules_list = [\"shadowsocks.common\", \"shadowsocks.shell\"]for x in modules_list: try: del sys.modules[x] except KeyError: print \"Error: key\", x, \"not found\"import shadowsocks.asyncdnsshadowsocks.asyncdns.DNSResolver.resolve = new_resolve 如果不想 hook shadowsocks的代码的话，把文件中末尾的代码删除即可，原文件代码末尾如下: 12345678910# hook shadowsocks's code remove the dns reqdef new_resolve(self, hostname, callback): callback((hostname, hostname), None)modules_list = [\"shadowsocks.common\", \"shadowsocks.shell\"]for x in modules_list: del sys.modules[x]import shadowsocks.asyncdnsshadowsocks.asyncdns.DNSResolver.resolve = new_resolve ssserver配置参考Configuration via Config File 创建一个配置文件 /etc/shadowsocks.json. 示例如下: 12345678910&#123; \"server\":\"my_server_ip\", \"server_port\":8388, \"local_address\": \"127.0.0.1\", \"local_port\":1080, \"password\":\"mypassword\", \"timeout\":300, \"method\":\"aes-256-cfb\", \"fast_open\": false&#125; 配置文件字段详解: Name Explanation server ssserver监听地址，0.0.0.0监听本地所有网卡地址 server_port ssserver服务端口 local_address 本地监听地址 local_port 本地端口 password 用于加密的密码 timeout 超时设置，单位秒，不建议太长 method 默认: “aes-256-cfb”, 详见 Encryption fast_open 是否使用 TCP_FASTOPEN, true / false workers worker数量, 仅在Unix/Linux生效 在控制台中执行，日志直接显示在控制台，首次测试使用建议该方式，可通过ctrl+C退出: 1ssserver -c /etc/shadowsocks.json 后台静默执行: 1234# 启动服务ssserver -c /etc/shadowsocks.json -d start# 停止服务ssserver -c /etc/shadowsocks.json -d stop","categories":[{"name":"developer tools","slug":"developer-tools","permalink":"https://vincentruan.github.io/categories/developer-tools/"}],"tags":[{"name":"Shadowsocks","slug":"Shadowsocks","permalink":"https://vincentruan.github.io/tags/Shadowsocks/"}]},{"title":"docker碎片拾遗","slug":"docker碎片拾遗","date":"2018-06-24T05:22:34.000Z","updated":"2020-02-17T02:40:44.761Z","comments":true,"path":"2018/06/24/docker碎片拾遗/","link":"","permalink":"https://vincentruan.github.io/2018/06/24/docker碎片拾遗/","excerpt":"","text":"进入shell环境12docker psdocker exec -it &lt;container&gt; bash and run 12apt-get updateapt-get install vim ！不要去改系统配置正常运行的docker先保存一下docker的ID，之后不要去改下面的配置，否则docker会更新为新的那个，导致数据丢失 docker指令1、启动docker1docker run -it --privileged=true -v /home/oracle/download:/usr/Downloads centos /bin/bash 2、查看当前docker运行1docker ps -a 3、提交docker1docker commit 9f73a02d5ef0[CONTAINER ID] docker.io/ubuntu[REPOSITORY] 4、查看容器的root用户密码1docker logs &lt;容器名orID&gt; 2&gt;&amp;1 | grep '^User: ' | tail -n1 因为docker容器启动时的root用户的密码是随机分配的。所以，通过这种方式就可以得到redmine容器的root用户的密码了。 5、查看容器日志1docker logs -f &lt;容器名orID&gt; 6、查看正在运行的容器12docker psdocker ps -a为查看所有的容器，包括已经停止的。 7、删除所有容器1docker rm $(docker ps -a -q) 8、删除单个容器1docker rm &lt;容器名orID&gt; 9、停止、启动、杀死一个容器12345docker stop &lt;容器名orID&gt;docker start &lt;容器名orID&gt;docker kill &lt;容器名orID&gt; 10、查看所有镜像1docker images 11、删除所有镜像1docker rmi $(docker images | grep none | awk '&#123;print $3&#125;' | sort -r) 12、运行一个新容器，同时为它命名、端口映射、文件夹映射。以redmine镜像为例1docker run --name redmine -p 9003:80 -p 9023:22 -d -v /var/redmine/files:/redmine/files -v /var/redmine/mysql:/var/lib/mysql sameersbn/redmine 13、一个容器连接到另一个容器1docker run -i -t --name sonar -d -link mmysql:db tpires/sonar-server sonar容器连接到mmysql容器，并将mmysql容器重命名为db。这样，sonar容器就可以使用db的相关的环境变量了。 14、拉取镜像1docker pull &lt;镜像名:tag&gt; 如docker pull sameersbn/redmine:latest 当需要把一台机器上的镜像迁移到另一台机器的时候，需要保存镜像与加载镜像。 机器a1docker save busybox-1 &gt; /home/save.tar 使用scp将save.tar拷到机器b上，然后：1docker load &lt; /home/save.tar 15、构建自己的镜像1docker build -t &lt;镜像名&gt; &lt;Dockerfile路径&gt; 如Dockerfile在当前路径：docker build -t xx/gitlab .","categories":[{"name":"docker","slug":"docker","permalink":"https://vincentruan.github.io/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://vincentruan.github.io/tags/docker/"}]},{"title":"Xshell显示X11图形化界面","slug":"Xshell显示X11图形化界面","date":"2018-06-17T15:10:35.000Z","updated":"2018-06-17T15:38:38.635Z","comments":true,"path":"2018/06/17/Xshell显示X11图形化界面/","link":"","permalink":"https://vincentruan.github.io/2018/06/17/Xshell显示X11图形化界面/","excerpt":"","text":"安装Xmanager全家桶使用前检查一下是否安装了Xshell、Xstart、Xmanager - Passive，正常安装Xmanager全家桶应该是全的 使用XStart登录通过SSH的方式尝试登录VPS， 正常成功后会这样提示 当然更多的可能是弹出个错误框提示“已拒绝X11转移申请”，这是因为默认的VPS一般不会安装XAUTH导致， 1sudo yum install xorg-x11-xauth 这里可能会缺一些其他组件，见招拆招即可，谷歌或者百度解决 设置XSHELL 打开会话对话框 选择要激活X11转发功能的会话 点击[属性]按钮 在[类别]中选择[连接-&gt;SSH-&gt;隧道] 选择[转发X11连接到] 如用户的PC上已安装Xmanager，请勾选[Xmanager(M)]。如使用其他PC X 服务器，请选择[X DISPLAY(D)]后输入适用的DISPLAY 点击[确定] 检查当前监听端口IMPORTANT 1sudo netstat -tnlp|grep sshd 注意上面监听的6010，Xmanager会把X DISPLAY选项自动查找为Xshell。其他 PC X 服务器程序需由用户进行设置。如果PC X 服务器使用TCP 6000号端口，DISPLAY设置为“localhost:0.0” ，也就是说，X11的偏移量是6000，因此下面需要设置一个最终要的DISPLAY的值:10.0，如下 123export DISPLAY=:10.0或者export DISPLAY=localhost:10.0 测试X11 DISPLAY如果本地已经有需要X11界面展示的应用，直接运行查看即可，如无，推荐使用xclock检查是否生效[以下步骤不是必须，自行选择] 1sudo yum install xclock 这里可能出现乱码之类的，可能需要安装x窗口相关包，和字体显示包 1sudo yum groupinstall \"X Window System\" \"Fonts\" 然后执行xclock，看是否在PC桌面显示对应的时钟图形。如果xclock出现Warning: Missing charsets in String to FontSet conversion，可以执行下面执行，然后重新执行 1export LC_ALL=C","categories":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/categories/Linux/"}],"tags":[{"name":"X11 Display","slug":"X11-Display","permalink":"https://vincentruan.github.io/tags/X11-Display/"},{"name":"XSHELL","slug":"XSHELL","permalink":"https://vincentruan.github.io/tags/XSHELL/"}]},{"title":"Hexo添加Gitalk评论插件","slug":"Hexo添加Gitalk评论插件","date":"2018-06-01T15:55:56.000Z","updated":"2018-06-01T16:18:58.699Z","comments":true,"path":"2018/06/01/Hexo添加Gitalk评论插件/","link":"","permalink":"https://vincentruan.github.io/2018/06/01/Hexo添加Gitalk评论插件/","excerpt":"","text":"安装Gitalk提供了两种方式： 直接引入 1234567&lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css\"&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js\"&gt;&lt;/script&gt;&lt;!-- or --&gt;&lt;link rel=\"stylesheet\" href=\"https://unpkg.com/gitalk/dist/gitalk.css\"&gt;&lt;script src=\"https://unpkg.com/gitalk/dist/gitalk.min.js\"&gt;&lt;/script&gt; npm安装 123npm i --save gitalkimport &apos;gitalk/dist/gitalk.css&apos;import Gitalk from &apos;gitalk&apos; 相对来说第一种会更简单。 使用A GitHub Application is needed for authorization, if you don’t have one, Click here to register a new one. Note: You must specify the website domain url in the Authorization callback URL field. 1234567891011const gitalk = new Gitalk(&#123; clientID: &apos;GitHub Application Client ID&apos;, clientSecret: &apos;GitHub Application Client Secret&apos;, repo: &apos;GitHub repo&apos;, owner: &apos;GitHub repo owner&apos;, admin: [&apos;GitHub repo owner and collaborators, only these guys can initialize github issues&apos;], id: location.pathname, // Ensure uniqueness and length less than 50 distractionFreeMode: false // Facebook-like distraction free mode&#125;)gitalk.render(&apos;gitalk-container&apos;) 修改主题文件 这里以next主题为例，参考Feature: Add Gitalk Support 不同的主题目录和模板引擎不同，可以自己修改, 修改next主题配置文件_config.yml，添加字段： 12345678910# Gitalk# more info please open https://github.com/gitalk/gitalkgitalk: enable: false clientID: clientSecret: repo: owner: admin: # support multiple admins split with comma, e.g. foo,bar pagerDirection: first 找到next/layout/_third-party/comments文件夹，新建gitalk.swig文件，代码如下： 1234567891011121314151617181920&#123;% if not (theme.duoshuo and theme.duoshuo.shortname) and not theme.duoshuo_shortname %&#125; &#123;% if theme.gitalk.enable %&#125; &#123;% if page.comments %&#125; &lt;script src=&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; const gitalk = new Gitalk(&#123; clientID: &apos;&#123;&#123;theme.gitalk.clientID&#125;&#125;&apos;, clientSecret: &apos;&#123;&#123;theme.gitalk.clientSecret&#125;&#125;&apos;, repo: &apos;&#123;&#123;theme.gitalk.repo&#125;&#125;&apos;, owner: &apos;&#123;&#123;theme.gitalk.owner&#125;&#125;&apos;, admin: &apos;&#123;&#123;theme.gitalk.admin&#125;&#125;&apos;.split(&apos;,&apos;), pagerDirection: &apos;&#123;&#123;theme.gitalk.pagerDirection&#125;&#125;&apos;, // facebook-like distraction free mode distractionFreeMode: false &#125;) gitalk.render(&apos;gitalk-container&apos;) &lt;/script&gt; &#123;% endif %&#125; &#123;% endif %&#125;&#123;% endif %&#125; 同目录下在index.swig文件末尾添加： 1&#123;% include &apos;gitalk.swig&apos; %&#125; 下步搞起，next/layout/_partials文件夹下，找到comments.swig文件，添加代码： 123&#123;% elseif theme.gitalk.enable %&#125; &lt;div id=&quot;gitalk-container&quot;&gt;&lt;/div&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;&gt; 因为github限制了issue的提交title长度不能超过50，可能会遇到Error: Validation Failed 按照这里的方案，使用MD5的方式降低长度即可 参考文档 Hexo添加Gitalk评论插件 Next 第三方服务集成 在hexo next主题上使用gitalk","categories":[{"name":"Hexo使用攻略","slug":"Hexo使用攻略","permalink":"https://vincentruan.github.io/categories/Hexo使用攻略/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://vincentruan.github.io/tags/hexo/"}]},{"title":"Hexo集成Algolia搜索插件","slug":"Hexo集成Algolia搜索插件","date":"2018-06-01T15:14:36.000Z","updated":"2018-06-01T15:17:31.107Z","comments":true,"path":"2018/06/01/Hexo集成Algolia搜索插件/","link":"","permalink":"https://vincentruan.github.io/2018/06/01/Hexo集成Algolia搜索插件/","excerpt":"","text":"本文转载自Hexo集成Algolia搜索插件 前言个人博客自从2016年10月21日搭建以来，迄今为止已经有49 篇日志了。虽然不是很多篇文章，但是搜索站内的内容已经力不从心了。 搜索了网上很多关于“Hexo 站内搜索”的内容，发现大部分都是使用Swiftype，但是发现Swiftype 搜索只有15 天的免费，之后就需要开始收费了。 因为只是为自己的个人博客 使用站内搜索，所以希望找一个类似与Swiftype 的，但是免费的站内搜索。最后找了Algolia 这个免费版本替代。 下面简单说下搭建过程： 搭建过程前提条件如果你的Next 版本为5.1.0 之后，可以使用Algolia。如果不是，请先升级到5.1.0 版本之后 一个Algolia 帐号官网地址 使用GitHub 或Google 帐号登录。 创建Index进入Dashboard，选择Indices 新建一个Index。 安装Hexo AlgoliaIndex 创建完成后，此时Index 为包含任何数据。需要安装Hexo Aloglia 扩展，这个扩展的功能是搜集站点的内容并通过API 发送给Aloglia。前往站点根目录，执行命令安装： 1npm install --save hexo-algolia 获取Key，更新站点信配置点击Dashborad 左侧的API Keys，其中的信息接下来将会被用到。包括Application ID 、Search-Only API Key 和 Admin API Key，其中Admin API Key需要保密保存 编辑站点配置文件，新增以下配置： 123456algolia: applicationID: &apos;SV57WJ53OS&apos; apiKey: &apos;c7d219504e44d09ab55f5f7a195fce98&apos; adminApiKey: &apos;adminApiKey&apos; indexName: &apos;dev_jobbymsblog&apos; chunkSize: 5000 更新Index当配置完成，在站点根目录下执行hexo algolia 来更新Index。请注意观察命令的输出。 主题集成更改主题配置文件，找到Algolia Search 配置部分： 123456789# Algolia Searchalgolia_search: enable: false hits: per_page: 10 labels: input_placeholder: Search for Posts hits_empty: &quot;We didn&apos;t find any results for the search: $&#123;query&#125;&quot; hits_stats: &quot;$&#123;hits&#125; results found in $&#123;time&#125; ms&quot; 将enable 改为true 即可，根据需要你可以调整labels 中的文本。 问题11. 点击搜索结果，结果跳转地址为： 1Cannot GET /undefined/ 按照5.1.0使用algolia搜索问题这里进行的处理，在这里总结一下： 因为hexo-aloglia 的作者没有把post.path 加入index，所以data.path 是undefined。 遇到这个问题，首先运行npm uninstll hexo-algolia 卸载之前的版本，再运行npm install hexo-algolia@0.2.0 --save,最后运行hexo algolia 命令重新index 就可以了。 参考文档 Swiftype站内搜索 Next 第三方服务集成","categories":[{"name":"Hexo使用攻略","slug":"Hexo使用攻略","permalink":"https://vincentruan.github.io/categories/Hexo使用攻略/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://vincentruan.github.io/tags/Hexo/"},{"name":"Algolia","slug":"Algolia","permalink":"https://vincentruan.github.io/tags/Algolia/"}]},{"title":"Linux xmr-stak挖矿教程","slug":"Linux-xmr-stak挖矿教程","date":"2018-05-27T13:51:10.000Z","updated":"2018-06-08T17:29:23.624Z","comments":true,"path":"2018/05/27/Linux-xmr-stak挖矿教程/","link":"","permalink":"https://vincentruan.github.io/2018/05/27/Linux-xmr-stak挖矿教程/","excerpt":"","text":"在Linux上编译 xmr-stakInstall DependenciesAMD APP SDK 3.0 (only needed to use AMD GPUs) download and install the latest version from https://www.dropbox.com/sh/mpg882ekirnsfa7/AADWz5X-TgVdsmWt0QwMgTWLa/AMD-APP-SDKInstaller-v3.0.130.136-GA-linux64.tar.bz2?dl=0(do not wonder why it is a link to a dropbox but AMD has removed the SDK downloads, see https://community.amd.com/thread/228059) Cuda 8.0+ (only needed to use NVIDIA GPUs) download and install https://developer.nvidia.com/cuda-downloads for minimal install choose Custom installation options during the install and select CUDA/Develpment CUDA/Runtime Driver components GNU Compiler12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# Ubuntu / Debiansudo apt install libmicrohttpd-dev libssl-dev cmake build-essential libhwloc-devgit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake ..make install# Archsudo pacman -S --needed base-devel hwloc openssl cmake libmicrohttpdgit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake ..make install# Fedorasudo dnf install gcc gcc-c++ hwloc-devel libmicrohttpd-devel libstdc++-static make openssl-devel cmakegit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake ..make install# CentOSsudo yum install centos-release-scl epel-releasesudo yum install cmake3 devtoolset-4-gcc* hwloc-devel libmicrohttpd-devel openssl-devel makescl enable devtoolset-4 bashgit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake3 ..make install# Ubuntu 14.04sudo add-apt-repository ppa:ubuntu-toolchain-r/testsudo apt updatesudo apt install gcc-5 g++-5 makesudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 1 --slave /usr/bin/g++ g++ /usr/bin/g++-5curl -L http://www.cmake.org/files/v3.4/cmake-3.4.1.tar.gz | tar -xvzf - -C /tmp/cd /tmp/cmake-3.4.1/ &amp;&amp; ./configure &amp;&amp; make &amp;&amp; sudo make install &amp;&amp; cd -sudo update-alternatives --install /usr/bin/cmake cmake /usr/local/bin/cmake 1 --forcesudo apt install libmicrohttpd-dev libssl-dev libhwloc-devgit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake ..make install# TinyCore Linux 8.x# TinyCore is 32-bit only, but there is an x86-64 port, known as &quot;Pure 64,&quot;# hosted on the TinyCore home page, and it works well.# Beware that huge page support is not enabled in the kernel distributed# with Pure 64. Consider http://wiki.tinycorelinux.net/wiki:custom_kernel# Note that as of yet there are no distro packages for microhttpd or hwloc.# hwloc is easy enough to install manually though, shown below.# Also note that only CPU mining has been tested on this platform, thus the# disabling of CUDA and OpenCL shown below.tce-load -iw openssl-dev.tcz cmake.tcz make.tcz gcc.tcz git.tcz \\ glibc_base-dev.tcz linux-4.8.1_api_headers.tcz \\ glibc_add_lib.tczwget https://www.open-mpi.org/software/hwloc/v1.11/downloads/hwloc-1.11.8.tar.gztar xzvf hwloc-1.11.8.tar.gzcd hwloc-1.11.8./configure --prefix=/usr/localmakesudo make installcd ..git clone http://github.com/fireice-uk/xmr-stakcd xmr-stakmkdir buildcd buildCC=gcc cmake .. -DCUDA_ENABLE=OFF \\ -DOpenCL_ENABLE=OFF \\ -DMICROHTTPD_ENABLE=OFFmake install g++ version 5.1 or higher is required for full C++11 support.If you want to compile the binary without installing libraries / compiler or just compile binary for some other distribution, please check the build_xmr-stak_docker.sh script. Some newer gcc versions are not supported by CUDA (e.g. Ubuntu 17.10). It will require installing gcc 5 but you can avoid changing defaults. In that case you can force CUDA to use an older compiler in the following way:1cmake -DCUDA_HOST_COMPILER=/usr/bin/gcc-5 .. To do a generic and static build for a system without gcc 5.1+1234cmake -DCMAKE_LINK_STATIC=ON -DXMR-STAK_COMPILE=generic .make installcd bin\\Releasecopy C:\\xmr-stak-dep\\openssl\\bin\\* . Note - cmake caches variables, so if you want to do a dynamic build later you need to specify ‘-DCMAKE_LINK_STATIC=OFF’ Reference xmr-stak","categories":[{"name":"block-chain","slug":"block-chain","permalink":"https://vincentruan.github.io/categories/block-chain/"}],"tags":[{"name":"xmr","slug":"xmr","permalink":"https://vincentruan.github.io/tags/xmr/"}]},{"title":"Day 1: Bower —— 管理你的客户端依赖关系","slug":"Day-1-Bower-——-管理你的客户端依赖关系","date":"2018-05-26T14:27:38.000Z","updated":"2018-05-26T14:40:10.462Z","comments":true,"path":"2018/05/26/Day-1-Bower-——-管理你的客户端依赖关系/","link":"","permalink":"https://vincentruan.github.io/2018/05/26/Day-1-Bower-——-管理你的客户端依赖关系/","excerpt":"","text":"编者注：我们发现了比较有趣的系列文章《30天学习30种新技术》，准备翻译，一天一篇更新，年终礼包。以下是第一天技术的译文。 我决定将第一天的学习主题选为Bower。 什么是Bower？Bower是一个客户端技术的软件包管理器，它可用于搜索、安装和卸载如JavaScript、HTML、CSS之类的网络资源。其他一些建立在Bower基础之上的开发工具，如YeoMan和Grunt，这个会在以后的文章中介绍。 为什么我会在意Bower？ 节省时间。为什么要学习Bower的第一个原因，就是它会为你节省寻找客户端的依赖关系的时间。每次我需要安装jQuery的时候，我都需要去jQuery网站下载包或使用CDN版本。但是有了Bower，你只需要输入一个命令，jquery就会安装在本地计算机上，你不需要去记版本号之类的东西，你也可以通过Bower的info命令去查看任意库的信息。 脱机工作。Bower会在用户主目录下创建一个.bower的文件夹，这个文件夹会下载所有的资源、并安装一个软件包使它们可以离线使用。如果你熟悉Java，Bower即是一个类似于现在流行的Maven构建系统的.m2仓库。每次你下载任何资源库都将被安装在两个文件夹中 —— 一个在的应用程序文件夹，另一个在用户主目录下的.bower文件夹。因此，下一次你需要这个仓库时，就会用那个用户主目录下.bower中的版本。 可以很容易地展现客户端的依赖关系。你可以创建一个名为bower.json的文件，在这个文件里你可以指定所有客户端的依赖关系，任何时候你需要弄清楚你正在使用哪些库，你可以参考这个文件。 让升级变得简单。假设某个库的新版本发布了一个重要的安全修补程序，为了安装新版本，你只需要运行一个命令，bower会自动更新所有有关新版本的依赖关系。 前提准备为了安装bower，你首先需要安装如下文件： Node：下载最新版本的node.js NPM：NPM是node程序包管理器。它是捆绑在nodejs的安装程序上的，所以一旦你已经安装了node，NPM也就安装好了。 Git：你需要从git仓库获取一些代码包。 安装Bower一旦你已经安装了上面所说的所有必要文件，键入以下命令安装Bower： 1$ npm install -g bower 这行命令是Bower的全局安装，-g 操作表示全局。 开始使用Bower安装完bower之后就可以使用所有的bower命令了。可以键入help 命令来查看bower可以完成那些操作，如下： 1234567891011121314151617181920212223242526272829303132$ bower helpUsage: bower &lt;command&gt; [&lt;args&gt;] [&lt;options&gt;]Commands: cache Manage bower cache help Display help information about Bower home Opens a package homepage into your favorite browser info Info of a particular package init Interactively create a bower.json file install Install a package locally link Symlink a package folder list List local packages lookup Look up a package URL by name prune Removes local extraneous packages register Register a package search Search for a package by name update Update a local package uninstall Remove a local packageOptions: -f, --force Makes various commands more forceful -j, --json Output consumable JSON -l, --log-level What level of logs to report -o, --offline Do not hit the network -q, --quiet Only output important information -s, --silent Do not output anything, besides errors -V, --verbose Makes output more verbose --allow-root Allows running commands as root 包的安装Bower是一个软件包管理器，所以你可以在应用程序中用它来安装新的软件包。举例来看一下来如何使用Bower安装JQuery，在你想要安装该包的地方创建一个新的文件夹，键入如下命令： 1$ bower install jquery 上述命令完成以后，你会在你刚才创建的目录下看到一个bower_components的文件夹，其中目录如下： 123456789101112131415$ tree bower_components/bower_components/└── jquery ├── README.md ├── bower.json ├── component.json ├── composer.json ├── jquery-migrate.js ├── jquery-migrate.min.js ├── jquery.js ├── jquery.min.js ├── jquery.min.map └── package.json1 directory, 10 files 包的使用现在就可以在应用程序中使用jQuery包了，在jQuery里创建一个简单的html5文件： 12345678910111213141516171819202122&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Learning Bower&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;button&gt;Animate Me!!&lt;/button&gt;&lt;div style=&quot;background:red;height:100px;width:100px;position:absolute;&quot;&gt;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;bower_components/jquery/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; $(document).ready(function()&#123; $(&quot;button&quot;).click(function()&#123; $(&quot;div&quot;).animate(&#123;left:&apos;250px&apos;&#125;); &#125;); &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 正如你所看到的，你刚刚引用jquery.min.js文件，现阶段完成。 所有包的列表如果你想找出所有安装在应用程序中的包，可以使用list命令： 1234$ bower listbower check-new Checking for new versions of the project dependencies..blog /Users/shekhargulati/day1/blog└── jquery#2.0.3 extraneous 包的搜索假如你想在你的应用程序中使用twitter的bootstrap框架，但你不确定包的名字，这时你可以使用search 命令： 123456$ bower search bootstrapSearch results: bootstrap git://github.com/twbs/bootstrap.git angular-bootstrap git://github.com/angular-ui/bootstrap-bower.git sass-bootstrap git://github.com/jlong/sass-twitter-bootstrap.git 包的信息如果你想看到关于特定的包的信息，可以使用info 命令来查看该包的所有信息： 1234567891011121314151617181920212223242526272829$ bower info bootstrapbower bootstrap#* not-cached git://github.com/twbs/bootstrap.git#*bower bootstrap#* resolve git://github.com/twbs/bootstrap.git#*bower bootstrap#* download https://github.com/twbs/bootstrap/archive/v3.0.0.tar.gzbower bootstrap#* extract archive.tar.gzbower bootstrap#* resolved git://github.com/twbs/bootstrap.git#3.0.0&#123; name: &apos;bootstrap&apos;, version: &apos;3.0.0&apos;, main: [ &apos;./dist/js/bootstrap.js&apos;, &apos;./dist/css/bootstrap.css&apos; ], ignore: [ &apos;**/.*&apos; ], dependencies: &#123; jquery: &apos;&gt;= 1.9.0&apos; &#125;, homepage: &apos;https://github.com/twbs/bootstrap&apos;&#125;Available versions: - 3.0.0 - 3.0.0-rc1 - 3.0.0-rc.2 - 2.3.2 ..... 如果你想得到单个包的信息，也可以使用info 命令： 12345678910111213141516171819$ bower info bootstrap#3.0.0bower bootstrap#3.0.0 cached git://github.com/twbs/bootstrap.git#3.0.0bower bootstrap#3.0.0 validate 3.0.0 against git://github.com/twbs/bootstrap.git#3.0.0&#123; name: &apos;bootstrap&apos;, version: &apos;3.0.0&apos;, main: [ &apos;./dist/js/bootstrap.js&apos;, &apos;./dist/css/bootstrap.css&apos; ], ignore: [ &apos;**/.*&apos; ], dependencies: &#123; jquery: &apos;&gt;= 1.9.0&apos; &#125;, homepage: &apos;https://github.com/twbs/bootstrap&apos;&#125; 包的卸载卸载包可以使用uninstall 命令： 1$ bower uninstall jquery bower.json文件的使用bower.json文件的使用可以让包的安装更容易，你可以在应用程序的根目录下创建一个名为“bower.json”的文件，并定义它的依赖关系。使用bower init 命令来创建bower.json文件： 123456789101112131415161718192021222324252627282930313233$ bower init[?] name: blog[?] version: 0.0.1[?] description:[?] main file:[?] keywords:[?] authors: Shekhar Gulati &lt;shekhargulati84@gmail.com&gt;[?] license: MIT[?] homepage:[?] set currently installed components as dependencies? Yes[?] add commonly ignored files to ignore list? Yes[?] would you like to mark this package as private which prevents it from being accidentally published to the registry? No&#123; name: &apos;blog&apos;, version: &apos;0.0.1&apos;, authors: [ &apos;Shekhar Gulati &lt;shekhargulati84@gmail.com&gt;&apos; ], license: &apos;MIT&apos;, ignore: [ &apos;**/.*&apos;, &apos;node_modules&apos;, &apos;bower_components&apos;, &apos;test&apos;, &apos;tests&apos; ], dependencies: &#123; jquery: &apos;~2.0.3&apos; &#125;&#125;[?] Looks good? Yes 可以查看该文件： 123456789101112131415161718&#123; &quot;name&quot;: &quot;blog&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;authors&quot;: [ &quot;Shekhar Gulati &lt;shekhargulati84@gmail.com&gt;&quot; ], &quot;license&quot;: &quot;MIT&quot;, &quot;ignore&quot;: [ &quot;**/.*&quot;, &quot;node_modules&quot;, &quot;bower_components&quot;, &quot;test&quot;, &quot;tests&quot; ], &quot;dependencies&quot;: &#123; &quot;jquery&quot;: &quot;~2.0.3&quot; &#125;&#125; 注意看，它已经加入了jQuery依赖关系。 现在假设也想用twitter bootstrap，我们可以用下面的命令安装twitter bootstrap并更新bower.json文件： 1$ bower install bootstrap --save 它会自动安装最新版本的bootstrap并更新bower.json文件： 12345678910111213141516171819&#123; &quot;name&quot;: &quot;blog&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;authors&quot;: [ &quot;Shekhar Gulati &lt;shekhargulati84@gmail.com&gt;&quot; ], &quot;license&quot;: &quot;MIT&quot;, &quot;ignore&quot;: [ &quot;**/.*&quot;, &quot;node_modules&quot;, &quot;bower_components&quot;, &quot;test&quot;, &quot;tests&quot; ], &quot;dependencies&quot;: &#123; &quot;jquery&quot;: &quot;~2.0.3&quot;, &quot;bootstrap&quot;: &quot;~3.0.0&quot; &#125;&#125; 这就是今天的学习，希望能让你对bower有个足够的了解，最好可以自己尝试一下。 原文 Day 1: Bower–Manage Your Client Side Dependencies翻译 SegmentFault","categories":[{"name":"30天学习30种新技术系列","slug":"30天学习30种新技术系列","permalink":"https://vincentruan.github.io/categories/30天学习30种新技术系列/"}],"tags":[{"name":"30天学习30种新技术系列","slug":"30天学习30种新技术系列","permalink":"https://vincentruan.github.io/tags/30天学习30种新技术系列/"}]},{"title":"30天学习30种新技术系列","slug":"30-天学习-30-种新技术系列","date":"2018-05-26T14:27:27.000Z","updated":"2018-05-26T14:49:45.231Z","comments":true,"path":"2018/05/26/30-天学习-30-种新技术系列/","link":"","permalink":"https://vincentruan.github.io/2018/05/26/30-天学习-30-种新技术系列/","excerpt":"","text":"编者注：我们发现了比较有趣的系列文章《30 天学习 30 种新技术》，准备翻译，一天一篇更新，年终礼包。以下是译文，英文标题表示还未翻译，附原文链接；中文标题表示已翻译，附译文链接。 更新：全系列已经全部翻译完成。 让你 30 天学习 30 种新技术，你会觉得这是挑战吗？ 我已经接受了挑战，我会在一个月的时间内每天学习一门新技术，挑战开始于 2013 年 10 月 29 日。下面就是我将要学习的新技术的列表，我会把每天学到的内容写出来。在我每天正常的工作之后，我会花几个小时学习一门新技术，再用一小时将今天学到的写在博客上。这项活动的目的是熟悉许多在开发者社区所使用的新技术。 我会把重点放在 JavaScript 及其相关技术的学习上，当然也会去了解一下像 Java 这类我比较感兴趣的其他技术。我也可能会在一门技术上花费好几天的时间，但我每次会选择和这门技术相关的不同的主题来讲。只要是有意义的，我将尽量展示它如何与 OpenShift 工作，我希望这是一次充满乐趣并能学到很多东西的旅程。（你可以在 twitter 上follow 我） 下边是学习列表： 2013.10.29 - Day 1: Bower —— 管理你的客户端依赖关系 2013.10.30 - Day 2: AngularJS —— 对 AngularJS 的初步认识 2013.10.31 - Day 3: Flask —— 使用 Python 和 OpenShift 进行即时 Web 开发 2013.11.01 - Day 4: PredictionIO —— 如何创建一个博客推荐器 2013.11.02 - Day 5: GruntJS —— 重复乏味的工作总会有人做（反正我不做） 2013.11.03 - Day 6: 在 Java 虚拟机上使用 Grails 进行快速 Web 开发 2013.11.04 - Day 7: GruntJS 在线重载 提升生产率至新境界 2013.11.05 - Day 8: Harp.JS —— 现代静态 Web 服务器 2013.11.06 - Day 9: TextBlob —— 对文本进行情感分析 2013.11.07 - Day 10: PhoneGap —— 开发手机应用如此简单 2013.11.08 - Day 11: AeroGear 推送服务器：使应用的通知推送变得简单 2013.11.09 - Day 12: OpenCV —— Java 开发者的人脸检测 2013.11.10 - Day 13: Dropwizard —— 非常棒的 Java REST 服务器栈 2013.11.11 - Day14：使用斯坦福 NER 软件包实现你自己的命名实体识别器（Named Entity Recognition，NER） 2013.11.12 - Day 15：Meteor —— 从零开始创建一个 Web 应用 2013.11.13 - Day 16: Goose Extractor —— 好用的文章提取工具 2013.11.14 - Day 17: 使用 JBoss Forge 和 OpenShift 构建部署 JAVA EE 6 应用 2013.11.15 - Day 18: BoilerPipe —— Java开发者的文章提取工具 2013.11.16 - Day 19: EmberJS 入门指南 2013.11.17 - Day 20: 斯坦福CoreNLP —— 用 Java 给 Twitter 情感分析 2013.11.18 - Day 21：Docker 入门教程 2013.11.19 - Day 22： 使用 Spring、MongoDB 和 AngularJS 开发单页面应用 2013.11.20 - Day 23： 使用 TimelineJS 构建精美的时间轴 2013.11.21 - Day 24: 使用 Yeoman 自动构建 Ember 项目 2013.11.22 - Day 25: Tornado —— 联合 Tornado、MongoDB 和 AngularJS 进行应用开发 2013.11.23 - Day 26: TogetherJS —— 让我们一起来编程！ 2013.11.24 - Day 27: Restify —— 在Node.js中构建正确的REST Web服务 2013.11.25 - Day 28: OpenShift 的 Eclipse 集成 2013.11.26 - Day 29: 编写你的第一个 Google Chrome 扩展程序 2013.11.27 - Day 30: Play Framework —— Java 开发者的梦想框架 原文 Learning 30 Technologies in 30 Days: A Developer Challenge翻译 SegmentFault","categories":[{"name":"30天学习30种新技术系列","slug":"30天学习30种新技术系列","permalink":"https://vincentruan.github.io/categories/30天学习30种新技术系列/"}],"tags":[{"name":"30天学习30种新技术系列","slug":"30天学习30种新技术系列","permalink":"https://vincentruan.github.io/tags/30天学习30种新技术系列/"}]},{"title":"教你免费搭建个人博客，Hexo&Github","slug":"教你免费搭建个人博客，Hexo-Github","date":"2018-05-26T09:39:47.000Z","updated":"2018-05-26T10:11:28.716Z","comments":true,"path":"2018/05/26/教你免费搭建个人博客，Hexo-Github/","link":"","permalink":"https://vincentruan.github.io/2018/05/26/教你免费搭建个人博客，Hexo-Github/","excerpt":"","text":"什么是 Hexo？https://hexo.io/zh-cn/docs/ Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 一、配置Github首先注册、登录 https://github.com/ 记住自己的Username（很重要） 然后右上角选择 Create a new repository https://github.com/new Repository name （填自己的名字） yourname.github.io(yourname与你的注册用户名一致,这个就是你博客的域名了) 例如，我的域名是github.com/zhihuya，就填入zhihuya.github.io。成功后出现下面的画面 二、环境安装（node、git）1、安装 Node.js https://nodejs.org/en/ 2、安装 Git https://github.com/waylau/git-for-win Git教程 https://github.com/waylau/git-for-win廖雪峰老师的教程，非常好。 3、安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，名称和邮箱是Github上的 4、安装 Hexo。所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。 1$ npm install -g hexo-cli （使用的cmder，超级好用~~。等待时间可能有点长） 好了到这一步我们环境全部安装好了。 三、设置在电脑F盘（自己随意）目录下新建文件夹 test，进入test，按住Shift键点击鼠标右键 因为我有安装Cmder，没有安装的点击“在此处打开命令窗口”，输入 1hexo init blog 稍微等待下，速度有点慢。成功提示 1INFO Start blogging with Hexo! 因为你初始化hexo 之后source目录下自带一篇hello world文章, 所以直接执行下方命令 123456$ hexo generate# 启动本地服务器$ hexo server# 在浏览器输入 http://localhost:4000/就可以看见网页和模板了INFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 访问http://localhost:4000/，便可以看到网站初步的模样，不要激动，我们还要把网页发布到Github上去。 重新打开CMD，输入： 1ssh-keygen -t rsa -C &quot;Github的注册邮箱地址&quot; 一路Enter过来就好，得到信息： 1Your public key has been saved in /c/Users/user/.ssh/id_rsa.pub. 找到该文件，打开（sublime text），Ctrl + a复制里面的所有内容，然后进入Sign in to GitHub：https://github.com/settings/ssh New SSH key ——Title：blog —— Key：输入刚才复制的—— Add SSH key 四、配置博客在blog目录下，用sublime打开_config.yml文件，修改参数信息 特别提醒，在每个参数的：后都要加一个空格 修改网站相关信息 123456title: 崔斯特测试所用博客subtitle: 副标题description: 网页描述author: 崔斯特language: zh-CNtimezone: Asia/Shanghai 配置部署（我的是zhihuya，修改成自己的） 1234deploy: type: git repo: https://github.com/zhihuya/zhihuya.github.io.git branch: master 五、发表文章在CMD中输入 12$ hexo new &quot;崔斯特测试文章&quot;INFO Created: F:\\test\\blog\\source\\_posts\\崔斯特测试文章.md 找到该文章，打开，使用Markdown语法，该语法介绍可以查看https://zhangslob.github.io/2017/02/26/%E5%88%A9%E7%94%A8HEXO%E6%90%AD%E5%BB%BA%E7%9A%84%E5%8D%9A%E5%AE%A2/ 123456---title: 崔斯特测试文章date: 2017-02-28 13:03:44tags:---这是一篇测试文章，欢迎关注作者博客[1]: https://zhangslob.github.io/ 保存，然后执行下列步骤： 12345678910111213141516F:\\test\\blog$ hexo cleanINFO Deleted database.INFO Deleted public folder.F:\\test\\blog$ hexo generateINFO Start processingINFO Files loaded in 1.48 s#省略INFO 29 files generated in 4.27 sF:\\test\\blog$ hexo serverINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 这个时候，打开http://localhost:4000/，发现刚才的文章已经成功了 最后一步，发布到网上，执行： 123456F:\\test\\blog$ hexo deployINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...#省略 其中会跳出Github登录，直接登录，如果没有问题输入zhihuya（换成你的）.github.io/ 崔斯特测试所用博客https://zhihuya.github.io/ 然后就可以看到已经发布了 六、总结发布文章的步骤： 1、hexo new 创建文章 2、Markdown语法编辑文章 3、部署（所有打开CMD都是在blog目录下） 1234hexo clean #清除缓存 网页正常情况下可以忽略此条命令hexo generate #生成hexo server #启动服务预览，非必要，可本地浏览网页hexo deploy #部署发布 简写Tips： hexo n “我的博客” == hexo new “我的博客” #新建文章 hexo p == hexo publish hexo g == hexo generate#生成 hexo s == hexo server #启动服务预览 hexo d == hexo deploy#部署 如果在执行 hexo deploy 后,出现 error deployer not found:github 的错误，执行： 1npm install hexo-deployer-git --save 出错是正常的，出错了自己先百度或google，实在不知道的可以询问我。 托管的话不仅有github可以用，还有个国内的https://coding.net/可选 引用说明 作者：zhangslob 链接：https://zhangslob.github.io/2017/02/28/教你免费搭建个人博客，Hexo-Github","categories":[{"name":"Hexo使用攻略","slug":"Hexo使用攻略","permalink":"https://vincentruan.github.io/categories/Hexo使用攻略/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://vincentruan.github.io/tags/hexo/"},{"name":"个人博客搭建","slug":"个人博客搭建","permalink":"https://vincentruan.github.io/tags/个人博客搭建/"},{"name":"github","slug":"github","permalink":"https://vincentruan.github.io/tags/github/"}]},{"title":"Hexo使用攻略-添加分类及标签","slug":"Hexo使用攻略-添加分类及标签","date":"2018-05-26T09:16:29.000Z","updated":"2018-06-01T16:19:04.056Z","comments":true,"path":"2018/05/26/Hexo使用攻略-添加分类及标签/","link":"","permalink":"https://vincentruan.github.io/2018/05/26/Hexo使用攻略-添加分类及标签/","excerpt":"","text":"1、创建“分类”选项1.1 生成“分类”页并添加tpye属性打开命令行，进入博客所在文件夹。执行命令 1$ hexo new page categories 成功后会提示： 1INFO Created: ~/Documents/blog/source/categories/index.md 根据上面的路径，找到index.md这个文件，打开后默认内容是这样的： 1234---title: 文章分类date: 2017-05-27 13:47:40--- 添加type: &quot;categories&quot;到内容中，添加后是这样的： 123456---title: 文章分类date: 2017-05-27 13:47:40type: &quot;categories&quot;comments: false--- 保存并关闭文件。 1.2 给文章添加“categories”属性打开需要添加分类的文章，为其添加categories属性。下方的categories: web前端表示添加这篇文章到“web前端”这个分类。注意：hexo一篇文章只能属于一个分类，也就是说如果在“- web前端”下方添加“-xxx”，hexo不会产生两个分类，而是把分类嵌套（即该文章属于 “- web前端”下的 “-xxx ”分类）。 123456---title: jQuery对表单的操作及更多应用date: 2017-05-26 12:12:57categories: - web前端--- 至此，成功给文章添加分类，点击首页的“分类”可以看到该分类下的所有文章。当然，只有添加了categories: xxx的文章才会被收录到首页的“分类”中。 2、创建“标签”选项2.1 生成“标签”页并添加tpye属性打开命令行，进入博客所在文件夹。执行命令 1$ hexo new page tags 成功后会提示： 1INFO Created: ~/Documents/blog/source/tags/index.md 根据上面的路径，找到index.md这个文件，打开后默认内容是这样的： 1234---title: 标签date: 2017-05-27 14:22:08--- 添加type: &quot;tags&quot;到内容中，添加后是这样的： 123456---title: 文章分类date: 2017-05-27 13:47:40type: &quot;tags&quot;comments: false--- 保存并关闭文件。 2.2 给文章添加“tags”属性打开需要添加标签的文章，为其添加tags属性。下方的tags:下方的- jQuery - 表格 - 表单验证就是这篇文章的标签了 12345678910---title: jQuery对表单的操作及更多应用date: 2017-05-26 12:12:57categories: - web前端tags:- jQuery- 表格- 表单验证--- 至此，成功给文章添加分类，点击首页的“标签”可以看到该标签下的所有文章。当然，只有添加了tags: xxx的文章才会被收录到首页的“标签”中。 细心的朋友可能已经发现，这两个的设置几乎一模一样！是的，没错，思路都是一样的。所以我们可以打开scaffolds/post.md文件，在tages:上面加入categories:,保存后，之后执行hexo new 文章名命令生成的文件，页面里就有categories:项了。 scaffolds目录下，是新建页面的模板，执行新建命令时，是根据这里的模板页来完成的，所以可以在这里根据你自己的需求添加一些默认值。","categories":[{"name":"Hexo使用攻略","slug":"Hexo使用攻略","permalink":"https://vincentruan.github.io/categories/Hexo使用攻略/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://vincentruan.github.io/tags/hexo/"}]},{"title":"Hexo Hello World","slug":"hexo-hello-world","date":"2018-05-26T09:16:29.000Z","updated":"2018-06-08T17:33:13.189Z","comments":true,"path":"2018/05/26/hexo-hello-world/","link":"","permalink":"https://vincentruan.github.io/2018/05/26/hexo-hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment hexo algolia12$ export HEXO_ALGOLIA_INDEXING_KEY=[algolia.apiKey]$ hexo algolia CI with jenkins使用Jenkins实现Hexo自动部署 hexo使用jenkins自动部署到阿里云 ###Cooperation 使用git clonegit@github.com:vincentruan/vincentruan.github.io.git拷贝仓库（git checkout -b hexo）； 在新拷贝的vincentruan.github.io文件夹下通过Git bash依次执行下列指令： npm install hexo-cli -g(首次安装)、npm install hexo、npm install、npm install hexo-deployer-git（记得，不需要hexo init这条指令,如果不慎在此时用了hexo init，则站点的配置文件_config.yml里面内容会被清空使用默认值，所以这一步一定要慎重 ）","categories":[{"name":"Hexo使用攻略","slug":"Hexo使用攻略","permalink":"https://vincentruan.github.io/categories/Hexo使用攻略/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://vincentruan.github.io/tags/hexo/"}]},{"title":"Markdown吃了吗?","slug":"Markdown吃了吗","date":"2018-05-20T11:00:56.000Z","updated":"2020-02-17T02:40:44.656Z","comments":true,"path":"2018/05/20/Markdown吃了吗/","link":"","permalink":"https://vincentruan.github.io/2018/05/20/Markdown吃了吗/","excerpt":"","text":"markdown 介绍 Markdown 是一种轻量级标记语言，它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML(或者HTML)文档”。 - wikipedia Daring Fireball: Markdown Project markdown Markdown wikipedia 介绍 MultiMarkdown 引入更多标记特性和输出选项的改进版Markdown why markdown 纯文本，兼容性极强，可以用任意文本编辑器打开. 语法简单（the syntax is so simple you can barely call it “syntax.”），零学习成本，极好的可读性，让你专注于文字写作而不是页面排版，并且兼容 HTML，simple but powerful . 格式转换方便，Markdown 的文本你可以轻松转换为 html、pdf、epub、电子书等。 适合团队协作，可以使用 git/svn 等进行版本控制管理。 阳志平：为什么 Markdown 成为科技界写作主流？ 图灵社区：用Markdown来写自由书籍-开源技术的方案 目前很多在线服务商均支持使用markdown编写： Github 最先支持，使用Markdown的一个分支版本来格式化评论、消息以及其它内容。 Stack Overflow 使用一种 Markdown 的分支作为它的文章格式化系统。 博客园 国内技术人的博客家园，每天活跃上万用户，高质量社区。 CSDN 号称全球最大中文IT社区，涵盖了多种语言、架构、博客、俱乐部等模块的技术论坛。 图灵社区 使用markdown语法供用户写作电子书. 简书 重拾文字的力量，交流故事，沟通想法，一个基于内容分享的社区。 为知笔记 国内顶尖笔记软件，支持使用Markdown语法编辑笔记。 有道云笔记 最新版本开始支持，并且支持一些扩展语法。 …… markdown 使用 Markdown: Basics （快速入门） Markdown 完整语法说明 (简体中文版) Github: Mastering Markdown GitHub 帮助中关于 Markdown 的语法帮助 MarkDown 语法团队规范 语法规范简洁版 Markdown Style Guide 语法规范复杂版 Markdown Cheatsheet GitHub Flavored Markdown GitHub 使用的 Markdown 语法，略微不同于标准 Markdown 语法。提供了一些更加简洁的语法，类似 URL autolinking, Strikethrough, Fenced code blocks, Syntax highlighting 等等 MultiMarkdown 介绍 对 markdown 进行的扩展功能 markdown 工具 马克飞象 web/chrome 离线客户端，markdown 全功能支持，最大特点内容能够同步到印象笔记（evernote）中，笔记的用户重度推荐，按年收费，目前作者 @weibo 正在开发跨平台的客户端。 StackEdit 在线 markdown 编辑器，可同步文档到Google Drive和 Dropbox，可发布文章到 Blogger，GitHub，Google Drive，Dropbox，Tumblr和WordPress。 cmd 作业部落 支持 win/mac/linux/web/chrome 全平台，支持实时同步预览，支持代码高亮、数学公式，区分写作和阅读模式，支持在线存储，分享文稿网址。 MacDown OSX 上的 Markdown 开源编辑器，支持代码高亮，实时预览等。 MarkdownPad Windows上的全功能Markdown编辑器，推荐win上使用，基本全部功能。 Marked2 多种 md 显示方案，不能够编辑文件，只用来展示文件，配合 subline text markdown edit 插件，完美使用； MWeb 专业的 Markdown 写作、记笔记、静态博客生成软件，由国内独立开发者@oulvhai开发，支持Toc、Table、代码高亮、支持发布到 Wordrpess 博客、支持 Metaweblog API 的博客服务、Wordpress.com、Evernote 和印象笔记、Blogger、Scriptogr.am、Tumblr等服务。 Haroopad 又一款简洁多功能的跨平台编辑器，全功能支持，再加上对社交网络友好的连接，多种主题等，感兴趣的可以看看。详情参考issue#1 Typora 不分栏，实时展示看到写出的内容，对于不喜欢「两栏」设计的人来说是一个选择 MarkEditor - ME MarkEditor以markdown为基础语法，多标签栏、文件夹结构，纯文本的方式带来优雅、高效的体验。 确实很棒的工具，带来很多新鲜的理念，支持、重构、提升 markdown，加快写作的体验。具体可以查看几篇评测文章： 简洁与强大，从不是矛盾的事物：写作工具 MarkEditor 功能详解 不止是一款简单的码字工具：MarkEditor 进阶功能介绍 码字必备：18 款优秀的 Markdown 写作工具 | 2015 年度盘点 喜欢哪一款，就看你的了。 这几款就够了，多了就有选择症 …… markdown流程图1.1 流程图1.1 横向流程图源码格式:graph LR A[方形] --> B(圆角) B --> C{条件a} C --> |a=1| D[结果1] C --> |a=2| E[结果2] F[横向流程图] 1.2 竖向流程图源码格式:graph TD A[方形] --> B(圆角) B --> C{条件a} C --> |a=1| D[结果1] C --> |a=2| E[结果2] F[竖向流程图] 1.3 标准流程图源码格式:123456789st=&gt;start: 开始框op=&gt;operation: 处理框cond=&gt;condition: 判断框sub1=&gt;subroutine: 子流程io=&gt;inputoutput: 输入输出框e=&gt;end: 结束框st-&gt;op-&gt;condcond(yes)-&gt;io-&gt;econd(no)-&gt;sub1(right)-&gt;op 1.4 标准流程图源码格式(横向):123456789st=&gt;start: 开始框op=&gt;operation: 处理框cond=&gt;condition: 判断框(是或否?)sub1=&gt;subroutine: 子流程io=&gt;inputoutput: 输入输出框e=&gt;end: 结束框st(right)-&gt;op(right)-&gt;condcond(yes)-&gt;io(bottom)-&gt;econd(no)-&gt;sub1(right)-&gt;op 1.2 UML时序图1.2.1 UML时序图源码样例:12345对象A-&gt;对象B: 对象B你好吗? (请求)Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B --&gt; 对象A: 我很好(响应)对象A --&gt; 对象B: 你真的好吗? 1.2.2 UML时序图源码复杂样例:1234567891011Title: 标题: 复杂使用对象A -&gt; 对象B: 对象B你好吗? (请求)Note right of 对象B: 对象B的描述Note right of 对象A: 对象A的描述(提示)对象B --&gt; 对象A: 我很好(响应)对象B --&gt; 小三: 你好吗?小三 -&gt; 对象A: 对象B找我了对象A --&gt; 对象B: 你真的好吗?Note over 小三, 对象B: 我们是朋友participant CNote right of C: 没人陪我玩 1.2.3 UML标准时序图样例:%%时序图例子, -> 实线, --> 虚线, ->> 实线箭头 sequenceDiagram participant 张三 participant 李四 张三 -> 王五: 王五你好吗? loop 健康检查 王五 -> 王五: 与疾病战斗 end Note right of 王五: 合理饮食 看医生... 李四 ->> 张三: 很好! 王五 -> 李四: 你怎么样? 李四 --> 王五: 很好! 1.3 甘特图样例:%%语法示例 gantt dateFormat YYYY-MM-DD title 软件开发甘特图 section 设计 需求 :done, des1, 2014-01-06, 2014-01-08 原型 :active, des2, 2014-01-09, 3d UI设计 :des3, after des2, 5d 未来任务: :des4, after des3, 5d section 开发 学习准备理解需求 :crit, done, 2014-01-06, 24h 设计框架 :crit, done, after des2, 2d 开发 :crit, active, 3d 未来任务 :crit, 5d 耍 :2d section 测试 功能测试 :active, a1, after des3, 3d 压力测试 :after a1, 20h 测试报告 :48h 数学公式矩阵方程$$\\begin{matrix} 1 &amp; x &amp; x^2 \\ 1 &amp; y &amp; y^2 \\ 1 &amp; z &amp; z^2 \\ \\end{matrix}$$ reference 参考 Why Markdown? A two-minute explanation 简书：献给写作者的 Markdown 新手指南 Markdown simple world MathJax语法规则 Mermaid语法规则 Mermaid官方教程 Mermaid Github仓库 [MathJax Github仓库](https://github.com/mathjax/MathJax","categories":[{"name":"Hexo使用攻略","slug":"Hexo使用攻略","permalink":"https://vincentruan.github.io/categories/Hexo使用攻略/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://vincentruan.github.io/tags/markdown/"},{"name":"流程图","slug":"流程图","permalink":"https://vincentruan.github.io/tags/流程图/"}]}]}