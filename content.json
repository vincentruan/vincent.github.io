{"meta":{"title":"星辰大海","subtitle":"My Conquest Is the Sea of Stars.","description":"The King is dead, long live the King!","author":"Vincent","url":"https://vincentruan.github.io"},"pages":[{"title":"about","date":"2020-02-24T08:30:26.000Z","updated":"2020-02-24T09:18:55.016Z","comments":true,"path":"about/index.html","permalink":"https://vincentruan.github.io/about/index.html","excerpt":"","text":"123456《鹧鸪天*欲上高楼去避愁》 --- 宋 * 辛弃疾欲上高楼去避愁，愁还随我上高楼。经行几处江山改，多少亲朋尽白头。归休去，去休归，不成人总要封侯？浮云出处元无定，得似浮云也自由。"},{"title":"tags","date":"2018-05-26T09:22:14.000Z","updated":"2018-05-26T09:22:57.773Z","comments":false,"path":"tags/index.html","permalink":"https://vincentruan.github.io/tags/index.html","excerpt":"","text":""},{"title":"文章分类","date":"2018-05-26T09:18:05.000Z","updated":"2018-05-26T09:19:34.334Z","comments":false,"path":"categories/index.html","permalink":"https://vincentruan.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Java开发必须掌握的线上问题排查命令 - 常见命令、JPS、JSTACK、JMAP、JSTAT、JHAT、JINFO、JAVAP等","slug":"Java开发必须掌握的线上问题排查命令-常见命令、JPS、JSTACK、JMAP、JSTAT、JHAT、JINFO、JAVAP等","date":"2020-06-06T14:29:47.000Z","updated":"2020-06-06T15:42:40.104Z","comments":true,"path":"2020/06/06/Java开发必须掌握的线上问题排查命令-常见命令、JPS、JSTACK、JMAP、JSTAT、JHAT、JINFO、JAVAP等/","link":"","permalink":"https://vincentruan.github.io/2020/06/06/Java开发必须掌握的线上问题排查命令-常见命令、JPS、JSTACK、JMAP、JSTAT、JHAT、JINFO、JAVAP等/","excerpt":"本文转载自java命令学习系列，文章内容略有调整。 Java开发必须掌握的线上问题排查命令作为一个合格的开发人员，不仅要能写得一手还代码，还有一项很重要的技能就是排查问题。这里提到的排查问题不仅仅是在coding的过程中debug等，还包括的就是线上问题的排查。由于在生产环境中，一般没办法debug（其实有些问题，debug也白扯。。。）,所以我们需要借助一些常用命令来查看运行时的具体情况，这些运行时信息包括但不限于运行日志、异常堆栈、堆使用情况、GC情况、JVM参数情况、线程情况等。 给一个系统定位问题的时候，知识、经验是关键，数据是依据，工具是运用知识处理数据的手段。为了便于我们排查和解决问题，Sun公司为我们提供了一些常用命令。这些命令一般都是jdk/lib/tools.jar中类库的一层薄包装。随着JVM的安装一起被安装到机器中，在bin目录中。下面就来认识一下这些命令以及具体使用方式。","text":"本文转载自java命令学习系列，文章内容略有调整。 Java开发必须掌握的线上问题排查命令作为一个合格的开发人员，不仅要能写得一手还代码，还有一项很重要的技能就是排查问题。这里提到的排查问题不仅仅是在coding的过程中debug等，还包括的就是线上问题的排查。由于在生产环境中，一般没办法debug（其实有些问题，debug也白扯。。。）,所以我们需要借助一些常用命令来查看运行时的具体情况，这些运行时信息包括但不限于运行日志、异常堆栈、堆使用情况、GC情况、JVM参数情况、线程情况等。 给一个系统定位问题的时候，知识、经验是关键，数据是依据，工具是运用知识处理数据的手段。为了便于我们排查和解决问题，Sun公司为我们提供了一些常用命令。这些命令一般都是jdk/lib/tools.jar中类库的一层薄包装。随着JVM的安装一起被安装到机器中，在bin目录中。下面就来认识一下这些命令以及具体使用方式。 jps功能显示当前所有java进程pid的命令。 常用指令jps：显示当前用户的所有java进程的PID jps -v 3331：显示虚拟机参数 jps -m 3331：显示传递给main()函数的参数 jps -l 3331：显示主类的全路径 jinfo功能实时查看和调整虚拟机参数，可以显示未被显示指定的参数的默认值（jps -v 则不能）。 jdk8中已经不支持该命令。 常用指令jinfo -flag CMSIniniatingOccupancyFration 1444：查询CMSIniniatingOccupancyFration参数值 jstat功能显示进程中的类装载、内存、垃圾收集、JIT编译等运行数据。 常用指令jstat -gc 3331 250 20 ：查询进程2764的垃圾收集情况，每250毫秒查询一次，一共查询20次。 jstat -gccause：额外输出上次GC原因 jstat -calss：件事类装载、类卸载、总空间以及所消耗的时间 jmap功能生成堆转储快照（heapdump） 常用指令jmap -heap 3331：查看java 堆（heap）使用情况 jmap -histo 3331：查看堆内存(histogram)中的对象数量及大小 jmap -histo:live 3331：JVM会先触发gc，然后再统计信息 jmap -dump:format=b,file=heapDump 3331：将内存使用的详细情况输出到文件，之后一般使用其他工具进行分析。 jhat功能一般与jmap搭配使用，用来分析jmap生成的堆转储文件。 由于有很多可视化工具（Eclipse Memory Analyzer 、IBM HeapAnalyzer）可以替代，所以很少用。不过在没有可视化工具的机器上也是可用的。 常用指令jmap -dump:format=b,file=heapDump 3331 + jhat heapDump：解析Java堆转储文件,并启动一个 web server jstack功能生成当前时刻的线程快照。 常用指令jstack 3331：查看线程情况 jstack -F 3331：正常输出不被响应时，使用该指令 jstack -l 3331：除堆栈外，显示关于锁的附件信息 常见问题定位过程频繁GC问题或内存溢出问题一、使用jps查看线程ID 二、使用jstat -gc 3331 250 20 查看gc情况，一般比较关注PERM区的情况，查看GC的增长情况。 三、使用jstat -gccause：额外输出上次GC原因 四、使用jmap -dump:format=b,file=heapDump 3331生成堆转储文件 五、使用jhat或者可视化工具（Eclipse Memory Analyzer 、IBM HeapAnalyzer）分析堆情况。 六、结合代码解决内存溢出或泄露问题。 死锁问题一、使用jps查看线程ID，转换为16进制1printf %x 线程号 二、使用jstack 3331：查看线程情况 结语经常使用适当的虚拟机监控和分析工具可以加快我们分析数据、定位解决问题的速度，但也要知道，工具永远都是知识技能的一层包装，没有什么工具是包治百病的。 Java命令学习系列（零）— 常见命令及Java Dump介绍常用命令：在JDK的bin目彔下,包含了java命令及其他实用工具。 jps:查看本机的Java中进程信息。 jstack:打印线程的栈信息,制作线程Dump。 jmap:打印内存映射,制作堆Dump。 jstat:性能监控工具。 jhat:内存分析工具。 jconsole:简易的可视化控制台。 jvisualvm:功能强大的控制台。 认识Java Dump：什么是Java Dump？ Java虚拟机的运行时快照。将Java虚拟机运行时的状态和信息保存到文件。 线程Dump,包含所有线程的运行状态。纯文本格式。 堆Dump,包含线程Dump,幵包含所有堆对象的状态。二进制格式。 Java Dump有什么用？ 补足传统Bug分析手段的不足: 可在任何Java环境使用;信息量充足。 针对非功能正确性的Bug,主要为:多线程幵发、内存泄漏。 制作Java Dump使用Java虚拟机制作Dump 指示虚拟机在发生内存不足错误时,自动生成堆Dump 1-XX:+HeapDumpOnOutOfMemoryError 使用图形化工具制作Dump 使用JDK(1.6)自带的工具:Java VisualVM。 使用命令行制作Dump jstack:打印线程的栈信息,制作线程Dump。 jmap:打印内存映射,制作堆Dump。 步骤： 检查虚拟机版本（java -version） 找出目标Java应用的进程ID（jps） 使用jstack命令制作线程Dump• Linux环境下使用kill命令制作线程Dump 使用jmap命令制作堆Dump Java命令学习系列（一）— Jps jps位于jdk的bin目录下，其作用是显示当前系统的java进程情况，及其id号。 jps相当于Solaris进程工具ps。不象”pgrep java”或”ps -ef grep java”，jps并不使用应用程序名来查找JVM实例。因此，它查找所有的Java应用程序，包括即使没有使用java执行体的那种（例如，定制的启动 器）。另外，jps仅查找当前用户的Java进程，而不是当前系统中的所有进程。 位置我们知道，很多Java命令都在jdk的JAVA_HOME/bin/目录下面，jps也不例外，他就在bin目录下，所以，他是java自带的一个命令。 功能jps(Java Virtual Machine Process Status Tool)是JDK 1.5提供的一个显示当前所有java进程pid的命令，简单实用，非常适合在linux/unix平台上简单察看当前java进程的一些简单情况。 原理jdk中的jps命令可以显示当前运行的java进程以及相关参数，它的实现机制如下：java程序在启动以后，会在java.io.tmpdir指定的目录下，就是临时文件夹里，生成一个类似于hsperfdata_User的文件夹，这个文件夹里（在Linux中为/tmp/hsperfdata_{userName}/），有几个文件，名字就是java进程的pid，因此列出当前运行的java进程，只是把这个目录里的文件名列一下而已。 至于系统的参数什么，就可以解析这几个文件获得。 12345678hollis@hos:/tmp/hsperfdata_hollis$ pwd/tmp/hsperfdata_hollishollis@hos:/tmp/hsperfdata_hollis$ lltotal 48drwxr-xr-x 2 hollis hollis 4096 4月 16 10:54 ./drwxrwxrwt 7 root root 12288 4月 16 10:56 ../-rw------- 1 hollis hollis 32768 4月 16 10:57 2679hollis@hos:/tmp/hsperfdata_hollis$ 上面的内容就是我机器中/tmp/hsperfdata_hollis目录下的内容，其中2679就是我机器上当前运行中的java的进程的pid，我们执行jps验证一下： 123hollis@hos:/tmp/hsperfdata_hollis$ jps2679 org.eclipse.equinox.launcher_1.3.0.v20130327-1440.jar4445 Jps 执行了jps命令之后，我们发现有两个java进程，一个是pid为2679的eclipse运行的进程，另外一个是pid为4445的jps使用的进程（他也是java命令，也要开一个进程） 使用想要学习一个命令，先来看看帮助，使用jps -help查看帮助： 123456hollis@hos:/tmp/hsperfdata_hollis$ jps -helpusage: jps [-help] jps [-q] [-mlvV] [&lt;hostid&gt;]Definitions: &lt;hostid&gt;: &lt;hostname&gt;[:&lt;port&gt;] 接下来，为了详细介绍这些参数，我们编写几个类，在main方法里写一个while(true)的循环，查看java进程情况。代码如下： 1234567891011package com.JavaCommand;/** * @author hollis */public class JpsDemo &#123; public static void main(String[] args) &#123; while(true)&#123; System.out.println(1); &#125; &#125;&#125; -q 只显示pid，不显示class名称,jar文件名和传递给main 方法的参数 123hollis@hos:/tmp/hsperfdata_hollis$ jps -q267911421 -m 输出传递给main 方法的参数，在嵌入式jvm上可能是null， 在这里，在启动main方法的时候，我给String[] args传递两个参数。hollis,chuang,执行jsp -m: 12hollis@hos:/tmp/hsperfdata_hollis$ jps -m12062 JpsDemo hollis,chuang -l 输出应用程序main class的完整package名 或者 应用程序的jar文件完整路径名 1234hollis@hos:/tmp/hsperfdata_hollis$ jps -l12356 sun.tools.jps.Jps2679 /home/hollis/tools/eclipse//plugins/org.eclipse.equinox.launcher_1.3.0.v20130327-1440.jar12329 com.JavaCommand.JpsDemo -v 输出传递给JVM的参数 在这里，在启动main方法的时候，我给jvm传递一个参数：-Dfile.encoding=UTF-8,执行jps -v： 1234hollis@hos:/tmp/hsperfdata_hollis$ jps -v2679 org.eclipse.equinox.launcher_1.3.0.v20130327-1440.jar -Djava.library.path=/usr/lib/jni:/usr/lib/x86_64-linux-gnu/jni -Dosgi.requiredJavaVersion=1.6 -XX:MaxPermSize=256m -Xms40m -Xmx512m13157 Jps -Denv.class.path=/home/hollis/tools/java/jdk1.7.0_71/lib:/home/hollis/tools/java/jdk1.7.0_71/jre/lib: -Dapplication.home=/home/hollis/tools/java/jdk1.7.0_71 -Xms8m13083 JpsDemo -Dfile.encoding=UTF-8 PS:jps命令有个地方很不好，似乎只能显示当前用户的java进程，要显示其他用户的还是只能用unix/linux的ps命令。 jps是我最常用的java命令。使用jps可以查看当前有哪些Java进程处于运行状态。如果我运行了一个web应用（使用tomcat、jboss、jetty等启动）的时候，我就可以使用jps查看启动情况。有的时候我想知道这个应用的日志会输出到哪里，或者启动的时候使用了哪些javaagent，那么我可以使用jps -v 查看进程的jvm参数情况。 JPS失效处理现象： 用ps -ef|grep java能看到启动的java进程，但是用jps查看却不存在该进程的id。待会儿解释过之后就能知道在该情况下，jconsole、jvisualvm可能无法监控该进程，其他java自带工具也可能无法使用 分析： jps、jconsole、jvisualvm等工具的数据来源就是这个文件（/tmp/hsperfdata_userName/pid)。所以当该文件不存在或是无法读取时就会出现jps无法查看该进程号，jconsole无法监控等问题 原因： （1）、磁盘读写、目录权限问题 若该用户没有权限写/tmp目录或是磁盘已满，则无法创建/tmp/hsperfdata_userName/pid文件。或该文件已经生成，但用户没有读权限 （2）、临时文件丢失，被删除或是定期清理 对于linux机器，一般都会存在定时任务对临时文件夹进行清理，导致/tmp目录被清空。这也是我第一次碰到该现象的原因。常用的可能定时删除临时目录的工具为crontab、redhat的tmpwatch、ubuntu的tmpreaper等等 这个导致的现象可能会是这样，用jconsole监控进程，发现在某一时段后进程仍然存在，但是却没有监控信息了。 （3）、java进程信息文件存储地址被设置，不在/tmp目录下 上面我们在介绍时说默认会在/tmp/hsperfdata_userName目录保存进程信息，但由于以上1、2所述原因，可能导致该文件无法生成或是丢失，所以java启动时提供了参数(-Djava.io.tmpdir)，可以对这个文件的位置进行设置，而jps、jconsole都只会从/tmp目录读取，而无法从设置后的目录读物信息，这是我第二次碰到该现象的原因 附：1.如何给main传递参数 在eclipse中，鼠标右键-&gt;Run As-&gt;Run COnfiguations-&gt;Arguments-&gt;在Program arguments中写下要传的参数值 1.如何给JVM传递参数 在eclipse中，鼠标右键-&gt;Run As-&gt;Run COnfiguations-&gt;Arguments-&gt;在VM arguments中写下要传的参数值（一般以-D开头） Java命令学习系列（二）— Jstack jstack是java虚拟机自带的一种堆栈跟踪工具。 功能jstack用于生成java虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。 So,jstack命令主要用来查看Java线程的调用堆栈的，可以用来分析线程问题（如死锁）。 线程状态想要通过jstack命令来分析线程的情况的话，首先要知道线程都有哪些状态，下面这些状态是我们使用jstack命令查看线程堆栈信息时可能会看到的线程的几种状态： NEW,未启动的。不会出现在Dump中。 RUNNABLE,在虚拟机内执行的。 BLOCKED,受阻塞并等待监视器锁。 WATING,无限期等待另一个线程执行特定操作。 TIMED_WATING,有时限的等待另一个线程的特定操作。 TERMINATED,已退出的。 Monitor在多线程的 JAVA程序中，实现线程之间的同步，就要说说 Monitor。 Monitor是 Java中用以实现线程之间的互斥与协作的主要手段，它可以看成是对象或者 Class的锁。每一个对象都有，也仅有一个 monitor。下 面这个图，描述了线程和 Monitor之间关系，以 及线程的状态转换图： 进入区(Entrt Set):表示线程通过synchronized要求获取对象的锁。如果对象未被锁住,则迚入拥有者;否则则在进入区等待。一旦对象锁被其他线程释放,立即参与竞争。 拥有者(The Owner):表示某一线程成功竞争到对象锁。 等待区(Wait Set):表示线程通过对象的wait方法,释放对象的锁,并在等待区等待被唤醒。 从图中可以看出，一个 Monitor在某个时刻，只能被一个线程拥有，该线程就是 “Active Thread”，而其它线程都是 “Waiting Thread”，分别在两个队列 “ Entry Set”和 “Wait Set”里面等候。在 “Entry Set”中等待的线程状态是 “Waiting for monitor entry”，而在 “Wait Set”中等待的线程状态是 “in Object.wait()”。 先看 “Entry Set”里面的线程。我们称被 synchronized保护起来的代码段为临界区。当一个线程申请进入临界区时，它就进入了 “Entry Set”队列。对应的 code就像： 1234synchronized(obj) &#123;.........&#125; 调用修饰表示线程在方法调用时,额外的重要的操作。线程Dump分析的重要信息。修饰上方的方法调用。 locked &lt;地址&gt; 目标：使用synchronized申请对象锁成功,监视器的拥有者。 waiting to lock &lt;地址&gt; 目标：使用synchronized申请对象锁未成功,在迚入区等待。 waiting on &lt;地址&gt; 目标：使用synchronized申请对象锁成功后,释放锁幵在等待区等待。 parking to wait for &lt;地址&gt; 目标 locked 12345at oracle.jdbc.driver.PhysicalConnection.prepareStatement- locked &lt;0x00002aab63bf7f58&gt; (a oracle.jdbc.driver.T4CConnection)at oracle.jdbc.driver.PhysicalConnection.prepareStatement- locked &lt;0x00002aab63bf7f58&gt; (a oracle.jdbc.driver.T4CConnection)at com.jiuqi.dna.core.internal.db.datasource.PooledConnection.prepareStatement 通过synchronized关键字,成功获取到了对象的锁,成为监视器的拥有者,在临界区内操作。对象锁是可以线程重入的。 waiting to lock 12345at com.jiuqi.dna.core.impl.CacheHolder.isVisibleIn(CacheHolder.java:165)- waiting to lock &lt;0x0000000097ba9aa8&gt; (a CacheHolder)at com.jiuqi.dna.core.impl.CacheGroup$Index.findHolderat com.jiuqi.dna.core.impl.ContextImpl.findat com.jiuqi.dna.bap.basedata.common.util.BaseDataCenter.findInfo 通过synchronized关键字,没有获取到了对象的锁,线程在监视器的进入区等待。在调用栈顶出现,线程状态为Blocked。 waiting on 12345at java.lang.Object.wait(Native Method)- waiting on &lt;0x00000000da2defb0&gt; (a WorkingThread)at com.jiuqi.dna.core.impl.WorkingManager.getWorkToDo- locked &lt;0x00000000da2defb0&gt; (a WorkingThread)at com.jiuqi.dna.core.impl.WorkingThread.run 通过synchronized关键字,成功获取到了对象的锁后,调用了wait方法,进入对象的等待区等待。在调用栈顶出现,线程状态为WAITING或TIMED_WATING。 parking to wait for park是基本的线程阻塞原语,不通过监视器在对象上阻塞。随concurrent包会出现的新的机制,不synchronized体系不同。 线程动作线程状态产生的原因 runnable:状态一般为RUNNABLE。 in Object.wait():等待区等待,状态为WAITING或TIMED_WAITING。 waiting for monitor entry:进入区等待,状态为BLOCKED。 waiting on condition:等待区等待、被park。 sleeping:休眠的线程,调用了Thread.sleep()。 Wait on condition 该状态出现在线程等待某个条件的发生。具体是什么原因，可以结合 stacktrace来分析。 最常见的情况就是线程处于sleep状态，等待被唤醒。 常见的情况还有等待网络IO：在java引入nio之前，对于每个网络连接，都有一个对应的线程来处理网络的读写操作，即使没有可读写的数据，线程仍然阻塞在读写操作上，这样有可能造成资源浪费，而且给操作系统的线程调度也带来压力。在 NewIO里采用了新的机制，编写的服务器程序的性能和可扩展性都得到提高。 正等待网络读写，这可能是一个网络瓶颈的征兆。因为网络阻塞导致线程无法执行。一种情况是网络非常忙，几乎消耗了所有的带宽，仍然有大量数据等待网络读 写；另一种情况也可能是网络空闲，但由于路由等问题，导致包无法正常的到达。所以要结合系统的一些性能观察工具来综合分析，比如 netstat统计单位时间的发送包的数目，如果很明显超过了所在网络带宽的限制 ; 观察 cpu的利用率，如果系统态的 CPU时间，相对于用户态的 CPU时间比例较高；如果程序运行在 Solaris 10平台上，可以用 dtrace工具看系统调用的情况，如果观察到 read/write的系统调用的次数或者运行时间遥遥领先；这些都指向由于网络带宽所限导致的网络瓶颈。 线程Dump的分析原则 结合代码阅读的推理。需要线程Dump和源码的相互推导和印证。 造成Bug的根源往往丌会在调用栈上直接体现,一定格外注意线程当前调用之前的所有调用。 入手点进入区等待 12345\"d&amp;a-3588\" daemon waiting for monitor entry [0x000000006e5d5000]java.lang.Thread.State: BLOCKED (on object monitor)at com.jiuqi.dna.bap.authority.service.UserService$LoginHandler.handle()- waiting to lock &lt;0x0000000602f38e90&gt; (a java.lang.Object)at com.jiuqi.dna.bap.authority.service.UserService$LoginHandler.handle() 线程状态BLOCKED,线程动作wait on monitor entry,调用修饰waiting to lock总是一起出现。表示在代码级别已经存在冲突的调用。必然有问题的代码,需要尽可能减少其发生。 同步块阻塞 一个线程锁住某对象,大量其他线程在该对象上等待。 123456789101112\"blocker\" runnablejava.lang.Thread.State: RUNNABLEat com.jiuqi.hcl.javadump.Blocker$1.run(Blocker.java:23)- locked &lt;0x00000000eb8eff68&gt; (a java.lang.Object)\"blockee-11\" waiting for monitor entryjava.lang.Thread.State: BLOCKED (on object monitor)at com.jiuqi.hcl.javadump.Blocker$2.run(Blocker.java:41)- waiting to lock &lt;0x00000000eb8eff68&gt; (a java.lang.Object)\"blockee-86\" waiting for monitor entryjava.lang.Thread.State: BLOCKED (on object monitor)at com.jiuqi.hcl.javadump.Blocker$2.run(Blocker.java:41)- waiting to lock &lt;0x00000000eb8eff68&gt; (a java.lang.Object) 持续运行的IO IO操作是可以以RUNNABLE状态达成阻塞。例如:数据库死锁、网络读写。 格外注意对IO线程的真实状态的分析。 一般来说,被捕捉到RUNNABLE的IO调用,都是有问题的。 以下堆栈显示： 线程状态为RUNNABLE。 调用栈在SocketInputStream或SocketImpl上,socketRead0等方法。 调用栈包含了jdbc相关的包。很可能发生了数据库死锁 1234567891011\"d&amp;a-614\" daemon prio=6 tid=0x0000000022f1f000 nid=0x37c8 runnable[0x0000000027cbd000]java.lang.Thread.State: RUNNABLEat java.net.SocketInputStream.socketRead0(Native Method)at java.net.SocketInputStream.read(Unknown Source)at oracle.net.ns.Packet.receive(Packet.java:240)at oracle.net.ns.DataPacket.receive(DataPacket.java:92)at oracle.net.ns.NetInputStream.getNextPacket(NetInputStream.java:172)at oracle.net.ns.NetInputStream.read(NetInputStream.java:117)at oracle.jdbc.driver.T4CMAREngine.unmarshalUB1(T4CMAREngine.java:1034)at oracle.jdbc.driver.T4C8Oall.receive(T4C8Oall.java:588) 分线程调度的休眠 正常的线程池等待 123456\"d&amp;a-131\" in Object.wait()java.lang.Thread.State: TIMED_WAITING (on object monitor)at java.lang.Object.wait(Native Method)at com.jiuqi.dna.core.impl.WorkingManager.getWorkToDo(WorkingManager.java:322)- locked &lt;0x0000000313f656f8&gt; (a com.jiuqi.dna.core.impl.WorkingThread)at com.jiuqi.dna.core.impl.WorkingThread.run(WorkingThread.java:40) 可疑的线程等待 1234567\"d&amp;a-121\" in Object.wait()java.lang.Thread.State: WAITING (on object monitor)at java.lang.Object.wait(Native Method)at java.lang.Object.wait(Object.java:485)at com.jiuqi.dna.core.impl.AcquirableAccessor.exclusive()- locked &lt;0x00000003011678d8&gt; (a com.jiuqi.dna.core.impl.CacheGroup)at com.jiuqi.dna.core.impl.Transaction.lock() 入手点总结wait on monitor entry： 被阻塞的,肯定有问题 runnable ： 注意IO线程 in Object.wait()： 注意非线程池等待 使用想要学习一个命令，先来看看帮助，使用jstack -help查看帮助： 12345678910111213141516hollis@hos:~$ jstack -helpUsage: jstack [-l] &lt;pid&gt; (to connect to running process) jstack -F [-m] [-l] &lt;pid&gt; (to connect to a hung process) jstack [-m] [-l] &lt;executable&gt; &lt;core&gt; (to connect to a core file) jstack [-m] [-l] [server_id@]&lt;remote server IP or hostname&gt; (to connect to a remote debug server)Options: -F to force a thread dump. Use when jstack &lt;pid&gt; does not respond (process is hung) -m to print both java and native frames (mixed mode) -l long listing. Prints additional information about locks -h or -help to print this help message -F当’jstack [-l] pid’没有相应的时候强制打印栈信息 -l长列表. 打印关于锁的附加信息,例如属于java.util.concurrent的ownable synchronizers列表. -m打印java和native c/c++框架的所有栈信息. -h | -help打印帮助信息 pid 需要被打印配置信息的java进程id,可以用jps查询. 首先，我们分析这么一段程序的线程情况： 12345678910/** * @author hollis */public class JStackDemo1 &#123; public static void main(String[] args) &#123; while (true) &#123; //Do Nothing &#125; &#125;&#125; 先是有jps查看进程号： 1234hollis@hos:~$ jps29788 JStackDemo129834 Jps22385 org.eclipse.equinox.launcher_1.3.0.v20130327-1440.jar 然后使用jstack 查看堆栈信息： 123456hollis@hos:~$ jstack 297882015-04-17 23:47:31...此处省略若干内容...\"main\" prio=10 tid=0x00007f197800a000 nid=0x7462 runnable [0x00007f197f7e1000] java.lang.Thread.State: RUNNABLE at javaCommand.JStackDemo1.main(JStackDemo1.java:7) 我们可以从这段堆栈信息中看出什么来呢？我们可以看到，当前一共有一条用户级别线程,线程处于runnable状态，执行到JStackDemo1.java的第七行。 看下面代码： 1234567891011121314151617/** * @author hollis */public class JStackDemo1 &#123; public static void main(String[] args) &#123; Thread thread = new Thread(new Thread1()); thread.start(); &#125;&#125;class Thread1 implements Runnable&#123; @Override public void run() &#123; while(true)&#123; System.out.println(1); &#125; &#125;&#125; 线程堆栈信息如下： 1234567\"Reference Handler\" daemon prio=10 tid=0x00007fbbcc06e000 nid=0x286c in Object.wait() [0x00007fbbc8dfc000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000783e066e0&gt; (a java.lang.ref.Reference$Lock) at java.lang.Object.wait(Object.java:503) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133) - locked &lt;0x0000000783e066e0&gt; (a java.lang.ref.Reference$Lock) 我们能看到： 线程的状态： WAITING 线程的调用栈 线程的当前锁住的资源： 线程当前等待的资源： 为什么同时锁住的等待同一个资源： 线程的执行中，先获得了这个对象的 Monitor（对应于 locked ）。当执行到 obj.wait(), 线程即放弃了 Monitor的所有权，进入 “wait set”队列（对应于 waiting on ）。 死锁分析学会了怎么使用jstack命令之后，我们就可以看看，如何使用jstack分析死锁了，这也是我们一定要掌握的内容。 啥叫死锁？ 所谓死锁： 是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。 说白了，我现在想吃鸡蛋灌饼，桌子上放着鸡蛋和饼，但是我和我的朋友同时分别拿起了鸡蛋和病，我手里拿着鸡蛋，但是我需要他手里的饼。他手里拿着饼，但是他想要我手里的鸡蛋。就这样，如果不能同时拿到鸡蛋和饼，那我们就不能继续做后面的工作（做鸡蛋灌饼）。所以，这就造成了死锁。 看一段死锁的程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package javaCommand;/** * @author hollis */public class JStackDemo &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(new DeadLockclass(true));//建立一个线程 Thread t2 = new Thread(new DeadLockclass(false));//建立另一个线程 t1.start();//启动一个线程 t2.start();//启动另一个线程 &#125;&#125;class DeadLockclass implements Runnable &#123; public boolean falg;// 控制线程 DeadLockclass(boolean falg) &#123; this.falg = falg; &#125; public void run() &#123; /** * 如果falg的值为true则调用t1线程 */ if (falg) &#123; while (true) &#123; synchronized (Suo.o1) &#123; System.out.println(\"o1 \" + Thread.currentThread().getName()); synchronized (Suo.o2) &#123; System.out.println(\"o2 \" + Thread.currentThread().getName()); &#125; &#125; &#125; &#125; /** * 如果falg的值为false则调用t2线程 */ else &#123; while (true) &#123; synchronized (Suo.o2) &#123; System.out.println(\"o2 \" + Thread.currentThread().getName()); synchronized (Suo.o1) &#123; System.out.println(\"o1 \" + Thread.currentThread().getName()); &#125; &#125; &#125; &#125; &#125;&#125;class Suo &#123; static Object o1 = new Object(); static Object o2 = new Object();&#125; 当我启动该程序时，我们看一下控制台： 我们发现，程序只输出了两行内容，然后程序就不再打印其它的东西了，但是程序并没有停止。这样就产生了死锁。 当线程1使用synchronized锁住了o1的同时，线程2也是用synchronized锁住了o2。当两个线程都执行完第一个打印任务的时候，线程1想锁住o2，线程2想锁住o1。但是，线程1当前锁着o1，线程2锁着o2。所以两个想成都无法继续执行下去，就造成了死锁。 然后，我们使用jstack来看一下线程堆栈信息： 1234567891011121314151617181920212223Found one Java-level deadlock:=============================\"Thread-1\": waiting to lock monitor 0x00007f0134003ae8 (object 0x00000007d6aa2c98, a java.lang.Object), which is held by \"Thread-0\"\"Thread-0\": waiting to lock monitor 0x00007f0134006168 (object 0x00000007d6aa2ca8, a java.lang.Object), which is held by \"Thread-1\"Java stack information for the threads listed above:===================================================\"Thread-1\": at javaCommand.DeadLockclass.run(JStackDemo.java:40) - waiting to lock &lt;0x00000007d6aa2c98&gt; (a java.lang.Object) - locked &lt;0x00000007d6aa2ca8&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745)\"Thread-0\": at javaCommand.DeadLockclass.run(JStackDemo.java:27) - waiting to lock &lt;0x00000007d6aa2ca8&gt; (a java.lang.Object) - locked &lt;0x00000007d6aa2c98&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745)Found 1 deadlock. 哈哈，堆栈写的很明显，它告诉我们 Found one Java-level deadlock，然后指出造成死锁的两个线程的内容。然后，又通过 Java stack information for the threads listed above来显示更详细的死锁的信息。 他说 Thread-1在想要执行第40行的时候，当前锁住了资源&lt;0x00000007d6aa2ca8&gt;,但是他在等待资源&lt;0x00000007d6aa2c98&gt; Thread-0在想要执行第27行的时候，当前锁住了资源&lt;0x00000007d6aa2c98&gt;,但是他在等待资源&lt;0x00000007d6aa2ca8&gt; 由于这两个线程都持有资源，并且都需要对方的资源，所以造成了死锁。 原因我们找到了，就可以具体问题具体分析，解决这个死锁了。 其他虚拟机执行Full GC时,会阻塞所有的用户线程。因此,即时获取到同步锁的线程也有可能被阻塞。 在查看线程Dump时,首先查看内存使用情况。 Java命令学习系列（三）— Jmap jmap是JDK自带的工具软件，主要用于打印指定Java进程(或核心文件、远程调试服务器)的共享对象内存映射或堆内存细节。可以使用jmap生成Heap Dump。在Java命令学习系列（零）— 常见命令及Java Dump介绍中分别有关于Java Dump以及线程 Dump的介绍。 这篇文章主要介绍Java的堆Dump以及jamp命令 什么是堆Dump堆Dump是反应Java堆使用情况的内存镜像，其中主要包括系统信息、虚拟机属性、完整的线程Dump、所有类和对象的状态等。 一般，在内存不足、GC异常等情况下，我们就会怀疑有内存泄露。这个时候我们就可以制作堆Dump来查看具体情况。分析原因。 基础知识《Java虚拟机的内存组成以及堆内存介绍》《Java GC工作原理》常见内存错误： outOfMemoryError 年老代内存不足。outOfMemoryError:PermGen Space 永久代内存不足。outOfMemoryError:GC overhead limit exceed 垃圾回收时间占用系统运行时间的98%或以上。 jmap用法摘要 12345678910111213141516171819202122232425262728Usage: jmap [option] &lt;pid&gt; (to connect to running process) jmap [option] &lt;executable &lt;core&gt; (to connect to a core file) jmap [option] [server_id@]&lt;remote server IP or hostname&gt; (to connect to remote debug server)where &lt;option&gt; is one of: &lt;none&gt; to print same info as Solaris pmap -heap to print java heap summary -histo[:live] to print histogram of java object heap; if the \"live\" suboption is specified, only count live objects -permstat to print permanent generation statistics -finalizerinfo to print information on objects awaiting finalization -dump:&lt;dump-options&gt; to dump java heap in hprof binary format dump-options: live dump only live objects; if not specified, all objects in the heap are dumped. format=b binary format file=&lt;file&gt; dump heap to &lt;file&gt; Example: jmap -dump:live,format=b,file=heap.bin &lt;pid&gt; -F force. Use with -dump:&lt;dump-options&gt; &lt;pid&gt; or -histo to force a heap dump or histogram when &lt;pid&gt; does not respond. The \"live\" suboption is not supported in this mode. -h | -help to print this help message -J&lt;flag&gt; to pass &lt;flag&gt; directly to the runtime system 指定进程号(pid)的进程 jmap [ option ] 指定核心文件 jmap [ option ] 指定远程调试服务器 jmap [ option ] [server-id@] 参数： option 选项参数是互斥的(不可同时使用)。想要使用选项参数，直接跟在命令名称后即可。pid 需要打印配置信息的进程ID。该进程必须是一个Java进程。想要获取运行的Java进程列表，你可以使用jps。executable 产生核心dump的Java可执行文件。core 需要打印配置信息的核心文件。remote-hostname-or-IP 远程调试服务器的(请查看jsadebugd)主机名或IP地址。server-id 可选的唯一id，如果相同的远程主机上运行了多台调试服务器，用此选项参数标识服务器。 选项: &lt;no option&gt; 如果使用不带选项参数的jmap打印共享对象映射，将会打印目标虚拟机中加载的每个共享对象的起始地址、映射大小以及共享对象文件的路径全称。这与Solaris的pmap工具比较相似。-dump:[live,]format=b,file=&lt;filename&gt; 以hprof二进制格式转储Java堆到指定filename的文件中。live子选项是可选的。如果指定了live子选项，堆中只有活动的对象会被转储。想要浏览heap dump，你可以使用jhat(Java堆分析工具)读取生成的文件。-finalizerinfo 打印等待终结的对象信息。-heap 打印一个堆的摘要信息，包括使用的GC算法、堆配置信息和generation wise heap usage。-histo[:live] 打印堆的柱状图。其中包括每个Java类、对象数量、内存大小(单位：字节)、完全限定的类名。打印的虚拟机内部的类名称将会带有一个’*’前缀。如果指定了live子选项，则只计算活动的对象。-permstat 打印Java堆内存的永久保存区域的类加载器的智能统计信息。对于每个类加载器而言，它的名称、活跃度、地址、父类加载器、它所加载的类的数量和大小都会被打印。此外，包含的字符串数量和大小也会被打印。-F 强制模式。如果指定的pid没有响应，请使用jmap -dump或jmap -histo选项。此模式下，不支持live子选项。-h 打印帮助信息。-help 打印帮助信息。-J&lt;flag&gt; 指定传递给运行jmap的JVM的参数。 举例查看java 堆（heap）使用情况,执行命令： hollis@hos:~/workspace/design_apaas/apaasweb/control/bin$ jmap -heap 31846 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950Attaching to process ID 31846, please wait...Debugger attached successfully.Server compiler detected.JVM version is 24.71-b01using thread-local object allocation.Parallel GC with 4 thread(s)//GC 方式Heap Configuration: //堆内存初始化配置 MinHeapFreeRatio = 0 //对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40) MaxHeapFreeRatio = 100 //对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70) MaxHeapSize = 2082471936 (1986.0MB) //对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小 NewSize = 1310720 (1.25MB)//对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小 MaxNewSize = 17592186044415 MB//对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小 OldSize = 5439488 (5.1875MB)//对应jvm启动参数-XX:OldSize=&lt;value&gt;:设置JVM堆的‘老生代’的大小 NewRatio = 2 //对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率 SurvivorRatio = 8 //对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值 PermSize = 21757952 (20.75MB) //对应jvm启动参数-XX:PermSize=&lt;value&gt;:设置JVM堆的‘永生代’的初始大小 MaxPermSize = 85983232 (82.0MB)//对应jvm启动参数-XX:MaxPermSize=&lt;value&gt;:设置JVM堆的‘永生代’的最大大小 G1HeapRegionSize = 0 (0.0MB)Heap Usage://堆内存使用情况PS Young GenerationEden Space://Eden区内存分布 capacity = 33030144 (31.5MB)//Eden区总容量 used = 1524040 (1.4534378051757812MB) //Eden区已使用 free = 31506104 (30.04656219482422MB) //Eden区剩余容量 4.614088270399305% used //Eden区使用比率From Space: //其中一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% usedTo Space: //另一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% usedPS Old Generation //当前的Old区内存分布 capacity = 86507520 (82.5MB) used = 0 (0.0MB) free = 86507520 (82.5MB) 0.0% usedPS Perm Generation//当前的 “永生代” 内存分布 capacity = 22020096 (21.0MB) used = 2496528 (2.3808746337890625MB) free = 19523568 (18.619125366210938MB) 11.337498256138392% used670 interned Strings occupying 43720 bytes. 查看堆内存(histogram)中的对象数量及大小。执行命令： hollis@hos:~/workspace/design_apaas/apaasweb/control/bin$ jmap -histo 3331 12345678910num #instances #bytes class name编号 个数 字节 类名---------------------------------------------- 1: 7 1322080 [I 2: 5603 722368 &lt;methodKlass&gt; 3: 5603 641944 &lt;constMethodKlass&gt; 4: 34022 544352 java.lang.Integer 5: 371 437208 &lt;constantPoolKlass&gt; 6: 336 270624 &lt;constantPoolCacheKlass&gt; 7: 371 253816 &lt;instanceKlassKlass&gt; jmap -histo:live 这个命令执行，JVM会先触发gc，然后再统计信息。 将内存使用的详细情况输出到文件，执行命令： hollis@hos:~/workspace/design_apaas/apaasweb/control/bin$ jmap -dump:format=b,file=heapDump 6900 然后用jhat命令可以参看 jhat -port 5000 heapDump 在浏览器中访问：http://localhost:5000/ 查看详细信息 这个命令执行，JVM会将整个heap的信息dump写入到一个文件，heap如果比较大的话，就会导致这个过程比较耗时，并且执行的过程中为了保证dump的信息是可靠的，所以会暂停应用。 总结 如果程序内存不足或者频繁GC，很有可能存在内存泄露情况，这时候就要借助Java堆Dump查看对象的情况。 要制作堆Dump可以直接使用jvm自带的jmap命令 可以先使用jmap -heap命令查看堆的使用情况，看一下各个堆空间的占用情况。 使用jmap -histo:[live]查看堆内存中的对象的情况。如果有大量对象在持续被引用，并没有被释放掉，那就产生了内存泄露，就要结合代码，把不用的对象释放掉。 也可以使用 jmap -dump:format=b,file=&lt;fileName&gt;命令将堆信息保存到一个文件中，再借助jhat命令查看详细内容 在内存出现泄露、溢出或者其它前提条件下，建议多dump几次内存，把内存文件进行编号归档，便于后续内存整理分析。 Error attaching to process: sun.jvm.hotspot.debugger.DebuggerException: Can’t attach to the process 在ubuntu中第一次使用jmap会报错：Error attaching to process: sun.jvm.hotspot.debugger.DebuggerException: Can&#39;t attach to the process，这是oracla文档中提到的一个bug:http://bugs.java.com/bugdatabase/view_bug.do?bug_id=7050524,解决方式如下： echo 0 | sudo tee /proc/sys/kernel/yama/ptrace_scope 该方法在下次重启前有效。 永久有效方法 sudo vi /etc/sysctl.d/10-ptrace.conf 编辑下面这行: kernel.yama.ptrace_scope = 1 修改为: kernel.yama.ptrace_scope = 0 重启系统，使修改生效。 Java命令学习系列（四）— jstat jstat(JVM Statistics Monitoring Tool)是用于监控虚拟机各种运行状态信息的命令行工具。他可以显示本地或远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据，在没有GUI图形的服务器上，它是运行期定位虚拟机性能问题的首选工具。 jstat位于java的bin目录下，主要利用JVM内建的指令对Java应用程序的资源和性能进行实时的命令行的监控，包括了对Heap size和垃圾回收状况的监控。可见，Jstat是轻量级的、专门针对JVM的工具，非常适用。 jstat 命令格式1jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]] 参数解释：Option — 选项，我们一般使用 -gcutil 查看gc情况 vmid — VM的进程号，即当前运行的java进程号 interval– 间隔时间，单位为秒或者毫秒 count — 打印次数，如果缺省则打印无数次 参数interval和count代表查询间隔和次数，如果省略这两个参数，说明只查询一次。假设需要每250毫秒查询一次进程5828垃圾收集状况，一共查询5次，那命令行如下： 1jstat -gc 5828 250 5 对于命令格式中的VMID与LVMID需要特别说明下：如果是本地虚拟机进程，VMID(Virtual Machine IDentifier,虚机标识符)和LVMID(Local Virtual Machine IDentifier,虚机标识符)是一致的，如果是远程虚拟机进程，那VMID的格式应当是：[protocol:][//] lvmid [@hostname[:port]/servername] option选项option代表这用户希望查询的虚拟机信息，主要分为3类：类装载、垃圾收集和运行期编译状况，具体选项及作用如下： –class 监视类装载、卸载数量、总空间及类装载所耗费的时间 –gc 监视Java堆状况，包括Eden区、2个Survivor区、老年代、永久代等的容量 –gccapacity 监视内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大和最小空间 –gcutil 监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比 –gccause 与-gcutil功能一样，但是会额外输出导致上一次GC产生的原因 –gcnew 监视新生代GC的状况 –gcnewcapacity 监视内容与-gcnew基本相同，输出主要关注使用到的最大和最小空间 –gcold 监视老年代GC的状况 –gcoldcapacity 监视内容与——gcold基本相同，输出主要关注使用到的最大和最小空间 –gcpermcapacity 输出永久代使用到的最大和最小空间 –compiler 输出JIT编译器编译过的方法、耗时等信息 –printcompilation 输出已经被JIT编译的方法 常见术语1、jstat –class&lt;pid&gt; : 显示加载class的数量，及所占空间等信息。 Loaded 装载的类的数量 Bytes 装载类所占用的字节数 Unloaded 卸载类的数量 Bytes 卸载类的字节数 Time 装载和卸载类所花费的时间 2、jstat -compiler &lt;pid&gt;显示VM实时编译的数量等信息。 Compiled 编译任务执行数量 Failed 编译任务执行失败数量 Invalid 编译任务执行失效数量 Time 编译任务消耗时间 FailedType 最后一个编译失败任务的类型 FailedMethod 最后一个编译失败任务所在的类及方法 3、jstat -gc &lt;pid&gt;: 可以显示gc的信息，查看gc的次数，及时间。 S0C 年轻代中第一个survivor（幸存区）的容量 (字节) S1C 年轻代中第二个survivor（幸存区）的容量 (字节) S0U 年轻代中第一个survivor（幸存区）目前已使用空间 (字节) S1U 年轻代中第二个survivor（幸存区）目前已使用空间 (字节) EC 年轻代中Eden（伊甸园）的容量 (字节) EU 年轻代中Eden（伊甸园）目前已使用空间 (字节) OC Old代的容量 (字节) OU Old代目前已使用空间 (字节) PC Perm(持久代)的容量 (字节) PU Perm(持久代)目前已使用空间 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 YGCT 从应用程序启动到采样时年轻代中gc所用时间(s) FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) 4、jstat -gccapacity &lt;pid&gt;:可以显示，VM内存中三代（young,old,perm）对象的使用和占用大小 NGCMN 年轻代(young)中初始化(最小)的大小(字节) NGCMX 年轻代(young)的最大容量 (字节) NGC 年轻代(young)中当前的容量 (字节) S0C 年轻代中第一个survivor（幸存区）的容量 (字节) S1C 年轻代中第二个survivor（幸存区）的容量 (字节) EC 年轻代中Eden（伊甸园）的容量 (字节) OGCMN old代中初始化(最小)的大小 (字节) OGCMX old代的最大容量(字节) OGC old代当前新生成的容量 (字节) OC Old代的容量 (字节) PGCMN perm代中初始化(最小)的大小 (字节) PGCMX perm代的最大容量 (字节)PGC perm代当前新生成的容量 (字节) PC Perm(持久代)的容量 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 FGC 从应用程序启动到采样时old代(全gc)gc次数 5、jstat -gcutil &lt;pid&gt;:统计gc信息 S0 年轻代中第一个survivor（幸存区）已使用的占当前容量百分比 S1 年轻代中第二个survivor（幸存区）已使用的占当前容量百分比 E 年轻代中Eden（伊甸园）已使用的占当前容量百分比 O old代已使用的占当前容量百分比 P perm代已使用的占当前容量百分比 YGC 从应用程序启动到采样时年轻代中gc次数 YGCT 从应用程序启动到采样时年轻代中gc所用时间(s) FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) 6、jstat -gcnew &lt;pid&gt;:年轻代对象的信息。 S0C 年轻代中第一个survivor（幸存区）的容量 (字节) S1C 年轻代中第二个survivor（幸存区）的容量 (字节) S0U 年轻代中第一个survivor（幸存区）目前已使用空间 (字节) S1U 年轻代中第二个survivor（幸存区）目前已使用空间 (字节) TT 持有次数限制 MTT 最大持有次数限制 EC 年轻代中Eden（伊甸园）的容量 (字节) EU 年轻代中Eden（伊甸园）目前已使用空间 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 YGCT 从应用程序启动到采样时年轻代中gc所用时间(s) 7、jstat -gcnewcapacity&lt;pid&gt;: 年轻代对象的信息及其占用量。 NGCMN 年轻代(young)中初始化(最小)的大小(字节) NGCMX 年轻代(young)的最大容量 (字节) NGC 年轻代(young)中当前的容量 (字节) S0CMX 年轻代中第一个survivor（幸存区）的最大容量 (字节) S0C 年轻代中第一个survivor（幸存区）的容量 (字节) S1CMX 年轻代中第二个survivor（幸存区）的最大容量 (字节) S1C 年轻代中第二个survivor（幸存区）的容量 (字节) ECMX 年轻代中Eden（伊甸园）的最大容量 (字节) EC 年轻代中Eden（伊甸园）的容量 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 FGC 从应用程序启动到采样时old代(全gc)gc次数 8、jstat -gcold &lt;pid&gt;：old代对象的信息。 PC Perm(持久代)的容量 (字节) PU Perm(持久代)目前已使用空间 (字节) OC Old代的容量 (字节) OU Old代目前已使用空间 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) 9、stat -gcoldcapacity &lt;pid&gt;: old代对象的信息及其占用量。 OGCMN old代中初始化(最小)的大小 (字节) OGCMX old代的最大容量(字节) OGC old代当前新生成的容量 (字节) OC Old代的容量 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) 10、jstat -gcpermcapacity&lt;pid&gt;: perm对象的信息及其占用量。 PGCMN perm代中初始化(最小)的大小 (字节) PGCMX perm代的最大容量 (字节)PGC perm代当前新生成的容量 (字节) PC Perm(持久代)的容量 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) 11、jstat -printcompilation &lt;pid&gt;：当前VM执行的信息。 Compiled 编译任务的数目 Size 方法生成的字节码的大小 Type 编译类型 Method 类名和方法名用来标识编译的方法。类名使用/做为一个命名空间分隔符。方法名是给定类中的方法。上述格式是由-XX:+PrintComplation选项进行设置的 Java命令学习系列（五）— jhat jhat(Java Heap Analysis Tool),是一个用来分析java的堆情况的命令。之前的文章讲到过，使用jmap可以生成Java堆的Dump文件。生成dump文件之后就可以用jhat命令，将dump文件转成html的形式，然后通过http访问可以查看堆情况。 jhat命令解析会Java堆dump并启动一个web服务器，然后就可以在浏览器中查看堆的dump文件了。 实例导出dump文件关于dump文件的生成可以看jmap命令的详细介绍. 1、运行java程序 123456789101112/** * Created by hollis on 16/1/21. */public class JhatTest &#123; public static void main(String[] args) &#123; while(true) &#123; String string = new String(\"hollis\"); System.out.println(string); &#125; &#125;&#125; 2、查看该进程的ID 1234HollisMacBook-Air:apaas hollis$ jps -l68680 org.jetbrains.jps.cmdline.Launcher62247 com.intellij.rt.execution.application.AppMain69038 sun.tools.jps.Jps 使用jps命令查看发现有三个java进程在运行，一个是我的IDEA使用的进程68680，一个是JPS命令使用的进程69038，另外一个就是上面那段代码运行的进程62247。 3、生成dump文件 123HollisMacBook-Air:test hollis$ jmap -dump:format=b,file=heapDump 62247Dumping heap to /Users/hollis/workspace/test/heapDump ...Heap dump file created 以上命令可以将进程6900的堆dump文件导出到heapDump文件中。查看当前目录就能看到heapDump文件。 除了使用jmap命令，还可以通过以下方式： 1、使用 jconsole 选项通过 HotSpotDiagnosticMXBean 从运行时获得堆转储（生成dump文件）、 2、虚拟机启动时如果指定了 -XX:+HeapDumpOnOutOfMemoryError 选项, 则在抛出 OutOfMemoryError 时, 会自动执行堆转储。 3、使用 hprof 命令 解析Java堆转储文件,并启动一个 web server12345678910HollisMacBook-Air:apaas hollis$ jhat heapDumpReading from heapDump...Dump file created Thu Jan 21 18:59:51 CST 2016Snapshot read, resolving...Resolving 341297 objects...Chasing references, expect 68 dots....................................................................Eliminating duplicate references....................................................................Snapshot resolved.Started HTTP server on port 7000Server is ready. 使用jhat命令，就启动了一个http服务，端口是7000 然后在访问http://localhost:7000/ 页面如下： 分析在浏览器里面看到dump文件之后就可以进行分析了。这个页面会列出当前进程中的所有对像情况。 该页面提供了几个查询功能可供使用： 1234567All classes including platform//Show all members of the rootsetShow instance counts for all classes (including platform)Show instance counts for all classes (excluding platform)Show heap histogramShow finalizer summaryExecute Object Query Language (OQL) query 一般查看堆异常情况主要看这个两个部分： Show instance counts for all classes (excluding platform)，平台外的所有对象信息。如下图： Show heap histogram 以树状图形式展示堆情况。如下图： 具体排查时需要结合代码，观察是否大量应该被回收的对象在一直被引用或者是否有占用内存特别大的对象无法被回收。 用法摘要这一部分放在后面介绍的原因是一般不太使用。 1234567891011121314151617181920HollisMacBook-Air:~ hollis$ jhat -helpUsage: jhat [-stack &lt;bool&gt;] [-refs &lt;bool&gt;] [-port &lt;port&gt;] [-baseline &lt;file&gt;] [-debug &lt;int&gt;] [-version] [-h|-help] &lt;file&gt; -J&lt;flag&gt; Pass &lt;flag&gt; directly to the runtime system. For example, -J-mx512m to use a maximum heap size of 512MB -stack false: Turn off tracking object allocation call stack. -refs false: Turn off tracking of references to objects -port &lt;port&gt;: Set the port for the HTTP server. Defaults to 7000 -exclude &lt;file&gt;: Specify a file that lists data members that should be excluded from the reachableFrom query. -baseline &lt;file&gt;: Specify a baseline object dump. Objects in both heap dumps with the same ID and same class will be marked as not being \"new\". -debug &lt;int&gt;: Set debug level. 0: No debug output 1: Debug hprof file parsing 2: Debug hprof file parsing, no server -version Report version number -h|-help Print this help and exit &lt;file&gt; The file to read -stack false|true 关闭对象分配调用栈跟踪(tracking object allocation call stack)。 如果分配位置信息在堆转储中不可用. 则必须将此标志设置为 false. 默认值为 true. -refs false|true 关闭对象引用跟踪(tracking of references to objects)。 默认值为 true. 默认情况下, 返回的指针是指向其他特定对象的对象,如反向链接或输入引用(referrers or incoming references), 会统计/计算堆中的所有对象。 -port port-number 设置 jhat HTTP server 的端口号. 默认值 7000. -exclude exclude-file 指定对象查询时需要排除的数据成员列表文件(a file that lists data members that should be excluded from the reachable objects query)。 例如, 如果文件列列出了 java.lang.String.value , 那么当从某个特定对象 Object o 计算可达的对象列表时, 引用路径涉及 java.lang.String.value 的都会被排除。 -baseline exclude-file 指定一个基准堆转储(baseline heap dump)。 在两个 heap dumps 中有相同 object ID 的对象会被标记为不是新的(marked as not being new). 其他对象被标记为新的(new). 在比较两个不同的堆转储时很有用. -debug int 设置 debug 级别. 0 表示不输出调试信息。 值越大则表示输出更详细的 debug 信息. -version 启动后只显示版本信息就退出 -J&lt; flag &gt; 因为 jhat 命令实际上会启动一个JVM来执行, 通过 -J 可以在启动JVM时传入一些启动参数. 例如, -J-Xmx512m 则指定运行 jhat 的Java虚拟机使用的最大堆内存为 512 MB. 如果需要使用多个JVM启动参数,则传入多个 -Jxxxxxx. OQLjhat还提供了一种对象查询语言(Object Query Language)，OQL有点类似SQL,可以用来查询。 OQL语句的执行页面: http://localhost:7000/oql/ OQL帮助信息页面为: http://localhost:7000/oqlhelp/ OQL的预发可以在帮助页面查看，这里就不详细讲解了。 参考资料jhat Java命令学习系列（六）— jinfojinfo可以输出java进程、core文件或远程debug服务器的配置信息。这些配置信息包括JAVA系统参数及命令行参数,如果进程运行在64位虚拟机上，需要指明-J-d64参数，如：jinfo -J-d64 -sysprops pid 另外，Java7的官方文档指出，这一命令在后续的版本中可能不再使用。笔者使用的版本(jdk8)中已经不支持该命令(笔者翻阅了java8中该命令的文档，其中已经明确说明不再支持)。提示如下： 123456789101112131415161718192021HollisMacBook-Air:test-workspace hollis$ jinfo 92520Attaching to process ID 92520, please wait...^@Exception in thread \"main\" java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at sun.tools.jinfo.JInfo.runTool(JInfo.java:97) at sun.tools.jinfo.JInfo.main(JInfo.java:71)Caused by: sun.jvm.hotspot.runtime.VMVersionMismatchException: Supported versions are 24.79-b02. Target VM is 25.40-b25 at sun.jvm.hotspot.runtime.VM.checkVMVersion(VM.java:234) at sun.jvm.hotspot.runtime.VM.&lt;init&gt;(VM.java:297) at sun.jvm.hotspot.runtime.VM.initialize(VM.java:368) at sun.jvm.hotspot.bugspot.BugSpotAgent.setupVM(BugSpotAgent.java:598) at sun.jvm.hotspot.bugspot.BugSpotAgent.go(BugSpotAgent.java:493) at sun.jvm.hotspot.bugspot.BugSpotAgent.attach(BugSpotAgent.java:331) at sun.jvm.hotspot.tools.Tool.start(Tool.java:163) at sun.jvm.hotspot.tools.JInfo.main(JInfo.java:128) ... 6 more 由于打印jvm常用信息可以使用jps命令，并且在后续的java版本中可能不再支持，所以这个命令笔者就不详细介绍了。下面给出help信息，读者可自行阅读使用。（这就好像上高中，老师讲到一些难点的时候说，不明白也不要紧，知道有这么一回事就可以了！） 用法摘要以键值对的形式打印出JAVA系统参数及命令行参数的名称和内容。 1234567891011121314-flag nameprints the name and value of the given command line flag.-flag [+|-]nameenables or disables the given boolean command line flag.-flag name=valuesets the given command line flag to the specified value.-flagsprints command line flags passed to the JVM. pairs.-syspropsprints Java System properties as name, value pairs.-hprints a help message-helpprints a help message 参考资料jinfo Java命令学习系列（七）— javap javap是jdk自带的一个工具，可以对代码反编译，也可以查看java编译器生成的字节码。 一般情况下，很少有人使用javap对class文件进行反编译，因为有很多成熟的反编译工具可以使用，比如jad。但是，javap还可以查看java编译器为我们生成的字节码。通过它，可以对照源代码和字节码，从而了解很多编译器内部的工作。 实例javap命令分解一个class文件，它根据options来决定到底输出什么。如果没有使用options,那么javap将会输出包，类里的protected和public域以及类里的所有方法。javap将会把它们输出在标准输出上。来看这个例子，先编译(javac)下面这个类。 123456789101112131415161718import java.awt.*;import java.applet.*;public class DocFooter extends Applet &#123; String date; String email; public void init() &#123; resize(500,100); date = getParameter(\"LAST_UPDATED\"); email = getParameter(\"EMAIL\"); &#125; public void paint(Graphics g) &#123; g.drawString(date + \" by \",100, 15); g.drawString(email,290,15); &#125;&#125; 在命令行上键入javap DocFooter后，输出结果如下 12345678Compiled from \"DocFooter.java\"public class DocFooter extends java.applet.Applet &#123; java.lang.String date; java.lang.String email; public DocFooter(); public void init(); public void paint(java.awt.Graphics);&#125; 如果加入了-c，即javap -c DocFooter，那么输出结果如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253Compiled from \"DocFooter.java\"public class DocFooter extends java.applet.Applet &#123; java.lang.String date; java.lang.String email; public DocFooter(); Code: 0: aload_0 1: invokespecial #1 // Method java/applet/Applet.\"&lt;init&gt;\":()V 4: return public void init(); Code: 0: aload_0 1: sipush 500 4: bipush 100 6: invokevirtual #2 // Method resize:(II)V 9: aload_0 10: aload_0 11: ldc #3 // String LAST_UPDATED 13: invokevirtual #4 // Method getParameter:(Ljava/lang/String;)Ljava/lang/String; 16: putfield #5 // Field date:Ljava/lang/String; 19: aload_0 20: aload_0 21: ldc #6 // String EMAIL 23: invokevirtual #4 // Method getParameter:(Ljava/lang/String;)Ljava/lang/String; 26: putfield #7 // Field email:Ljava/lang/String; 29: return public void paint(java.awt.Graphics); Code: 0: aload_1 1: new #8 // class java/lang/StringBuilder 4: dup 5: invokespecial #9 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 8: aload_0 9: getfield #5 // Field date:Ljava/lang/String; 12: invokevirtual #10 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 15: ldc #11 // String by 17: invokevirtual #10 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 20: invokevirtual #12 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 23: bipush 100 25: bipush 15 27: invokevirtual #13 // Method java/awt/Graphics.drawString:(Ljava/lang/String;II)V 30: aload_1 31: aload_0 32: getfield #7 // Field email:Ljava/lang/String; 35: sipush 290 38: bipush 15 40: invokevirtual #13 // Method java/awt/Graphics.drawString:(Ljava/lang/String;II)V 43: return &#125; 上面输出的内容就是字节码。 用法摘要12345678910-help 帮助-l 输出行和变量的表-public 只输出public方法和域-protected 只输出public和protected类和成员-package 只输出包，public和protected类和成员，这是默认的-p -private 输出所有类和成员-s 输出内部类型签名-c 输出分解后的代码，例如，类中每一个方法内，包含java字节码的指令，-verbose 输出栈大小，方法参数的个数-constants 输出静态final常量 总结javap可以用于反编译和查看编译器编译后的字节码。平时一般用javap -c比较多，该命令用于列出每个方法所执行的JVM指令，并显示每个方法的字节码的实际作用。可以通过字节码和源代码的对比，深入分析java的编译原理，了解和解决各种Java原理级别的问题。 Java代码的编译与反编译那些事儿编程语言在介绍编译和反编译之前，我们先来简单介绍下编程语言（Programming Language）。编程语言（Programming Language）分为低级语言（Low-level Language）和高级语言（High-level Language）。 机器语言（Machine Language）和汇编语言（Assembly Language）属于低级语言，直接用计算机指令编写程序。 而C、C++、Java、Python等属于高级语言，用语句（Statement）编写程序，语句是计算机指令的抽象表示。 举个例子，同样一个语句用C语言、汇编语言和机器语言分别表示如下： 计算机只能对数字做运算，符号、声音、图像在计算机内部都要用数字表示，指令也不例外，上表中的机器语言完全由十六进制数字组成。最早的程序员都是直接用机器语言编程，但是很麻烦，需要查大量的表格来确定每个数字表示什么意思，编写出来的程序很不直观，而且容易出错，于是有了汇编语言，把机器语言中一组一组的数字用助记符（Mnemonic）表示，直接用这些助记符写出汇编程序，然后让汇编器（Assembler）去查表把助记符替换成数字，也就把汇编语言翻译成了机器语言。 但是，汇编语言用起来同样比较复杂，后面，就衍生出了Java、C、C++等高级语言。 什么是编译上面提到语言有两种，一种低级语言，一种高级语言。可以这样简单的理解：低级语言是计算机认识的语言、高级语言是程序员认识的语言。 那么如何从高级语言转换成低级语言呢？这个过程其实就是编译。 从上面的例子还可以看出，C语言的语句和低级语言的指令之间不是简单的一一对应关系，一条a=b+1;语句要翻译成三条汇编或机器指令，这个过程称为编译（Compile），由编译器（Compiler）来完成，显然编译器的功能比汇编器要复杂得多。用C语言编写的程序必须经过编译转成机器指令才能被计算机执行，编译需要花一些时间，这是用高级语言编程的一个缺点，然而更多的是优点。首先，用C语言编程更容易，写出来的代码更紧凑，可读性更强，出了错也更容易改正。 将便于人编写、阅读、维护的高级计算机语言所写作的源代码程序，翻译为计算机能解读、运行的低阶机器语言的程序的过程就是编译。负责这一过程的处理的工具叫做编译器 现在我们知道了什么是编译，也知道了什么是编译器。不同的语言都有自己的编译器，Java语言中负责编译的编译器是一个命令：javac javac是收录于JDK中的Java语言编译器。该工具可以将后缀名为.java的源文件编译为后缀名为.class的可以运行于Java虚拟机的字节码。 当我们写完一个HelloWorld.java文件后，我们可以使用javac HelloWorld.java命令来生成HelloWorld.class文件，这个class类型的文件是JVM可以识别的文件。通常我们认为这个过程叫做Java语言的编译。其实，class文件仍然不是机器能够识别的语言，因为机器只能识别机器语言，还需要JVM再将这种class文件类型字节码转换成机器可以识别的机器语言。 什么是反编译反编译的过程与编译刚好相反，就是将已编译好的编程语言还原到未编译的状态，也就是找出程序语言的源代码。就是将机器看得懂的语言转换成程序员可以看得懂的语言。Java语言中的反编译一般指将class文件转换成java文件。 有了反编译工具，我们可以做很多事情，最主要的功能就是有了反编译工具，我们就能读得懂Java编译器生成的字节码。如果你想问读懂字节码有啥用，那么我可以很负责任的告诉你，好处大大的。比如我的博文几篇典型的原理性文章，都是通过反编译工具得到反编译后的代码分析得到的。如深入理解多线程（一）— Synchronized的实现原理、深度分析Java的枚举类型—-枚举的线程安全性及序列化问题、Java中的Switch对整型、字符型、字符串型的具体实现细节、Java的类型擦除等。我最近在GitChat写了一篇关于Java语法糖的文章，其中大部分内容都用到反编译工具来洞悉语法糖背后的原理。 Java反编译工具本文主要介绍3个Java的反编译工具：javap、jad和cfr javapjavap是jdk自带的一个工具，可以对代码反编译，也可以查看java编译器生成的字节码。javap和其他两个反编译工具最大的区别是他生成的文件并不是java文件，也不像其他两个工具生成代码那样更容易理解。拿一段简单的代码举例，如我们想分析Java 7中的switch是如何支持String的，我们先有以下可以编译通过的源代码： 123456789101112131415public class switchDemoString &#123; public static void main(String[] args) &#123; String str = \"world\"; switch (str) &#123; case \"hello\": System.out.println(\"hello\"); break; case \"world\": System.out.println(\"world\"); break; default: break; &#125; &#125;&#125; 执行以下两个命令： 12javac switchDemoString.javajavap -c switchDemoString.class 生成代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class com.hollis.suguar.switchDemoString &#123; public com.hollis.suguar.switchDemoString(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return public static void main(java.lang.String[]); Code: 0: ldc #2 // String world 2: astore_1 3: aload_1 4: astore_2 5: iconst_m1 6: istore_3 7: aload_2 8: invokevirtual #3 // Method java/lang/String.hashCode:()I 11: lookupswitch &#123; // 2 99162322: 36 113318802: 50 default: 61 &#125; 36: aload_2 37: ldc #4 // String hello 39: invokevirtual #5 // Method java/lang/String.equals:(Ljava/lang/Object;)Z 42: ifeq 61 45: iconst_0 46: istore_3 47: goto 61 50: aload_2 51: ldc #2 // String world 53: invokevirtual #5 // Method java/lang/String.equals:(Ljava/lang/Object;)Z 56: ifeq 61 59: iconst_1 60: istore_3 61: iload_3 62: lookupswitch &#123; // 2 0: 88 1: 99 default: 110 &#125; 88: getstatic #6 // Field java/lang/System.out:Ljava/io/PrintStream; 91: ldc #4 // String hello 93: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 96: goto 110 99: getstatic #6 // Field java/lang/System.out:Ljava/io/PrintStream; 102: ldc #2 // String world 104: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 107: goto 110 110: return&#125; 我个人的理解，javap并没有将字节码反编译成java文件，而是生成了一种我们可以看得懂字节码。其实javap生成的文件仍然是字节码，只是程序员可以稍微看得懂一些。如果你对字节码有所掌握，还是可以看得懂以上的代码的。其实就是把String转成hashcode，然后进行比较。 个人认为，一般情况下我们会用到javap命令的时候不多，一般只有在真的需要看字节码的时候才会用到。但是字节码中间暴露的东西是最全的，你肯定有机会用到，比如我在分析synchronized的原理的时候就有是用到javap。通过javap生成的字节码，我发现synchronized底层依赖了ACC_SYNCHRONIZED标记和monitorenter、monitorexit两个指令来实现同步。 jadjad是一个比较不错的反编译工具，只要下载一个执行工具，就可以实现对class文件的反编译了。还是上面的源代码，使用jad反编译后内容如下： 命令：jad switchDemoString.class 123456789101112131415161718192021222324public class switchDemoString&#123; public switchDemoString() &#123; &#125; public static void main(String args[]) &#123; String str = \"world\"; String s; switch((s = str).hashCode()) &#123; default: break; case 99162322: if(s.equals(\"hello\")) System.out.println(\"hello\"); break; case 113318802: if(s.equals(\"world\")) System.out.println(\"world\"); break; &#125; &#125;&#125; 看，这个代码你肯定看的懂，因为这不就是标准的java的源代码么。这个就很清楚的可以看到原来字符串的switch是通过equals()和hashCode()方法来实现的。 但是，jad已经很久不更新了，在对Java7生成的字节码进行反编译时，偶尔会出现不支持的问题，在对Java 8的lambda表达式反编译时就彻底失败。 CFRjad很好用，但是无奈的是很久没更新了，所以只能用一款新的工具替代他，CFR是一个不错的选择，相比jad来说，他的语法可能会稍微复杂一些，但是好在他可以work。 如，我们使用cfr对刚刚的代码进行反编译。执行一下命令： 1java -jar cfr_0_125.jar switchDemoString.class --decodestringswitch false 得到以下代码： 12345678910111213141516171819202122232425262728public class switchDemoString &#123; public static void main(String[] arrstring) &#123; String string; String string2 = string = \"world\"; int n = -1; switch (string2.hashCode()) &#123; case 99162322: &#123; if (!string2.equals(\"hello\")) break; n = 0; break; &#125; case 113318802: &#123; if (!string2.equals(\"world\")) break; n = 1; &#125; &#125; switch (n) &#123; case 0: &#123; System.out.println(\"hello\"); break; &#125; case 1: &#123; System.out.println(\"world\"); break; &#125; &#125; &#125;&#125; 通过这段代码也能得到字符串的switch是通过equals()和hashCode()方法来实现的结论。 相比Jad来说，CFR有很多参数，还是刚刚的代码，如果我们使用以下命令，输出结果就会不同： 1java -jar cfr_0_125.jar switchDemoString.class 123456789101112131415public class switchDemoString &#123; public static void main(String[] arrstring) &#123; String string; switch (string = \"world\") &#123; case \"hello\": &#123; System.out.println(\"hello\"); break; &#125; case \"world\": &#123; System.out.println(\"world\"); break; &#125; &#125; &#125;&#125; 所以--decodestringswitch表示对于switch支持string的细节进行解码。类似的还有--decodeenumswitch、--decodefinally、--decodelambdas等。在我的关于语法糖的文章中，我使用--decodelambdas对lambda表达式警进行了反编译。 源码： 12345public static void main(String... args) &#123; List&lt;String&gt; strList = ImmutableList.of(\"Hollis\", \"公众号：Hollis\", \"博客：www.hollischuang.com\"); strList.forEach( s -&gt; &#123; System.out.println(s); &#125; );&#125; java -jar cfr_0_125.jar lambdaDemo.class --decodelambdas false反编译后代码： 12345678public static /* varargs */ void main(String ... args) &#123; ImmutableList strList = ImmutableList.of((Object)\"Hollis\", (Object)\"\\u516c\\u4f17\\u53f7\\uff1aHollis\", (Object)\"\\u535a\\u5ba2\\uff1awww.hollischuang.com\"); strList.forEach((Consumer&lt;String&gt;)LambdaMetafactory.metafactory(null, null, null, (Ljava/lang/Object;)V, lambda$main$0(java.lang.String ), (Ljava/lang/String;)V)());&#125;private static /* synthetic */ void lambda$main$0(String s) &#123; System.out.println(s);&#125; CFR还有很多其他参数，均用于不同场景，读者可以使用java -jar cfr_0_125.jar --help进行了解。这里不逐一介绍了。 如何防止反编译由于我们有工具可以对Class文件进行反编译，所以，对开发人员来说，如何保护Java程序就变成了一个非常重要的挑战。但是，魔高一尺、道高一丈。当然有对应的技术可以应对反编译咯。但是，这里还是要说明一点，和网络安全的防护一样，无论做出多少努力，其实都只是提高攻击者的成本而已。无法彻底防治。 典型的应对策略有以下几种： 隔离Java程序 让用户接触不到你的Class文件 对Class文件进行加密 提到破解难度 代码混淆 将代码转换成功能上等价，但是难于阅读和理解的形式 Java虚拟机的内存组成以及堆内存介绍什么是Java虚拟机这里就不介绍了，不明白的可以另外一篇博文：JDK,JRE,JVM区别与联系 java内存组成介绍：堆(Heap)和非堆(Non-heap)内存 按照官方的说法：“Java 虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在 Java 虚拟机启动时创建的。”“在JVM中堆之外的内存称为非堆内存(Non-heap memory)”。可以看出JVM主要管理两种类型的内存：堆和非堆。简单来说堆就是Java代码可及的内存，是留给开发人员使用的；非堆就是JVM留给 自己用的，所以方法区、JVM内部处理或优化所需的内存(如JIT编译后的代码缓存)、每个类结构(如运行时常数池、字段和方法数据)以及方法和构造方法 的代码都在非堆内存中。 JVM内存区域模型 1.方法区 也称”永久代” 、“非堆”， 它用于存储虚拟机加载的类信息、常量、静态变量、是各个线程共享的内存区域。默认最小值为16MB，最大值为64MB，可以通过-XX:PermSize 和 -XX:MaxPermSize 参数限制方法区的大小。 运行时常量池：是方法区的一部分，其中的主要内容来自于JVM对Class的加载。 Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译器生成的各种符号引用，这部分内容将在类加载后放到方法区的运行时常量池中。 2.虚拟机栈 描述的是java 方法执行的内存模型：每个方法被执行的时候 都会创建一个“栈帧”用于存储局部变量表(包括参数)、操作栈、方法出口等信息。每个方法被调用到执行完的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。声明周期与线程相同，是线程私有的。 局部变量表存放了编译器可知的各种基本数据类型(boolean、byte、char、short、int、float、long、double)、对象引用(引用指针，并非对象本身)，其中64位长度的long和double类型的数据会占用2个局部变量的空间，其余数据类型只占1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量是完全确定的，在运行期间栈帧不会改变局部变量表的大小空间。 3.本地方法栈 与虚拟机栈基本类似，区别在于虚拟机栈为虚拟机执行的java方法服务，而本地方法栈则是为Native方法服务。 4.堆 也叫做java 堆、GC堆是java虚拟机所管理的内存中最大的一块内存区域，也是被各个线程共享的内存区域，在JVM启动时创建。该内存区域存放了对象实例及数组(所有new的对象)。其大小通过-Xms(最小值)和-Xmx(最大值)参数设置，-Xms为JVM启动时申请的最小内存，默认为操作系统物理内存的1/64但小于1G，-Xmx为JVM可申请的最大内存，默认为物理内存的1/4但小于1G，默认当空余堆内存小于40%时，JVM会增大Heap到-Xmx指定的大小，可通过-XX:MinHeapFreeRation=来指定这个比列；当空余堆内存大于70%时，JVM会减小heap的大小到-Xms指定的大小，可通过XX:MaxHeapFreeRation=来指定这个比列，对于运行系统，为避免在运行时频繁调整Heap的大小，通常-Xms与-Xmx的值设成一样。 由于现在收集器都是采用分代收集算法，堆被划分为新生代和老年代。新生代主要存储新创建的对象和尚未进入老年代的对象。老年代存储经过多次新生代GC(Minor GC)任然存活的对象。 新生代： 程序新创建的对象都是从新生代分配内存，新生代由Eden Space和两块相同大小的Survivor Space(通常又称S0和S1或From和To)构成，可通过-Xmn参数来指定新生代的大小，也可以通过-XX:SurvivorRation来调整Eden Space及Survivor Space的大小。 老年代： 用于存放经过多次新生代GC任然存活的对象，例如缓存对象，新建的对象也有可能直接进入老年代，主要有两种情况：①.大对象，可通过启动参数设置-XX:PretenureSizeThreshold=1024(单位为字节，默认为0)来代表超过多大时就不在新生代分配，而是直接在老年代分配。②.大的数组对象，切数组中无引用外部对象。 老年代所占的内存大小为-Xmx对应的值减去-Xmn对应的值。 12345Young Generation 即图中的Eden + From Space + To SpaceEden 存放新生的对象Survivor Space 有两个，存放每次垃圾回收后存活的对象Old Generation Tenured Generation 即图中的Old Space 主要存放应用程序中生命周期长的存活对象 5.程序计数器 是最小的一块内存区域，它的作用是当前线程所执行的字节码的行号指示器，在虚拟机的模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、异常处理、线程恢复等基础功能都需要依赖计数器完成。 直接内存直接内存并不是虚拟机内存的一部分，也不是Java虚拟机规范中定义的内存区域。jdk1.4中新加入的NIO，引入了通道与缓冲区的IO方式，它可以调用Native方法直接分配堆外内存，这个堆外内存就是本机内存，不会影响到堆内存的大小。 Java堆内存的10个要点 Java堆内存是操作系统分配给JVM的内存的一部分。 当我们创建对象时，它们存储在Java堆内存中。 为了便于垃圾回收，Java堆空间分成三个区域，分别叫作New Generation, Old Generation或叫作Tenured Generation，还有Perm Space。 你可以通过用JVM的命令行选项 -Xms, -Xmx, -Xmn来调整Java堆空间的大小。不要忘了在大小后面加上”M”或者”G”来表示单位。举个例子，你可以用 -Xmx256m来设置堆内存最大的大小为256MB。 你可以用JConsole或者 Runtime.maxMemory(), Runtime.totalMemory(), Runtime.freeMemory()来查看Java中堆内存的大小。 你可以使用命令“jmap”来获得heap dump，用“jhat”来分析heap dump。 Java堆空间不同于栈空间，栈空间是用来储存调用栈和局部变量的。 Java垃圾回收器是用来将死掉的对象(不再使用的对象)所占用的内存回收回来，再释放到Java堆空间中。 当你遇到java.lang.outOfMemoryError时，不要紧张，有时候仅仅增加堆空间就可以了，但如果经常出现的话，就要看看Java程序中是不是存在内存泄露了。 请使用Profiler和Heap dump分析工具来查看Java堆空间，可以查看给每个对象分配了多少内存。 Java GC工作原理GC的基本原理GC是什么?为什么要有GC呢? GC是垃圾收集的意思（GarbageCollection）,内存处理是编程人员容易出现问题的地方，忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃，Java提供的GC功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的，Java语言没有提供释放已分配内存的显示操作方法。 所以，Java的内存管理实际上就是对象的管理，其中包括对象的分配和释放。对于程序员来说，分配对象使用new关键字；释放对象时，只要将对象所有引用赋值为null，让程序不能够再访问到这个对象，我们称该对象为”不可达的”.GC将负责回收所有”不可达”对象的内存空间。对于GC来说，当程序员创建对象时，GC就开始监控这个对象的地址、大小以及使用情况。通常，GC采用有向图的方式记录和管理堆（heap）中的所有对象。通过这种方式确定哪些对象是”可达的”，哪些对象是”不可达的”.当GC确定一些对象为”不可达”时，GC就有责任回收这些内存空间。但是，为了保证GC能够在不同平台实现的问题，Java规范对GC的很多行为都没有进行严格的规定。例如，对于采用什么类型的回收算法、什么时候进行回收等重要问题都没有明确的规定。因此，不同的JVM的实现者往往有不同的实现算法。这也给Java程序员的开发带来行多不确定性。本文研究了几个与GC工作相关的问题，努力减少这种不确定性给Java程序带来的负面影响。 增量式GC（IncrementalGC）GC在JVM中通常是由一个或一组进程来实现的，它本身也和用户程序一样占用heap空间，运行时也占用CPU.当GC进程运行时，应用程序停止运行。因此，当GC运行时间较长时，用户能够感到Java程序的停顿，另外一方面，如果GC运行时间太短，则可能对象回收率太低，这意味着还有很多应该回收的对象没有被回收，仍然占用大量内存。因此，在设计GC的时候，就必须在停顿时间和回收率之间进行权衡。一个好的GC实现允许用户定义自己所需要的设置，例如有些内存有限有设备，对内存的使用量非常敏感，希望GC能够准确的回收内存，它并不在意程序速度的放慢。另外一些实时网络游戏，就不能够允许程序有长时间的中断。增量式GC就是通过一定的回收算法，把一个长时间的中断，划分为很多个小的中断，通过这种方式减少GC对用户程序的影响。虽然，增量式GC在整体性能上可能不如普通GC的效率高，但是它能够减少程序的最长停顿时间。SunJDK提供的HotSpotJVM就能支持增量式GC.HotSpotJVM缺省GC方式为不使用增量GC，为了启动增量GC，我们必须在运行Java程序时增加-Xincgc的参数。HotSpotJVM增量式GC的实现是采用TrainGC算法。它的基本想法就是，将堆中的所有对象按照创建和使用情况进行分组（分层），将使用频繁高和具有相关性的对象放在一队中，随着程序的运行，不断对组进行调整。当GC运行时，它总是先回收最老的（最近很少访问的）的对象，如果整组都为可回收对象，GC将整组回收。这样，每次GC运行只回收一定比例的不可达对象，保证程序的顺畅运行。 为什么要分代分代的垃圾回收策略，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。在Java程序运行的过程中，会产生大量的对象，其中有些对象是与业务信息相关，比如Http请求中的Session对象、线程、Socket连接，这类对象跟业务直接挂钩，因此生命周期比较长。但是还有一些对象，主要是程序运行过程中生成的临时变量，这些对象生命周期会比较短，比如：String对象，由于其不变类的特性，系统会产生大量的这些对象，有些对象甚至只用一次即可回收。试想，在不进行对象存活时间区分的情况下，每次垃圾回收都是对整个堆空间进行回收，花费时间相对会长，同时，因为每次回收都需要遍历所有存活对象，但实际上，对于生命周期长的对象而言，这种遍历是没有效果的，因为可能进行了很多次遍历，但是他们依旧存在。因此，分代垃圾回收采用分治的思想，进行代的划分，把不同生命周期的对象放在不同代上，不同代上采用最适合它的垃圾回收方式进行回收。 虚拟机中的共划分为三个代：年轻代(Young Generation)、年老点(Old Generation)和持久代(Permanent Generation)。其中持久代主要存放的是Java类的类信息，与垃圾收集要收集的Java对象关系不大。年轻代和年老代的划分是对垃圾收集影响比较大的。 年轻代: 所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。年轻代分三个区。一个Eden区，两个Survivor区(一般而言)。大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区(两个中的一个)，当这个Survivor区满时，此区的存活对象将被复制到另外一个Survivor区，当这个Survivor去也满了的时候，从第一个Survivor区复制过来的并且此时还存活的对象，将被复制“年老区(Tenured)”。需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来 对象，和从前一个Survivor复制过来的对象，而复制到年老区的只有从第一个Survivor去过来的对象。而且，Survivor区总有一个是空的。同时，根据程序需要，Survivor区是可以配置为多个的(多于两个)，这样可以增加对象在年轻代中的存在时间，减少被放到年老代的可能。 年老代: 在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 持久代: 用于存放静态文件，如今Java类、方法等。持久代对垃圾回收没有显着影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。持久代大小通过-XX:MaxPermSize=进行设置。 什么情况下触发垃圾回收由于对象进行了分代处理，因此垃圾回收区域、时间也不一样。GC有两种类型：Scavenge GC和Full GC。 Scavenge GC一般情况下，当新对象生成，并且在Eden申请空间失败时，就会触发Scavenge GC，对Eden区域进行GC，清除非存活对象，并且把尚且存活的对象移动到Survivor区。然后整理Survivor的两个区。这种方式的GC是对年轻代的Eden区进行，不会影响到年老代。因为大部分对象都是从Eden区开始的，同时Eden区不会分配的很大，所以Eden区的GC会频繁进行。因而，一般在这里需要使用速度快、效率高的算法，使Eden去能尽快空闲出来。Full GC对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个对进行回收，所以比Scavenge GC要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于FullGC的调节。有如下原因可能导致Full GC：· 年老代(Tenured)被写满· 持久代(Perm)被写满· System.gc()被显示调用·上一次GC之后Heap的各域分配策略动态变化 详解finalize函数finalize是位于Object类的一个方法，该方法的访问修饰符为protected，由于所有类为Object的子类，因此用户类很容易访问到这个方法。由于，finalize函数没有自动实现链式调用，我们必须手动的实现，因此finalize函数的最后一个语句通常是super.finalize（）。通过这种方式，我们可以实现从下到上实现finalize的调用，即先释放自己的资源，然后再释放父类的资源。根据Java语言规范，JVM保证调用finalize函数之前，这个对象是不可达的，但是JVM不保证这个函数一定会被调用。另外，规范还保证finalize函数最多运行一次。很多Java初学者会认为这个方法类似与C++中的析构函数，将很多对象、资源的释放都放在这一函数里面。其实，这不是一种很好的方式。原因有三，其一，GC为了能够支持finalize函数，要对覆盖这个函数的对象作很多附加的工作。其二，在finalize运行完成之后，该对象可能变成可达的，GC还要再检查一次该对象是否是可达的。因此，使用finalize会降低GC的运行性能。其三，由于GC调用finalize的时间是不确定的，因此通过这种方式释放资源也是不确定的。通常，finalize用于一些不容易控制、并且非常重要资源的释放，例如一些I/O的操作，数据的连接。这些资源的释放对整个应用程序是非常关键的。在这种情况下，程序员应该以通过程序本身管理（包括释放）这些资源为主，以finalize函数释放资源方式为辅，形成一种双保险的管理机制，而不应该仅仅依靠finalize来释放资源。下面给出一个例子说明，finalize函数被调用以后，仍然可能是可达的，同时也可说明一个对象的finalize只可能运行一次。 123456789101112class MyObject&#123; Testmain;//记录Test对象，在finalize中时用于恢复可达性 publicMyObject(Testt) &#123; main=t;//保存Test对象 &#125; protectedvoidfinalize() &#123; main.ref=this;//恢复本对象，让本对象可达 System.out.println(\"Thisisfinalize\");//用于测试finalize只运行一次 &#125;&#125; 1234567891011121314classTest&#123; MyObjectref; publicstaticvoidmain(String[]args)&#123; Testtest=newTest(); test.ref=newMyObject(test); test.ref=null;//MyObject对象为不可达对象，finalize将被调用 System.gc(); if(test.ref!=null)System.out.println(\"MyObject还活着\"); &#125;&#125;运行结果：Thisisfinalize MyObject还活着：此例子中，需要注意的是虽然MyObject对象在finalize中变成可达对象，但是下次回收时候，finalize却不再被调用，因为finalize函数最多只调用一次。 程序如何与GC进行交互Java2增强了内存管理功能，增加了一个java.lang.ref包，其中定义了三种引用类。这三种引用类分别为SoftReference、WeakReference和PhantomReference.通过使用这些引用类，程序员可以在一定程度与GC进行交互，以便改善GC的工作效率。这些引用类的引用强度介于可达对象和不可达对象之间。创建一个引用对象也非常容易，例如如果你需要创建一个SoftReference对象，那么首先创建一个对象，并采用普通引用方式（可达对象）；然后再创建一个SoftReference引用该对象；最后将普通引用设置为null.通过这种方式，这个对象就只有一个SoftReference引用。同时，我们称这个对象为SoftReference对象。SoftReference的主要特点是据有较强的引用功能。只有当内存不够的时候，才进行回收这类内存，因此在内存足够的时候，它们通常不被回收。另外，这些引用对象还能保证在Java抛出OutOfMemory异常之前，被设置为null.它可以用于实现一些常用图片的缓存，实现Cache的功能，保证最大限度的使用内存而不引起OutOfMemory.以下给出这种引用类型的使用伪代码； 12345678910111213141516//申请一个图像对象Imageimage=newImage();//创建Image对象 …//使用image …//使用完了image，将它设置为soft引用类型，并且释放强引用；SoftReferencesr=newSoftReference(image);image=null; …//下次使用时if(sr!=null)image=sr.get();else&#123;//由于GC由于低内存，已释放image，因此需要重新装载；image=newImage();sr=newSoftReference(image);&#125; Weak引用对象与Soft引用对象的最大不同就在于：GC在进行回收时，需要通过算法检查是否回收Soft引用对象，而对于Weak引用对象，GC总是进行回收。Weak引用对象更容易、更快被GC回收。虽然，GC在运行时一定回收Weak对象，但是复杂关系的Weak对象群常常需要好几次GC的运行才能完成。Weak引用对象常常用于Map结构中，引用数据量较大的对象，一旦该对象的强引用为null时，GC能够快速地回收该对象空间。Phantom引用的用途较少，主要用于辅助finalize函数的使用。Phantom对象指一些对象，它们执行完了finalize函数，并为不可达对象，但是它们还没有被GC回收。这种对象可以辅助finalize进行一些后期的回收工作，我们通过覆盖Reference的clear（）方法，增强资源回收机制的灵活性。 一些Java编程的建议根据GC的工作原理，我们可以通过一些技巧和方式，让GC运行更加有效率，更加符合应用程序的要求。一些关于程序设计的几点建议： 1. 最基本的建议就是尽早释放无用对象的引用。大多数程序员在使用临时变量的时候，都是让引用变量在退出活动域（scope）后，自动设置为null.我们在使用这种方式时候，必须特别注意一些复杂的对象图，例如数组，队列，树，图等，这些对象之间有相互引用关系较为复杂。对于这类对象，GC回收它们一般效率较低。如果程序允许，尽早将不用的引用对象赋为null.这样可以加速GC的工作。 2. 尽量少用finalize函数。finalize函数是Java提供给程序员一个释放对象或资源的机会。但是，它会加大GC的工作量，因此尽量少采用finalize方式回收资源。 3. 如果需要使用经常使用的图片，可以使用soft应用类型。它可以尽可能将图片保存在内存中，供程序调用，而不引起OutOfMemory. 4. 注意集合数据类型，包括数组，树，图，链表等数据结构，这些数据结构对GC来说，回收更为复杂。另外，注意一些全局的变量，以及一些静态变量。这些变量往往容易引起悬挂对象（danglingreference），造成内存浪费。 5. 当程序有一定的等待时间，程序员可以手动执行System.gc（），通知GC运行，但是Java语言规范并不保证GC一定会执行。使用增量式GC可以缩短Java程序的暂停时间。 Java的垃圾回收机制a、 停止—复制(stop-and-copy)：先暂停程序的运行，然后将所有存活的对象从当前堆复制到另一个堆，没有复制的全部都是垃圾。当对象被复制到新堆时，它们是一个挨着一个的，紧凑的。效率很低：首先，得有两个堆空间占用率200%;其次，垃圾较少时，复制大量的活着的对象，是很大的浪费。 b、 标记—清扫(mark-and-sweep)：从对战和静态存储区出发，遍历所有的引用，进而找出所有存活的对象，如果活着，就标记。只有全部标记完毕的时候，清理动作才开始。在清理的时候，没有标记的对象将会被释放，不会发生任何肤质动作。但是盛夏的对空间是不连续的，垃圾回收器要是希望得到连续空间的话，就得重新整理剩下的对象。 c、 注意：“停止—复制”的意思是这种垃圾回收动作不是在后台进行的;相反，垃圾回收动作发生的同时，程序将会被暂停。有人将垃圾回收视为低优先级的后台进程，而事实上并不是这样，当可用内存数量比较低的时候，Sun版本的垃圾回收器就会暂停运行程序。同样，“标记-清扫”工作也必须在程序暂停的情况下才能进行。 d、 在java虚拟机中，内存分配是以较大的块为单位的。每个块内都用相应的代数(generation count)来记录它是否还存活。代数随着引用的次数而增加。垃圾回收器将对上次回收动作之后的新分配的块进行整理。这对处理大量短命的临时对象很有帮助。垃圾回收器会定期进行完整的清理动作——大型对象仍然不会被复制(只是代数增加)，内涵小型对象的那些块则被复制并整理。Java虚拟机会进行监视，如果所有对象都很稳定，垃圾回收器的效率降低的话，就切换到“标记—清扫”方式;同样，java虚拟机会追踪“标记—清扫”的效果，要是堆空间出现很多碎片，就会切换到“停止—复制”方式。这就是“自适应”技术。 总结：Java垃圾回收器是一种“自适应的、分代的、停止—复制、标记-清扫”式的垃圾回收器 JAVA线程dump的分析 — jstack pidJava 的线程线程是指能独立于程序的其它部分运行的执行单元。 JAVA语言能够很好的实现多线程的程序。我们在调试程序，或者在开发后期需要做性能调优的时候，往往也需要了解当前程序正在运行的线程的状态，正在执行的操作，从而分析系统可能存在的问题。 在阅读本文之间，应对 Java线程的编程原理，同步机制有一定了解 产生 JAVA线程 dumpJAVA 的线程 DUMP，就象当前 JAVA进程的一个快照，打印出所有线程的状态和调用堆栈，以及 Monitor的状态。在不同的操作系统下，产生线程 DUMP的方式是不同的。 在 windows环境中，在启动程序的控制台里敲： Ctrl - Break，线程的 dump会产生在标准输出中（ 缺省标准输出就是控制台，如果对输出进行了重定向，则要查看输出文件）。 在 unix， linux和 MacOS 环境中，在控制台中敲： Ctrl-\\，或者，用 “kill -3 ” ，或者 “kill – QUIT ”。 Pid是用所关注的 JAVA进程号，您可以用 “ps -ef | grep java” 找到，或者使用 JDK 5.0中的 “jps -v” 命令获得。 在各个操作系统平台，都可以用 JDK 5.0工具包中的 jstack 这里要注意的是： 不同的 JAVA虚机的线程 DUMP的创建方法和文件格式是不一样的，不同的 JVM版本， dump信息也有差别。本文中，只以 SUN的 hotspot JVM 5.0_06 为例。 在实际运行中，往往一次 dump的信息，还不足以确认问题。建议产生三次 dump信息，如果每次 dump都指向同一个问题，我们才确定问题的典型性。 线程分析JVM 线程在线程中，有一些 JVM内部的后台线程，来执行譬如垃圾回收，或者低内存的检测等等任务，这些线程往往在 JVM初始化的时候就存在，如下所示： 1234567891011121314151617181920212223242526272829303132333435\"Low Memory Detector\" daemon prio=10 tid=0x081465f8 nid=0x7 runnable [0x00000000..0x00000000]\"CompilerThread0\" daemon prio=10 tid=0x08143c58 nid=0x6 waiting on condition [0x00000000..0xfb5fd798]\"Signal Dispatcher\" daemon prio=10 tid=0x08142f08 nid=0x5 waiting on condition [0x00000000..0x00000000]\"Finalizer\" daemon prio=10 tid=0x08137ca0 nid=0x4 in Object.wait() [0xfbeed000..0xfbeeddb8]at java.lang.Object.wait(Native Method)- waiting on &lt;0xef600848&gt; (a java.lang.ref.ReferenceQueue$Lock)at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:116)- locked &lt;0xef600848&gt; (a java.lang.ref.ReferenceQueue$Lock)at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:132)at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)\"Reference Handler\" daemon prio=10 tid=0x081370f0 nid=0x3 in Object.wait() [0xfbf4a000..0xfbf4aa38]at java.lang.Object.wait(Native Method)- waiting on &lt;0xef600758&gt; (a java.lang.ref.Reference$Lock)at java.lang.Object.wait(Object.java:474)at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)- locked &lt;0xef600758&gt; (a java.lang.ref.Reference$Lock)\"VM Thread\" prio=10 tid=0x08134878 nid=0x2 runnable\"VM Periodic Task Thread\" prio=10 tid=0x08147768 nid=0x8 waiting on condition 我们更多的是要观察用户级别的线程，如下所示： 1234567891011\"Thread-1\" prio=10 tid=0x08223860 nid=0xa waiting on condition [0xef47a000..0xef47ac38]at java.lang.Thread.sleep(Native Method)at testthread.MySleepingThread.method2(MySleepingThread.java:53)- locked &lt;0xef63d600&gt; (a testthread.MySleepingThread)at testthread.MySleepingThread.run(MySleepingThread.java:35)at java.lang.Thread.run(Thread.java:595) 我们能看到： 线程的状态： waiting on condition 线程的调用栈 线程的当前锁住的资源： 这些信息对我们随后的分析都有用处。 线程的状态分析正如我们刚看到的那样，线程的状态是一个重要的指标，它会显示在线程 Stacktrace的头一行结尾的地方。那么线程常见的有哪些状态呢？线程在什么样的情况下会进入这种状态呢？我们能从中发现什么线索？&lt; /span&gt; Runnable该状态表示线程具备所有运行条件，在运行队列中准备操作系统的调度，或者正在运行。 Wait on condition该状态出现在线程等待某个条件的发生。具体是什么原因，可以结合 stacktrace来分析。最常见的情况是线程在等待网络的读写，比如当网络数据没有准备好读时，线程处于这种等待状态，而一旦有数据准备好读之后，线程会重新激活，读取并处理数据。在 Java引入 NewIO之前，对于每个网络连接，都有一个对应的线程来处理网络的读写操作，即使没有可读写的数据，线程仍然阻塞在读写操作上，这样有可能造成资源浪费，而且给操作系统的线程调度也带来压力。在 NewIO里采用了新的机制，编写的服务器程序的性能和可扩展性都得到提高。 如果发现有大量的线程都在处在 Wait on condition，从线程 stack看， 正等待网络读写，这可能是一个网络瓶颈的征兆。因为网络阻塞导致线程无法执行。一种情况是网络非常忙，几 乎消耗了所有的带宽，仍然有大量数据等待网络读 写；另一种情况也可能是网络空闲，但由于路由等问题，导致包无法正常的到达。所以要结合系统的一些性能观察工具来综合分析，比如 netstat统计单位时间的发送包的数目，如果很明显超过了所在网络带宽的限制 ; 观察 cpu的利用率，如果系统态的 CPU时间，相对于用户态的 CPU时间比例较高；如果程序运行在 Solaris 10平台上，可以用 dtrace工具看系统调用的情况，如果观察到 read/write的系统调用的次数或者运行时间遥遥领先；这些都指向由于网络带宽所限导致的网络瓶颈。 另外一种出现 Wait on condition的常见情况是该线程在 sleep，等待 sleep的时间到了时候，将被唤醒。 1.3 Waiting for monitor entry 和 in Object.wait() 在多线程的 JAVA程序中，实现线程之间的同步，就要说说 Monitor。 Monitor是 Java中用以实现线程之间的互斥与协作的主要手段，它可以看成是对象或者 Class的锁。每一个对象都有，也仅有一个 monitor。下 面这个图，描述了线程和 Monitor之间关系，以 及线程的状态转换图： 从图中可以看出，每个 Monitor在某个时刻，只能被一个线程拥有，该线程就是 “Active Thread”，而其它线程都是 “Waiting Thread”，分别在两个队列 “ Entry Set”和 “Wait Set”里面等候。在 “Entry Set”中等待的线程状态是 “Waiting for monitor entry”，而在 “Wait Set”中等待的线程状态是 “in Object.wait()”。 先看 “Entry Set”里面的线程。我们称被 synchronized保护起来的代码段为临界区。当一个线程申请进入临界区时，它就进入了 “Entry Set”队列。对应的 code就像： 1234synchronized(obj) &#123;.........&#125; 这时有两种可能性： 该 monitor不被其它线程拥有， Entry Set里面也没有其它等待线程。本线程即成为相应类或者对象的 Monitor的 Owner，执行临界区的代码 该 monitor被其它线程拥有，本线程在 Entry Set队列中等待。 在第一种情况下，线程将处于 “Runnable”的状态，而第二种情况下，线程 DUMP会显示处于 “waiting for monitor entry”。如下所示： 123456789\"Thread-0\" prio=10 tid=0x08222eb0 nid=0x9 waiting for monitor entry [0xf927b000..0xf927bdb8]at testthread.WaitThread.run(WaitThread.java:39)- waiting to lock &lt;0xef63bf08&gt; (a java.lang.Object)- locked &lt;0xef63beb8&gt; (a java.util.ArrayList)at java.lang.Thread.run(Thread.java:595) 临界区的设置，是为了保证其内部的代码执行的原子性和完整性。但是因为临界区在任何时间只允许线程串行通过，这 和我们多线程的程序的初衷是相反的。 如果在多线程的程序中，大量使用 synchronized，或者不适当的使用了它，会造成大量线程在临界区的入口等待，造成系统的性能大幅下降。如果在线程 DUMP中发现了这个情况，应该审查源码，改进程序。 现在我们再来看现在线程为什么会进入 “Wait Set”。当线程获得了 Monitor，进入了临界区之后，如果发现线程继续运行的条件没有满足，它则调用对象（一般就是被 synchronized 的对象）的 wait() 方法，放弃了 Monitor，进入 “Wait Set”队列。只有当别的线程在该对象上调用了 notify() 或者 notifyAll() ， “ Wait Set”队列中线程才得到机会去竞争，但是只有一个线程获得对象的 Monitor，恢复到运行态。在 “Wait Set”中的线程， DUMP中表现为： in Object.wait()，类似于： 12345678910111213\"Thread-1\" prio=10 tid=0x08223250 nid=0xa in Object.wait() [0xef47a000..0xef47aa38]at java.lang.Object.wait(Native Method)- waiting on &lt;0xef63beb8&gt; (a java.util.ArrayList)at java.lang.Object.wait(Object.java:474)at testthread.MyWaitThread.run(MyWaitThread.java:40)- locked &lt;0xef63beb8&gt; (a java.util.ArrayList)at java.lang.Thread.run(Thread.java:595) 仔细观察上面的 DUMP信息，你会发现它有以下两行： 123- locked &lt;0xef63beb8&gt; (a java.util.ArrayList)- waiting on &lt;0xef63beb8&gt; (a java.util.ArrayList) 这里需要解释一下，为什么先 lock了这个对象，然后又 waiting on同一个对象呢？让我们看看这个线程对应的代码： 12345synchronized(obj) &#123; ......... obj.wait(); .........&#125; 线程的执行中，先用 synchronized 获得了这个对象的 Monitor（对应于 locked ）。当执行到 obj.wait(), 线程即放弃了 Monitor的所有权，进入 “wait set”队列（对应于 waiting on ）。 往往在你的程序中，会出现多个类似的线程，他们都有相似的 DUMP信息。这也可能是正常的。比如，在程序中，有多个服务线程，设计成从一个队列里面读取请求数据。这个队列就是 lock以及 waiting on的对象。当队列为空的时候，这些线程都会在这个队列上等待，直到队列有了数据，这些线程被 Notify，当然只有一个线程获得了 lock，继续执行，而其它线程继续等待。 JDK 5.0 的 lock 上面我们提到如果 synchronized和 monitor机制运用不当，可能会造成多线程程序的性能问题。在 JDK 5.0中，引入了 Lock机制，从而使开发者能更灵活的开发高性能的并发多线程程序，可以替代以往 JDK中的 synchronized和 Monitor的 机制。但是，要注意的是，因为 Lock类只是一个普通类， JVM无从得知 Lock对象的占用情况，所以在线程 DUMP中，也不会包含关于 Lock的信息， 关于死锁等问题，就不如用 synchronized的编程方式容易识别。 案例分析死锁在多线程程序的编写中，如果不适当的运用同步机制，则有可能造成程序的死锁，经常表现为程序的停顿，或者不再响应用户的请求。 比如在下面这个示例中，是个较为典型的死锁情况： 1234567891011121314151617181920\"Thread-1\" prio=5 tid=0x00acc490 nid=0xe50 waiting for monitor entry [0x02d3f000..0x02d3fd68]at deadlockthreads.TestThread.run(TestThread.java:31)- waiting to lock &lt;0x22c19f18&gt; (a java.lang.Object)- locked &lt;0x22c19f20&gt; (a java.lang.Object)\"Thread-0\" prio=5 tid=0x00accdb0 nid=0xdec waiting for monitor entry [0x02cff000..0x02cff9e8]at deadlockthreads.TestThread.run(TestThread.java:31)- waiting to lock &lt;0x22c19f20&gt; (a java.lang.Object)- locked &lt;0x22c19f18&gt; (a java.lang.Object) 在 JAVA 5中加强了对死锁的检测。线程 Dump中可以直接报告出 Java级别的死锁，如下所示： Found one Java-level deadlock: =============================1234567891011\"Thread-1\":waiting to lock monitor 0x0003f334 (object 0x22c19f18, a java.lang.Object),which is held by \"Thread-0\"\"Thread-0\":waiting to lock monitor 0x0003f314 (object 0x22c19f20, a java.lang.Object),which is held by \"Thread-1\" 热锁热锁，也往往是导致系统性能瓶颈的主要因素。其表现特征为，由于多个线程对临界区，或者锁的竞争，可能出现： 频繁的线程的上下文切换：从操作系统对线程的调度来看，当 线程在等待资源而阻塞的时候，操作系统会将之切换出来，放到等待的队列，当线程获得资源之后，调度算法会将这个线程切换进去，放到执行队列中。 大量的系统调用：因为线程的上下文切换，以及热锁的竞争，或 者临界区的频繁的进出，都可能导致大量的系统调用。 大部分 CPU开销用在 “系统态 ”：线程上下文切换，和系统调用，都会导致 CPU在 “系统态 ”运行，换而言之，虽然系统很忙碌，但是 CPU用在 “用户态 ”的比例较小，应用程序得不到充分的 CPU资源。 随着 CPU数目的增多，系统的性能反而下降。因为 CPU数目多，同 时运行的线程就越多，可能就会造成更频繁的线程上下文切换和系统态的 CPU开销，从而导致更糟糕的性能。 上面的描述，都是一个 scalability（可扩展性）很差的系统的表现。从整体的性能指标看，由于线程热锁的存在，程序的响应时间会变长，吞吐量会降低。&lt; /span&gt; 那么，怎么去了解 “热锁 ”出现在什么地方呢？一个重要的方法还是结合操作系统的各种工具观察系统资源使用状况，以及收集 Java线程的 DUMP信息，看线程都阻塞在什么方法上，了解原因，才能找到对应的解决方法。 我们曾经遇到过这样的例子，程序运行时，出现了以上指出的各种现象，通过观察操作系统的资源使用统计信息，以及线程 DUMP信息，确定了程序中热锁的存在，并发现大多数的线程状态都是 Waiting for monitor entry或者 Wait on monitor，且是阻塞在压缩和解压缩的方法上。后来采用第三方的压缩包 javalib替代 JDK自带的压缩包后，系统的性能提高了几倍。 总结本文就介绍了 Java线程 DUMP的基本知识和分析的基本方法，并且解释了如何利用线程的 DUMP信息，以及结合操作系统的各种资源使用情况，分析程序的性能问题，从而达到改进程序，提高性能的目的。 JDK,JRE,JVM区别与联系JDK : Java Development ToolKit(Java开发工具包)。JDK是整个JAVA的核心，包括了Java运行环境（Java Runtime Envirnment），一堆Java工具（javac/java/jdb等）和Java基础的类库（即Java API 包括rt.jar）。 JDK有以下三种版本： J2SE，standard edition，标准版，是我们通常用的一个版本 J2EE，enterpsise edtion，企业版，使用这种JDK开发J2EE应用程序 J2ME，micro edtion，主要用于移动设备、嵌入式设备上的java应用程序 我们常常用JDK来代指Java API，Java API是Java的应用程序接口，其实就是前辈们写好的一些java Class，包括一些重要的语言结构以及基本图形，网络和文件I/O等等 ，我们在自己的程序中，调用前辈们写好的这些Class，来作为我们自己开发的一个基础。当然，现在已经有越来越多的性能更好或者功能更强大的第三方类库供我们使用。 JRE:Java Runtime Enviromental(java运行时环境)。也就是我们说的JAVA平台，所有的Java程序都要在JRE下才能运行。包括JVM和JAVA核心类库和支持文件。与JDK相比，它不包含开发工具——编译器、调试器和其它工具。 JVM：Java Virtual Mechinal(JAVA虚拟机)。JVM是JRE的一部分，它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。JVM有自己完善的硬件架构，如处理器、堆栈、寄存器等，还具有相应的指令系统。JVM 的主要工作是解释自己的指令集（即字节码）并映射到本地的 CPU 的指令集或 OS 的系统调用。Java语言是跨平台运行的，其实就是不同的操作系统，使用不同的JVM映射规则，让其与操作系统无关，完成了跨平台性。JVM 对上层的 Java 源文件是不关心的，它关注的只是由源文件生成的类文件（ class file ）。类文件的组成包括 JVM 指令集，符号表以及一些补助信息。 关于JVM的内存结构请看这篇文章：Java虚拟机的内存组成以及堆内存介绍 下图很好的表面了JDK,JRE,JVM三者间的关系： #Linux端口被占用的解决 Error: JBoss port is in use. Please check 原因：原因很简单，端口被占用 解决： 知道端口号，直接查找进程ID，杀掉进程 知道端口号，查看是否被占用，比如说知道jboss用的是8080端口，那就直接使用命令： 1netstat -tln | grep 8080 netstat -tln 查看端口使用情况，而netstat -tln | grep 8080 则是只查看端口8080的使用情况 查看端口属于哪个程序？端口被哪个进程占用 1lsof -i :8080 可以看到端口使用情况如下 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEjava 8253 hollis 143u IPv4 757826 0t0 TCP *:http-alt (LISTEN)java 8253 hollis 737u IPv4 756898 0t0 TCP 10.16.47.163:39451-&gt;10.101.104.55:http-alt (ESTABLISHED)java 8253 hollis 806u IPv4 757695 0t0 TCP 10.16.47.163:50381-&gt;10.101.104.50:http-alt (ESTABLISHED) 使用命令 kill -9 进程id(8253)杀掉进程 不知道知道端口号，但是知道进程的名字，比如知道是个java进程，找到进程ID，直接杀死 使用命令 1ps aux|grep java 查找哪些进程适合java相关的进程 hollis 15690 1.2 6.4 3537252 524812 pts/28 Sl 3月12 0:17 /home/hollis/tools/java/jdk1.7.0_71/bin/java -D[Standalone] -XX:+UseCompressedOops -server -Xms1024m -Xmx1024m -XX:PermSize=128m -XX:MaxPermSize=192m -Djava.awt.headless=true -Djava.net.preferIPv4Stack=true -Dorg.jboss.boot.log.file=/home/hollis/out/logs/jboss_stdout.log -Dlogging.configuration=file:/home/hollis/workspace/stand/standalone/control/jboss/config/logging.properties -Djboss.modules.system.pkgs=com.sun.btrace -Dapplication.name=standalone-sync-appinfo -Dlog4j.ignoreTCL=true -Dlogback.ignoreTCL=true -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,address=7001,server=y,suspend=n -Dproject.name=standalone-sync-appinfo -Dorg.apache.tomcat.util.http.ServerCookie.ALLOW_EQUALS_IN_VALUE=true -DloggingRoot=/home/hollis/out/logs -DloggingCharset=UTF-8 -DloggingLevel=DEBUG -jar /opt/taobao/install/jboss-7.2.0/jboss-modules.jar -mp /opt/taobao/install/jboss-7.2.0/modules:/home/hollis/workspace/stand/standalone/control/jboss/hilton/modules -jaxpmodule javax.xml.jaxp-provider org.jboss.as.standalone -Djboss.home.dir=/opt/taobao/install/jboss-7.2.0 -Djboss.server.base.dir=/home/hollis/workspace/stand/standalone/deploy/target -Djboss.server.config.dir=/home/hollis/workspace/stand/standalone/control/jboss/config -Djboss.server.log.dir=/home/hollis/out/logs 使用命令 kill -9 进程id(15690)杀掉进程","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/tags/JAVA/"},{"name":"JPS","slug":"JPS","permalink":"https://vincentruan.github.io/tags/JPS/"},{"name":"JMAP","slug":"JMAP","permalink":"https://vincentruan.github.io/tags/JMAP/"},{"name":"JSTACK","slug":"JSTACK","permalink":"https://vincentruan.github.io/tags/JSTACK/"},{"name":"JSTAT","slug":"JSTAT","permalink":"https://vincentruan.github.io/tags/JSTAT/"},{"name":"JHAT","slug":"JHAT","permalink":"https://vincentruan.github.io/tags/JHAT/"},{"name":"JINFO","slug":"JINFO","permalink":"https://vincentruan.github.io/tags/JINFO/"},{"name":"JAVAP","slug":"JAVAP","permalink":"https://vincentruan.github.io/tags/JAVAP/"}]},{"title":"Linux常用命令整理","slug":"Linux常用命令整理","date":"2020-06-06T14:24:04.000Z","updated":"2020-06-06T14:40:55.785Z","comments":true,"path":"2020/06/06/Linux常用命令整理/","link":"","permalink":"https://vincentruan.github.io/2020/06/06/Linux常用命令整理/","excerpt":"本文并不会对所有命令进行详细讲解，只给出常见用法和解释。具体用法可以使用--help查看帮助或者直接通过google搜索学习。 查找文件find / -name filename.txt 根据名称查找/目录下的filename.txt文件。 find . -name &quot;*.xml&quot; 递归查找所有的xml文件 find . -name &quot;*.xml&quot; |xargs grep &quot;hello world&quot; 递归查找所有文件内容中包含hello world的xml文件 grep -H &#39;spring&#39; *.xml 查找所以有的包含spring的xml文件 find ./ -size 0 | xargs rm -f &amp; 删除文件大小为零的文件 ls -l | grep &#39;.jar&#39; 查找当前目录中的所有jar文件 grep &#39;test&#39; d* 显示所有以d开头的文件中包含test的行。 grep &#39;test&#39; aa bb cc 显示在aa，bb，cc文件中匹配test的行。 grep &#39;[a-z]\\{5\\}&#39; aa 显示所有包含每个字符串至少有5个连续小写字符的字符串的行。","text":"本文并不会对所有命令进行详细讲解，只给出常见用法和解释。具体用法可以使用--help查看帮助或者直接通过google搜索学习。 查找文件find / -name filename.txt 根据名称查找/目录下的filename.txt文件。 find . -name &quot;*.xml&quot; 递归查找所有的xml文件 find . -name &quot;*.xml&quot; |xargs grep &quot;hello world&quot; 递归查找所有文件内容中包含hello world的xml文件 grep -H &#39;spring&#39; *.xml 查找所以有的包含spring的xml文件 find ./ -size 0 | xargs rm -f &amp; 删除文件大小为零的文件 ls -l | grep &#39;.jar&#39; 查找当前目录中的所有jar文件 grep &#39;test&#39; d* 显示所有以d开头的文件中包含test的行。 grep &#39;test&#39; aa bb cc 显示在aa，bb，cc文件中匹配test的行。 grep &#39;[a-z]\\{5\\}&#39; aa 显示所有包含每个字符串至少有5个连续小写字符的字符串的行。 查看一个程序是否运行ps –ef|grep tomcat 查看所有有关tomcat的进程 终止线程kill -9 19979 终止线程号位19979的进程 查看文件，包含隐藏文件1ls -al 当前工作目录1pwd 复制文件cp source dest 复制文件 cp -r sourceFolder targetFolder 递归复制整个文件夹 scp sourecFile romoteUserName@remoteIp:remoteAddr 远程拷贝 创建目录1mkdir newfolder 删除目录rmdir deleteEmptyFolder 删除空目录 rm -rf deleteFile 递归删除目录中所有内容 移动文件1mv /temp/movefile /targetFolder 重命令1mv oldNameFile newNameFile 切换用户12su -usernamesudo su - username 修改文件权限chmod 777 file.java //file.java的权限-rwxrwxrwx，r表示读、w表示写、x表示可执行 压缩文件1tar -czf test.tar.gz /test1 /test2 列出压缩文件列表1tar -tzf test.tar.gz 解压文件1tar -xvzf test.tar.gz 查看文件头10行1head -n 10 example.txt 查看文件尾10行1tail -n 10 example.txt 查看日志类型文件tail -f exmaple.log //这个命令会自动显示新增内容，屏幕只显示10行内容的（可设置）。 使用超级管理员身份执行命令sudo rm a.txt 使用管理员身份删除文件 查看端口占用情况netstat -tln | grep 8080 查看端口8080的使用情况 查看端口属于哪个程序1lsof -i :8080 查看进程ps aux|grep java 查看java进程 ps aux 查看所有进程 以树状图列出目录的内容1tree a ps:Mac下使用tree命令 文件下载wget http://file.tgz mac下安装wget命令 1curl http://file.tgz 网络检测1ping www.just-ping.com 远程登录1ssh userName@ip 打印信息echo $JAVA_HOME 打印java home环境变量的值 java 常用命令参考站点内关于的文章，java javac, jps ,jstat,jmap, jstack 其他命令svn git maven linux命令学习网站:http://explainshell.com/ 参考资料Linux端口被占用的解决(Error: JBoss port is in use. Please check) linux 中强大且常用命令：find、grep","categories":[{"name":"LINUX","slug":"LINUX","permalink":"https://vincentruan.github.io/categories/LINUX/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/tags/Linux/"}]},{"title":"【转载】Nginx反向代理，负载均衡，redis session共享，keepalived高可用","slug":"【转载】Nginx反向代理，负载均衡，redis-session共享，keepalived高可用","date":"2020-03-23T08:47:55.000Z","updated":"2020-06-06T15:43:39.195Z","comments":true,"path":"2020/03/23/【转载】Nginx反向代理，负载均衡，redis-session共享，keepalived高可用/","link":"","permalink":"https://vincentruan.github.io/2020/03/23/【转载】Nginx反向代理，负载均衡，redis-session共享，keepalived高可用/","excerpt":"来自：MrLinFeng - 博客园 链接：www.cnblogs.com/mrlinfeng/p/6146866.html 使用的资源： nginx主服务器一台，nginx备服务器一台，使用keepalived进行宕机切换。 tomcat服务器两台，由nginx进行反向代理和负载均衡，此处可搭建服务器集群。 redis服务器一台，用于session的分离共享。 nginx主服务器：192.168.50.133 nginx备服务器：192.168.50.135 tomcat项目服务器1:192.168.50.137 tomcat项目服务器2:192.168.50.139 redis服务器：192.168.50.140 注意访问时需要配置防火墙规则，或者关闭防火墙","text":"来自：MrLinFeng - 博客园 链接：www.cnblogs.com/mrlinfeng/p/6146866.html 使用的资源： nginx主服务器一台，nginx备服务器一台，使用keepalived进行宕机切换。 tomcat服务器两台，由nginx进行反向代理和负载均衡，此处可搭建服务器集群。 redis服务器一台，用于session的分离共享。 nginx主服务器：192.168.50.133 nginx备服务器：192.168.50.135 tomcat项目服务器1:192.168.50.137 tomcat项目服务器2:192.168.50.139 redis服务器：192.168.50.140 注意访问时需要配置防火墙规则，或者关闭防火墙 Nginx反向代理与负载均衡架构图： 此时需要用到三台服务器，一台nginx服务器，两台正式部署项目的服务器：选择的是192.168.50.133主nginx和192.168.50.137,192.168.50.139两台tomcat服务器 首先在两台服务器上安装tomcat：这个也是简单，不多说 安装tomcat：上传解压即可使用，bin目录下 startup.sh启动，shutdown.sh关闭 配置防火墙端口：vim /etc/sysconfig/iptables 编辑，开放8080端口，80端口等一些常用端口，当然后边有用到一些端口都是需要配置开放的，不建议关闭防火墙 编辑好后 service iptables restart 重新加载防火墙配置 如果是自己测试嫌配置麻烦，关闭防火墙： service iptables stop 重启后防火墙打开，即在此次开机状态下有效，完全关闭再使用 chkconfig iptables off ,即会在重启后也关闭防火墙，注意有时候服务都起了但访问出错，可能就是防火墙问题哦 启动tomcat访问：192.168.50.137:8080，192.168.50.139:8080，打开tomcat首页即成功。 然后编写测试项目，部署到两台tomcat上，eclipse新建web项目，项目名为testproject，在webapp下新建一个jsp页面为index.jsp,添加如下内容 将项目中web.xml中的访问顺序index.jsp上移到第一个访问 然后右键导出为war包，testproject.war，将该war包上传到两台服务器的tomcat的webapps中 然后修改tomcat的server.xml文件，在tomcat conf目录中：可以使用notepad++的插件NppFTP直接连上linux，然后使用notepad++修改文件哦，保存记得使用UTF-8无BOM格式，具体去百度吧，哈哈 修改Engine标签中，添加jvmRoute，用于标识nginx访问的是哪个服务器tomcat，137服务器标识为137Server1，139服务器标识为139Server2 在两台tomcat的server.xml文件，Host标签中添加：，path标识访问路径，docBase为项目名，表示访问项目 此时，重新启动tomcat，访问192.168.50.137:8080，192.168.50.139:8080,显示index.jsp内容：两台服务器访问显示如下 至此，两台tomcat服务器搭建完成。 在nginx主机192.168.50.133上安装nginx： 先使用yum命令安装gcc，安装pcre，zlib，openssl： 1yum install -y gcc``yum install -y pcre pcre-devel``yum install -y zlib zlib-devel``yum install -y openssl openssl-devel 在/usr/local/目录下新建nginx-src目录，将nginx-1.8.0.tar.gz放到此处，解压 1tar -zxvf nginx-1.8.0.tar.gz 进入解压后目录 依次执行命令： 1./configure` `make` `mkae install 此时nginx安装完毕，安装目录是/usr/local/nginx，nginx默认占用80端口 其中，sbin目录为nginx执行命令，conf目录下的nginx.conf为默认加载的配置文件 启动nginx： 1./sbin/nginx 关闭nginx： 1./sbin/nginx -s stop 启动nginx后访问192.168.50.133:80即可访问nginx：显示nginx欢迎页 至此，nginx安装完毕。 反向代理与负载均衡配置现有两台服务器，一台为192.168.50.137，一台为192.168.50.139，服务器上各有一台tomcat，端口均为8080，在192.168.50.133上有nginx，经过配置nginx，当访问192.168.50.133:80时，即可访问192.168.50.137:8080，192.168.50.139:8080中随机一台，此时192.168.50.133:80被nginx监听，当有请求时，代理到192.168.50.137:8080，192.168.50.139:8080随机一台即可，即为nginx反向代理功能，同时此时可以通过nginx将请求进行转发，保证了一个入口，将所有请求转发到两台服务器上也减轻了任何一台的负载压力，当有大量请求时，可以搭建大量服务器，在入口代理服务器上使用nginx进行转发，即是负载均衡功能。 配置即是配置nginx安装目录中conf目录下的nginx.conf文件即可：具体配置如下，重点是红色部分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100#Nginx所用用户和组#user niumd niumd;#工作的子进程数量（通常等于CPU数量或者2倍于CPU）worker_processes 2;#错误日志存放路径#error_log logs/error.log;#error_log logs/error.log notice;error_log logs/error.log info;#指定pid存放文件pid logs/nginx.pid;events &#123; #使用网络IO模型linux建议epoll，FreeBSD建议采用kqueue #use epoll; #允许最大连接数 worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #定义日志格式 #log_format main '$remote_addr - $remote_user [$time_local] $request ' # '\"$status\" $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log off; access_log logs/access.log; client_header_timeout 3m; client_body_timeout 3m; send_timeout 3m; client_header_buffer_size 1k; large_client_header_buffers 4 4k; sendfile on; tcp_nopush on; tcp_nodelay on; #fastcgi_intercept_errors on; error_page 404 /404.html; #keepalive_timeout 75 20; gzip on; gzip_min_length 1000; gzip_types text/plain text/css application/x-javascript; #配置被代理的服务器 upstream blank &#123; #ip_hash; server 192.168.50.137:8080; server 192.168.50.139:8080; &#125; server &#123; #nginx监听80端口，请求该端口时转发到真实目标 listen 80; #配置访问域名 server_name localhost; location / &#123; #这里配置代理是指上面定义的两个被代理目标，blank名字必须一致 proxy_pass http://blank; #proxy_redirect off; #如果是非80端口，配置为Host $host：端口号，目的是将代理服务器收到的用户的信息传到真实服务器上 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 300; proxy_send_timeout 300; proxy_read_timeout 300; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; add_header Access-Control-Allow-Origin *; &#125; #此处定义500 502 503 504的错误页面 error_page 500 502 503 504 /50x.html; #错误页面位置 location = /50x.html &#123; #root表示路径 html为nginx安装目录中的html文件夹 #位于/usr/local/nginx/html/下 root html; &#125; &#125;&#125; 启动两台tomcat，重新启动nginx： 访问192.168.50.133:80将会随机访问192.168.50.137:8080和192.168.50.139:8080其中一台。（问题：每次刷新nginx服务器地址sessionid会变，session不能共享。） nginx轮询策略： nginx负载均衡到多台服务器上时，默认采用轮询策略： 常见策略： 1、轮询 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 2、weight指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况，数字越大命中率越高。例如：轮询几率是2:1upstream bakend {server 192.168.0.14 weight=2;server 192.168.0.15 weight=1;} 2、ip_hash每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。例如：upstream bakend {ip_hash;server 192.168.0.14:88;server 192.168.0.15:80;} 其他策略可以自行查询学习,nginx还有很多其他可配置项，静态资源缓存，重定向等，想深入的童鞋请自行学习 nginx配置详解 实际问题：虽然解决了，但是不是很理解，记录一下 其中192.168.50.133:80是有外网映射的，外网55.125.55.55:5555映射到192.168.50.133:80上，此时使用55.125.55.55:5555访问，会映射到192.168.50.133:80上，然后会被转发到192.168.50.137:8080或192.168.50.139:8080，但是此时却出现图片，js，css等静态文件无法访问的情况，通过两种方法解决。 .映射非80端口 让55.125.55.55:5555映射192.168.50.133的非80端口，例如55.125.55.55:5555映射192.168.50.133:5555，然后再在nginx配置文件中配置如下，注意红色加大部分：这地方不理解 1234567891011121314151617181920212223242526272829303132........ upstream blank &#123; #ip_hash; server 192.168.50.137:8080; server 192.168.50.139:8080; &#125; server &#123; #nginx监听5555端口，请求该端口时转发到真实目标 listen 5555; #配置访问域名 server_name 192.168.11.133; location / &#123; #这里配置代理是指上面定义的两个被代理目标，blank名字必须一致 proxy_pass http://blank; #proxy_redirect off; #非80端口使用，目的是将代理服务器收到的用户的信息传到真实服务器上 proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 300; proxy_send_timeout 300; proxy_read_timeout 300; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; add_header Access-Control-Allow-Origin *; &#125;........ 此时访问55.125.55.55:5555，映射到192.168.50.133:5555上，然后转发到192.168.50.137:8080或192.168.50.139:8080上，此时静态文件均能访问。 .使用域名在外网服务器上使用nginx进行转发 将55.125.55.55绑定域名为test.baidubaidu.com，此时在55.125.55.55服务器上使用nginx, 12345678910111213141516171819202122........location / &#123; #加入判断，如果域名为test.baidubaidu.com，转发到192.168.50.133:80，然后再进行转发，注意，此处未进行测试，貌似是这么写的，$host为nginx变量，可以获取域名 if($host = \"test.baidubaidu.com\" )&#123; proxy_pass http://192.168.50.133:80; &#125; #proxy_redirect off; #非80端口使用，目的是将代理服务器收到的用户的信息传到真实服务器上，我也不是很理解 proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 300; proxy_send_timeout 300; proxy_read_timeout 300; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; add_header Access-Control-Allow-Origin *; &#125;........ 以上即nginx反向代理与负载均衡介绍，经过此次学习，发现nginx确实是博大精深，一个配置文件搞得我不要不要的。。。 session共享问题由于nginx是随机分配请求，假设一个用户登录时访问网站登录时被分配到192.168.50.137:8080上，然后进行了登录操作，此时该服务器上就会有该用户登录的session信息，然后登陆后重定向到网站首页或个人中心时，此时如果被分配到192.168.50.139:8080上，那么这台服务器上没有该用户session信息，于是又会变成未登录状态，所以由于nginx的负载均衡会导致session共享的问题。 解决方法： 1.nginx提供了ip_hash策略，可以保持用户ip进行hash值计算固定分配到某台服务器上，然后只要是该ip则会保持分配到该服务器上，保证用户访问的是同一台服务器，那么session问题就不存在了。这也是解决session共享的一种方式，也称为黏性session。但是假设一台tomcat服务器挂了的话，那么session也会丢失。所以比较好的方案是抽取session。 2.session存在memcache或者redis中，以这种方式来同步session，把session抽取出来，放到内存级数据库里面，解决了session共享问题，同时读取速度也是非常之快。 本例中： Redis解决session共享： 在redis服务器192.168.50.140上搭建redis，redis默认端口为6379 Redis搭建： redis依赖gcc，先安装： 1yum install -y gcc-c++ 下载redis，我使用的是redis-3.2.1.tar.gz，上传至linux /usr/local/redis-src/中，解压 进入解压后目录redis-3.2.1，执行make命令进行编译 安装到目录/usr/local/redis 执行： 1make PREFIX=/usr/local/redis install 安装完成之后将redis配置文件拷贝到安装目录下，redis.conf是redis的配置文件，redis.conf在redis源码目录,port默认6379。 执行命令： 1cp /usr/local/redis-src/redis-``3.2``.``1``/redis.conf /usr/local/redis/ 在redis安装目录启动和关闭redis： 启动： 1./bin/redis-server ./redis.conf 这种启动方式叫做前端启动，必须保持在当前窗口，如果ctrl + c 退出，那么redis也就退出了，不建议使用 那么后端启动： 首先修改redis.conf中daemonize的值，打开可以看到默认是no，修改为daemonize yes，启动即可。也可以在该配置文件中修改redis默认端口6379为其他值。 关闭redis： 1./bin/redis-cli shutdown 至此，redis服务器搭建完成。 tomcat与redis集成实现session共享： 环境为tomcat7 + jdk1.6的话： 在所有需要共享session的服务器的tomcat中目录下： lib目录中添加以下三个jar包，注意版本最好一致，不然极容易出现错误，下边的测试是可用的： conf目录中content.xml中加入：配置redis服务 123456&lt;Valve className=\"com.radiadesign.catalina.session.RedisSessionHandlerValve\"/&gt; &lt;Manager className=\"com.radiadesign.catalina.session.RedisSessionManager\"host=\"192.168.50.140\"port=\"6379\"database=\"0\" maxInactiveInterval=\"60\" /&gt; 环境为tomcat7 + jdk1.7或1.8的话： 在所有需要共享session的服务器的tomcat中目录下： lib目录中添加以下三个jar包，测试通过： conf目录中content.xml中加入：配置redis服务 123456&lt;Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" /&gt; &lt;Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"host=\"192.168.50.140\" port=\"6379\" database=\"0\" maxInactiveInterval=\"60\"/&gt; 根据我这测试，是jkd1.8+tomcat7，在137和139两台tomcat中加入jar包且进行如上配置： 上传jar包 修改content.xml 启动redis服务，重新启动所有tomcat，启动nginx，刷新nginx页面,两台tomcat页面可以看到sessionid值不变，关闭某台tomcat，nginx中sessionid不变，说明session是共享的。 问题： 有可能此时访问会报错，redis无法访问，这是由于redis的安全机制，默认只有127.0.0.1才能访问，在redis.conf中可以找到bind 127.0.0.1，你可以将此ip改为访问者ip， 如果有多个访问者，也可以把bind 127.0.0.1注释掉，然后在配置文件中找到protected-mode，修改protected-mode yes改为protected-mode no 关闭redis保护模式即可 详细可以参考这：http://www.cnblogs.com/liusxg/p/5712493.html 经过大牛指点：添加两个注意点： 1.按照如上配置,使用redis数据库,放入session中的对象必须要实现java.io.Serializable接口，使用memcache的可以不用实现Serializable接口 原因是:因为tomcat里使用的将session放置redis使用的工具类,是使用的jdk序列化模式存储的，这一点也是很容易理解的，session.setAttribute(String key, Object value)，存储Object类型 object放入redis中又要能取出来，只能是序列化进行存储了，然后取出的时候进行反序列化。 所以我们在session中存储的任何对象，都必须实现序列化接口。 2.按照如上配置,使用redis做session存储空间时,web应用的session-time的时间单位会变成[秒],而不是原本的[分] 原因是:因为tomcat里使用的将session放置redis使用的工具类,在存储时为对tomcat容器时间做转换， 在redis中设置过期时间是使用秒作为单位的，有个命令叫expire可以设置redis键值过期时间，所以在context.xml配置文件中我们需要制定session过期时间（默认是60秒，配成1800即30分钟），这一点很重要。 请注意！！！！ context.xml配置说明： 12345678910&lt;Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" /&gt; &lt;Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"//这里是redis服务器地址host=\"192.168.50.140\"//这里是redis端口，redis默认端口是6379port=\"6379\"//这里是redis数据库中的标识，标识第0个，默认使用0即可database=\"0\" //需要注意的是这里由于redis过期时间默认设置为60，单位是秒，session过期时间为30分钟，所以需要设置为1800对应30分钟maxInactiveInterval=\"1800\"/&gt; keepalived高可用架构图： 上图画的不对称好难看，将就下吧 根据上边一路走来，已经是搭好了从nginx主到服务器的这条线的，那么同理，使用nginx备机192.168.50.135上再搭建nginx，也是代理192.168.137和139两台服务器。搞了一次之后也就简单了 在192.168.50.135上安装nginx，配置nginx配置即可，不再赘述，nginx备机配置如下： 配置和上边的是一样的 12345678910111213141516171819........upstream blank &#123; #ip_hash; server 192.168.50.137:8080; server 192.168.50.139:8080;&#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; proxy_pass http://blank; root html; index index.html index.htm; &#125;........ 那么现在就是相当于有两套nginx了，代理的服务器是一样的，为什么要搞两套？ 假设只有一台nginx的话，这个nginx服务器挂了。那怎么办？ 所以需要一台备份nginx。 正常情况下，主nginx作为反向代理服务器即可，假设nginx服务器挂了的话，能够立即切换到备份机上，保证用户可以访问，然后运维人员把主nginx服务器故障修好之后，又能够自动切换到主nginx提供服务。通过keepalived来监测两台服务器，正常情况时，将nginx主服务器ip（192.168.50.133）绑定到keepalived定义的一个虚拟ip（我设置为192.168.50.88）上，通过这个虚拟IP可以访问nginx，然后备机（192.168.50.135）啥事不干，就是每隔一小段时间（设置为1秒）keepalived会告诉备机，你不用管，我还活着呢，如果突然主机死了，那么就会超过一秒备机没有收到主机或者的消息，那么备机马上接管主机，keeplived将虚拟ip绑定到备机身上，网站继续提供服务。 突然主机又复活了（运维人员排除故障了），那么备机又将收到主机的活着的消息，于是将管理权交回给主机，虚拟ip又绑到主机上，大概就是这么个过程，个人理解。 先在两台nginx服务器（主备）上都装上keepalived： 下载：这里使用rpm安装，是区分32,64位的，不要搞错了哦 keepalived-1.2.7-3.el6.x86_64.rpm openssl-1.0.1e-30.el6_6.4.x86_64.rpm 要求必须是openssl-1.0.1e或以上才行、如果版本已经符合（因为安装nginx时已经安装openssl，使用yum安装应该是符合的）、不用再安装openssl，使用 rpm -q openssl 查看当前openssl版本，我这已经是1.0.1e 48的，所以就不安装了 将两个rpm安装包上传到两台nginx服务器，进入上传到的目录，运行以下命令安装:–nodeps是忽略依赖包，当然最好是把依赖包装上，去掉–nodeps可以看到错误，需要哪些依赖包 如果需要安装openssl 1rpm –Uvh --nodeps ./openssl-``1.0``.1e-``30``.el6_6.``4``.x86_64.rpm 安装keepalived： 1``rpm -Uvh --nodeps ./keepalived-``1.2``.``7``-``3``.el6.x86_64.rpm 安装完毕后再/etc/keepalived/目录下有个文件 keepalived.conf即是本台服务器keepalived的核心配置文件了： 重点：keepalived配置，配置文件上边部分按照下面的配置就行了，配置文件后面的内容可以不用管，还没有去研究其他部分 先配置主机192.168.50.133的keepalived，按下边进行配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344! Configuration File for keepalived #这是全局配置global_defs &#123; #指定keepalived在发生切换时需要发送email到的对象，一行一个 notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; #指定发件人 notification_email_from Alexandre.Cassen@firewall.loc #指定smtp服务器地址 #smtp_server 192.168.200.1 #指定smtp连接超时时间 #smtp_connect_timeout 30 #运行keepalived机器的一个标识 router_id LVS_DEVEL&#125; #主备配置vrrp_instance VI_1 &#123; #标示状态为MASTER 备份机为BACKUP state MASTER #设置keepalived实例绑定的服务器网卡，一般为eth0，linux使用ifconfig命令可查看当前服务器网卡标识名 interface eth0 #同一实例下（即同一组主备机下）virtual_router_id必须相同 virtual_router_id 51 #MASTER权重要高于BACKUP，MASTER为100则BACKUP最大为99 priority 100 #MASTER与BACKUP负载均衡器之间同步检查的时间间隔，单位是秒，设置为1秒 advert_int 1 #设置认证 authentication &#123; #主从服务器验证方式，PASS为明文密码验证 auth_type PASS #密码 auth_pass 1111 &#125; #设置虚拟IP，与我们的主备机在同一网段下，最后一位随便给就是拉，可以设置多个，换行即可 virtual_ipaddress &#123; 192.168.50.88 &#125;&#125; 备机192.168.50.135的keepalived配置： 备机配置注意的地方：需要修改state为BACKUP , priority比MASTER低，virtual_router_id和master的值一致 123456789101112131415161718192021222324252627282930313233343536373839404142! Configuration File for keepalived #这是全局配置global_defs &#123; #指定keepalived在发生切换时需要发送email到的对象，一行一个 notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; #指定发件人 notification_email_from Alexandre.Cassen@firewall.loc #指定smtp服务器地址 #smtp_server 192.168.200.1 #指定smtp连接超时时间 #smtp_connect_timeout 30 #运行keepalived机器的一个标识 router_id LVS_DEVEL&#125; #主备配置vrrp_instance VI_1 &#123; #备机为BACKUP state BACKUP #备机网卡标识，一般都是eth0，先查询一下 interface eth0 #virtual_router_id必须与主机相同 virtual_router_id 51 #权重，备机必须比主机小 priority 99 #MASTER与BACKUP负载均衡器之间同步检查的时间间隔，单位是秒，设置为1秒 advert_int 1 #认证，与主机一致 authentication &#123; auth_type PASS auth_pass 1111 &#125; #虚拟IP，绑定的虚拟ip与主机一致 virtual_ipaddress &#123; 192.168.50.135 &#125;&#125; 酱紫，keepalived就配置完成了。 keeplived启动关闭命令： 1service keepalived start``service keepalived stop 启动两台nginx，启动主机keepalived，启动备机keepalived服务。 这时，nginx主机在提供服务，备机是闲着的，虚拟ip是192.168.50.88，在主机和备机上使用命令 1ip addr 可以发现： 主机：可以看到，192.168.50.133 带有虚拟ip192.168.50.88，在浏览器中输入192.168.50.88，即可访问到主nginx192.168.50.133.然后转发到tomcat服务器上 浏览器访问虚拟ip：192.168.50.88，效果如下 备机：ip addr命令执行：可以看到，备机nginx没有绑定虚拟ip 以上是初始状态下的情况，也是正常服务的情况。 现在测试高可用，假设主机nginx服务器挂了，模拟为关闭nginx主机或者将keepalived服务停止，那么主机上keepalived死了就没办法告诉备机自己活着，而备机超过1秒没有接收到主机给自己的消息，马上接管虚拟ip，同时在配置文件中配置切换主备机时发送邮件，此时开发团队收到邮件即知道主机挂了，马上去排除主机的故障。 将主机上的keepalived服务停止，service keepalived stop ,然后查看虚拟ip绑定情况， 主机挂了：可以看到虚拟ip就没有绑在主机上 备机情况：虚拟ip已经绑定到备机，此时主机虽然挂了，但是切换到备机上了（发现故障和切换的时间差最大也就是1秒），虚拟ip也绑到备机上了，访问虚拟ip，就会请求备机nginx然后转发到web服务器实现高可用。 运维人员收到邮件后就去排除主机故障了，搞定之后（模拟为keepalived服务启动），这时主机告诉备机，我又活了，于是备机将管理权又交给主机（切换为主机nginx提供服务）： 主机keepalived服务启动后，即吧主机维护好之后：可以看到，虚拟ip又自动绑到了主机上 备机情况，主机活了之后，备机转交管理权，虚拟ip切换到主机上，备机不绑定虚拟ip,貌似启动keepalived服务之后并不能马上切回，应该是起服务需要点时间吧，但是不影响，这段时间还是备机绑定虚拟IP的 这就是keepalived高可用的模拟。 注意问题： 主机挂了之后，主机nginx恢复时，一定要将nginx也启动，否则即使虚拟ip切换到了主机上，但是主机nginx没起那也是没法转发的。所以要把\\nginx启动要加在开机启动中。**** Nginx服务开机自启动在linux系统的/etc/init.d/目录下创建nginx文件，使用如下命令：（vim命令不会的自己去学吧哈哈） 1vi /etc/init.d/nginx 将如下内容搞到该文件中:注意红色部分修改成你的路径即可，nginxd值是启动nginx的nginx路径，nginx_config值是nginx配置文件nginx.conf路径，nginx_pid值是nginx.pid所在路径，如果按照我方法安装的话，是在nginx安装目录的logs里边的 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#!/bin/bash# nginx Startup script for the Nginx HTTP Server# it is v.0.0.2 version.# chkconfig: - 85 15# description: Nginx is a high-performance web and proxy server.# It has a lot of features, but it's not for everyone.# processname: nginx# pidfile: /usr/local/nginx/logs/nginx.pid# config: /usr/local/nginx/conf/nginx.confnginxd=/usr/local/nginx/sbin/nginxnginx_config=/usr/local/nginx/conf/nginx.confnginx_pid=/usr/local/nginx/logs/nginx.pidRETVAL=0prog=\"nginx\"# Source function library.. /etc/rc.d/init.d/functions# Source networking configuration.. /etc/sysconfig/network# Check that networking is up.[ $&#123;NETWORKING&#125; = \"no\" ] &amp;&amp; exit 0[ -x $nginxd ] || exit 0# Start nginx daemons functions.start() &#123;if [ -e $nginx_pid ];then echo \"nginx already running....\" exit 1fi echo -n $\"Starting $prog: \" daemon $nginxd -c $&#123;nginx_config&#125; RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch /var/lock/subsys/nginx return $RETVAL&#125;# Stop nginx daemons functions.stop() &#123; echo -n $\"Stopping $prog: \" killproc $nginxd RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f /var/lock/subsys/nginx /var/run/nginx.pid&#125;# reload nginx service functions.reload() &#123; echo -n $\"Reloading $prog: \" #kill -HUP `cat $&#123;nginx_pid&#125;` killproc $nginxd -HUP RETVAL=$? echo&#125;# See how we were called.case \"$1\" instart) start ;;stop) stop ;;reload) reload ;;restart) stop start ;;status) status $prog RETVAL=$? ;;*) echo $\"Usage: $prog &#123;start|stop|restart|reload|status|help&#125;\" exit 1esacexit $RETVAL 然后设置该文件的访问权限：执行以下命令，意为所有用户可访问 1chmod a+x /etc/init.d/nginx 最后将ngix加入到rc.local文件中，这样开机的时候nginx就默认启动了 1vi /etc/rc.local 添加 1/etc/init.d/nginx start 保存并退出，下次重启就会生效，nginx的开机自启动。测试无误的。 解决nginx进程和keepalived不同时存在问题keepalived是通过检测keepalived进程是否存在判断服务器是否宕机，如果keepalived进程在，但是nginx进程不在了，那么keepalived是不会做主备切换。因为是nginx挂了，然后无法做代理，keepalived还在不会切换到备机。 所以一直检测nginx是否还在，如果不在，那么让keepalived也停止，同生共死。 注：只需要在主机上搞就行了，备机没必要检测nginx，因为基本是主机在服务。 解决：写个脚本来监控nginx进程是否存在，如果nginx不存在就将keepalived进程杀掉。 注：keepalived不需要开机启动，假如开机自启的话，如果keepalived比nginx 更快启动的话，脚本检测会把keepalived停掉的，所以没必要，只需要nginx开机启动，启动主机后自行手动的把keepalived服务启动即可。 在主nginx上编写nginx进程检测脚本（check_nginx_dead.sh）,在keepalived配置文件目录下创建脚本: 1vi /etc/keepalived/check_nginx_dead.sh 把下边这些内容搞到脚本文件中，内容如下： 123456#!/bin/bash# 如果进程中没有nginx则将keepalived进程kill掉A=`ps -C nginx --no-header |wc -l` ## 查看是否有 nginx进程 把值赋给变量Aif [ $A -eq 0 ];then ## 如果没有进程值得为 零 service keepalived stop ## 则结束 keepalived 进程fi 给访问权限：不然不行哦，这里卡了我半小时 1chmod a+x /etc/keepalived/check_nginx_dead.sh 先测试一下脚本： 把nginx停了，此时keepalived还在运行，所以不会切换，虚拟ip无法访问到web服务器 然后执行脚本： 主机脚本检测nginx不在了，把keepalived停掉，从输出可以看到确实停止了，主机虚拟没有绑定虚拟ip 备机：成功绑定虚拟ip 所以，只需要让该脚本一直执行，即一直检测nginx进程是否在，如果没得了，那么直接停止主机keepalived，切换备机，保证能够访问web服务器。 按如下修改keepalived配置文件keepalived.conf，添加脚本定义检测： 只需要在正确的位置添加红色部分即可：那么脚本则是两秒执行一次，一旦发现主机nginx不在了，keepalived停止，切换备机 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859! Configuration File for keepalived #这是全局配置global_defs &#123; #指定keepalived在发生切换时需要发送email到的对象，一行一个 notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; #指定发件人 notification_email_from Alexandre.Cassen@firewall.loc #指定smtp服务器地址 #smtp_server 192.168.200.1 #指定smtp连接超时时间 #smtp_connect_timeout 30 #运行keepalived机器的一个标识 router_id LVS_DEVEL&#125; vrrp_script check_nginx_dead &#123; ##监控脚本路径 script \"/etc/keepalived/check_nginx_dead.sh\" ##时间间隔，2秒 interval 2 ##权重 weight 2 &#125; #主备配置vrrp_instance VI_1 &#123; #标示状态为MASTER 备份机为BACKUP state MASTER #设置keepalived实例绑定的服务器网卡，一般为eth0，linux使用ifconfig命令可查看当前服务器网卡标识名 interface eth0 #同一实例下（即同一组主备机下）virtual_router_id必须相同 virtual_router_id 51 #MASTER权重要高于BACKUP，MASTER为100则BACKUP最大为99 priority 100 #MASTER与BACKUP负载均衡器之间同步检查的时间间隔，单位是秒，设置为1秒 advert_int 1 #设置认证 authentication &#123; #主从服务器验证方式，PASS为明文密码验证 auth_type PASS #密码 auth_pass 1111 &#125; track_script &#123; #监控脚本 check_nginx_dead &#125; #设置虚拟IP，与我们的主备机在同一网段下，最后一位随便给就是拉，可以设置多个，换行即可 virtual_ipaddress &#123; 192.168.50.88 &#125;&#125; 保存后，重新启动主机keepalived服务即可。 测试： 回到负载均衡高可用的初始状态，保证主、备上的keepalived、nginx全部启动。 停止主nginx服务： 主机查看keepalived进程，发现没有，说明已经停止了，虚拟ip也没有绑在主机上 备机：绑定虚拟ip，切换成功。 测试通过，如果主机nginx挂了之后，keepalived也会随着挂掉，然后切换备机。 nginx.conf配置文件详解Nginx 配置文件主要分成四部分：main（全局设置）、server（主机设置）、upstream（上游服务器设置，主要为反向代理、负载均衡相关配置）和 location（URL匹配特定位置后的设置）。main 部分设置的指令影响其他所有部分的设置；server 部分的指令主要用于制定虚拟主机域名、IP 和端口号；upstream 的指令用于设置一系列的后端服务器，设置反向代理及后端服务器的负载均衡；location 部分用于匹配网页位置（比如，根目录“/”，“/images”，等等）。他们之间的关系：server 继承 main，location 继承 server；upstream 既不会继承指令也不会被继承。 当前 nginx 支持的几个指令上下文()： nginx.conf 配置文件 下面是 nginx.conf 详细的配置文件介绍（以下配置参数很多时候并不一定用的到，只是作为配置参数说明参考，可以看下面的通用版介绍） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307#定义Nginx运行的用户和用户组user www www; #nginx进程数，通常设置成和cpu的数量相等worker_processes 4; #全局错误日志定义类型，[debug | info | notice | warn | error | crit]#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#进程pid文件#pid logs/nginx.pid;#指定进程可以打开的最大描述符：数目#工作模式与连接数上限##这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。worker_rlimit_nofile 65535;events &#123; #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型 #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。 #补充说明： #与apache相类，nginx针对不同的操作系统，有不同的事件模型 #A）标准事件模型 #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll #B）高效事件模型 #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 #Epoll：使用于Linux内核2.6版本及以后的系统。 #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 use epoll #单个进程最大连接数（最大连接数=连接数+进程数） #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cup跑到100%就行。 worker_connections 1024; #keepalive 超时时间 keepalive_timeout 60; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。 #分页大小可以用命令getconf PAGESIZE 取得。 #[root@web001 ~]# getconf PAGESIZE #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。 #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态. open_file_cache_min_uses 1; #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误. open_file_cache_errors on;&#125;#设定http服务器，利用它的反向代理功能提供负载均衡支持http&#123; #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #默认编码 charset utf-8; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; #负载均衡配置 upstream piao.jd.com &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3; #nginx的upstream目前支持4种方式的分配 #1、轮询（默认） #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 #2、weight #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 #例如： #upstream bakend &#123; # server 192.168.0.14 weight=10; # server 192.168.0.15 weight=10; #&#125; #2、ip_hash #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 #例如： #upstream bakend &#123; # ip_hash; # server 192.168.0.14:88; # server 192.168.0.15:80; #&#125; #3、fair（第三方） #按后端服务器的响应时间来分配请求，响应时间短的优先分配。 #upstream backend &#123; # server server1; # server server2; # fair; #&#125; #4、url_hash（第三方） #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 #upstream backend &#123; # server squid1:3128; # server squid2:3128; # hash $request_uri; # hash_method crc32; #&#125; #tips: #upstream bakend&#123;#定义负载均衡设备的Ip及设备状态&#125;&#123; # ip_hash; # server 127.0.0.1:9090 down; # server 127.0.0.1:8080 weight=2; # server 127.0.0.1:6060; # server 127.0.0.1:7070 backup; #&#125; #在需要使用负载均衡的server中增加 proxy_pass http://bakend/; #每个设备的状态设置为: #1.down表示单前的server暂时不参与负载 #2.weight为weight越大，负载的权重就越大。 #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误 #4.fail_timeout:max_fails次失败后，暂停的时间。 #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。 #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug #client_body_temp_path设置记录文件的目录 可以设置最多3层目录 #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡 &#125; #虚拟主机的配置 server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.jd.com jd.com; #默认入口文件名称 index index.html index.htm index.php; root /data/www/jd; #对******进行负载均衡 location ~ .*.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址； #$remote_user：用来记录客户端用户名称； #$time_local： 用来记录访问时间与时区； #$request： 用来记录请求的url与http协议； #$status： 用来记录请求状态；成功是200， #$body_bytes_sent ：记录发送给客户端文件主体内容大小； #$http_referer：用来记录从那个页面链接访问过来的； #$http_user_agent：记录客户浏览器的相关信息； #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。 log_format access '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" $http_x_forwarded_for'; #定义本虚拟主机的访问日志 access_log /usr/local/nginx/logs/host.access.log main; access_log /usr/local/nginx/logs/host.access.404.log log404; #对 \"/connect-controller\" 启用反向代理 location /connect-controller &#123; proxy_pass http://127.0.0.1:88; #请注意此处端口号不能与虚拟主机监听的端口号一样（也就是server监听的端口） proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。 #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答。 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候响应超时时间 #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #后端服务器数据回传时间(代理发送超时) #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; &#125; #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; &#125;&#125;","categories":[{"name":"NGINX","slug":"NGINX","permalink":"https://vincentruan.github.io/categories/NGINX/"}],"tags":[{"name":"NGINX","slug":"NGINX","permalink":"https://vincentruan.github.io/tags/NGINX/"}]},{"title":"【转载】20条Linux命令面试问答","slug":"【转载】20条Linux命令面试问答","date":"2020-03-23T08:27:24.000Z","updated":"2020-03-24T13:07:33.173Z","comments":true,"path":"2020/03/23/【转载】20条Linux命令面试问答/","link":"","permalink":"https://vincentruan.github.io/2020/03/23/【转载】20条Linux命令面试问答/","excerpt":"版权声明：本文是Linux中国翻译，已按转载要求注明信息。原文：http://www.linuxtechi.com/20-linux-commands-interview-questions-answers/作者： Pradeep Kumar译文：LCTT http://linux.cn/article-4790-1.html译者： ZTinoZ 问:1 如何查看当前的Linux服务器的运行级别？ 答: ‘who -r’ 和 ‘runlevel’ 命令可以用来查看当前的Linux服务器的运行级别。 问:2 如何查看Linux的默认网关？ 答: 用 “route -n” 和 “netstat -nr” 命令，我们可以查看默认网关。除了默认的网关信息，这两个命令还可以显示当前的路由表。","text":"版权声明：本文是Linux中国翻译，已按转载要求注明信息。原文：http://www.linuxtechi.com/20-linux-commands-interview-questions-answers/作者： Pradeep Kumar译文：LCTT http://linux.cn/article-4790-1.html译者： ZTinoZ 问:1 如何查看当前的Linux服务器的运行级别？ 答: ‘who -r’ 和 ‘runlevel’ 命令可以用来查看当前的Linux服务器的运行级别。 问:2 如何查看Linux的默认网关？ 答: 用 “route -n” 和 “netstat -nr” 命令，我们可以查看默认网关。除了默认的网关信息，这两个命令还可以显示当前的路由表。 问:3 如何在Linux上重建初始化内存盘镜像文件？ 答: 在CentOS 5.X / RHEL 5.X中，可以用mkinitrd命令来创建初始化内存盘文件，举例如下： 1# mkinitrd -f -v /boot/initrd-$(uname -r).img $(uname -r) 如果你想要给特定的内核版本创建初始化内存盘，你就用所需的内核名替换掉 ‘uname -r’ 。 在CentOS 6.X / RHEL 6.X中，则用dracut命令来创建初始化内存盘文件，举例如下： 1# dracut -f 以上命令能给当前的系统版本创建初始化内存盘，给特定的内核版本重建初始化内存盘文件则使用以下命令： 1# dracut -f initramfs-2.x.xx-xx.el6.x86_64.img 2.x.xx-xx.el6.x86_64 问:4 cpio命令是什么？ 答: cpio就是复制入和复制出的意思。cpio可以向一个归档文件（或单个文件）复制文件、列表，还可以从中提取文件。 问:5 patch命令是什么？如何使用？ 答: 顾名思义，patch命令就是用来将修改（或补丁）写进文本文件里。patch命令通常是接收diff的输出并把文件的旧版本转换为新版本。举个例子，Linux内核源代码由百万行代码文件构成，所以无论何时，任何代码贡献者贡献出代码，只需发送改动的部分而不是整个源代码，然后接收者用patch命令将改动写进原始的源代码里。 创建一个diff文件给patch使用， 1# diff -Naur old_file new_file &gt; diff_file 旧文件和新文件要么都是单个的文件要么都是包含文件的目录，-r参数支持目录树递归。 一旦diff文件创建好，我们就能在旧的文件上打上补丁，把它变成新文件： 1# patch &lt; diff_file 问:6 aspell有什么用 ? 答: 顾名思义，aspell就是Linux操作系统上的一款交互式拼写检查器。aspell命令继任了更早的一个名为ispell的程序，并且作为一款免费替代品 ，最重要的是它非常好用。当aspell程序主要被其它一些需要拼写检查能力的程序所使用的时候，在命令行中作为一个独立运行的工具的它也能十分有效。 问:7 如何从命令行查看域SPF记录？ 答: 我们可以用dig命令来查看域SPF记录。举例如下： 1linuxtechi@localhost:~$ dig -t TXT google.com 问:8 如何识别Linux系统中指定文件(/etc/fstab)的关联包？ 答: 1# rpm -qf /etc/fstab 以上命令能列出提供”/etc/fstab”这个文件的包。 问:9 哪条命令用来查看bond0的状态？ 答: 1cat /proc/net/bonding/bond0 问:10 Linux系统中的/proc文件系统有什么用？ 答: /proc文件系统是一个基于内存的文件系统，其维护着关于当前正在运行的内核状态信息，其中包括CPU、内存、分区划分、I/O地址、直接内存访问通道和正在运行的进程。这个文件系统所代表的并不是各种实际存储信息的文件，它们指向的是内存里的信息。/proc文件系统是由系统自动维护的。 问:11 如何在/usr目录下找出大小超过10MB的文件？ 答: 1# find /usr -size +10M 问:12 如何在/home目录下找出120天之前被修改过的文件？ 答: 1# find /home -mtime +120 问:13 如何在/var目录下找出90天之内未被访问过的文件？ 答: 1# find /var \\! -atime -90 问:14 在整个目录树下查找文件”core”，如发现则无需提示直接删除它们。 答: 1# find / -name core -exec rm &#123;&#125; \\; 问:15 strings命令有什么作用？ 答: strings命令用来提取和显示非文本文件中的文本字符串。（LCTT 译注：当用来分析你系统上莫名其妙出现的二进制程序时，可以从中找到可疑的文件访问，对于追查入侵有用处） 问:16 tee 过滤器有什么作用 ? 答: tee 过滤器用来向多个目标发送输出内容。如果用于管道的话，它可以将输出复制一份到一个文件，并复制另外一份到屏幕上（或一些其它程序）。 1linuxtechi@localhost:~$ ll /etc | nl | tee /tmp/ll.out 在以上例子中，从ll输出可以捕获到 /tmp/ll.out 文件中，并且同样在屏幕上显示了出来。 问:17 export PS1 = “$LOGNAME@hostname:\\$PWD:” 这条命令是在做什么？ 答: 这条export命令会更改登录提示符来显示用户名、本机名和当前工作目录。 问:18 ll | awk ‘{print $3,”owns”,$9}’ 这条命令是在做什么？ 答: 这条ll命令会显示这些文件的文件名和它们的拥有者。 问:19 :Linux中的at命令有什么用？ 答: at命令用来安排一个程序在未来的做一次一次性执行。所有提交的任务都被放在 /var/spool/at 目录下并且到了执行时间的时候通过atd守护进程来执行。 问:20 linux中lspci命令的作用是什么？ 答: lspci命令用来显示你的系统上PCI总线和附加设备的信息。指定-v，-vv或-vvv来获取越来越详细的输出，加上-r参数的话，命令的输出则会更具有易读性","categories":[{"name":"LINUX","slug":"LINUX","permalink":"https://vincentruan.github.io/categories/LINUX/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://vincentruan.github.io/tags/LINUX/"}]},{"title":"善用google guava提高编程效率","slug":"善用google-guava提高编程效率","date":"2020-03-18T13:07:38.000Z","updated":"2020-03-18T14:45:52.768Z","comments":true,"path":"2020/03/18/善用google-guava提高编程效率/","link":"","permalink":"https://vincentruan.github.io/2020/03/18/善用google-guava提高编程效率/","excerpt":"工具类 就是封装平常用的方法，不需要你重复造轮子，节省开发人员时间，提高工作效率。谷歌作为大公司，当然会从日常的工作中提取中很多高效率的方法出来。所以就诞生了guava。。 高效设计良好的API，被Google的开发者设计，实现和使用 遵循高效的java语法实践 使代码更刻度，简洁，简单 节约时间，资源，提高生产力 Guava工程包含了若干被Google的 Java项目广泛依赖 的核心库，例如： 集合 [collections] 缓存 [caching] 原生类型支持 [primitives support] 并发库 [concurrency libraries] 通用注解 [common annotations] 字符串处理 [string processing] I/O 等等。","text":"工具类 就是封装平常用的方法，不需要你重复造轮子，节省开发人员时间，提高工作效率。谷歌作为大公司，当然会从日常的工作中提取中很多高效率的方法出来。所以就诞生了guava。。 高效设计良好的API，被Google的开发者设计，实现和使用 遵循高效的java语法实践 使代码更刻度，简洁，简单 节约时间，资源，提高生产力 Guava工程包含了若干被Google的 Java项目广泛依赖 的核心库，例如： 集合 [collections] 缓存 [caching] 原生类型支持 [primitives support] 并发库 [concurrency libraries] 通用注解 [common annotations] 字符串处理 [string processing] I/O 等等。 使用引入maven依赖(就是引入jar包) (从版本号就能看出 guava是一步步改进的，并且跟随的jdk不断的提取其中优秀的部分) 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;20.0&lt;/version&gt;&lt;/dependency&gt; 集合的创建123456789// 普通Collection的创建List&lt;String&gt; list = Lists.newArrayList();Set&lt;String&gt; set = Sets.newHashSet();Map&lt;String, String&gt; map = Maps.newHashMap();// 不变Collection的创建ImmutableList&lt;String&gt; iList = ImmutableList.of(\"a\", \"b\", \"c\");ImmutableSet&lt;String&gt; iSet = ImmutableSet.of(\"e1\", \"e2\");ImmutableMap&lt;String, String&gt; iMap = ImmutableMap.of(\"k1\", \"v1\", \"k2\", \"v2\"); 创建不可变集合 先理解什么是immutable(不可变)对象 1.在多线程操作下，是线程安全的。 2.所有不可变集合会比可变集合更有效的利用资源。 3.中途不可改变 1ImmutableList&lt;String&gt; immutableList = ImmutableList.of(\"1\",\"2\",\"3\",\"4\"); 这句话就声明了一个不可变的list集合，里面有数据1，2，3，4。方法中的==操作集合的方法都声明过期==，并且抛出异常。 没用guava之前是需要声明并且加各种包裹集合才能实现这个功能。 当我们需要一个map中包含key为String value为List类型的时候 以前我们是这样写的 123456Map&lt;String,List&lt;Integer&gt;&gt; map = new HashMap&lt;String,List&lt;Integer&gt;&gt;();List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();list.add(1);list.add(2);map.put(\"aa\", list);System.out.println(map.get(\"aa\"));//[1, 2] 而现在 1234Multimap&lt;String,Integer&gt; map = ArrayListMultimap.create(); map.put(\"aa\", 1);map.put(\"aa\", 2);System.out.println(map.get(\"aa\")); //[1, 2] 其他的黑科技集合 12345678910111213MultiSet: 无序+可重复 count()方法获取单词的次数 增强了可读性+操作简单创建方式: Multiset&lt;String&gt; set = HashMultiset.create();Multimap: key-value key可以重复 创建方式: Multimap&lt;String, String&gt; teachers = ArrayListMultimap.create();BiMap: 双向Map(Bidirectional Map) 键与值都不能重复创建方式: BiMap&lt;String, String&gt; biMap = HashBiMap.create();Table: 双键的Map Map--&gt; Table--&gt;rowKey+columnKey+value //和sql中的联合主键有点像创建方式: Table&lt;String, String, Integer&gt; tables = HashBasedTable.create();...等等(guava中还有很多java里面没有给出的集合类型) MultisetJDK的集合，提供了有序且可以重复的List，无序且不可以重复的Set。那这里其实对于集合涉及到了2个概念，一个order，一个dups。那么List vs Set，and then some ? Multiset是什么，我想上面的图，你应该了解它的概念了。Multiset就是无序的，但是可以重复的集合，它就是游离在List/Set之间的“灰色地带”！（至于有序的，不允许重复的集合嘛，guava还没有提供，当然在未来应该会提供UniqueList，我猜的，哈哈） 来看一个Multiset的示例： Multiset自带一个有用的功能，就是可以跟踪每个对象的数量。 Immutable vs unmodifiable来我们先看一个unmodifiable的例子： 你看到JDK提供的unmodifiable的缺陷了吗？ 实际上，Collections.unmodifiableXxx所返回的集合和源集合是同一个对象，只不过可以对集合做出改变的API都被override，会抛出UnsupportedOperationException。 也即是说我们改变源集合，导致不可变视图（unmodifiable View）也会发生变化，oh my god! 当然，在不使用guava的情况下，我们是怎么避免上面的问题的呢？ 上面揭示了一个概念：Defensive Copies，保护性拷贝。 OK，unmodifiable看上去没有问题呢，但是guava依然觉得可以改进，于是提出了Immutable的概念，来看： 就一个copyOf，你不会忘记，如此cheap 用Google官方的说法是：we’re using just one class,just say exactly what we mean，很了不起吗（不仅仅是个概念，Immutable在COPY阶段还考虑了线程的并发性等，很智能的！） guava提供了很多Immutable集合，比如ImmutableList/ImmutableSet/ImmutableSortedSet/ImmutableMap/…… 看一个ImmutableMap的例子： 可不可以一对多：MultimapJDK提供给我们的Map是一个键，一个值，一对一的，那么在实际开发中，显然存在一个KEY多个VALUE的情况（比如一个分类下的书本），我们往往这样表达：Map&lt;k,List&gt;，好像有点臃肿！臃肿也就算了，更加不爽的事，我们还得判断KEY是否存在来决定是否new 一个LIST出来，有点麻烦！更加麻烦的事情还在后头，比如遍历，比如删除，so hard…… 来看guava如何替你解决这个大麻烦的： 友情提示下，guava所有的集合都有create方法，这样的好处在于简单，而且我们不必在重复泛型信息了。 get()/keys()/keySet()/values()/entries()/asMap()都是非常有用的返回view collection的方法。 Multimap的实现类有：ArrayListMultimap/HashMultimap/LinkedHashMultimap/TreeMultimap/ImmutableMultimap/…… 可不可以双向：BiMapJDK提供的MAP让我们可以find value by key，那么能不能通过find key by value呢，能不能KEY和VALUE都是唯一的呢。这是一个双向的概念，即forward+backward。 在实际场景中有这样的需求吗？比如通过用户ID找到mail，也需要通过mail找回用户名。没有guava的时候，我们需要create forward map AND create backward map，and now just let guava do that for you. biMap / biMap.inverse() / biMap.inverse().inverse() 它们是什么关系呢？ 你可以稍微看一下BiMap的源码实现，实际上，当你创建BiMap的时候，在内部维护了2个map，一个forward map，一个backward map，并且设置了它们之间的关系。 因此，biMap.inverse() != biMap ；biMap.inverse().inverse() == biMap 可不可以多个KEY：Table我们知道数据库除了主键外，还提供了复合索引，而且实际中这样的多级关系查找也是比较多的，当然我们可以利用嵌套的Map来实现：Map&lt;k1,Map&lt;k2,v2&gt;&gt;。为了让我们的代码看起来不那么丑陋，guava为我们提供了Table。 Table涉及到3个概念：rowKey,columnKey,value，并提供了多种视图以及操作方法让你更加轻松的处理多个KEY的场景。 将集合转换为特定规则的字符串以前我们将list转换为特定规则的字符串是这样写的: 123456789101112131415161718//use javaList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;aa&quot;);list.add(&quot;bb&quot;);list.add(&quot;cc&quot;);String str = &quot;&quot;;for(int i=0; i&lt;list.size(); i++)&#123; str = str + &quot;-&quot; +list.get(i);&#125;//str 为-aa-bb-cc//use guavaList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;aa&quot;);list.add(&quot;bb&quot;);list.add(&quot;cc&quot;);String result = Joiner.on(&quot;-&quot;).join(list);//result为 aa-bb-cc 把map集合转换为特定规则的字符串12345Map&lt;String, Integer&gt; map = Maps.newHashMap();map.put(\"xiaoming\", 12);map.put(\"xiaohong\",13);String result = Joiner.on(\",\").withKeyValueSeparator(\"=\").join(map);// result为 xiaoming=12,xiaohong=13 将String转换为特定的集合123456789101112//use javaList&lt;String&gt; list = new ArrayList&lt;String&gt;();String a = \"1-2-3-4-5-6\";String[] strs = a.split(\"-\");for(int i=0; i&lt;strs.length; i++)&#123; list.add(strs[i]);&#125;//use guavaString str = \"1-2-3-4-5-6\";List&lt;String&gt; list = Splitter.on(\"-\").splitToList(str);//list为 [1, 2, 3, 4, 5, 6] 如果 1str=\"1-2-3-4- 5- 6 \"; guava还可以使用 ==使用 “-“ 切分字符串并去除空串与空格== omitEmptyStrings().trimResults() 去除空串与空格 123String str = \"1-2-3-4- 5- 6 \"; List&lt;String&gt; list = Splitter.on(\"-\").omitEmptyStrings().trimResults().splitToList(str);System.out.println(list); 就能忽略中间的空格 将String转换为map12String str = \"xiaoming=11,xiaohong=23\";Map&lt;String,String&gt; map = Splitter.on(\",\").withKeyValueSeparator(\"=\").split(str); 比如String提供的split方法，我们得关心空字符串吧，还得考虑返回的结果中存在null元素吧，只提供了前后trim的方法（如果我想对中间元素进行trim呢）。 那么，看下面的代码示例，guava让你不必在操心这些： Joiner是连接器，Splitter是分割器，通常我们会把它们定义为static final，利用on生成对象后在应用到String进行处理，这是可以复用的。要知道apache commons StringUtils提供的都是static method。更加重要的是，guava提供的Joiner/Splitter是经过充分测试，它的稳定性和效率要比apache高出不少，这个你可以自行测试下。 发现没有我们想对String做什么操作，就是生成自己定制化的Joiner/Splitter，多么直白，简单，流畅的API！ 对于Joiner，常用的方法是 跳过NULL元素：skipNulls() / 对于NULL元素使用其他替代：useForNull(String) 对于Splitter，常用的方法是：trimResults()/omitEmptyStrings()。注意拆分的方式，有字符串，还有正则，还有固定长度分割（太贴心了！） 其实除了Joiner/Splitter外，guava还提供了字符串匹配器：CharMatcher CharMatcher，将字符的匹配和处理解耦，并提供丰富的方法供你使用！ guava还支持多个字符切割，或者特定的正则分隔12String input = \"aa.dd,,ff,,.\";List&lt;String&gt; result = Splitter.onPattern(\"[.|,]\").omitEmptyStrings().splitToList(input); ==关于字符串的操作 都是在Splitter这个类上进行的。== 123456// 判断匹配结果boolean result = CharMatcher.inRange('a', 'z').or(CharMatcher.inRange('A', 'Z')).matches('K'); //true// 保留数字文本String s1 = CharMatcher.digit().retainFrom(\"abc 123 efg\"); //123// 删除数字文本String s2 = CharMatcher.digit().removeFrom(\"abc 123 efg\"); //abc efg 集合的过滤我们对于集合的过滤，思路就是迭代，然后再具体对每一个数判断，这样的代码放在程序中，难免会显得很臃肿，虽然功能都有，但是很不好看。 guava写法 123456789101112131415161718//按照条件过滤ImmutableList&lt;String&gt; names = ImmutableList.of(\"begin\", \"code\", \"Guava\", \"Java\");Iterable&lt;String&gt; fitered = Iterables.filter(names, Predicates.or(Predicates.equalTo(\"Guava\"), Predicates.equalTo(\"Java\")));System.out.println(fitered); // [Guava, Java]//自定义过滤条件 使用自定义回调方法对Map的每个Value进行操作ImmutableMap&lt;String, Integer&gt; m = ImmutableMap.of(\"begin\", 12, \"code\", 15); // Function&lt;F, T&gt; F表示apply()方法input的类型，T表示apply()方法返回类型 Map&lt;String, Integer&gt; m2 = Maps.transformValues(m, new Function&lt;Integer, Integer&gt;() &#123; public Integer apply(Integer input) &#123; if(input&gt;12)&#123; return input; &#125;else&#123; return input+1; &#125; &#125; &#125;);System.out.println(m2); //&#123;begin=13, code=15&#125; set的交集, 并集, 差集 1234567891011121314151617HashSet setA = newHashSet(1, 2, 3, 4, 5); HashSet setB = newHashSet(4, 5, 6, 7, 8); SetView union = Sets.union(setA, setB); System.out.println(\"union:\"); for (Integer integer : union) System.out.println(integer); //union:12345867 SetView difference = Sets.difference(setA, setB); System.out.println(\"difference:\"); for (Integer integer : difference) System.out.println(integer); //difference:123 SetView intersection = Sets.intersection(setA, setB); System.out.println(\"intersection:\"); for (Integer integer : intersection) System.out.println(integer); //intersection:45 map的交集，并集，差集 123456MapDifference differenceMap = Maps.difference(mapA, mapB); differenceMap.areEqual(); Map entriesDiffering = differenceMap.entriesDiffering(); Map entriesOnlyOnLeft = differenceMap.entriesOnlyOnLeft(); Map entriesOnlyOnRight = differenceMap.entriesOnlyOnRight(); Map entriesInCommon = differenceMap.entriesInCommon(); 检查参数1234567891011121314151617//use javaif(list!=null &amp;&amp; list.size()&gt;0)'''if(str!=null &amp;&amp; str.length()&gt;0)'''if(str !=null &amp;&amp; !str.isEmpty())//use guavaif(!Strings.isNullOrEmpty(str))//use javaif (count &lt;= 0) &#123; throw new IllegalArgumentException(\"must be positive: \" + count); &#125; //use guavaPreconditions.checkArgument(count &gt; 0, \"must be positive: %s\", count); 免去了很多麻烦！并且会使你的代码看上去更好看。而不是代码里面充斥着!=null， !=”” 检查是否为空,不仅仅是字符串类型，其他类型的判断 全部都封装在 Preconditions类里 里面的方法全为静态。 其中的一个方法的源码 1234567@CanIgnoreReturnValuepublic static &lt;T&gt; T checkNotNull(T reference) &#123; if (reference == null) &#123; throw new NullPointerException(); &#125; return reference;&#125; 方法声明（不包括额外参数） 描述 检查失败时抛出的异常 checkArgument(boolean) 检查boolean是否为true，用来检查传递给方法的参数。 IllegalArgumentException checkNotNull(T) 检查value是否为null，该方法直接返回value，因此可以内嵌使用checkNotNull NullPointerException checkState(boolean) 用来检查对象的某些状态。 IllegalStateException checkElementIndex(int index, int size) 检查index作为索引值对某个列表、字符串或数组是否有效。index&gt;=0 &amp;&amp; index&lt;size IndexOutOfBoundsException checkPositionIndexes(int start, int end, int size) 检查[start, end]表示的位置范围对某个列表、字符串或数组是否有效 IndexOutOfBoundsException MoreObjects这个方法是在Objects过期后 官方推荐使用的替代品，该类最大的好处就是不用大量的重写toString，用一种很优雅的方式实现重写，或者在某个场景定制使用。 1234Person person = new Person(\"aa\",11);String str = MoreObjects.toStringHelper(\"Person\").add(\"age\", person.getAge()).toString();System.out.println(str); //输出Person&#123;age=11&#125; 强大的Ordering排序器排序器[Ordering]是Guava流畅风格比较器[Comparator]的实现，它可以用来为构建复杂的比较器，以完成集合排序的功能。 123456789101112131415161718natural() 对可排序类型做自然排序，如数字按大小，日期按先后排序usingToString() 按对象的字符串形式做字典排序[lexicographical ordering]from(Comparator) 把给定的Comparator转化为排序器reverse() 获取语义相反的排序器nullsFirst() 使用当前排序器，但额外把null值排到最前面。nullsLast() 使用当前排序器，但额外把null值排到最后面。compound(Comparator) 合成另一个比较器，以处理当前排序器中的相等情况。lexicographical() 基于处理类型T的排序器，返回该类型的可迭代对象Iterable&lt;T&gt;的排序器。onResultOf(Function) 对集合中元素调用Function，再按返回值用当前排序器排序。Person person = new Person(\"aa\",14); //String name ,Integer agePerson ps = new Person(\"bb\",13);Ordering&lt;Person&gt; byOrdering = Ordering.natural().nullsFirst().onResultOf(new Function&lt;Person,String&gt;()&#123; public String apply(Person person)&#123; return person.age.toString(); &#125;&#125;);byOrdering.compare(person, ps);System.out.println(byOrdering.compare(person, ps)); //1 person的年龄比ps大 所以输出1 计算中间代码的运行时间123456Stopwatch stopwatch = Stopwatch.createStarted();for(int i=0; i&lt;100000; i++)&#123; &#125;long nanos = stopwatch.elapsed(TimeUnit.MILLISECONDS);System.out.println(nanos); TimeUnit 可以指定时间输出精确到多少时间 文件操作以前我们写文件读取的时候要定义缓冲区，各种条件判断，各种$%#$$%#$@# 而现在我们只需要使用好guava的api 就能使代码变得简洁，并且不用担心因为写错逻辑而背锅了 123456789101112File file = new File(\"/test.txt\");List&lt;String&gt; list = null;try &#123; list = Files.readLines(file, Charsets.UTF_8);&#125; catch (Exception e) &#123;&#125;Files.copy(from,to); //复制文件Files.deleteDirectoryContents(File directory); //删除文件夹下的内容(包括文件与子文件夹) Files.deleteRecursively(File file); //删除文件或者文件夹 Files.move(File from, File to); //移动文件URL url = Resources.getResource(\"abc.xml\"); //获取classpath根下的abc.xml文件url Files类中还有许多方法可以用，可以多多翻阅。 guava缓存对于大多数互联网项目而言，缓存的重要性，不言而喻！ 如果我们的应用系统，并不想使用一些第三方缓存组件（如redis），我们仅仅想在本地有一个功能足够强大的缓存，很可惜JDK提供的那些SET/MAP还不行！ 12345678910111213141516171819202122232425// 缓存的实现private static final CacheLoader&lt;Long, String&gt; cacheLoader = new CacheLoader&lt;Long, String&gt;() &#123; @Override public String load(Long key) throws Exception &#123; // TODO 从数据库加载数据 System.out.println(\"从数据库加载数据\"); return key + \":value\"; &#125;&#125;;// 定义缓存的策略private static final LoadingCache&lt;Long, String&gt; loadingCache = CacheBuilder.newBuilder() .expireAfterAccess(2, TimeUnit.SECONDS) // 设置在2秒内未访问则过期 .expireAfterWrite(2, TimeUnit.SECONDS) // 设置缓存在写入2秒后失效 .refreshAfterWrite(3, TimeUnit.SECONDS) // 设置缓存在写入3秒后，通过CacheLoader的load方法进行刷新 .maximumSize(100L) // 设置缓存数量上限为100 .build(cacheLoader);public static void main(String[] args) throws Exception &#123; //loadingCache.put(1L, \"James\"); System.out.println(loadingCache.get(1L)); Thread.sleep(5000L); System.out.println(loadingCache.get(1L));&#125; 首先，这是一个本地缓存，guava提供的cache是一个简洁、高效，易于维护的。为什么这么说呢？因为并没有一个单独的线程用于刷新 OR 清理cache，对于cache的操作，都是通过访问/读写带来的，也就是说在读写中完成缓存的刷新操作！ guava的缓存设计的比较巧妙，可以很精巧的使用。guava缓存创建分为两种，一种是CacheLoader,另一种则是callback方式 CacheLoader 12345678910111213141516LoadingCache&lt;String,String&gt; cahceBuilder=CacheBuilder .newBuilder() .build(new CacheLoader&lt;String, String&gt;()&#123; @Override public String load(String key) throws Exception &#123; String strProValue=\"hello \"+key+\"!\"; return strProValue; &#125; &#125;); System.out.println(cahceBuilder.apply(\"begincode\")); //hello begincode!System.out.println(cahceBuilder.get(\"begincode\")); //hello begincode!System.out.println(cahceBuilder.get(\"wen\")); //hello wen!System.out.println(cahceBuilder.apply(\"wen\")); //hello wen!System.out.println(cahceBuilder.apply(\"da\"));//hello da!cahceBuilder.put(\"begin\", \"code\");System.out.println(cahceBuilder.get(\"begin\")); //code api中已经把apply声明为过期，声明中推荐使用get方法获取值 callback方式: 12345678Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder().maximumSize(1000).build(); String resultVal = cache.get(\"code\", new Callable&lt;String&gt;() &#123; public String call() &#123; String strProValue=\"begin \"+\"code\"+\"!\"; return strProValue; &#125; &#125;); System.out.println(\"value : \" + resultVal); //value : begin code! 让异步回调更加简单JDK中提供了Future/FutureTask/Callable来对异步回调进行支持，但是还是看上去挺复杂的，能不能更加简单呢？比如注册一个监听回调。 1234567891011121314151617181920212223ExecutorService es = Executors.newFixedThreadPool(3);ListeningExecutorService listeningExecutorService = MoreExecutors.listeningDecorator(es);ListenableFuture&lt;?&gt; listenableFuture = listeningExecutorService.submit(() -&gt; &#123; if(new Random().nextInt(3) == 2)&#123; throw new NullPointerException(); &#125; return 1;&#125;);FutureCallback&lt;Integer&gt; futureCallback = new FutureCallback&lt;Integer&gt;() &#123; @Override public void onSuccess(@Nullable Integer o) &#123; System.out.println(\"------\" + o); &#125; @Override public void onFailure(Throwable throwable) &#123; System.out.println(\"------\" + throwable.getMessage()); &#125;&#125;;Futures.addCallback(listenableFuture,futureCallback); 我们可以通过guava对JDK提供的线程池进行装饰，让其具有异步回调监听功能，然后在设置监听器即可！ 函数式编程：Funcitons 上面的代码是为了完成将List集合中的元素，先截取5个长度，然后转成大写。 函数式编程的好处在于在集合遍历操作中提供自定义Function的操作，比如transform转换。我们再也不需要一遍遍的遍历集合，显著的简化了代码！ 对集合的transform操作可以通过Function完成 断言：Predicate Predicate最常用的功能就是运用在集合的过滤当中！ 需要注意的是Lists并没有提供filter方法，不过你可以使用Collections2.filter完成！ OptionalOptional用于包含非空对象的不可变对象。 Optional对象，用于不存在值表示null。这个类有各种实用的方法，以方便代码来处理为可用或不可用，而不是检查null值。 类声明​ 以下是com.google.common.base.Optional类的声明： 1234@GwtCompatible(serializable=true)public abstract class Optional&lt;T&gt; extends Object implements Serializable 类方法 S.N. 方法及说明 1 static Optional absent() 返回没有包含的参考Optional的实例。 2 abstract Set asSet() 返回一个不可变的单集的唯一元素所包含的实例(如果存在);否则为一个空的不可变的集合。 3 abstract boolean equals(Object object) 返回true如果对象是一个Optional实例，无论是包含引用彼此相等或两者都不存在。 4 static Optional fromNullable(T nullableReference) 如果nullableReference非空，返回一个包含引用Optional实例;否则返回absent()。 5 abstract T get() 返回所包含的实例，它必须存在。 6 abstract int hashCode() 返回此实例的哈希码。 7 abstract boolean isPresent() 返回true，如果这支架包含一个(非空)的实例。 8 static Optional of(T reference) 返回包含给定的非空引用Optional实例。 9 abstract Optional or(Optional secondChoice) 返回此Optional，如果它有一个值存在; 否则返回secondChoice。 10 abstract T or(Supplier supplier) 返回所包含的实例(如果存在); 否则supplier.get()。 11 abstract T or(T defaultValue) 返回所包含的实例(如果存在);否则为默认值。 12 abstract T orNull() 返回所包含的实例(如果存在);否则返回null。 13 static Iterable presentInstances(Iterable&gt; optionals) 从提供的optionals返回每个实例的存在的值，从而跳过absent()。 14 abstract String toString() 返回此实例的字符串表示。 15 abstract Optional transform(Function function) 如果实例存在，则它被转换给定的功能;否则absent()被返回。 继承的方法​ 这个类继承了以下类的方法： ​ java.lang.Object Optional示例​ 使用所选择的编辑器，创建下面的java程序，比如 C:/&gt; Guava GuavaTester.java 1234567891011121314151617181920212223242526272829303132import com.google.common.base.Optional;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester guavaTester = new GuavaTester(); Integer value1 = null; Integer value2 = new Integer(10); //Optional.fromNullable - allows passed parameter to be null. Optional&lt;Integer&gt; a = Optional.fromNullable(value1); //Optional.of - throws NullPointerException if passed parameter is null Optional&lt;Integer&gt; b = Optional.of(value2); System.out.println(guavaTester.sum(a,b)); &#125; public Integer sum(Optional&lt;Integer&gt; a, Optional&lt;Integer&gt; b)&#123; //Optional.isPresent - checks the value is present or not System.out.println(\"First parameter is present: \" + a.isPresent()); System.out.println(\"Second parameter is present: \" + b.isPresent()); //Optional.or - returns the value if present otherwise returns //the default value passed. Integer value1 = a.or(new Integer(0)); //Optional.get - gets the value, value should be present Integer value2 = b.get(); return value1 + value2; &#125; &#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123First parameter is present: falseSecond parameter is present: true10 Preconditions在guava中，对于null的处理手段是快速失败， 1234String name = \"\";Preconditions.checkNotNull(name, \"name is not null\");Integer age = 30;Preconditions.checkArgument(age&gt;=18, \"your age is under 18\"); 你可以看看guava的源码，很多方法的第一行就是：Preconditions.checkNotNull(elements); 要知道null是模糊的概念，是成功呢，还是失败呢，还是别的什么含义呢？ Preconditions提供静态方法来检查方法或构造函数，被调用是否给定适当的参数。它检查的先决条件。其方法失败抛出IllegalArgumentException。 类声明​ 以下是com.google.common.base.Preconditions类的声明： 123@GwtCompatiblepublic final class Preconditions extends Object 类方法 S.N. 方法及说明 1 static void checkArgument(boolean expression) 确保涉及的一个或多个参数来调用方法表达式的真相。 2 static void checkArgument(boolean expression, Object errorMessage) 确保涉及的一个或多个参数来调用方法表达式的真相。 3 static void checkArgument(boolean expression, String errorMessageTemplate, Object… errorMessageArgs) 确保涉及的一个或多个参数来调用方法表达式的真相。 4 static int checkElementIndex(int index, int size) 确保索引指定一个数组，列表或尺寸大小的字符串有效的元素。 5 static int checkElementIndex(int index, int size, String desc) 确保索引指定一个数组，列表或尺寸大小的字符串有效的元素。 6 static T checkNotNull(T reference) 确保对象引用作为参数传递给调用方法不为空。 7 static T checkNotNull(T reference, Object errorMessage) 确保对象引用作为参数传递给调用方法不为空。 8 static T checkNotNull(T reference, String errorMessageTemplate, Object… errorMessageArgs) 确保对象引用作为参数传递给调用方法不为空。 9 static int checkPositionIndex(int index, int size) 确保索引指定一个数组，列表或尺寸大小的字符串的有效位置。 10 static int checkPositionIndex(int index, int size, String desc) 确保索引指定一个数组，列表或尺寸大小的字符串的有效位置。 11 static void checkPositionIndexes(int start, int end, int size) 确保开始和结束指定数组，列表或字符串大小有效的位置，并按照顺序。 12 static void checkState(boolean expression) 确保涉及调用实例的状态，但不涉及任何参数来调用方法表达式的真相。 13 static void checkState(boolean expression, Object errorMessage) 确保涉及调用实例的状态，但不涉及任何参数来调用方法表达式的真相。 14 static void checkState(boolean expression, String errorMessageTemplate, Object… errorMessageArgs) 确保涉及调用实例的状态，但不涉及任何参数来调用方法表达式的真相。 继承的方法​ 这个类继承了以下类方法： ​ java.lang.Object Preconditions 示例​ 使用所选择的编辑器，创建下面的java程序比如 C:/&gt; Guava GuavaTester.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344import com.google.common.base.Preconditions;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester guavaTester = new GuavaTester(); try &#123; System.out.println(guavaTester.sqrt(-3.0)); &#125;catch(IllegalArgumentException e)&#123; System.out.println(e.getMessage()); &#125; try &#123; System.out.println(guavaTester.sum(null,3)); &#125;catch(NullPointerException e)&#123; System.out.println(e.getMessage()); &#125; try &#123; System.out.println(guavaTester.getValue(6)); &#125;catch(IndexOutOfBoundsException e)&#123; System.out.println(e.getMessage()); &#125; &#125; public double sqrt(double input) throws IllegalArgumentException &#123; Preconditions.checkArgument(input &gt; 0.0, \"Illegal Argument passed: Negative value %s.\", input); return Math.sqrt(input); &#125; public int sum(Integer a, Integer b)&#123; a = Preconditions.checkNotNull(a, \"Illegal Argument passed: First parameter is Null.\"); b = Preconditions.checkNotNull(b, \"Illegal Argument passed: Second parameter is Null.\"); return a+b; &#125; public int getValue(int input)&#123; int[] data = &#123;1,2,3,4,5&#125;; Preconditions.checkElementIndex(input,data.length, \"Illegal Argument passed: Invalid index.\"); return 0; &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123Illegal Argument passed: Negative value -3.0.Illegal Argument passed: First parameter is Null.Illegal Argument passed: Invalid index. (6) must be less than size (5) OrderingOrdering(排序)可以被看作是一个丰富的比较具有增强功能的链接，多个实用方法，多类型排序功能等。 类声明​ 以下是com.google.common.collect.Ordering类的声明： 1234@GwtCompatiblepublic abstract class Ordering&lt;T&gt; extends Object implements Comparator&lt;T&gt; 类方法 S.N. 方法及说明 1 static Ordering allEqual() 返回一个排序，它把所有的值相等，说明“没有顺序。”通过这个顺序以任何稳定的排序算法的结果，在改变没有顺序元素。 2 static Ordering arbitrary() 返回一个任意顺序对所有对象，其中compare(a, b) == 0 意味着a == b（身份平等）。 3 int binarySearch(List sortedList, T key) 搜索排序列表使用键的二进制搜索算法。 4 abstract int compare(T left, T right) 比较两个参数的顺序。 5 Ordering compound(Comparator secondaryComparator) 返回首先使用排序这一点，但它排序中的“tie”，然后委托给secondaryComparator事件。 6 static Ordering compound(Iterable&gt; comparators) 返回一个排序它尝试每个给定的比较器，以便直到一个非零结果找到，返回该结果，并返回零仅当所有比较器返回零。 7 static Ordering explicit(List valuesInOrder) 返回根据它们出现的定列表中的顺序比较对象进行排序。 8 static Ordering explicit(T leastValue, T… remainingValuesInOrder) 返回根据它们所赋予本方法的顺序进行比较的对象进行排序。 9 static Ordering from(Comparator comparator) 返回基于现有的比较实例进行排序。 10 List greatestOf(Iterable iterable, int k) 返回根据这个顺序给出迭代，为了从最大到最小的k个最大的元素。 11 List greatestOf(Iterator iterator, int k) 返回从给定的迭代器按照这个顺序，从最大到最小k个最大的元素。 12 ImmutableList immutableSortedCopy(Iterable elements) 返回包含的元素排序这种排序的不可变列表。 13 boolean isOrdered(Iterable iterable) 返回true如果在迭代后的第一个的每个元素是大于或等于在它之前，根据该排序的元素。 14 boolean isStrictlyOrdered(Iterable iterable) 返回true如果在迭代后的第一个的每个元素是严格比在它之前，根据该排序的元素更大。 15 List leastOf(Iterable iterable, int k) 返回根据这个顺序给出迭代，从而从低到最大的k个最低的元素。 16 List leastOf(Iterator elements, int k) 返回第k从给定的迭代器，按照这个顺序从最低到最大至少元素。 17 Ordering&gt; lexicographical() 返回一个新的排序它通过比较对应元素两两直到非零结果发现排序迭代;规定“字典顺序”。 18 E max(E a, E b) 返回两个值按照这个顺序的较大值。 19 E max(E a, E b, E c, E… rest) 返回指定的值，根据这个顺序是最大的。 20 E max(Iterable iterable) 返回指定的值，根据这个顺序是最大的。 21 E max(Iterator iterator) 返回指定的值，根据这个顺序是最大的。 22 E min(E a, E b) 返回两个值按照这个顺序的较小者。 23 E min(E a, E b, E c, E… rest) 返回最少指定的值，根据这个顺序。 24 E min(Iterable iterable) 返回最少指定的值，根据这个顺序。 25 E min(Iterator iterator) 返回最少指定的值，根据这个顺序。 26 static Ordering natural() 返回使用值的自然顺序排序序列化。 27 Ordering nullsFirst() 返回对待null小于所有其他值，并使用此来比较非空值排序。 28 Ordering nullsLast() 返回对待null作为大于所有其他值，并使用这个顺序来比较非空值排序。 29 Ordering onResultOf(Function function) 返回一个新的排序在F上，首先应用功能给它们，然后比较使用此这些结果的顺序元素。 30 Ordering reverse() 返回相反顺序; 顺序相当于Collections.reverseOrder（Comparator）。 31 List sortedCopy(Iterable elements) 返回包含的元素排序此排序可变列表;使用这个只有在结果列表可能需要进一步修改，或可能包含null。 32 static Ordering usingToString() 返回由它们的字符串表示的自然顺序，toString()比较对象进行排序。 方法继承​ 这个类从以下类继承的方法： ​ java.lang.Object Ordering 示例​ 使用所选择的编辑器，创建下面的java程序比如 C:/&gt; Guava GuavaTester.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import java.util.ArrayList;import java.util.Collections;import java.util.List;import com.google.common.collect.Ordering;public class GuavaTester &#123; public static void main(String args[])&#123; List&lt;Integer&gt; numbers = new ArrayList&lt;Integer&gt;(); numbers.add(new Integer(5)); numbers.add(new Integer(2)); numbers.add(new Integer(15)); numbers.add(new Integer(51)); numbers.add(new Integer(53)); numbers.add(new Integer(35)); numbers.add(new Integer(45)); numbers.add(new Integer(32)); numbers.add(new Integer(43)); numbers.add(new Integer(16)); Ordering ordering = Ordering.natural(); System.out.println(\"Input List: \"); System.out.println(numbers); Collections.sort(numbers,ordering ); System.out.println(\"Sorted List: \"); System.out.println(numbers); System.out.println(\"======================\"); System.out.println(\"List is sorted: \" + ordering.isOrdered(numbers)); System.out.println(\"Minimum: \" + ordering.min(numbers)); System.out.println(\"Maximum: \" + ordering.max(numbers)); Collections.sort(numbers,ordering.reverse()); System.out.println(\"Reverse: \" + numbers); numbers.add(null); System.out.println(\"Null added to Sorted List: \"); System.out.println(numbers); Collections.sort(numbers,ordering.nullsFirst()); System.out.println(\"Null first Sorted List: \"); System.out.println(numbers); System.out.println(\"======================\"); List&lt;String&gt; names = new ArrayList&lt;String&gt;(); names.add(\"Ram\"); names.add(\"Shyam\"); names.add(\"Mohan\"); names.add(\"Sohan\"); names.add(\"Ramesh\"); names.add(\"Suresh\"); names.add(\"Naresh\"); names.add(\"Mahesh\"); names.add(null); names.add(\"Vikas\"); names.add(\"Deepak\"); System.out.println(\"Another List: \"); System.out.println(names); Collections.sort(names,ordering.nullsFirst().reverse()); System.out.println(\"Null first then reverse sorted list: \"); System.out.println(names); &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123456789101112131415161718Input List: [5, 2, 15, 51, 53, 35, 45, 32, 43, 16]Sorted List: [2, 5, 15, 16, 32, 35, 43, 45, 51, 53]======================List is sorted: trueMinimum: 2Maximum: 53Reverse: [53, 51, 45, 43, 35, 32, 16, 15, 5, 2]Null added to Sorted List: [53, 51, 45, 43, 35, 32, 16, 15, 5, 2, null]Null first Sorted List: [null, 2, 5, 15, 16, 32, 35, 43, 45, 51, 53]======================Another List: [Ram, Shyam, Mohan, Sohan, Ramesh, Suresh, Naresh, Mahesh, null, Vikas, Deepak]Null first then reverse sorted list: [Vikas, Suresh, Sohan, Shyam, Ramesh, Ram, Naresh, Mohan, Mahesh, Deepak, null] ObjectsObjects类提供适用于所有对象，如equals, hashCode等辅助函数 类声明​ 以下是com.google.common.base.Objects类的声明： 123@GwtCompatiblepublic final class Objects extends Object 类方法 S.N. 方法及说明 1 static boolean equal(Object a, Object b) 确定两个可能是空的对象是否相等。 2 static T firstNonNull(T first, T second) 不推荐使用。使用MoreObjects.firstNonNull（T，T）来代替。定于2016年6月去除该方法。 3 static int hashCode(Object… objects) 生成多个值的哈希码。 4 static Objects.ToStringHelper toStringHelper(Class clazz) 不推荐使用。使用MoreObjects.toStringHelper（Class）来代替。定于2016年6月去除该方法。 5 static Objects.ToStringHelper toStringHelper(Object self) 不推荐使用。使用MoreObjects.toStringHelper（Object）来代替。定于2016年6月去除该方法。 6 static Objects.ToStringHelper toStringHelper(String className) 不推荐使用。使用MoreObjects.toStringHelper（String）来代替。定于2016年6月去除该方法。 方法继承​ 这个类从以下类继承的方法： ​ java.lang.Object Objects 示例​ 使用所选择的编辑器，创建下面的java程序比如 C:/&gt; Guava GuavaTester.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778import com.google.common.base.Objects;public class GuavaTester &#123; public static void main(String args[])&#123; Student s1 = new Student(\"Mahesh\", \"Parashar\", 1, \"VI\"); Student s2 = new Student(\"Suresh\", null, 3, null); System.out.println(s1.equals(s2)); System.out.println(s1.hashCode()); System.out.println( Objects.toStringHelper(s1) .add(\"Name\",s1.getFirstName()+\" \" + s1.getLastName()) .add(\"Class\", s1.getClassName()) .add(\"Roll No\", s1.getRollNo()) .toString()); &#125;&#125;class Student &#123; private String firstName; private String lastName; private int rollNo; private String className; public Student(String firstName, String lastName, int rollNo, String className)&#123; this.firstName = firstName; this.lastName = lastName; this.rollNo = rollNo; this.className = className; &#125; @Override public boolean equals(Object object)&#123; if(!(object instanceof Student) || object == null)&#123; return false; &#125; Student student = (Student)object; // no need to handle null here // Objects.equal(\"test\", \"test\") == true // Objects.equal(\"test\", null) == false // Objects.equal(null, \"test\") == false // Objects.equal(null, null) == true return Objects.equal(firstName, student.firstName) // first name can be null &amp;&amp; Objects.equal(lastName, student.lastName) // last name can be null &amp;&amp; Objects.equal(rollNo, student.rollNo) &amp;&amp; Objects.equal(className, student.className);// class name can be null &#125; @Override public int hashCode()&#123; //no need to compute hashCode by self return Objects.hashCode(className,rollNo); &#125; public String getFirstName() &#123; return firstName; &#125; public void setFirstName(String firstName) &#123; this.firstName = firstName; &#125; public String getLastName() &#123; return lastName; &#125; public void setLastName(String lastName) &#123; this.lastName = lastName; &#125; public int getRollNo() &#123; return rollNo; &#125; public void setRollNo(int rollNo) &#123; this.rollNo = rollNo; &#125; public String getClassName() &#123; return className; &#125; public void setClassName(String className) &#123; this.className = className; &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123false85871Student&#123;Name=Mahesh Parashar, Class=VI, Roll No=1&#125; RangeRange 表示一个间隔或一个序列。它被用于获取一组数字/串在一个特定范围之内。 类声明​ 以下是com.google.common.collect.Range类的声明： 1234@GwtCompatiblepublic final class Range&lt;C extends Comparable&gt; extends Object implements Predicate&lt;C&gt;, Serializable 方法 S.N. 方法及说明 1 static &gt; Range all() 返回包含C型的每一个值范围 2 boolean apply(C input)Deprecated. 只有提供满足谓词接口;使用包含(C)来代替。 3 static &gt; Range atLeast(C endpoint) 返回包含大于或等于终点(endpoint)的所有值的范围内。 4 static &gt; Range atMost(C endpoint) 返回包含的所有值小于或等于终点的范围内。 5 Range canonical(DiscreteDomain domain) 返回此范围内，在给定域中的规范形式。 6 static &gt; Range closed(C lower, C upper) 返回包含大于所有值或等于降低且小于或等于上限的范围内。 7 static &gt; Range closedOpen(C lower, C upper) 返回包含大于或等于下限和所有值严格大于上限以下的范围内。 8 boolean contains(C value) 返回true，如果值是这个范围的范围之内。 9 boolean containsAll(Iterable values) 如果值每一个元素都包含在这个范围内，则返回 true。 10 static &gt; Range downTo(C endpoint, BoundType boundType) 返回的范围内的给定的端点，它可以是包容性（闭合）或专用（开），没有上限。 11 static &gt; Range encloseAll(Iterable values) 返回包含所有给定值的最小范围内。 12 boolean encloses(Range other) 返回true，如果其他的边界不在该范围的边界之外延伸。 13 boolean equals(Object object) 返回true，如果对象是具有相同端点和绑定类型，这个范围内的范围。 14 static &gt; Range greaterThan(C endpoint) 返回一个包含所有值严格大于端点的范围内。 15 int hashCode() 返回此范围内的哈希码。 16 boolean hasLowerBound() 如果此范围内具有更低的终点返回true。 17 boolean hasUpperBound() 如果此范围内有上端点返回true。 18 Range intersection(Range connectedRange) 返回由两者范围和connectedRange封闭，如果这样的范围存在的最大范围。 19 boolean isConnected(Range other) 如果存在这是由两者此范围和其他封闭（可能为空）的范围，则返回true。 20 boolean isEmpty() 返回true，如果这个范围是形式 [v..v) 或 (v..v]. 21 static &gt; Range lessThan(C endpoint) 返回一个包含所有值严格小于端点的范围内。 22 BoundType lowerBoundType() 返回类型这个范围的下限：如果范围包括它的下端点BoundType.CLOSED，如果没有BoundType.OPEN。 23 C lowerEndpoint() 返回该范围的较低端点。 24 static &gt; Range open(C lower, C upper) 返回一个包含所有值严格大于下限和严格比上端更小一个范围。 25 static &gt; Range openClosed(C lower, C upper) 返回包含所有值严格低于更大且小于或等于上限的范围内。 26 static &gt; Range range(C lower, BoundType lowerType, C upper, BoundType upperType) 返回包含任何值由下到上，每个端点可以是包容性（关闭）或专用（开）的范围。 27 static &gt; Range singleton(C value) 返回包含只在给定范围内的值。 28 Range span(Range other) 返回最小的范围包围两者这个范围和other等。 29 String toString() 返回该范围内的字符串表示，如“[3..5）”（其他实例列在类文档）。 30 BoundType upperBoundType() 返回类型此范围的上限：如果范围包括其上的端点返回BoundType.CLOSED，如果没有返回BoundType.OPEN。 31 C upperEndpoint() 返回此范围的上限端点。 32 static &gt; Range upTo(C endpoint, BoundType boundType) 返回一个范围，没有下限到给定的端点，它可以是包容性（闭合）或专用（开）。 方法继承​ 这个类从以下类继承的方法： ​ java.lang.Object Range 例子​ 选择使用任何编辑器创建以下java程序在 C:/&gt; Guava ​ GuavaTester.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import com.google.common.collect.ContiguousSet;import com.google.common.collect.DiscreteDomain;import com.google.common.collect.Range;import com.google.common.primitives.Ints;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testRange(); &#125; private void testRange()&#123; //create a range [a,b] = &#123; x | a &lt;= x &lt;= b&#125; Range&lt;Integer&gt; range1 = Range.closed(0, 9); System.out.print(\"[0,9] : \"); printRange(range1); System.out.println(\"5 is present: \" + range1.contains(5)); System.out.println(\"(1,2,3) is present: \" + range1.containsAll(Ints.asList(1, 2, 3))); System.out.println(\"Lower Bound: \" + range1.lowerEndpoint()); System.out.println(\"Upper Bound: \" + range1.upperEndpoint()); //create a range (a,b) = &#123; x | a &lt; x &lt; b&#125; Range&lt;Integer&gt; range2 = Range.open(0, 9); System.out.print(\"(0,9) : \"); printRange(range2); //create a range (a,b] = &#123; x | a &lt; x &lt;= b&#125; Range&lt;Integer&gt; range3 = Range.openClosed(0, 9); System.out.print(\"(0,9] : \"); printRange(range3); //create a range [a,b) = &#123; x | a &lt;= x &lt; b&#125; Range&lt;Integer&gt; range4 = Range.closedOpen(0, 9); System.out.print(\"[0,9) : \"); printRange(range4); //create an open ended range (9, infinity Range&lt;Integer&gt; range5 = Range.greaterThan(9); System.out.println(\"(9,infinity) : \"); System.out.println(\"Lower Bound: \" + range5.lowerEndpoint()); System.out.println(\"Upper Bound present: \" + range5.hasUpperBound()); Range&lt;Integer&gt; range6 = Range.closed(3, 5); printRange(range6); //check a subrange [3,5] in [0,9] System.out.println(\"[0,9] encloses [3,5]:\" + range1.encloses(range6)); Range&lt;Integer&gt; range7 = Range.closed(9, 20); printRange(range7); //check ranges to be connected System.out.println(\"[0,9] is connected [9,20]:\" + range1.isConnected(range7)); Range&lt;Integer&gt; range8 = Range.closed(5, 15); //intersection printRange(range1.intersection(range8)); //span printRange(range1.span(range8)); &#125; private void printRange(Range&lt;Integer&gt; range)&#123; System.out.print(\"[ \"); for(int grade : ContiguousSet.create(range, DiscreteDomain.integers())) &#123; System.out.print(grade +\" \"); &#125; System.out.println(\"]\"); &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 1234567891011121314151617[0,9] : [ 0 1 2 3 4 5 6 7 8 9 ]5 is present: true(1,2,3) is present: trueLower Bound: 0Upper Bound: 9(0,9) : [ 1 2 3 4 5 6 7 8 ](0,9] : [ 1 2 3 4 5 6 7 8 9 ][0,9) : [ 0 1 2 3 4 5 6 7 8 ](9,infinity) : Lower Bound: 9Upper Bound present: false[ 3 4 5 ][0,9] encloses [3,5]:true[ 9 10 11 12 13 14 15 16 17 18 19 20 ][0,9] is connected [9,20]:true[ 5 6 7 8 9 ][ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ] ThrowablesThrowable类提供了相关的Throwable接口的实用方法。 类声明​ 以下是com.google.common.base.Throwables类的声明： 12public final class Throwables extends Object 类方法 S.N. 方法及说明 1 static List getCausalChain(Throwable throwable) 获取一个Throwable的原因链的列表。 2 static Throwable getRootCause(Throwable throwable) 返回抛出的最里面的原因。 3 static String getStackTraceAsString(Throwable throwable) 返回包含toString()的结果字符串，随后完整抛出，递归的堆栈跟踪。 4 static RuntimeException propagate(Throwable throwable) 传播抛出原样如果RuntimeException或Error是一个实例，否则作为最后的报告，把它包装在一个RuntimeException，然后传播。 5 static void propagateIfInstanceOf(Throwable throwable, Class declaredType) 传播抛出对象完全按原样，当且仅当它是declaredType的一个实例。 6 static void propagateIfPossible(Throwable throwable) 传播抛出对象完全按原样，当且仅当它是RuntimeException或Error的一个实例。 7 static void propagateIfPossible(Throwable throwable, Class declaredType) 传播抛出对象完全按原样，当且仅当它是RuntimeException，错误或的declaredType的一个实例。 8 static void propagateIfPossible(Throwable throwable, Class declaredType1, Class declaredType2) 传播抛出对象完全按原样，当且仅当它是RuntimeException，Error，declaredType1或declaredType2的一个实例。 继承的方法​ 这个类继承了以下类方法： ​ java.lang.Object Throwables示例​ 创建使用所选择的任何编辑器下面的java程序，比如 C:/&gt; Guava GuavaTester.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import java.io.IOException;import com.google.common.base.Objects;import com.google.common.base.Throwables;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); try &#123; tester.showcaseThrowables(); &#125; catch (InvalidInputException e) &#123; //get the root cause System.out.println(Throwables.getRootCause(e)); &#125;catch (Exception e) &#123; //get the stack trace in string format System.out.println(Throwables.getStackTraceAsString(e)); &#125; try &#123; tester.showcaseThrowables1(); &#125;catch (Exception e) &#123; System.out.println(Throwables.getStackTraceAsString(e)); &#125; &#125; public void showcaseThrowables() throws InvalidInputException&#123; try &#123; sqrt(-3.0); &#125; catch (Throwable e) &#123; //check the type of exception and throw it Throwables.propagateIfInstanceOf(e, InvalidInputException.class); Throwables.propagate(e); &#125; &#125; public void showcaseThrowables1()&#123; try &#123; int[] data = &#123;1,2,3&#125;; getValue(data, 4); &#125; catch (Throwable e) &#123; Throwables.propagateIfInstanceOf(e, IndexOutOfBoundsException.class); Throwables.propagate(e); &#125; &#125; public double sqrt(double input) throws InvalidInputException&#123; if(input &lt; 0) throw new InvalidInputException(); return Math.sqrt(input); &#125; public double getValue(int[] list, int index) throws IndexOutOfBoundsException &#123; return list[index]; &#125; public void dummyIO() throws IOException &#123; throw new IOException(); &#125;&#125;class InvalidInputException extends Exception &#123;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 12345InvalidInputExceptionjava.lang.ArrayIndexOutOfBoundsException: 4 at GuavaTester.getValue(GuavaTester.java:52) at GuavaTester.showcaseThrowables1(GuavaTester.java:38) at GuavaTester.main(GuavaTester.java:19) MultisetMultiset接口扩展设置有重复的元素，并提供了各种实用的方法来处理这样的元素在集合中出现。 接口声明​ 以下是com.google.common.collect.Multiset接口的声明： 123@GwtCompatiblepublic interface Multiset&lt;E&gt; extends Collection&lt;E&gt; 接口方法 S.N. 方法及说明 1 boolean add(E element) 添加一个出现的指定元素这个multiset。 2 int add(E element, int occurrences) 增加大量的元素到这个multiset。 3 boolean contains(Object element) 确定此多集是否包含指定的元素。 4 boolean containsAll(Collection elements) 返回true，如果这个多集至少包含一个出现的指定集合中的所有元素。 5 int count(Object element) 返回出现的元素的在该multiset的数目（元素的数量）。 6 Set elementSet() 返回集包含在此多集不同的元素。 7 Set&gt; entrySet() 返回此多集的内容的视图，分组在Multiset.Entry实例中，每一个都提供了多集的一个元素和元素的计数。 8 boolean equals(Object object) 比较指定对象与此multiset是否相等。 9 int hashCode() 返回此multiset的哈希码。 10 Iterator iterator() 返回一个迭代在这个集合中的元素。 11 boolean remove(Object element) 移除此多集multiset的单个出现的指定元素，如果存在。 12 int remove(Object element, int occurrences) 删除了一些出现，从该多集multiset的指定元素。 13 boolean removeAll(Collection c) 删除所有这一切都包含在指定集合（可选操作）在此集合的元素。 14 boolean retainAll(Collection c) 保持那些包含在指定collection（可选操作）在此只集合中的元素。 15 int setCount(E element, int count) 添加或删除，使得该元素达到所期望的计数的元件的必要出现。 16 boolean setCount(E element, int oldCount, int newCount) 有条件设置元素的计数为一个新值，如在setCount（对象，INT）中所述，条件是该元素预期的当前计数。 17 String toString() 返回该对象的字符串表示。 方法继承​ 此接口继承从以下接口方法： ​ java.util.Collection Multiset 示例​ 使用所选择的编辑器创建下面的java程序，比如说 C:/&gt; Guava GuavaTester.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import java.util.Iterator;import java.util.Set;import com.google.common.collect.HashMultiset;import com.google.common.collect.Multiset;public class GuavaTester &#123; public static void main(String args[])&#123; //create a multiset collection Multiset&lt;String&gt; multiset = HashMultiset.create(); multiset.add(\"a\"); multiset.add(\"b\"); multiset.add(\"c\"); multiset.add(\"d\"); multiset.add(\"a\"); multiset.add(\"b\"); multiset.add(\"c\"); multiset.add(\"b\"); multiset.add(\"b\"); multiset.add(\"b\"); //print the occurrence of an element System.out.println(\"Occurrence of 'b' : \"+multiset.count(\"b\")); //print the total size of the multiset System.out.println(\"Total Size : \"+multiset.size()); //get the distinct elements of the multiset as set Set&lt;String&gt; set = multiset.elementSet(); //display the elements of the set System.out.println(\"Set [\"); for (String s : set) &#123; System.out.println(s); &#125; System.out.println(\"]\"); //display all the elements of the multiset using iterator Iterator&lt;String&gt; iterator = multiset.iterator(); System.out.println(\"MultiSet [\"); while(iterator.hasNext())&#123; System.out.println(iterator.next()); &#125; System.out.println(\"]\"); //display the distinct elements of the multiset with their occurrence count System.out.println(\"MultiSet [\"); for (Multiset.Entry&lt;String&gt; entry : multiset.entrySet()) &#123; System.out.println(\"Element: \"+entry.getElement() +\", Occurrence(s): \" + entry.getCount()); &#125; System.out.println(\"]\"); //remove extra occurrences multiset.remove(\"b\",2); //print the occurrence of an element System.out.println(\"Occurence of 'b' : \"+multiset.count(\"b\")); &#125; &#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123456789101112131415161718192021222324252627Occurence of 'b' : 5Total Size : 10Set [dbca]MultiSet [dbbbbbccaa]MultiSet [Element: d, Occurence(s): 1Element: b, Occurence(s): 5Element: c, Occurence(s): 2Element: a, Occurence(s): 2]Occurence of 'b' : 3 BimapBiMap是一种特殊的映射其保持映射，同时确保没有重复的值是存在于该映射和一个值可以安全地用于获取键背面的倒数映射。 接口声明​ 以下是com.google.common.collect.Bimap&lt;K，V&gt;接口的声明： 123@GwtCompatiblepublic interface BiMap&lt;K,V&gt;extends Map&lt;K,V&gt; 接口方法 S.N. 方法及说明 1 V forcePut(K key, V value) 另一种put的形式是默默删除，在put(K, V)运行前的任何现有条目值值。 2 BiMap inverse() 返回此bimap，每一个bimap的值映射到其相关联的键的逆视图。 3 V put(K key, V value) 关联指定值与此映射中(可选操作)指定的键。 4 void putAll(Map map) 将所有从指定映射此映射(可选操作)的映射。 5 Set values() 返回此映射中包含Collection的值视图。 继承的方法​ 这个类继承自以下接口方法： ​ java.util.Map BiMap 示例​ 使用所选择的编辑器创建下面的java程序，比如说 C:/&gt; Guava GuavaTester.java 12345678910111213141516import com.google.common.collect.BiMap;import com.google.common.collect.HashBiMap;public class GuavaTester &#123; public static void main(String args[])&#123; BiMap&lt;Integer, String&gt; empIDNameMap = HashBiMap.create(); empIDNameMap.put(new Integer(101), \"Mahesh\"); empIDNameMap.put(new Integer(102), \"Sohan\"); empIDNameMap.put(new Integer(103), \"Ramesh\"); //Emp Id of Employee \"Mahesh\" System.out.println(empIDNameMap.inverse().get(\"Mahesh\")); &#125; &#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看看以下结果： 1101 TableTable代表一个特殊的映射，其中两个键可以在组合的方式被指定为单个值。它类似于创建映射的映射。 接口声明​ 以下是 com.google.common.collect.Table&lt;R，C，V&gt; 接口的声明： 12@GwtCompatiblepublic interface Table&lt;R,C,V&gt; 接口方法 S.N. 方法 &amp; 描述 1 Set&gt; cellSet() 返回集合中的所有行键/列键/值三元组。 2 void clear() 从表中删除所有映射。 3 Map column(C columnKey) 返回在给定列键的所有映射的视图。 4 Set columnKeySet() 返回一组具有表中的一个或多个值的列键。 5 Map&gt; columnMap() 返回关联的每一列键与行键对应的映射值的视图。 6 boolean contains(Object rowKey, Object columnKey) 返回true，如果表中包含与指定的行和列键的映射。 7 boolean containsColumn(Object columnKey) 返回true，如果表中包含与指定列的映射。 8 boolean containsRow(Object rowKey) 返回true，如果表中包含与指定的行键的映射关系。 9 boolean containsValue(Object value) 返回true，如果表中包含具有指定值的映射。 10 boolean equals(Object obj) 比较指定对象与此表是否相等。 11 V get(Object rowKey, Object columnKey) 返回对应于给定的行和列键，如果没有这样的映射存在值，返回null。 12 int hashCode() 返回此表中的哈希码。 13 boolean isEmpty() 返回true，如果表中没有映射。 14 V put(R rowKey, C columnKey, V value) 关联指定值与指定键。 15 void putAll(Table table) 复制从指定的表中的所有映射到这个表。 16 V remove(Object rowKey, Object columnKey) 如果有的话，使用给定键相关联删除的映射。 17 Map row(R rowKey) 返回包含给定行键的所有映射的视图。 18 Set rowKeySet() 返回一组行键具有在表中的一个或多个值。 19 Map&gt; rowMap() 返回关联的每一行按键与键列对应的映射值的视图。 20 int size() 返回行键/列键/表中的值映射关系的数量。 21 Collection values() 返回所有值，其中可能包含重复的集合。 Table 例子​ 选择使用任何编辑器创建以下java程序在 C:/&gt; Guava GuavaTester.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import java.util.Map;import java.util.Set;import com.google.common.collect.HashBasedTable;import com.google.common.collect.Table;public class GuavaTester &#123; public static void main(String args[])&#123; //Table&lt;R,C,V&gt; == Map&lt;R,Map&lt;C,V&gt;&gt; /* * Company: IBM, Microsoft, TCS * IBM -&gt; &#123;101:Mahesh, 102:Ramesh, 103:Suresh&#125; * Microsoft -&gt; &#123;101:Sohan, 102:Mohan, 103:Rohan &#125; * TCS -&gt; &#123;101:Ram, 102: Shyam, 103: Sunil &#125; * * */ //create a table Table&lt;String, String, String&gt; employeeTable = HashBasedTable.create(); //initialize the table with employee details employeeTable.put(\"IBM\", \"101\",\"Mahesh\"); employeeTable.put(\"IBM\", \"102\",\"Ramesh\"); employeeTable.put(\"IBM\", \"103\",\"Suresh\"); employeeTable.put(\"Microsoft\", \"111\",\"Sohan\"); employeeTable.put(\"Microsoft\", \"112\",\"Mohan\"); employeeTable.put(\"Microsoft\", \"113\",\"Rohan\"); employeeTable.put(\"TCS\", \"121\",\"Ram\"); employeeTable.put(\"TCS\", \"122\",\"Shyam\"); employeeTable.put(\"TCS\", \"123\",\"Sunil\"); //get Map corresponding to IBM Map&lt;String,String&gt; ibmEmployees = employeeTable.row(\"IBM\"); System.out.println(\"List of IBM Employees\"); for(Map.Entry&lt;String, String&gt; entry : ibmEmployees.entrySet())&#123; System.out.println(\"Emp Id: \" + entry.getKey() + \", Name: \" + entry.getValue()); &#125; //get all the unique keys of the table Set&lt;String&gt; employers = employeeTable.rowKeySet(); System.out.print(\"Employers: \"); for(String employer: employers)&#123; System.out.print(employer + \" \"); &#125; System.out.println(); //get a Map corresponding to 102 Map&lt;String,String&gt; EmployerMap = employeeTable.column(\"102\"); for(Map.Entry&lt;String, String&gt; entry : EmployerMap.entrySet())&#123; System.out.println(\"Employer: \" + entry.getKey() + \", Name: \" + entry.getValue()); &#125; &#125; &#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123456List of IBM EmployeesEmp Id: 102, Name: RameshEmp Id: 101, Name: MaheshEmp Id: 103, Name: SureshEmployers: IBM TCS Microsoft Employer: IBM, Name: Ramesh CacheGuava通过接口LoadingCache提供了一个非常强大的基于内存的LoadingCache&lt;K，V&gt;。在缓存中自动加载值，它提供了许多实用的方法，在有缓存需求时非常有用。 接口声明​ 以下是forcom.google.common.cache.LoadingCache&lt;K，V&gt;接口的声明： 1234@Beta@GwtCompatiblepublic interface LoadingCache&lt;K,V&gt; extends Cache&lt;K,V&gt;, Function&lt;K,V&gt; 接口方法 S.N. 方法及说明 1 V apply(K key) 不推荐使用。提供满足功能接口;使用get(K)或getUnchecked(K)代替。 2 ConcurrentMap asMap() 返回存储在该缓存作为一个线程安全的映射条目的视图。 3 V get(K key) 返回一个键在这个高速缓存中，首先装载如果需要该值相关联的值。 4 ImmutableMap getAll(Iterable keys) 返回一个键相关联的值的映射，创建或必要时检索这些值。 5 V getUnchecked(K key) 返回一个键在这个高速缓存中，首先装载如果需要该值相关联的值。 6 void refresh(K key) 加载键key，可能是异步的一个新值。 LoadingCache 示例​ 使用所选择的编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394import java.util.HashMap;import java.util.Map;import java.util.concurrent.ExecutionException;import java.util.concurrent.TimeUnit;import com.google.common.base.MoreObjects;import com.google.common.cache.CacheBuilder;import com.google.common.cache.CacheLoader;import com.google.common.cache.LoadingCache;public class GuavaTester &#123; public static void main(String args[])&#123; //create a cache for employees based on their employee id LoadingCache employeeCache = CacheBuilder.newBuilder() .maximumSize(100) // maximum 100 records can be cached .expireAfterAccess(30, TimeUnit.MINUTES) // cache will expire after 30 minutes of access .build(new CacheLoader()&#123; // build the cacheloader @Override public Employee load(String empId) throws Exception &#123; //make the expensive call return getFromDatabase(empId); &#125; &#125;); try &#123; //on first invocation, cache will be populated with corresponding //employee record System.out.println(\"Invocation #1\"); System.out.println(employeeCache.get(\"100\")); System.out.println(employeeCache.get(\"103\")); System.out.println(employeeCache.get(\"110\")); //second invocation, data will be returned from cache System.out.println(\"Invocation #2\"); System.out.println(employeeCache.get(\"100\")); System.out.println(employeeCache.get(\"103\")); System.out.println(employeeCache.get(\"110\")); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; private static Employee getFromDatabase(String empId)&#123; Employee e1 = new Employee(\"Mahesh\", \"Finance\", \"100\"); Employee e2 = new Employee(\"Rohan\", \"IT\", \"103\"); Employee e3 = new Employee(\"Sohan\", \"Admin\", \"110\"); Map database = new HashMap(); database.put(\"100\", e1); database.put(\"103\", e2); database.put(\"110\", e3); System.out.println(\"Database hit for\" + empId); return database.get(empId); &#125;&#125;class Employee &#123; String name; String dept; String emplD; public Employee(String name, String dept, String empID)&#123; this.name = name; this.dept = dept; this.emplD = empID; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getDept() &#123; return dept; &#125; public void setDept(String dept) &#123; this.dept = dept; &#125; public String getEmplD() &#123; return emplD; &#125; public void setEmplD(String emplD) &#123; this.emplD = emplD; &#125; @Override public String toString() &#123; return MoreObjects.toStringHelper(Employee.class) .add(\"Name\", name) .add(\"Department\", dept) .add(\"Emp Id\", emplD).toString(); &#125; &#125; 验证结果​ 使用javac编译器如下编译类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看看结果： 1234567891011Invocation #1Database hit for100Employee&#123;Name=Mahesh, Department=Finance, Emp Id=100&#125;Database hit for103Employee&#123;Name=Rohan, Department=IT, Emp Id=103&#125;Database hit for110Employee&#123;Name=Sohan, Department=Admin, Emp Id=110&#125;Invocation #2Employee&#123;Name=Mahesh, Department=Finance, Emp Id=100&#125;Employee&#123;Name=Rohan, Department=IT, Emp Id=103&#125;Employee&#123;Name=Sohan, Department=Admin, Emp Id=110&#125; JoinerJoiner 提供了各种方法来处理字符串加入操作，对象等。 类声明​ 以下是com.google.common.base.Joiner类的声明： 123@GwtCompatiblepublic class Joiner extends Object 类方法 S.N. 方法及说明 1 A appendTo(A appendable, Iterable parts) 每个追加部分的字符串表示，使用每个之间先前配置的分离器，可用来追加。 2 A appendTo(A appendable, Iterator parts) 每个追加部分的字符串表示，使用每个之间先前配置的分离器，可用来追加。 3 A appendTo(A appendable, Object[] parts) 每个追加部分的字符串表示，使用每个之间先前配置的分离器，可用来追加。 4 A appendTo(A appendable, Object first, Object second, Object… rest) 追加到可追加的每个其余参数的字符串表示。 5 StringBuilder appendTo(StringBuilder builder, Iterable parts) 每个追加部分的字符串表示，使用每个之间先前配置的分离器，为构建者。 6 StringBuilder appendTo(StringBuilder builder, Iterator parts) 每个追加部分的字符串表示，使用每个之间先前配置的分离器，为构建者。 7 StringBuilder appendTo(StringBuilder builder, Object[] parts) 每个追加部分的字符串表示，使用每个之间先前配置的分离器，为构建者。 8 StringBuilder appendTo(StringBuilder builder, Object first, Object second, Object… rest) 追加到构建器的每个其余参数的字符串表示。 9 String join(Iterable parts) 返回一个包含每个部分的字符串表示，使用每个之间先前配置的分隔符的字符串。 10 String join(Iterator parts) 返回一个包含每个部分的字符串表示，使用每个之间先前配置的分隔符的字符串。 11 String join(Object[] parts) 返回一个包含每个部分的字符串表示，使用每个之间先前配置的分隔符的字符串。 12 String join(Object first, Object second, Object… rest) 返回一个包含每个参数的字符串表示，使用每个之间先前配置的分隔符的字符串。 13 static Joiner on(char separator) 返回一个加入者其连续元素之间自动地分隔符。 14 static Joiner on(String separator) 返回一个加入者其连续元素之间自动地分隔符。 15 Joiner skipNulls() 返回一个相同的行为，因为这加入者，除了自动跳过任何提供空元素的加入者。 16 Joiner useForNull(String nullText) 返回一个相同的行为，因为这一个加入者，除了自动替换nullText任何提供null元素。 17 Joiner.MapJoiner withKeyValueSeparator(String keyValueSeparator) 返回使用给定键值分离器MapJoiner，和相同的结构，否则为Joiner连接符 。 继承的方法​ 这个类继承了以下类方法： ​ java.lang.Object Joiner 示例​ 使用所选择的编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 123456789101112131415import java.util.Arrays;import com.google.common.base.Joiner;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testJoiner(); &#125; private void testJoiner()&#123; System.out.println(Joiner.on(\",\") .skipNulls() .join(Arrays.asList(1,2,3,4,5,null,6))); &#125;&#125; 验证输出结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看看结果： 11,2,3,4,5,6 SpiltterSplitter 提供了各种方法来处理分割操作字符串，对象等。 类声明​ 以下是com.google.common.base.Splitter类的声明： 123@GwtCompatible(emulated=true)public final class Splitter extends Object 类方法 S.N. 方法及说明 1 static Splitter fixedLength(int length) 返回分离器的划分字符串到给定长度的片段。 2 Splitter limit(int limit) 返回一个分离器，其行为等同于这个分离器，但停止分裂后达到了极限。 3 Splitter omitEmptyStrings() 返回使用给定的单字符分离器分离器。 4 static Splitter on(char separator) 返回使用给定的单字符分离器分离器。 5 static Splitter on(CharMatcher separatorMatcher) 返回一个分离器的匹配考虑由给定CharMatcher是一个分隔任何单个字符。 6 static Splitter on(Pattern separatorPattern) 返回分离器的考虑任何序列匹配模式是一个分隔符。 7 static Splitter on(String separator) 返回使用给定的固定的字符串作为分隔符分离器。 8 static Splitter onPattern(String separatorPattern) 返回分离器的考虑任何序列匹配一个给定模式(正则表达式)是一个分隔符。 9 Iterable split(CharSequence sequence) 分割成序列串组件并使其可通过迭代器，其可以被懒惰地评估计算。 10 List splitToList(CharSequence sequence) 拆分序列化为字符串组成部分，并将其返回为不可变列表。 11 Splitter trimResults() 返回分离器的行为等同于该分离器，但会自动删除开头和结尾的空白，从每个返回子;相当于trimResults(CharMatcher.WHITESPACE). 12 Splitter trimResults(CharMatcher trimmer) 返回分离器的行为等同于该分离器，但会删除所有开头或结尾的字符匹配每一个给定的CharMatcher返回字符串。 13 Splitter.MapSplitter withKeyValueSeparator(char separator) 返回MapSplitter这样会将在此基础上分离器的条目，并分割成入口键和值使用指定的分隔符。 14 Splitter.MapSplitter withKeyValueSeparator(Splitter keyValueSplitter) 返回MapSplitter这样会将在此基础上分离器的条目，并分割成条目使用指定的键值分离器键和值。 15 Splitter.MapSplitter withKeyValueSeparator(String separator) 返回MapSplitter这样会将在此基础上分离器的条目，并分割成入口键和值使用指定的分隔符。 继承的方法​ 这个类继承了以下类方法： ​ java.lang.Object Splitter 例子​ 使用所选择的编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 123456789101112131415import com.google.common.base.Splitter;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testSplitter(); &#125; private void testSplitter()&#123; System.out.println(Splitter.on(',') .trimResults() .omitEmptyStrings() .split(\"the ,quick, , brown , fox, jumps, over, the, lazy, little dog.\")); &#125;&#125; 验证输出​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 1[the, quick, brown, fox, jumps, over, the, lazy, little dog.] CharMatcherCharMatcher提供了各种方法来处理各种JAVA char类型值。 类声明​ 以下是com.google.common.base.CharMatcher类的声明： 123@GwtCompatible(emulated=true)public final class CharMatcher extends Object 字体 S.N. 字段及说明 1 static CharMatcher ANY 匹配任意字符。 2 static CharMatcher ASCII 确定字符是否为ASCII码，这意味着它的代码点低于128。 3 static CharMatcher BREAKING_WHITESPACE 确定一个字符是否是一个破空白（即，一个空格可以解释为格式目的词之间休息）。 4 static CharMatcher DIGIT 确定一个字符是否是根据Unicode数字。 5 static CharMatcher INVISIBLE 确定一个字符是否是看不见的;也就是说，如果它的Unicode类是任何SPACE_SEPARATOR，LINE_SEPARATOR，PARAGRAPH_SEPARATOR，控制，FORMAT，SURROGATE和PRIVATE_USE根据ICU4J。 6 static CharMatcher JAVA_DIGIT 确定一个字符是否是按照Java的定义一个数字。 7 static CharMatcher JAVA_ISO_CONTROL 确定一个字符是否是所指定的Character.isISOControl(char)ISO控制字符。 8 static CharMatcher JAVA_LETTER 确定一个字符是否是按照Java的定义的字母。 9 static CharMatcher JAVA_LETTER_OR_DIGIT 确定一个字符是否是按照Java的定义，一个字母或数字。 10 static CharMatcher JAVA_LOWER_CASE 确定一个字符是否是按照Java定义的小写。 11 static CharMatcher JAVA_UPPER_CASE 确定一个字符是否是按照Java定义的大写。 12 static CharMatcher NONE 匹配任何字符。 13 static CharMatcher SINGLE_WIDTH 确定一个字符是否是单宽度（不是双倍宽度）。 14 static CharMatcher WHITESPACE 决定根据最新的Unicode标准是否字符是空白，如图所示这里。 构造函数 S.N. 构造函数 &amp; 描述 1 protected CharMatcher() 构造方法，供子类使用。 类方法 S.N. 方法 &amp; 描述 1 CharMatcher and(CharMatcher other) 返回一个匹配器，匹配两种匹配器和其他任何字符。 2 static CharMatcher anyOf(CharSequence sequence) 返回一个字符匹配匹配任何字符出现在给定的字符序列。 3 boolean apply(Character character) 不推荐使用。只有提供满足谓词接口;用匹配（字符）代替。 4 String collapseFrom(CharSequence sequence, char replacement) 返回输入字符序列的字符串拷贝，每个组连续的字符匹配此匹配由单一的替换字符替换。 5 int countIn(CharSequence sequence) 返回一个字符序列中发现匹配的字符的数目。 6 static CharMatcher forPredicate(Predicate predicate) 返回与相同的行为给定的基于字符的谓词匹配，但运行在原始的字符，而不是实例。 7 int indexIn(CharSequence sequence) 返回第一个匹配字符的索引中的一个字符序列，或-1，如果没有匹配的字符存在。 8 int indexIn(CharSequence sequence, int start) 返回第一个匹配字符的索引中的一个字符序列，从给定位置开始，或-1，如果没有字符的位置之后匹配。 9 static CharMatcher inRange(char startInclusive, char endInclusive) 返回一个字符匹配匹配给定范围内的任何字符（两个端点也包括在内）。 10 static CharMatcher is(char match) 返回一个字符匹配匹配只有一个指定的字符。 11 static CharMatcher isNot(char match) 返回一个字符匹配匹配除了指定的任何字符。 12 int lastIndexIn(CharSequence sequence) 返回最后一个匹配字符的索引中的字符序列，或-1，如果没有匹配的字符存在。 13 abstract boolean matches(char c) 确定给定字符一个true或false值。 14 boolean matchesAllOf(CharSequence sequence) 确定给定字符一个true或false值。 15 boolean matchesAnyOf(CharSequence sequence) 返回true如果字符序列包含至少一个匹配的字符。 16 boolean matchesNoneOf(CharSequence sequence) 返回true，如果一个字符序列中没有匹配的字符。 17 CharMatcher negate() 返回一个匹配器，不受此匹配匹配任何字符。 18 static CharMatcher noneOf(CharSequence sequence) 返回一个字符匹配器匹配不存在于给定的字符序列的任何字符。 19 CharMatcher or(CharMatcher other) 返回一个匹配器，匹配任何匹配或其他任何字符。 20 CharMatcher precomputed() 返回一个字符匹配功能上等同于这一个，但它可能会快于原来的查询;您的里程可能会有所不同。 21 String removeFrom(CharSequence sequence) 返回包含的字符序列的所有非匹配的字符，为了一个字符串。 22 String replaceFrom(CharSequence sequence, char replacement) 返回输入字符序列的字符串副本，其中每个字符匹配该匹配器由一个给定的替换字符替换。 23 String replaceFrom(CharSequence sequence, CharSequence replacement) 返回输入字符序列的字符串副本，其中每个字符匹配该匹配器由一个给定的替换序列替换。 24 String retainFrom(CharSequence sequence) 返回包含的字符序列的所有字符匹配，为了一个字符串。 25 String toString() 返回此CharMatcher，如CharMatcher.or（WHITESPACE，JAVA_DIGIT）的字符串表示。 26 String trimAndCollapseFrom(CharSequence sequence, char replacement) 折叠匹配字符完全一样collapseFrom一组如collapseFrom(java.lang.CharSequence, char) 做的一样，不同之处在于，无需更换一组被移除的匹配字符在开始或该序列的结束。 27 String trimFrom(CharSequence sequence) 返回输入字符序列省略了所有匹配器从一开始，并从该串的末尾匹配字符的字符串。 28 String trimLeadingFrom(CharSequence sequence) 返回输入字符序列，它省略了所有这些匹配的字符串开始处匹配字符的字符串。 29 String trimTrailingFrom(CharSequence sequence) 返回输入字符序列，它省略了所有这些匹配的字符串的结尾匹配字符的字符串。 继承的方法​ 这个类继承了以下类方法： ​ java.lang.Object CharMatcher 例子​ 使用所选择的编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 123456789101112131415161718import com.google.common.base.CharMatcher;import com.google.common.base.Splitter;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testCharMatcher(); &#125; private void testCharMatcher()&#123; System.out.println(CharMatcher.DIGIT.retainFrom(\"mahesh123\")); // only the digits System.out.println(CharMatcher.WHITESPACE.trimAndCollapseFrom(\" Mahesh Parashar \", ' ')); // trim whitespace at ends, and replace/collapse whitespace into single spaces System.out.println(CharMatcher.JAVA_DIGIT.replaceFrom(\"mahesh123\", \"*\")); // star out all digits System.out.println(CharMatcher.JAVA_DIGIT.or(CharMatcher.JAVA_LOWER_CASE).retainFrom(\"mahesh123\")); // eliminate all characters that aren't digits or lowercase &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看看结果 1234123Mahesh Parasharmahesh***mahesh123 CaseFormatCaseFormat是一种实用工具类，以提供不同的ASCII字符格式之间的转换。 类声明​ 以下是com.google.common.base.CaseFormat类的声明： 123@GwtCompatiblepublic enum CaseFormat extends Enum&lt;CaseFormat&gt; 枚举常量 S.N. 枚举常量和说明 1 LOWER_CAMEL Java变量的命名规则，如“lowerCamel”。 2 LOWER_HYPHEN 连字符连接变量的命名规则，如“lower-hyphen”。 3 LOWER_UNDERSCORE C ++变量命名规则，如“lower_underscore”。 4 UPPER_CAMEL Java和C++类的命名规则，如“UpperCamel”。 5 UPPER_UNDERSCORE Java和C++常量的命名规则，如“UPPER_UNDERSCORE”。 方法 S.N. 方法及说明 1 Converter converterTo(CaseFormat targetFormat) 返回一个转换，从这个格式转换targetFormat字符串。 2 String to(CaseFormat format, String str) 从这一格式指定格式的指定字符串 str 转换。 3 static CaseFormat valueOf(String name) 返回此类型具有指定名称的枚举常量。 4 static CaseFormat[] values() 返回一个包含该枚举类型的常量数组中的顺序被声明。 继承的方法​ 这个类继承了以下类方法： ​ java.lang.Enum ​ java.lang.Object CaseFormat 示例​ 使用所选择的编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 123456789101112131415import com.google.common.base.CaseFormat;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testCaseFormat(); &#125; private void testCaseFormat()&#123; String data = \"test_data\"; System.out.println(CaseFormat.LOWER_HYPHEN.to(CaseFormat.LOWER_CAMEL, \"test-data\")); System.out.println(CaseFormat.LOWER_UNDERSCORE.to(CaseFormat.LOWER_CAMEL, \"test_data\")); System.out.println(CaseFormat.UPPER_UNDERSCORE.to(CaseFormat.UPPER_CAMEL, \"test_data\")); &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123testDatatestDataTestData BytesBytes是byte的基本类型实用工具类。 类声明​ 以下是com.google.common.primitives.Bytes类的声明： 123@GwtCompatiblepublic final class Bytes extends Object 方法： S.N. 方法及说明 1 static List asList(byte… backingArray) 返回由指定数组支持的固定大小的列表，类似 Arrays.asList(Object[]). 2 static byte[] concat(byte[]… arrays) 则返回来自每个阵列提供组合成一个单一的阵列值。 3 static boolean contains(byte[] array, byte target) 返回true，如果目标是否存在在任何地方数组元素。 4 static byte[] ensureCapacity(byte[] array, int minLength, int padding) 返回一个包含相同的值数组的数组，但保证是一个规定的最小长度。 5 static int hashCode(byte value) 返回哈希码的值;等于调用的结果 ((Byte) value).hashCode(). 6 static int indexOf(byte[] array, byte target) 返回目标数组的首次出现的索引值。 7 static int indexOf(byte[] array, byte[] target) 返回指定目标的第一个匹配的起始位置数组内，或-1如果不存在。 8 static int lastIndexOf(byte[] array, byte target) 返回目标在数组中最后一个出场的索引的值。 9 static byte[] toArray(Collection collection) 返回包含集合的每个值的数组，转换为字节值中的方式Number.byteValue(). 继承的方法​ 这个类继承了以下类方法： ​ java.lang.Object Bytes 示例​ 使用所选择的编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 12345678910111213141516171819202122232425262728293031323334import java.util.List;import com.google.common.primitives.Bytes;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testBytes(); &#125; private void testBytes()&#123; byte[] byteArray = &#123;1,2,3,4,5,5,7,9,9&#125;; //convert array of primitives to array of objects List&lt;Byte&gt; objectArray = Bytes.asList(byteArray); System.out.println(objectArray.toString()); //convert array of objects to array of primitives byteArray = Bytes.toArray(objectArray); System.out.print(\"[ \"); for(int i = 0; i&lt; byteArray.length ; i++)&#123; System.out.print(byteArray[i] + \" \"); &#125; System.out.println(\"]\"); byte data = 5; //check if element is present in the list of primitives or not System.out.println(\"5 is in list? \"+ Bytes.contains(byteArray, data)); //Returns the index System.out.println(\"Index of 5: \" + Bytes.indexOf(byteArray,data)); //Returns the last index maximum System.out.println(\"Last index of 5: \" + Bytes.lastIndexOf(byteArray,data)); &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 12345[1, 2, 3, 4, 5, 5, 7, 9, 9][ 1 2 3 4 5 5 7 9 9 ]5 is in list? trueIndex of 5: 4Last index of 5: 5 ShortsShorts是基本类型short的实用工具类。 类声明​ 以下是com.google.common.primitives.Shorts类的声明： 123@GwtCompatiblepublic final class Shorts extends Object 字段 S.N. 字段及说明 1 static int BYTES 所需要的字节数来表示一个原始short的值。 2 static short MAX_POWER_OF_TWO 两个最大的幂可以被表示为short。 方法 S.N. 方法及说明 1 static List asList(short… backingArray) 返回由指定数组支持的固定大小的列表，类似 Arrays.asList(Object[]). 2 static short checkedCast(long value) 返回 short 值，该值等于value，如果可能的话。 3 static int compare(short a, short b) 比较两个指定的short值。 4 static short[] concat(short[]… arrays) 每个阵列提供组合成一个单一的阵列，则返回其值。 5 static boolean contains(short[] array, short target) 返回true，如果目标是否存在在任何地方数组元素。 6 static short[] ensureCapacity(short[] array, int minLength, int padding) 返回一个包含相同的值数组的数组，但保证是一个规定的最小长度。 7 static short fromByteArray(byte[] bytes) 返回短值，其大端表示被存储在最前2字节的字节;相当于 ByteBuffer.wrap(bytes).getShort(). 8 static short fromBytes(byte b1, byte b2) 返回short值的字节表示的是给定2个字节，以 big-endian 顺序; 相当于 Shorts.fromByteArray(new byte[] {b1, b2}). 9 static int hashCode(short value) 返回值的哈希码;等于调用的结果 ((Short) value).hashCode(). 10 static int indexOf(short[] array, short target) 返回值目标数组的首次出现的索引。 11 static int indexOf(short[] array, short[] target) 返回指定目标的第一个匹配的起始位置数组或-1，如果不存在这样的发生。 12 static String join(String separator, short… array) 返回包含由分离器分离所提供的短值的字符串。 13 static int lastIndexOf(short[] array, short target) 返回目标在数组中最后一个出现的索引的值。 14 static Comparator lexicographicalComparator() 返回一个比较，比较两个 short 阵列字典顺序。 15 static short max(short… array) 返回出现在数组中的最大值。 16 static short min(short… array) 返回出现在数组的最小值。 17 static short saturatedCast(long value) 返回short最接近int的值。 18 static Converter stringConverter() 返回使用字符串和shorts之间的一个转换器序列化对象 Short.decode(java.lang.String) and Short.toString(). 19 static short[] toArray(Collection collection) 返回包含集合的每个值的数组，转换为 short 值的方式Number.shortValue(). 20 static byte[] toByteArray(short value) 返回在2元素的字节数组值大尾数法表示;相当于 ByteBuffer.allocate(2).putShort(value).array(). 继承的方法​ 这个类继承了以下类方法： ​ java.lang.Object Shorts 示例​ 使用所选择的编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.List;import com.google.common.primitives.Shorts;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testShorts(); &#125; private void testShorts()&#123; short[] shortArray = &#123;1,2,3,4,5,6,7,8,9&#125;; //convert array of primitives to array of objects List&lt;Short&gt; objectArray = Shorts.asList(shortArray); System.out.println(objectArray.toString()); //convert array of objects to array of primitives shortArray = Shorts.toArray(objectArray); System.out.print(\"[ \"); for(int i = 0; i&lt; shortArray.length ; i++)&#123; System.out.print(shortArray[i] + \" \"); &#125; System.out.println(\"]\"); short data = 5; //check if element is present in the list of primitives or not System.out.println(\"5 is in list? \"+ Shorts.contains(shortArray, data)); //Returns the minimum System.out.println(\"Min: \" + Shorts.min(shortArray)); //Returns the maximum System.out.println(\"Max: \" + Shorts.max(shortArray)); data = 2400; //get the byte array from an integer byte[] byteArray = Shorts.toByteArray(data); for(int i = 0; i&lt; byteArray.length ; i++)&#123; System.out.print(byteArray[i] + \" \"); &#125; &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123456[1, 2, 3, 4, 5, 6, 7, 8, 9][ 1 2 3 4 5 6 7 8 9 ]5 is in list? trueMin: 1Max: 99 96 Ints整数Ints是原始的int类型的实用工具类。 类声明​ 以下是com.google.common.primitives.Ints类的声明： 123@GwtCompatiblepublic final class Ints extends Object 字段 S.N. 字段及说明 1 static int BYTES 所需要的字节数来表示一个原始int值。 2 static int MAX_POWER_OF_TWO 两个最大的幂可以被表示为整数。 方法 S.N. 方法及说明 1 static List asList(int… backingArray) 返回由指定数组支持的固定大小的列表，类似Arrays.asList(Object[]). 2 static int checkedCast(long value) 返回int值等于值，如果可能的话。 3 static int compare(int a, int b) 比较两个指定的int值。 4 static int[] concat(int[]… arrays) 每个阵列提供组合成一个单一的阵列，则返回值。 5 static boolean contains(int[] array, int target) 返回true，如果target是否存在在任何地方数组元素。 6 static int[] ensureCapacity(int[] array, int minLength, int padding) 返回一个包含相同的值数组的数组，但保证是一个规定的最小长度。 7 static int fromByteArray(byte[] bytes) 返回int值，其大端表示存储在第一个4字节的字节;相当于ByteBuffer.wrap(bytes).getInt(). 8 static int fromBytes(byte b1, byte b2, byte b3, byte b4) 返回int值的字节表示的是给定的4个字节，在big-endian的顺序;相当于 Ints.fromByteArray(new byte[] {b1, b2, b3, b4}). 9 static int hashCode(int value) 返回值的哈希码; 等于调用 ((Integer) value).hashCode() 的结果 10 static int indexOf(int[] array, int target) 返回值目标数组的第一次亮相的索引。 11 static int indexOf(int[] array, int[] target) 返回指定目标的第一个匹配的起始位置数组内，或-1，如果不存在。 12 static String join(String separator, int… array) 返回包含由分离器分离所提供的整型值的字符串。 13 static int lastIndexOf(int[] array, int target) 返回target 在数组中最后一个出场的索引值。 14 static Comparator lexicographicalComparator() 返回一个比较，比较两个int数组字典顺序。 15 static int max(int… array) 返回出现在数组中的最大值。 16 static int min(int… array) 返回最小值出现在数组。 17 static int saturatedCast(long value) 返回最接近的int值。 18 static Converter stringConverter() 返回使用字符串和整数之间的一个转换器序列化对象 Integer.decode(java.lang.String) 和 Integer.toString(). 19 static int[] toArray(Collection collection) 返回包含集合的每个值的数组，转换为int值的方式Number.intValue(). 20 static byte[] toByteArray(int value) 返回一个4元素的字节数组值大端表示;相当于 ByteBuffer.allocate(4).putInt(value).array(). 21 static Integer tryParse(String string) 解析指定的字符串作为符号十进制整数。 继承的方法​ 这个类继承了以下类方法： ​ java.lang.Object Ints 示例​ 使用所选择的任何编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.List;import com.google.common.primitives.Ints;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testInts(); &#125; private void testInts()&#123; int[] intArray = &#123;1,2,3,4,5,6,7,8,9&#125;; //convert array of primitives to array of objects List&lt;Integer&gt; objectArray = Ints.asList(intArray); System.out.println(objectArray.toString()); //convert array of objects to array of primitives intArray = Ints.toArray(objectArray); System.out.print(\"[ \"); for(int i = 0; i&lt; intArray.length ; i++)&#123; System.out.print(intArray[i] + \" \"); &#125; System.out.println(\"]\"); //check if element is present in the list of primitives or not System.out.println(\"5 is in list? \"+ Ints.contains(intArray, 5)); //Returns the minimum System.out.println(\"Min: \" + Ints.min(intArray)); //Returns the maximum System.out.println(\"Max: \" + Ints.max(intArray)); //get the byte array from an integer byte[] byteArray = Ints.toByteArray(20000); for(int i = 0; i&lt; byteArray.length ; i++)&#123; System.out.print(byteArray[i] + \" \"); &#125; &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123456[1, 2, 3, 4, 5, 6, 7, 8, 9][ 1 2 3 4 5 6 7 8 9 ]5 is in list? trueMin: 1Max: 90 0 78 32 LongsLongs是基本类型long的实用工具类。 类声明​ 以下是com.google.common.primitives.Longs类的声明： 123@GwtCompatiblepublic final class Longs extends Object 字段 S.N. 字段及说明 1 static int BYTES 所需要的字节数来表示一个原始long 值。 2 static long MAX_POWER_OF_TWO 两个最大幂可以被表示为一个long。 方法 S.N. 方法及说明 1 static List asList(long… backingArray) 返回由指定数组支持的固定大小的列表，类似Arrays.asList(Object[]). 2 static int compare(long a, long b) 比较两个指定数的long值。 3 static long[] concat(long[]… arrays) 每个数组提供组合成一个单一的数组，则返回值。 4 static boolean contains(long[] array, long target) 返回true，如果target是否存在在任何地方数组元素。 5 static long[] ensureCapacity(long[] array, int minLength, int padding) 返回一个包含相同的值数组的数组，但保证是一个规定的最小长度。 6 static long fromByteArray(byte[] bytes) 返回long值，其大端表示存储在头8个字节的字节;相当于ByteBuffer.wrap(bytes).getLong(). 7 static long fromBytes(byte b1, byte b2, byte b3, byte b4, byte b5, byte b6, byte b7, byte b8) 返回long值，字节表示的是给定的8个字节，在big-endian的顺序;相当于 Longs.fromByteArray(new byte[] {b1, b2, b3, b4, b5, b6, b7, b8}). 8 static int hashCode(long value) 返回哈希码的值;等于调用 ((Long) value).hashCode() 的结果 9 static int indexOf(long[] array, long target) 返回目标数组的首次出现的索引值。 10 static int indexOf(long[] array, long[] target) 返回指定目标的第一个匹配的起始位置数组内，或-1，如果不存在。 11 static String join(String separator, long… array) 返回包含由分离器分离所提供long 的字符串值。 12 static int lastIndexOf(long[] array, long target) 返回target 在数组中最后一个出场的索引值。 13 static Comparator lexicographicalComparator() 返回一个比较，比较两个long数组字典顺序。 14 static long max(long… array) 返回出现在数组中的最大值。 15 static long min(long… array) 返回最小值出现在数组。 16 static Converter stringConverter() 返回使用字符串和长整型之间的转换可序列化器对象Long.decode(java.lang.String) 和 Long.toString(). 17 static long[] toArray(Collection collection) 返回包含集合的每个值的数组，转换为一个long值的方式Number.longValue(). 18 static byte[] toByteArray(long value) 返回字节数组值大端在8元素的表示;相当于 ByteBuffer.allocate(8).putLong(value).array(). 19 static Long tryParse(String string) Parses the specified string as a signed decimal long value. 继承的方法​ 这个类继承了以下类方法： ​ java.lang.Object Longs 示例​ 使用所选择的任何编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.List;import com.google.common.primitives.Ints;import com.google.common.primitives.Longs;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testLongs(); &#125; private void testLongs()&#123; long[] longArray = &#123;1,2,3,4,5,6,7,8,9&#125;; //convert array of primitives to array of objects List&lt;Long&gt; objectArray = Longs.asList(longArray); System.out.println(objectArray.toString()); //convert array of objects to array of primitives longArray = Longs.toArray(objectArray); System.out.print(\"[ \"); for(int i = 0; i&lt; longArray.length ; i++)&#123; System.out.print(longArray[i] + \" \"); &#125; System.out.println(\"]\"); //check if element is present in the list of primitives or not System.out.println(\"5 is in list? \"+ Longs.contains(longArray, 5)); //Returns the minimum System.out.println(\"Min: \" + Longs.min(longArray)); //Returns the maximum System.out.println(\"Max: \" + Longs.max(longArray)); //get the byte array from an integer byte[] byteArray = Longs.toByteArray(20000); for(int i = 0; i&lt; byteArray.length ; i++)&#123; System.out.print(byteArray[i] + \" \"); &#125; &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123456[1, 2, 3, 4, 5, 6, 7, 8, 9][ 1 2 3 4 5 6 7 8 9 ]5 is in list? trueMin: 1Max: 90 0 0 0 0 0 78 32 FloatsFloats是float基本类型的实用工具类。 类声明​ 以下是com.google.common.primitives.Floats类的声明： 123@GwtCompatible(emulated=true) public final class Floats extends Object 字体 S.N. 字段及说明 1 static int BYTES 所需要的字节数来表示一个原始浮点值。 方法 S.N. 方法及说明 1 static List asList(float… backingArray) 返回由指定数组支持的固定大小的列表，类似 Arrays.asList(Object[]). 2 static int compare(float a, float b) 通过比较两个指定的浮点值 Float.compare(float, float). 3 static float[] concat(float[]… arrays) 每个数组提供组合成一个单一的数组，则返回值。 4 static boolean contains(float[] array, float target) 返回true，如果target是否存在在任何地方数组元素。 5 static float[] ensureCapacity(float[] array, int minLength, int padding) 返回一个包含相同的值数组的数组，但保证是一个规定的最小长度。 6 static int hashCode(float value) 返回哈希码的值;等于调用的结果 ((Float) value).hashCode(). 7 static int indexOf(float[] array, float target) 返回目标数组的首次出现的索引值。 8 static int indexOf(float[] array, float[] target) 返回指定目标的第一个匹配的起始位置数组内，或-1，如果不存在。 9 static boolean isFinite(float value) 返回true，如果值代表一个实数。 10 static String join(String separator, float… array) 返回包含所提供的浮点值，所指定的Float.toString(float)，并通过分离器分离转换为字符串的字符串。 11 static int lastIndexOf(float[] array, float target) 返回target 在数组中最后一个出场的索引值。 12 static Comparator lexicographicalComparator() 返回一个比较，比较两个浮点阵列字典顺序。 13 static float max(float… array) 返回存在于数组的最大值，使用比较为相同的规则 Math.min(float, float). 14 static float min(float… array) 返回存在于数组的最小值，使用比较为相同的规则 Math.min(float, float). 15 static Converter stringConverter() 返回使用字符串和浮点数之间的一个转换器序列化对象 Float.valueOf(java.lang.String) 和 Float.toString(). 16 static float[] toArray(Collection collection) 返回一个包含集合中的每个值的数组，转换为浮点值的方式Number.floatValue(). 17 static Float tryParse(String string) 解析指定的字符串作为单精度浮点值。 继承的方法​ 这个类继承了以下类方法： ​ java.lang.Object Floats 示例​ 使用所选择的任何编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 1234567891011121314151617181920212223242526272829303132333435363738import java.util.List;import com.google.common.primitives.Floats;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testFloats(); &#125; private void testFloats()&#123; float[] floatArray = &#123;1.0f,2.0f,3.0f,4.0f,5.0f,6.0f,7.0f,8.0f,9.0f&#125;; //convert array of primitives to array of objects List&lt;Float&gt; objectArray = Floats.asList(floatArray); System.out.println(objectArray.toString()); //convert array of objects to array of primitives floatArray = Floats.toArray(objectArray); System.out.print(\"[ \"); for(int i = 0; i&lt; floatArray.length ; i++)&#123; System.out.print(floatArray[i] + \" \"); &#125; System.out.println(\"]\"); //check if element is present in the list of primitives or not System.out.println(\"5.0 is in list? \"+ Floats.contains(floatArray, 5.0f)); //return the index of element System.out.println(\"5.0 position in list \"+ Floats.indexOf(floatArray, 5.0f)); //Returns the minimum System.out.println(\"Min: \" + Floats.min(floatArray)); //Returns the maximum System.out.println(\"Max: \" + Floats.max(floatArray)); &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123456[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0][ 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 ]5.0 is in list? true5.0 position in list 4Min: 1.0Max: 9.0 DoublesDoubles是double基本类型的实用工具类。 类声明​ 以下是com.google.common.primitives.Doubles类的声明： 123@GwtCompatible(emulated=true) public final class Doubles extends Object 字段 S.N. 字段及说明 1 static int BYTES 所需要的字节数来表示基本的double值。 方法 S.N. 方法及说明 1 static List asList(double… backingArray) 返回由指定数组支持的固定大小的列表，类似 Arrays.asList(Object[]). 2 static int compare(double a, double b) 比较两个指定的double值。 3 static double[] concat(double[]… arrays) 每个数组提供组合成一个单一的数组，则返回值。 4 static boolean contains(double[] array, double target) 返回true，如果target是否存在在任何地方数组元素。 5 static double[] ensureCapacity(double[] array, int minLength, int padding) 返回一个包含相同的值数组的数组，但保证是一个规定的最小长度。 6 static int hashCode(double value) 返回哈希码的值;等于调用 ((Double) value).hashCode() 的结果. 7 static int indexOf(double[] array, double target) 返回目标数组的首次出现的索引值。 8 static int indexOf(double[] array, double[] target) 返回指定目标的第一个匹配的起始位置数组内，或-1，如果不存在。 9 static boolean isFinite(double value) 返回true，如果值代表一个实数。 10 static String join(String separator, double… array) 返回包含所提供的double 值的字符串，所指定的转换为字符串 Double.toString(double), 及相隔分离。 11 static int lastIndexOf(double[] array, double target) 返回target 在数组中最后一个出现的索引值。 12 static Comparator lexicographicalComparator() 返回一个比较，比较两个double阵列字典顺序。 13 static double max(double… array) 返回存在于数组的最大值，使用比较为相同的规则 Math.max(double, double). 14 static double min(double… array) 返回存在于数组的最小值，使用比较为相同的规则 Math.min(double, double). 15 static Converter stringConverter() 返回字符串转换之间和double采用序列化器对象 Double.valueOf(java.lang.String) and Double.toString(). 16 static double[] toArray(Collection collection) 返回一个包含集合中的每个值的数组，转换为double值的方式Number.doubleValue(). 17 static Double tryParse(String string) 解析指定的字符串作为一个双精度浮点值。 方法继承​ 这个类继承了以下类方法： ​ java.lang.Object Doubles 示例​ 使用所选择的任何编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 1234567891011121314151617181920212223242526272829303132333435363738import java.util.List;import com.google.common.primitives.Doubles;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testDoubles(); &#125; private void testDoubles()&#123; double[] doubleArray = &#123;1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0&#125;; //convert array of primitives to array of objects List&lt;Double&gt; objectArray = Doubles.asList(doubleArray); System.out.println(objectArray.toString()); //convert array of objects to array of primitives doubleArray = Doubles.toArray(objectArray); System.out.print(\"[ \"); for(int i = 0; i&lt; doubleArray.length ; i++)&#123; System.out.print(doubleArray[i] + \" \"); &#125; System.out.println(\"]\"); //check if element is present in the list of primitives or not System.out.println(\"5.0 is in list? \"+ Doubles.contains(doubleArray, 5.0f)); //return the index of element System.out.println(\"5.0 position in list \"+ Doubles.indexOf(doubleArray, 5.0f)); //Returns the minimum System.out.println(\"Min: \" + Doubles.min(doubleArray)); //Returns the maximum System.out.println(\"Max: \" + Doubles.max(doubleArray)); &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123456[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0][ 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 ]5.0 is in list? true5.0 position in list 4Min: 1.0Max: 9.0 CharsChars是基本char类型的实用工具类。 类声明​ 以下是com.google.common.primitives.Chars类的声明： 123@GwtCompatible(emulated=true) public final class Chars extends Object 字段 S.N. 字段及说明 1 static int BYTES 所需要的字节数来表示一个原始char值。 方法 S.N. 方法及说明 1 static List asList(char… backingArray) 返回由指定数组支持的固定大小的列表，类似 Arrays.asList(Object[]). 2 static char checkedCast(long value) 返回char值等于value值，如果可能的话。 3 static int compare(char a, char b) 比较两个指定的char值。 4 static char[] concat(char[]… arrays) 每个数组提供组合成一个单一的数组，则返回值。 5 static boolean contains(char[] array, char target) 返回true，如果target是否存在在任何地方数组元素。 6 static char[] ensureCapacity(char[] array, int minLength, int padding) 返回一个包含相同的值数组的数组，但保证是一个规定的最小长度。 7 static char fromByteArray(byte[] bytes) 返回char值，其大端表示被存储在第一个2字节的字节;相当于 ByteBuffer.wrap(bytes).getChar(). 8 static char fromBytes(byte b1, byte b2) 返回char值的字节表示是给定2个字节，在big-endian的顺序;相当于 Chars.fromByteArray(new byte[] {b1, b2}). 9 static int hashCode(char value) 返回哈希码的值;等于调用的结果 ((Character) value).hashCode(). 10 static int indexOf(char[] array, char target) 返回目标数组的首次出现的索引值。 11 static int indexOf(char[] array, char[] target) 返回指定目标的第一个匹配的起始位置数组内，或-1，如果不存在。 12 static String join(String separator, char… array) 返回包含由分离器分离所提供的char值字符串。 13 static int lastIndexOf(char[] array, char target) 返回target 在数组中最后一个出现的索引值。 14 static Comparator lexicographicalComparator() 返回一个比较器，它比较两个字符数组字典顺序。 15 static char max(char… array) 返回在数组中的最大值。 16 static char min(char… array) 返回出现在数组最小值。 17 static char saturatedCast(long value) 返回值char最近的值。 18 static char[] toArray(Collection collection) 复制字符实例的集合到原始char值的新数组。 19 static byte[] toByteArray(char value) 返回在2元素的字节数组值大端表示;相当于 ByteBuffer.allocate(2).putChar(value).array(). 方法继承​ 这个类从以下类继承的方法： ​ java.lang.Object Chars 例子​ 选择使用任何编辑器创建以下java程序在 C:/&gt; Guava GuavaTester.java 123456789101112131415161718192021222324252627282930313233343536import java.util.List;import com.google.common.primitives.Chars;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testChars(); &#125; private void testChars()&#123; char[] charArray = &#123;'a','b','c','d','e','f','g','h'&#125;; //convert array of primitives to array of objects List&lt;Character&gt; objectArray = Chars.asList(charArray); System.out.println(objectArray.toString()); //convert array of objects to array of primitives charArray = Chars.toArray(objectArray); System.out.print(\"[ \"); for(int i = 0; i&lt; charArray.length ; i++)&#123; System.out.print(charArray[i] + \" \"); &#125; System.out.println(\"]\"); //check if element is present in the list of primitives or not System.out.println(\"c is in list? \"+ Chars.contains(charArray, 'c')); //return the index of element System.out.println(\"c position in list \"+ Chars.indexOf(charArray, 'c')); //Returns the minimum System.out.println(\"Min: \" + Chars.min(charArray)); //Returns the maximum System.out.println(\"Max: \" + Chars.max(charArray)); &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123456[a, b, c, d, e, f, g, h][ a b c d e f g h ]c is in list? truec position in list 2Min: aMax: h BooleansBooleans是布尔型基本的实用工具类。 类声明​ 以下是com.google.common.primitives.Booleans类的声明： 123@GwtCompatible(emulated=true) public final class Booleans extends Object 方法 S.N. 方法及说明 1 static List asList(boolean… backingArray) 返回由指定数组支持的固定大小的列表，类似 Arrays.asList(Object[]). 2 static int compare(boolean a, boolean b) 比较两个指定的布尔值的标准方式(假的比真的少考虑以下)。 3 static boolean[] concat(boolean[]… arrays) 每个数组提供组合成一个单一的数组，则值返回。 4 static boolean contains(boolean[] array, boolean target) 返回true，如果target存在在任何地方数组元素。 5 static int countTrue(boolean… values) 返回为true值的数目。 6 static boolean[] ensureCapacity(boolean[] array, int minLength, int padding) 返回一个包含相同的值数组的数组，但保证是一个规定的最小长度。 7 static int hashCode(boolean value) 返回哈希码的值;等于调用的结果 ((Boolean) value).hashCode(). 8 static int indexOf(boolean[] array, boolean target) 返回目标数组的首次出现的索引值。 9 static int indexOf(boolean[] array, boolean[] target) 返回指定目标的第一个匹配的起始位置数组内，或-1，如果不存在。 10 static String join(String separator, boolean… array) 返回包含由分离器分离所提供的布尔值的字符串。 11 static int lastIndexOf(boolean[] array, boolean target) 返回target 在数组中最后一个出现的索引值。 12 static Comparator lexicographicalComparator() 返回一个比较器，它比较两个布尔数组字典顺序。 13 static boolean[] toArray(Collection collection) 复制Boolean实例集合到原始的布尔值的新数组。 方法继承​ 这个类继承了以下类方法： ​ java.lang.Object Booleans 示例​ 使用所选择的任何编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 123456789101112131415161718192021222324252627282930313233343536373839import java.util.List;import com.google.common.primitives.Booleans;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testBooleans(); &#125; private void testBooleans()&#123; boolean[] booleanArray = &#123;true,true,false,true,true,false,false&#125;; //convert array of primitives to array of objects List&lt;Boolean&gt; objectArray = Booleans.asList(booleanArray); System.out.println(objectArray.toString()); //convert array of objects to array of primitives booleanArray = Booleans.toArray(objectArray); System.out.print(\"[ \"); for(int i = 0; i&lt; booleanArray.length ; i++)&#123; System.out.print(booleanArray[i] + \" \"); &#125; System.out.println(\"]\"); //check if element is present in the list of primitives or not System.out.println(\"true is in list? \"+ Booleans.contains(booleanArray, true)); //return the first index of element System.out.println(\"true position in list \"+ Booleans.indexOf(booleanArray, true)); //Returns the count of true values System.out.println(\"true occured: \" + Booleans.countTrue()); //Returns the comparisons System.out.println(\"false Vs true: \" + Booleans.compare(false, true)); System.out.println(\"false Vs false: \" + Booleans.compare(false, false)); System.out.println(\"true Vs false: \" + Booleans.compare(true, false)); System.out.println(\"true Vs true: \" + Booleans.compare(true, true)); &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123456789[true, true, false, true, true, false, false][ true true false true true false false ]true is in list? truetrue position in list 0true occured: 0false Vs true: -1false Vs false: 0true Vs false: 1true Vs true: 0 IntMathIntMath提供整型的实用方法。 类声明​ 以下是com.google.common.math.IntMath类的声明： 123@GwtCompatible(emulated=true)public final class IntMath extends Object 方法 S.N. 方法及说明 1 static int binomial(int n, int k) 返回n个选择K，也被称为n和k，或Integer.MAX_VALUE的二项式系数，如果结果在一个int不适合。 2 static int checkedAdd(int a, int b) 返回a和b的总和，只要它不会溢出。 3 static int checkedMultiply(int a, int b) 返回a和b的产物，只要它不会溢出。 4 static int checkedPow(int b, int k) 返回b的第k幂，只要它不会溢出。 5 static int checkedSubtract(int a, int b) 返回a和b的差，只要它不会溢出。 6 static int divide(int p, int q, RoundingMode mode) 返回除以p由q，使用指定RoundingMode的四舍五入结果。 7 static int factorial(int n) 返回n个！，也就是说，前n个正整数的乘积，如果n==0则返回1，或者是Integer.MAX_VALUE如果结果不适合在一个int值。 8 static int gcd(int a, int b) 返回a, b的最大公约数。 9 static boolean isPowerOfTwo(int x) 返回true，如果x代表两个幂。 10 static int log10(int x, RoundingMode mode) 返回基数为10的对数x，根据指定的舍入模式圆形。 11 static int log2(int x, RoundingMode mode) 返回基数为2-对数x，根据指定的舍入模式圆形。 12 static int mean(int x, int y) 返回x和y的算术平均值，取整。 13 static int mod(int x, int m) 返回x模m，一个非负的值小于m以下。 14 static int pow(int b, int k) 返回b的第k幂。 15 static int sqrt(int x, RoundingMode mode) 返回x的平方根，大概指定的舍入模式。 方法继承​ 这个类从以下类继承的方法： ​ java.lang.Object IntMath 例子​ 选择使用任何编辑器创建以下java程序在 C:/&gt; Guava GuavaTester.java 123456789101112131415161718192021222324252627282930313233343536373839import java.math.RoundingMode;import com.google.common.math.IntMath;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testIntMath(); &#125; private void testIntMath()&#123; try&#123; System.out.println(IntMath.checkedAdd(Integer.MAX_VALUE, Integer.MAX_VALUE)); &#125;catch(ArithmeticException e)&#123; System.out.println(\"Error: \" + e.getMessage()); &#125; System.out.println(IntMath.divide(100, 5, RoundingMode.UNNECESSARY)); try&#123; //exception will be thrown as 100 is not completely divisible by 3 thus rounding // is required, and RoundingMode is set as UNNESSARY System.out.println(IntMath.divide(100, 3, RoundingMode.UNNECESSARY)); &#125;catch(ArithmeticException e)&#123; System.out.println(\"Error: \" + e.getMessage()); &#125; System.out.println(\"Log2(2): \"+IntMath.log2(2, RoundingMode.HALF_EVEN)); System.out.println(\"Log10(10): \"+IntMath.log10(10, RoundingMode.HALF_EVEN)); System.out.println(\"sqrt(100): \"+IntMath.sqrt(IntMath.pow(10,2), RoundingMode.HALF_EVEN)); System.out.println(\"gcd(100,50): \"+IntMath.gcd(100,50)); System.out.println(\"modulus(100,50): \"+IntMath.mod(100,50)); System.out.println(\"factorial(5): \"+IntMath.factorial(5)); &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123456789Error: overflow20Error: mode was UNNECESSARY, but rounding was necessaryLog2(2): 1Log10(10): 1sqrt(100): 10gcd(100,50): 50modulus(100,50): 0factorial(5): 120 LongMathLongMath提供long基础类型的实用方法。 类声明​ 以下是com.google.common.math.LongMath类的声明： 123@GwtCompatible(emulated=true)public final class LongMath extends Object 方法 S.N. 方法及说明 1 static long binomial(int n, int k) 返回n个选择K，也称为n和k，或为Long.MAX_VALUE的二项式系数，如果long结果不相符。 1 static long checkedAdd(long a, long b) 返回a和b的总和，只要它不会溢出。 2 static long checkedMultiply(long a, long b) 返回a和b的产物，只要它不会溢出。 3 static long checkedPow(long b, int k) 返回b的第k幂，只要它不会溢出。 4 static long checkedSubtract(long a, long b) 返回a和b的差，只要它不会溢出。 5 static long divide(long p, long q, RoundingMode mode) 返回除以p由q，使用指定的RoundingMode四舍五入的结果。 6 static long factorial(int n) 返回n！，也就是说，前n个正整数的乘积，如果n==则返回1，或为Long.MAX_VALUE如果结果long不相符。 7 static long gcd(long a, long b) 返回a, b的最大公约数。 8 static boolean isPowerOfTwo(long x) 返回true，如果x代表两个幂。 9 static int log10(long x, RoundingMode mode) 返回基数为10的对数x，根据指定的舍入模式圆形。 10 static int log2(long x, RoundingMode mode) 返回基数为2-对数x，根据指定的舍入模式圆形。 11 static long mean(long x, long y) 返回x和y的算术平均值，四舍五入向负无穷大。 12 static int mod(long x, int m) 返回x模m，一个非负的值小于m以下。 13 static long mod(long x, long m) 返回x模m，一个非负的值小于m以下。 14 static long pow(long b, int k) 返回b为第k幂。 15 static long sqrt(long x, RoundingMode mode) 返回x的平方根，大概指定的舍入模式。 方法继承​ 这个类继承了以下类方法： ​ java.lang.Object LongMath 示例​ 使用所选择的任何编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 123456789101112131415161718192021222324252627282930313233343536373839import java.math.RoundingMode;import com.google.common.math.LongMath;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testLongMath(); &#125; private void testLongMath()&#123; try&#123; System.out.println(LongMath.checkedAdd(Long.MAX_VALUE, Long.MAX_VALUE)); &#125;catch(ArithmeticException e)&#123; System.out.println(\"Error: \" + e.getMessage()); &#125; System.out.println(LongMath.divide(100, 5, RoundingMode.UNNECESSARY)); try&#123; //exception will be thrown as 100 is not completely divisible by 3 thus rounding // is required, and RoundingMode is set as UNNESSARY System.out.println(LongMath.divide(100, 3, RoundingMode.UNNECESSARY)); &#125;catch(ArithmeticException e)&#123; System.out.println(\"Error: \" + e.getMessage()); &#125; System.out.println(\"Log2(2): \"+LongMath.log2(2, RoundingMode.HALF_EVEN)); System.out.println(\"Log10(10): \"+LongMath.log10(10, RoundingMode.HALF_EVEN)); System.out.println(\"sqrt(100): \"+LongMath.sqrt(LongMath.pow(10,2), RoundingMode.HALF_EVEN)); System.out.println(\"gcd(100,50): \"+LongMath.gcd(100,50)); System.out.println(\"modulus(100,50): \"+LongMath.mod(100,50)); System.out.println(\"factorial(5): \"+LongMath.factorial(5)); &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 123456789Error: overflow20Error: mode was UNNECESSARY, but rounding was necessaryLog2(2): 1Log10(10): 1sqrt(100): 10gcd(100,50): 50modulus(100,50): 0factorial(5): 120 BigIntegerMathBigIntegerMath提供BigInteger的实用方法。 类声明​ 以下是com.google.common.math.BigIntegerMath类的声明： 123@GwtCompatible(emulated=true)public final class BigIntegerMath extends Object 方法 S.N. 方法及说明 1 static BigInteger binomial(int n, int k) 返回n选择k，也被称为n和k的二项式系数，即n! / (k! (n - k)!)。 2 static BigInteger divide(BigInteger p, BigInteger q, RoundingMode mode) 返回除以p由q，使用指定的RoundingMode四舍五入的结果。 3 static BigInteger factorial(int n) 返回n个！，即，在第一n个正整数的乘积，或1如果n== 0。 4 static boolean isPowerOfTwo(BigInteger x) 返回true，如果x代表两个幂。 5 static int log10(BigInteger x, RoundingMode mode) 返回基数为10的对数x，根据指定的舍入模式范围。 6 static int log2(BigInteger x, RoundingMode mode) 返回基数为2-对数x，根据指定的舍入模式圆形。 7 static BigInteger sqrt(BigInteger x, RoundingMode mode) 返回x的平方根，大概指定的舍入模式。 继承的方法​ 这个类继承了以下类方法： ​ java.lang.Object BigIntegerMath 示例​ 使用所选择的任何编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 123456789101112131415161718192021222324252627282930import java.math.BigInteger;import java.math.RoundingMode;import com.google.common.math.BigIntegerMath;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); tester.testBigIntegerMath(); &#125; private void testBigIntegerMath()&#123; System.out.println(BigIntegerMath.divide(BigInteger.TEN, new BigInteger(\"2\"), RoundingMode.UNNECESSARY)); try&#123; //exception will be thrown as 100 is not completely divisible by 3 thus rounding // is required, and RoundingMode is set as UNNESSARY System.out.println(BigIntegerMath.divide(BigInteger.TEN, new BigInteger(\"3\"), RoundingMode.UNNECESSARY)); &#125;catch(ArithmeticException e)&#123; System.out.println(\"Error: \" + e.getMessage()); &#125; System.out.println(\"Log2(2): \"+BigIntegerMath.log2(new BigInteger(\"2\"), RoundingMode.HALF_EVEN)); System.out.println(\"Log10(10): \"+BigIntegerMath.log10(BigInteger.TEN, RoundingMode.HALF_EVEN)); System.out.println(\"sqrt(100): \"+BigIntegerMath.sqrt(BigInteger.TEN.multiply(BigInteger.TEN), RoundingMode.HALF_EVEN)); System.out.println(\"factorial(5): \"+BigIntegerMath.factorial(5)); &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 1234565Error: Rounding necessaryLog2(2): 1Log10(10): 1sqrt(100): 10factorial(5): 120 Multimap多重映射接口扩展映射，使得其键一次可被映射到多个值。 接口声明​ 以下是com.google.common.collect.Multimap&lt;K，V&gt;接口的声明： 12@GwtCompatiblepublic interface Multimap&lt;K,V&gt; 接口方法 S.N. 方法及说明 1 Map&gt; asMap() 返回此multimap中的视图，从每个不同的键在键的关联值的非空集合映射。 2 void clear() 将删除所有multimap中的键值对，留下空。 3 boolean containsEntry(Object key, Object value) 返回true如果此多重映射包含至少一个键 - 值对用键键和值value。 4 boolean containsKey(Object key) 返回true，如果这个multimap中至少包含一个键值对的键key。 5 boolean containsValue(Object value) 返回true，如果这个multimap至少包含一个键值对的值值。 6 Collection&gt; entries() 返回包含在此multimap中，为Map.Entry的情况下，所有的键 - 值对的视图集合。 7 boolean equals(Object obj) 比较指定对象与此多重映射是否相等。 8 Collection get(K key) 返回，如果有的话，在这个multimap中键关联的值的视图集合。 9 int hashCode() 返回此多重映射的哈希码。 10 boolean isEmpty() 返回true，如果这个multimap中未包含键 - 值对。 11 Multiset keys() 返回一个视图集合包含从每个键值对这个multimap中的关键，没有折叠重复。 12 Set keySet() Returns a view collection of all distinct keys contained in this multimap. 13 boolean put(K key, V value) 存储键 - 值对在这个multimap中。 14 boolean putAll(K key, Iterable values) 存储一个键 - 值对在此multimap中的每个值，都使用相同的键 key。 15 boolean putAll(Multimap multimap) 存储了所有键 - 值对多重映射在这个multimap中，通过返回 multimap.entries() 的顺序. 16 boolean remove(Object key, Object value) 删除一个键 - 值对用键键，并从该多重映射的值的值，如果这样的存在。 17 Collection removeAll(Object key) 删除与键键关联的所有值。 18 Collection replaceValues(K key, Iterable values) 存储与相同的键值，替换任何现有值的键的集合。 19 int size() 返回此多重映射键 - 值对的数量。 20 Collection values() 返回一个视图集合包含从包含在该multimap中的每个键 - 值对的值，而不发生重复 (so values().size() == size()). Multimap 示例​ 使用所选择的任何编辑器创建下面的java程序 C:/&gt; Guava GuavaTester.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import java.util.Collection;import java.util.List;import java.util.Map;import java.util.Set;import com.google.common.collect.ArrayListMultimap;import com.google.common.collect.Multimap;public class GuavaTester &#123; public static void main(String args[])&#123; GuavaTester tester = new GuavaTester(); Multimap&lt;String,String&gt; multimap = tester.getMultimap(); List&lt;String&gt; lowerList = (List&lt;String&gt;)multimap.get(\"lower\"); System.out.println(\"Initial lower case list\"); System.out.println(lowerList.toString()); lowerList.add(\"f\"); System.out.println(\"Modified lower case list\"); System.out.println(lowerList.toString()); List&lt;String&gt; upperList = (List&lt;String&gt;)multimap.get(\"upper\"); System.out.println(\"Initial upper case list\"); System.out.println(upperList.toString()); upperList.remove(\"D\"); System.out.println(\"Modified upper case list\"); System.out.println(upperList.toString()); Map&lt;String, Collection&lt;String&gt;&gt; map = multimap.asMap(); System.out.println(\"Multimap as a map\"); for (Map.Entry&lt;String, Collection&lt;String&gt;&gt; entry : map.entrySet()) &#123; String key = entry.getKey(); Collection&lt;String&gt; value = multimap.get(\"lower\"); System.out.println(key + \":\" + value); &#125; System.out.println(\"Keys of Multimap\"); Set&lt;String&gt; keys = multimap.keySet(); for(String key:keys)&#123; System.out.println(key); &#125; System.out.println(\"Values of Multimap\"); Collection&lt;String&gt; values = multimap.values(); System.out.println(values); &#125; private Multimap&lt;String,String&gt; getMultimap()&#123; //Map&lt;String, List&lt;String&gt;&gt; // lower -&gt; a, b, c, d, e // upper -&gt; A, B, C, D Multimap&lt;String,String&gt; multimap = ArrayListMultimap.create(); multimap.put(\"lower\", \"a\"); multimap.put(\"lower\", \"b\"); multimap.put(\"lower\", \"c\"); multimap.put(\"lower\", \"d\"); multimap.put(\"lower\", \"e\"); multimap.put(\"upper\", \"A\"); multimap.put(\"upper\", \"B\"); multimap.put(\"upper\", \"C\"); multimap.put(\"upper\", \"D\"); return multimap; &#125;&#125; 验证结果​ 使用javac编译器编译如下类 1C:\\Guava&gt;javac GuavaTester.java ​ 现在运行GuavaTester看到的结果 1C:\\Guava&gt;java GuavaTester ​ 看到结果。 12345678910111213141516Initial lower case list[a, b, c, d, e]Modified lower case list[a, b, c, d, e, f]Initial upper case list[A, B, C, D]Modified upper case list[A, B, C]Multimap as a mapupper:[a, b, c, d, e, f]lower:[a, b, c, d, e, f]Keys of MultimapupperlowerValues of Multimap[A, B, C, a, b, c, d, e, f]","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/tags/JAVA/"},{"name":"GUAVA","slug":"GUAVA","permalink":"https://vincentruan.github.io/tags/GUAVA/"}]},{"title":"B+树和数据库索引原理简述","slug":"B-树和数据库索引原理简述","date":"2020-02-27T07:12:49.000Z","updated":"2020-02-28T08:31:39.690Z","comments":true,"path":"2020/02/27/B-树和数据库索引原理简述/","link":"","permalink":"https://vincentruan.github.io/2020/02/27/B-树和数据库索引原理简述/","excerpt":"所以下面我们就从二叉树到平衡二叉树，再到 B- 树，最后到 B+ 树来一步一步了解数据库索引底层的原理！ 二叉树（Binary Search Trees）二叉树是每个结点最多有两个子树的树结构。通常子树被称作“左子树”（Left Subtree）和“右子树”（Right Subtree）。二叉树常被用于实现二叉查找树和二叉堆。 二叉树有如下特性： 每个结点都包含一个元素以及 n 个子树，这里 0≤n≤2。 左子树和右子树是有顺序的，次序不能任意颠倒。左子树的值要小于父结点，右子树的值要大于父结点。","text":"所以下面我们就从二叉树到平衡二叉树，再到 B- 树，最后到 B+ 树来一步一步了解数据库索引底层的原理！ 二叉树（Binary Search Trees）二叉树是每个结点最多有两个子树的树结构。通常子树被称作“左子树”（Left Subtree）和“右子树”（Right Subtree）。二叉树常被用于实现二叉查找树和二叉堆。 二叉树有如下特性： 每个结点都包含一个元素以及 n 个子树，这里 0≤n≤2。 左子树和右子树是有顺序的，次序不能任意颠倒。左子树的值要小于父结点，右子树的值要大于父结点。 光看概念有点枯燥，假设我们现在有这样一组数[35 27 48 12 29 38 55]，顺序的插入到一个数的结构中，步骤如下 ： 好了，这就是一棵二叉树啦！我们能看到，经过一系列的插入操作之后，原本无序的一组数已经变成一个有序的结构了，并且这个树满足了上面提到的两个二叉树的特性！ 但是如果同样是上面那一组数，我们自己升序排列后再插入，也就是说按照[12 27 29 35 38 48 55]的顺序插入，会怎么样呢？ 线性退化 由于是升序插入，新插入的数据总是比已存在的结点数据都要大，所以每次都会往结点的右边插入，最终导致这棵树严重偏科！ 上图就是最坏的情况，也就是一棵树退化为一个线性链表了，这样查找效率自然就低了，完全没有发挥树的优势了呢！ 为了较大发挥二叉树的查找效率，让二叉树不再偏科，保持各科平衡，所以有了平衡二叉树！ 平衡二叉树 (AVL Trees)平衡二叉树是一种特殊的二叉树，所以他也满足前面说到的二叉树的两个特性，同时还有一个特性：它的左右两个子树的高度差的绝对值不超过 1，并且左右两个子树都是一棵平衡二叉树。 大家也看到了前面[35 27 48 12 29 38 55]插入完成后的图，其实就已经是一棵平衡二叉树啦。 那如果按照[12 27 29 35 38 48 55]的顺序插入一棵平衡二叉树，会怎么样呢？ 我们看看插入以及平衡的过程： 这棵树始终满足平衡二叉树的几个特性而保持平衡！这样我们的树也不会退化为线性链表了！ 我们需要查找一个数的时候就能沿着树根一直往下找，这样的查找效率和二分法查找是一样的呢！ 一棵平衡二叉树能容纳多少的结点呢？这跟树的高度是有关系的，假设树的高度为 h，那每一层最多容纳的结点数量为 2^(n-1)，整棵树最多容纳节点数为 2^0+2^1+2^2+…+2^(h-1)。 这样计算，100w 数据树的高度大概在 20 左右，也就是说从有着 100w 条数据的平衡二叉树中找一个数据，最坏的情况下需要 20 次查找。 如果是内存操作，效率也是很高的！但是我们数据库中的数据基本都是放在磁盘中的，每读取一个二叉树的结点就是一次磁盘 IO，这样我们找一条数据如果要经过 20 次磁盘的 IO？ 那性能就成了一个很大的问题了！那我们是不是可以把这棵树压缩一下，让每一层能够容纳更多的节点呢？虽然我矮，但是我胖啊… B-Tree这颗矮胖的树就是 B-Tree，注意中间是杠精的杠而不是减，所以也不要读成 B 减 Tree 了~ 那 B-Tree 有哪些特性呢？一棵 m 阶的 B-Tree 有如下特性： 每个结点最多 m 个子结点。 除了根结点和叶子结点外，每个结点最少有 m/2（向上取整）个子结点。 如果根结点不是叶子结点，那根结点至少包含两个子结点。 所有的叶子结点都位于同一层。 每个结点都包含 k 个元素（关键字），这里 m/2≤k。 每个节点中的元素（关键字）从小到大排列。 每个元素（关键字）字左结点的值，都小于或等于该元素（关键字）。右结点的值都大于或等于该元素（关键字）。 是不是感觉跟丈母娘张口问你要彩礼一样，列一堆的条件，而且每一条都让你很懵逼！ 下面我们以一个[0,1,2,3,4,5,6,7]的数组插入一棵 3 阶的 B-Tree 为例，将所有的条件都串起来，你就明白了！ 那么，你是否对 B-Tree 的几点特性都清晰了呢？在二叉树中，每个结点只有一个元素。 但是在 B-Tree 中，每个结点都可能包含多个元素，并且非叶子结点在元素的左右都有指向子结点的指针。 如果需要查找一个元素，那流程是怎么样的呢？我们看下图，如果我们要在下面的 B-Tree 中找到关键字 24，那流程如下： 从这个流程我们能看出，B-Tree 的查询效率好像也并不比平衡二叉树高。但是查询所经过的结点数量要少很多，也就意味着要少很多次的磁盘 IO，这对性能的提升是很大的。 从前面对 B-Tree 操作的图，我们能看出来，元素就是类似 1、2、3 这样的数值。 但是数据库的数据都是一条条的数据，如果某个数据库以 B-Tree 的数据结构存储数据，那数据怎么存放的呢？ 我们看下一张图： 普通的 B-Tree 的结点中，元素就是一个个的数字。但是上图中，我们把元素部分拆分成了 key-data 的形式，Key 就是数据的主键，Data 就是具体的数据。 这样我们在找一条数的时候，就沿着根结点往下找就 OK 了，效率是比较高的。 B+TreeB+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构。 B+Tree 与 B-Tree 的结构很像，但是也有几个自己的特性： 所有的非叶子节点只存储关键字信息。 所有卫星数据（具体数据）都存在叶子结点中。 所有的叶子结点中包含了全部元素的信息。 所有叶子节点之间都有一个链指针。 如果上面 B-Tree 的图变成 B+Tree，那应该如下： 大家仔细对比于 B-Tree 的图能发现什么不同？ 非叶子结点上已经只有 Key 信息了，满足上面第 1 点特性！ 所有叶子结点下面都有一个 Data 区域，满足上面第 2 点特性！ 非叶子结点的数据在叶子结点上都能找到，如根结点的元素 4、8 在最底层的叶子结点上也能找到，满足上面第 3 点特性！ 注意图中叶子结点之间的箭头，满足上面第 4 点特性！ B-Tree or B+Tree？在讲这两种数据结构在数据库中的选择之前，我们还需要了解的一个知识点是操作系统从磁盘读取数据到内存是以磁盘块（Block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。 即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。 这样做的理论依据是计算机科学中著名的局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。 预读的长度一般为页（Page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页的大小通常为 4K）。 B-Tree 和 B+Tree 该如何选择呢？都有哪些优劣呢？ ①B-Tree 因为非叶子结点也保存具体数据，所以在查找某个关键字的时候找到即可返回。 而 B+Tree 所有的数据都在叶子结点，每次查找都得到叶子结点。所以在同样高度的 B-Tree 和 B+Tree 中，B-Tree 查找某个关键字的效率更高。 ②由于 B+Tree 所有的数据都在叶子结点，并且结点之间有指针连接，在找大于某个关键字或者小于某个关键字的数据的时候，B+Tree 只需要找到该关键字然后沿着链表遍历就可以了，而 B-Tree 还需要遍历该关键字结点的根结点去搜索。 ③由于 B-Tree 的每个结点（这里的结点可以理解为一个数据页）都存储主键+实际数据，而 B+Tree 非叶子结点只存储关键字信息，而每个页的大小是有限的，所以同一页能存储的 B-Tree 的数据会比 B+Tree 存储的更少。 这样同样总量的数据，B-Tree 的深度会更大，增大查询时的磁盘 I/O 次数，进而影响查询效率。 鉴于以上的比较，所以在常用的关系型数据库中，都是选择 B+Tree 的数据结构来存储数据！ 下面我们以 MySQL 的 InnoDB 存储引擎为例讲解，其他类似 SQL Server、Oracle 的原理！ InnoDB 引擎数据存储在 InnoDB 存储引擎中，也有页的概念，默认每个页的大小为 16K，也就是每次读取数据时都是读取 4*4K 的大小！ 假设我们现在有一个用户表，我们往里面写数据： 这里需要注意的一点是，在某个页内插入新行时，为了减少数据的移动，通常是插入到当前行的后面或者是已删除行留下来的空间，所以在某一个页内的数据并不是完全有序的（后面页结构部分有细讲）。 但是为了数据访问顺序性，在每个记录中都有一个指向下一条记录的指针，以此构成了一条单向有序链表，不过在这里为了方便演示我是按顺序排列的！ 由于数据还比较少，一个页就能容下，所以只有一个根结点，主键和数据也都是保存在根结点（左边的数字代表主键，右边名字、性别代表具体的数据）。 假设我们写入 10 条数据之后，Page1 满了，再写入新的数据会怎么存放呢？ 我们继续看下图： 有个叫“秦寿生”的朋友来了，但是 Page1 已经放不下数据了，这时候就需要进行页分裂，产生一个新的 Page。 在 InnoDB 中的流程是怎么样的呢？ 产生新的 Page2，然后将 Page1 的内容复制到 Page2。 产生新的 Page3，“秦寿生”的数据放入 Page3。 原来的 Page1 依然作为根结点，但是变成了一个不存放数据只存放索引的页，并且有两个子结点 Page2、Page3。 这里有两个问题需要注意的是： ①为什么要复制 Page1 为 Page2 而不是创建一个新的页作为根结点，这样就少了一步复制的开销了？ 如果是重新创建根结点，那根结点存储的物理地址可能经常会变，不利于查找。 并且在 InnoDB 中根结点是会预读到内存中的，所以结点的物理地址固定会比较好！ ②原来 Page1 有 10 条数据，在插入第 11 条数据的时候进行裂变，根据前面对 B-Tree、B+Tree 特性的了解，那这至少是一棵 11 阶的树，裂变之后每个结点的元素至少为 11/2=5 个。 那是不是应该页裂变之后主键 1-5 的数据还是在原来的页，主键 6-11 的数据会放到新的页，根结点存放主键 6？ 如果是这样的话，新的页空间利用率只有 50%，并且会导致更为频繁的页分裂。 所以 InnoDB 对这一点做了优化，新的数据放入新创建的页，不移动原有页面的任何记录。 随着数据的不断写入，这棵树也逐渐枝繁叶茂，如下图： 每次新增数据，都是将一个页写满，然后新创建一个页继续写，这里其实是有个隐含条件的，那就是主键自增！ 主键自增写入时新插入的数据不会影响到原有页，插入效率高！且页的利用率高！ 但是如果主键是无序的或者随机的，那每次的插入可能会导致原有页频繁的分裂，影响插入效率！降低页的利用率！这也是为什么在 InnoDB 中建议设置主键自增的原因！ 这棵树的非叶子结点上存的都是主键，那如果一个表没有主键会怎么样？在 InnoDB 中，如果一个表没有主键，那默认会找建了唯一索引的列，如果也没有，则会生成一个隐形的字段作为主键！ 有数据插入那就有删除，如果这个用户表频繁的插入和删除，那会导致数据页产生碎片，页的空间利用率低，还会导致树变的“虚高”，降低查询效率！这可以通过索引重建来消除碎片提高查询效率！ InnoDB 引擎数据查找数据插入了怎么查找呢？ 找到数据所在的页。这个查找过程就跟前面说到的 B+Tree 的搜索过程是一样的，从根结点开始查找一直到叶子结点。 在页内找具体的数据。读取第 1 步找到的叶子结点数据到内存中，然后通过分块查找的方法找到具体的数据。 这跟我们在新华字典中找某个汉字是一样的，先通过字典的索引定位到该汉字拼音所在的页，然后到指定的页找到具体的汉字。 InnoDB 中定位到页后用了哪种策略快速查找某个主键呢？这我们就需要从页结构开始了解。 左边蓝色区域称为 Page Directory，这块区域由多个 Slot 组成，是一个稀疏索引结构，即一个槽中可能属于多个记录，最少属于 4 条记录，最多属于 8 条记录。 槽内的数据是有序存放的，所以当我们寻找一条数据的时候可以先在槽中通过二分法查找到一个大致的位置。 右边区域为数据区域，每一个数据页中都包含多条行数据。注意看图中最上面和最下面的两条特殊的行记录 Infimum 和 Supremum，这是两个虚拟的行记录。 在没有其他用户数据的时候 Infimum 的下一条记录的指针指向 Supremum。 当有用户数据的时候，Infimum 的下一条记录的指针指向当前页中最小的用户记录，当前页中最大的用户记录的下一条记录的指针指向 Supremum，至此整个页内的所有行记录形成一个单向链表。 行记录被 Page Directory 逻辑的分成了多个块，块与块之间是有序的，也就是说“4”这个槽指向的数据块内最大的行记录的主键都要比“8”这个槽指向的数据块内最小的行记录的主键要小。但是块内部的行记录不一定有序。 每个行记录的都有一个 n_owned 的区域（图中粉红色区域），n_owned 标识这个块有多少条数据。 伪记录 Infimum 的 n_owned 值总是 1，记录 Supremum 的 n_owned 的取值范围为[1,8]，其他用户记录 n_owned 的取值范围[4,8]。 并且只有每个块中最大的那条记录的 n_owned 才会有值，其他的用户记录的 n_owned 为 0。 所以当我们要找主键为 6 的记录时，先通过二分法在稀疏索引中找到对应的槽，也就是 Page Directory 中“8”这个槽。 “8”这个槽指向的是该数据块中最大的记录，而数据是单向链表结构，所以无法逆向查找。 所以需要找到上一个槽即“4”这个槽，然后通过“4”这个槽中最大的用户记录的指针沿着链表顺序查找到目标记录。 聚集索引&amp;非聚集索引前面关于数据存储的都是演示的聚集索引的实现，如果上面的用户表需要以“用户名字”建立一个非聚集索引，是怎么实现的呢？ 我们看下图： 非聚集索引的存储结构与前面是一样的，不同的是在叶子结点的数据部分存的不再是具体的数据，而是数据的聚集索引的 Key。 所以通过非聚集索引查找的过程是先找到该索引 Key 对应的聚集索引的 Key，然后再拿聚集索引的 Key 到主键索引树上查找对应的数据，这个过程称为回表！ PS：图中的这些名字均来源于网络，希望没有误伤正在看这篇文章的你~^_^ InnoDB 与 MyISAM 引擎对比上面包括存储和搜索都是拿的 InnoDB 引擎为例，那 MyISAM 与 InnoDB 在存储上有啥不同呢？憋缩话，看图： 上图为 MyISAM 主键索引的存储结构，我们能看到的不同是： 主键索引树的叶子结点的数据区域没有存放实际的数据，存放的是数据记录的地址。 数据的存储不是按主键顺序存放的，是按写入的顺序存放。 也就是说 InnoDB 引擎数据在物理上是按主键顺序存放，而 MyISAM 引擎数据在物理上按插入的顺序存放。 并且 MyISAM 的叶子结点不存放数据，所以非聚集索引的存储结构与聚集索引类似，在使用非聚集索引查找数据的时候通过非聚集索引树就能直接找到数据的地址了，不需要回表，这比 InnoDB 的搜索效率会更高呢！ 索引优化建议大家经常会在很多的文章或书中能看到一些索引的使用建议，比如说： like 的模糊查询以 % 开头，会导致索引失效。 一个表建的索引尽量不要超过 5 个。 尽量使用覆盖索引。 尽量不要在重复数据多的列上建索引。 …… 很多这里就不一一列举了！那看完这篇文章，我们能否带着疑问去分析一下为什么要有这些建议？ 原作者：苏静，转载自心里没点B树，怎能吃透数据库索引底层原理？","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentruan.github.io/categories/数据库/"}],"tags":[{"name":"B树","slug":"B树","permalink":"https://vincentruan.github.io/tags/B树/"},{"name":"B+树","slug":"B-树","permalink":"https://vincentruan.github.io/tags/B-树/"},{"name":"数据库","slug":"数据库","permalink":"https://vincentruan.github.io/tags/数据库/"},{"name":"索引","slug":"索引","permalink":"https://vincentruan.github.io/tags/索引/"}]},{"title":"微服务-API网关","slug":"微服务-API网关","date":"2020-02-27T06:29:12.000Z","updated":"2020-02-28T08:33:48.807Z","comments":true,"path":"2020/02/27/微服务-API网关/","link":"","permalink":"https://vincentruan.github.io/2020/02/27/微服务-API网关/","excerpt":"API 网关什么是 API 网关既然需要 API 网关为我所用，首先就让我们来了解一下什么是 API 网关。 什么是 API 网关网关一词最早出现在网络设备，比如两个相互独立的局域网之间通过路由器进行通信，中间的路由被称之为网关。 任何一个应用系统如果需要被其他系统调用，就需要暴露 API，这些 API 代表着一个一个的功能点。 如果两个系统中间通信，在系统之间加上一个中介者协助 API 的调用，这个中介者就是 API 网关。","text":"API 网关什么是 API 网关既然需要 API 网关为我所用，首先就让我们来了解一下什么是 API 网关。 什么是 API 网关网关一词最早出现在网络设备，比如两个相互独立的局域网之间通过路由器进行通信，中间的路由被称之为网关。 任何一个应用系统如果需要被其他系统调用，就需要暴露 API，这些 API 代表着一个一个的功能点。 如果两个系统中间通信，在系统之间加上一个中介者协助 API 的调用，这个中介者就是 API 网关。 对接两个系统的 API 网关 当然，API 网关可以放在两个系统之间，同时也可以放在客户端与服务端之间。 对接客户端和服务端的 API 网关 知道了 API 网关的基本定义，再来看看为什么我们要使用它。 为何要使用 API 网关网关作为系统的唯一入口，也就是说，进入系统的所有请求都需要经过 API 网关。 当系统外部的应用或者客户端访问系统的时候，都会遇到这样的情况： 系统要判断它们的权限 如果传输协议不一致，需要对协议进行转换 如果调用水平扩展的服务，需要做负载均衡 一旦请求流量超出系统承受的范围，需要做限流操作 针对每个请求以及回复，系统会记录响应的日志 也就是说，只要是涉及到对系统的请求，并且能够从业务中抽离出来的功能，都有可能在网关上实现。 例如：协议转换，负载均衡，请求路由，流量控制等等。后面我们会一一给大家介绍这些功能。 在了解 API 网关有哪些基本功能以后，来看看它可以服务于哪些系统或者客户端。 API 网关服务定位API 网关拥有处理请求的能力，从定位来看分为 5 类： ①面向 WebApp，这部分的系统以网站和 H5 应用为主。通过前后端分离的设计，将大部分的业务功能都放在了后端，前面的 Web App 只展示页面的内容。 ②MobileApp，这里的 Mobile 指的是 iOS 和 Android，设计思路和 WebApp 基本相同。区别是 API 网关需要做一些移动设备管理的工作（MDM）。例如：设备的注册，激活，使用，淘汰等，全生命周期的管理。由于移动设备的特殊性，导致了我们在考虑移动设备请求的时候，需要考虑请求，设备，使用者之间的关系。 ③面向合作伙伴的 OpenAPI，通常系统会给合作伙伴提供接口。这些接口会全部开放或者部分开发，在有条件限制（时间，流量）的情况下给合作伙伴访问。因此需要更多考虑 API 网关的流量和安全以及协议转换的管理。 ④企业内部可扩展 API，给企业内部的其他部门或者项目使用，也可以作为中台输出的一部分，支持其他系统。这里需要更多地考虑划分功能边界，认证和授权问题。 ⑤面向 IOT 设备，会接收来自 IOT 设备的请求，特别是工业传感器等设备。这里需要考虑协议转换和数据过滤。 API 网关架构既然谈了 API 网关的功能和定位，接下来说说它的架构： API 网关系统架构图 API 网关拆分成为 3 个系统： Gateway-Core（核心） Gateway-Admin（管理） Gateway-Monitor（监控） Gateway-Core 核心网关，负责接收客户端请求，调度、加载和执行组件，将请求路由到上游服务端，并处理其返回的结果。 大多数的功能都在这一层完成，例如：验证，鉴权，负载均衡，协议转换，服务路由，数据缓存。如果没有其他两个子系统，它也是可以单独运行的。 Gateway-Admin 网关管理界面，可以进行 API、组件等系统基础信息的配置；例如：限流的策略，缓存配置，告警设置。 Gateway-Monitor 监控日志、生成各种运维管理报表、自动告警等；管理和监控系统主要是为核心系统服务的，起到支撑的作用。 API 网关技术原理上面谈到了网关的架构思路，这里谈几点技术原理。平时我们在使用网关的时候，多注重其实现的功能。例如：路由，负载均衡，限流，缓存，日志，发布等等。 实际上这些功能的背后有一些原理我们可以了解，这样在应用功能的时候会更加笃定。下面是几个原理分享给大家。 协议转换每个系统内部服务之间的调用，可以统一使用一种协议，例如：HTTP，GRPC。 假设每个系统使用的协议不同，那么系统之间的调用或者数据传输，就存在协议转换的问题了。如果解决这个问题呢？API 网关通过泛化调用的方式实现协议之间的转化。 实际上就是将不同的协议转换成“通用协议”，然后再将通用协议转化成本地系统能够识别的协议。 这一转化工作通常在 API 网关完成。通用协议用得比较多的有 JSON，当然也有使用 XML 或者自定义 JSON 文件的。 不同的协议需要转化成共同语言进行传输 链式处理设计模式中有一种责任链模式，它将“处理请求”和“处理步骤”分开。每个处理步骤，只关心这个步骤上需要做的处理操作，处理步骤存在先后顺序。 消息从第一个“处理步骤”流入，从最后一个“处理步骤”流出，每个步骤对经过的消息进行处理，整个过程形成了一个链条。在 API 网关中也用到了类似的模式。 Zuul 网关过滤器链式处理 下面以 Zuul 为例，当消息出入网关需要经历一系列的过滤器。这些过滤器之间是有先后顺序的，并且在每个过滤器需要进行的工作也是各不一样： PRE：前置过滤器，用来处理通用事务，比如鉴权，限流，熔断降级，缓存。并且可以通过 Custom 过滤器进行扩展。 ROUTING：路由过滤器，在这种过滤器中把用户请求发送给 Origin Server。它主要负责：协议转化和路由的工作。 POST：后置过滤器，从 Origin Server 返回的响应信息会经过它，再返回给调用者。在返回的 Response 上加入 Response Header，同时可以做 Response 的统计和日志记录。 ERROR：错误过滤器，当上面三个过滤器发生异常时，错误信息会进到这里，并对错误进行处理。 异步请求所有的请求通过 API 网关访问应用服务，一旦吞吐量上去了，如何高效地处理这些请求？ 拿 Zuul 为例，Zuul1 采用：一个线程处理一个请求的方式。线程负责接受请求，然后调用应用返回结果。 如果把网络请求看成一次 IO 操作的话，处理请求的线程，从接受请求，到服务返回响应，都是阻塞状态。 同时，如果多个线程都处在这种状态，会导致系统缓慢。因为每个网关能够开启的线程数量是有限的，特别是在访问的高峰期。 每个线程处理一个请求 为了解决这个问题，Zuul2 启动了异步请求的机制。每个请求进入网关的时候，会被包装成一个事件，CPU 内核会维持一个监听器，不断轮询“请求事件”。 一旦，发现请求事件，就会调用对应的应用。获取应用返回的信息以后，按照请求的要求把数据/文件放到指定的缓冲区，同时发送一个通知事件，告诉请求端数据已经就绪，可以从这个缓冲获取数据/文件。 这个过程是异步的，请求的线程不用一直等待数据的返回。它在请求完毕以后，就直接返回了，这时它可以做其他的事情。 当请求数据被 CPU 内核获取，并且发送到指定的数据缓冲区时，请求的线程会接到“数据返回”的通知，然后就直接使用数据，不用自己去做取数据的操作。 异步请求处理，CPU 处理数据以后通知请求端 实现异步处理请求有两种模式，分别是： Reactor Proactor Reactor 工作原理流水图 Reactor：通过 handle_events 事件循环处理请求。用户线程注册事件处理器之后，可以继续执行其他的工作（异步），而 Reactor 线程负责调用内核的 Select 函数检查 Socket 状态。 当有 Socket 被激活时（获取网络数据），则通知相应的用户线程，执行 handle_event 进行数据读取、处理的工作。 Proactor 工作原理流水图 Proactor：用户线程使用 CPU 内核提供的异步 IO 发起请求，请求发起以后立即返回。CPU 内核继续执行用户请求线程代码。 此时用户线程已将 AsynchronousOperation（异步处理）和 CompletionHandler（完成获取资源）注册到内核。之后操作系统开启独立的内核线程去处理 IO 操作。 当请求的数据到达时，由内核负责读取 Socket（网络请求）中的数据，并写入用户指定的缓冲区中。 最后内核将数据和用户线程注册的 CompletionHandler 分发给内部 Proactor，Proactor 将 IO 完成的信息通知给用户线程（一般通过调用用户线程注册的完成事件处理函数），完成异步 IO。 API 网关实现功能说起对 API 网关的使用，我们还是对具体功能更加感兴趣。让我们一起来看看它实现了哪些功能。 负载均衡当网关后面挂接同一应用的多个副本时，每次用户的请求都会通过网关的负载均衡算法，路由到对应的服务上面。例如：随机算法，权重算法，Hash 算法等等。 如果上游服务采取微服务的架构，也可以和注册中心合作实现动态的负载均衡。 当微服务动态挂载（动态扩容）的时候，可以通过服务注册中心获取微服务的注册信息，从而实现负载均衡。 Nginx+Lua+服务注册中心实现动态负载均衡 路由选择这个不言而喻，网关可以根据请求的 URL 地址解析，知道需要访问的服务。再通过路由表把请求路由到目标服务上去。 有时候因为网络原因，服务可能会暂时的不可用，这个时候我们希望可以再次对服务进行重试。 Zuul 作为 API 网关将请求路由到上游服务器 例如：Zuul 与 Spring Retry 合作完成路由重试。 1234#是否开启重试功能zuul.retryable=true#对当前服务的重试次数ribbon.MaxAutoRetries=2 流量控制限流是 API 网关常用的功能之一，当上游服务超出请求承载范围，或者服务因为某种原因无法正常使用，都会导致服务处理能力下滑。 这个时候，API 网关作为“看门人”，就可以限制流入的请求，让应用服务器免受冲击。 限流实际上就是限制流入请求的数量，其算法不少，有令牌桶算法，漏桶算法，连接数限制等等。这里我们就介绍三个常用的，一般通过 Nginx+Lua 来实现。 令牌桶限流 统一鉴权访问应用服务器的请求都需要拥有一定权限，如果说每访问一个服务都需要验证一次权限，这个对效率是很大的影响。可以把权限认证放到 API 网关来进行。 目前比较常见的做法是，用户通过登录服务获取 Token，把它存放到客户端，在每次请求的时候把这个 Token 放入请求头，一起发送给服务器。 API 网关要做的事情就是解析这个 Token，知道访问者是谁（鉴定），他能做什么/访问什么（权限）。 说白了就是看访问者能够访问哪些 URL，这里根据权限/角色定义一个访问列表。 如果要实现多个系统的 OSS（Single Sign On 单点登录），API 网关需要和 CAS（Central Authentication Service 中心鉴权服务）做连接，来确定请求者的身份和权限。 熔断降级当应用服务出现异常，不能继续提供服务的时候，也就是说应用服务不可用了。作为 API 网关需要做出处理，把请求导入到其他服务上。 或者对服务进行降级处理，例如：用兜底的服务数据返回客户端，或者提示服务暂时不可用。 同时通过服务注册中心，监听存在问题的服务，一旦服务恢复，随即恢复路由请求到该服务。 例如：Zuul 中提供了 ZuulFallbackProvider 接口来实现熔断，它提供两个方法，一个指明熔断拦截的服务 getRoute，一个指定返回内容 ClientHttpResponse。 12345678910111213public interface ZuulFallbackProvider &#123; /** * The route this fallback will be used for. * @return The route the fallback will be used for. */ public String getRoute(); /** * Provides a fallback response. * @return The fallback response. */ public ClientHttpResponsefallbackResponse();&#125; 我们通过自定义的 Fallback 方法，并且将其指定给某个 Route 来实现该 Route 访问出问题的熔断处理。 主要继承 ZuulFallbackProvider 接口来实现，ZuulFallbackProvider 默认有两个方法，一个用来指明熔断拦截哪个服务，一个定制返回内容。 API 网关熔断降级 发布测试在发布版本的时候会采用：金丝雀发布和蓝绿发布。作为 API 网关可以使用路由选择和流量切换来协助上述行为。这里以金丝雀发布为例，看看 API 网关如何做路由转换的。 假设将 4 个服务从 V1 更新到 V2 版本，这 4 个服务的流量请求由 1 个 API 网关管理。 那么先将一台服务与 API 网关断开，部署 V2 版本的服务，然后 API 网关再将流量导入到 V2 版本的服务上。 这里流量的导入可以是逐步进行的，一旦 V2 版本的服务趋于稳定。再如法炮制，将其他服务替换成 V2 版本。 金丝雀发布一般先发 1 台，或者一个小比例，例如 2% 的服务器，主要做流量验证用，也称为金丝雀（Canary）测试（灰度测试）。 其来历是，旷工下矿洞前，先放一只金丝雀探查是否有毒气，金丝雀发布由此得名。 金丝雀测试需要完善的监控设施配合，通过监控指标反馈，观察金丝雀的健康状况，作为后续发布或回滚的依据。 如果金丝测试通过，则把剩余的 V1 版本全部升级为 V2 版本。如果金丝雀测试失败，则直接回退金丝雀，发布失败。 缓存数据 我们可以在 API 网关缓存一些修改频率不高的数据。例如：用户信息，配置信息，通过服务定期刷新这个缓存就行了： 用户请求先访问 API 网关，如果发现有缓存信息，直接返回给用户。 如果没有发现缓存信息，回源到应用服务器获取信息。 另外，有一个缓存更新服务，定期把应用服务器中的信息更新到网关本地缓存中。 日志记录通过 API 网关上的过滤器我们可以加入日志服务，记录请求和返回信息。同时可以建立一个管理员的界面去监控这些数据。 日志服务简图 日志记录了以后，可以做很多功能扩展。我们整理了以下几点供大家参考： 报表分析：针对服务访问情况，提供可视化展示。 实时查询：了解实时关键信息，例如：吞吐量，并发数。在秒杀活动的时候，会特别关注。 异常告警：针对关键参数进行监控，对于统计结果支持阈值报警，对接阿里云通知中心、短信、钉钉进行告警。 日志投递：将日志进行归档，存放到文件库或者数据仓库中，以便后期分析。 日志记录衍生的功能 流行 API 网关对比在介绍了 API 网关的功能以后，再来看看目前几个流行的 API 网关项目。看看他们各自的特点，并且把他们做一个简单的比较。这些网关目前都是开源的，大家可以有选择地在项目中使用。 KongKong 是 Mash ape 公司的开源项目，它是一个在 Nginx 中运行的 Lua 应用程序，并且可以通过 Lua-Nginx 模块实现扩展。 所以，可以通过插件集合的方式定制功能，例如：HTTP 基本认证、密钥认证、CORS（Cross-origin Resource Sharing，跨域资源共享）、TCP、UDP、日志、API 限流、请求转发以及监控，都是目前已有的插件。 由于是基于 Nginx 的，所以可以对网关进行水平扩展，来应对大批量的网络请求。 Kong 架构图 Kong 主要有三个组件： KongServer ：基于 Nginx 的服务器，用来接收 API 请求。 ApacheCassandra/PostgreSQL：用来存储操作数据。 Kongdashboard：UI 管理工具。 Traefik Traefik 架构图 Traefik 是 HTTP 反向代理和负载均衡器，可以轻松部署微服务，可以与现有的组件（Docker、Swarm，Kubernetes，Marathon，Consul，Etcd）做集成。 因为支持动态配置，所以它的伸缩性很好。不过它只支持 HTTP、HTTPS 和 GRPC。如果你需要 TCP 负载均衡，那么您需要选择其他方案了。 Ambassador Ambassador 架构图 Ambassador 是一个基于 Envoy Proxy 构建的，Kubernetes 原生的开源微服务网关。 它在构建之初就致力于支持多个独立的团队，这些团队需要为最终用户快速发布、监控和更新服务。 Ambassador 还具有 Kubernetes Ingress 和负载均衡的能力。它支持处理 Kubernetes Ingress Controller 和负载均衡等功能，可以与 Istio 无缝集成。 Zuul Zuul 2 结构图 Zuul 是 Spring Cloud 全家桶中的微服务 API 网关。所有从设备或网站来的请求都会经过 Zuul 到达后端的 Netflix 应用程序。 作为一个边界性质的应用程序，Zuul 提供了动态路由、监控、弹性负载和安全功能。包括 Zuul1 和 Zuul2 两个版本。 介绍了几个开源 API 网关的基本信息以后，我们从几个维度对他们进行比较： 从开源社区活跃度来说，Kong 和 Traefik 较好；从成熟度来看，较好的是 Kong、Traefik；从架构优势的扩展性来看，Kong 有丰富的插件，Ambassador 也有插件但不多，而 Zuul 是需要自研。 但 Zuul 由于与 Spring Cloud 集成，如果使用 Spring Cloud 的小伙伴可以考虑使用。 总结API 网关是系统内外通讯的中介者。从定位上来说它服务 WebApp，MobileApp，合作伙伴 OpenAPI，企业内部可扩展 API，以及 IOT 设备。 从架构设计角度来说，分为 Gateway-Core（核心）、Gateway-Admin（管理）、Gateway-Monitor（监控）三部分。 API 网关需要注意的技术原理有，协议转换，链式处理以及异步请求。它的应用比较广泛，例如：负载均衡，路由选择，流量控制，统一鉴权，熔断降级，发布测试，缓存数据，日志记录等。 比较流行的开源 API网关有 Kong，Traefik，Ambassador，Zuul。从使用上来说他们各有千秋，可以根据项目的情况选取。 转载自https://mp.weixin.qq.com/s?__biz=MjM5ODI5Njc2MA==&amp;mid=2655826846&amp;idx=1&amp;sn=483ea4f2d1d34f921ef07e35a4af63c1&amp;chksm=bd74fe498a03775fc5980c568e1af13f53c64ebaaedea643dc4ec03acc338fac7a323e3656a7&amp;scene=21#wechat_redirect 原作者：崔皓 各大API网关性能比较API网关最基本的功能就是反向代理，所以在对API网关做技术选型的时候需要着重考察其性能表现，本文对Nginx、Haproxy、Netty、Spring Cloud Gateway、Zuul2做了性能测试，测试代码可以在github获得。 测试方法 准备了三台2CPU 4G内存的服务器，分别运行Tomcat、API Gateway、Gatling（压测工具） 先对Tomcat做压测，取Tomcat充分预热后的压测结果作为基准。压的是Tomcat自带的example：/examples/jsp/jsp2/simpletag/book.jsp 在对Netty、Zuul2、Spring Cloud Gateway做压测时候也是先压个几轮做预热。 被测的API网关都没有添加额外业务，只做反向代理 吞吐量下图是吞吐量的情况，可以看到Netty、Nginx、Haproxy均比直压Tomcat低一点点，而Spring Cloud Gateway和Zuul2则要低得多。 下面这张图可以更明显的看到吞吐量比较，Tomcat为100%因为它是基准值，Netty、Nginx、Haproxy的只比基准值低8%，而Spring Cloud Gateway和Zuul2则只是基准值的35%和34%（难兄难弟）。 平均响应时间下图可以看到Netty、Nginx、Haproxy的平均响应时间与Tomcat差不多。但是Spring Cloud Gateway和Zuul2则是Tomcat的3倍多，不出所料。 下图同样是以Tomcat作为基准值的比较： 响应时间分布光看平均响应时间是不够的，我们还得看P50、P90、P99、P99.9以及Max响应时间（可惜Gatling只能设置4个百分位，否则我还想看看P99.99的响应时间）。 为何要观察P99.9的响应时间？光看P90不够吗？理由有两个： 1）观察P99、P99.9、P99.99的响应时间可以观察系统的在高压情况下的稳定性，如果这三个时间的增长比较平滑那么说明该系统在高压力情况下比较稳定，如果这个曲线非常陡峭则说明不稳定。 2）观察P99、P99.9、P99.99的响应时间能够帮助你估算用户体验。假设你有一个页面会发出5次请求，那么这5次请求均落在P90以内概率是多少？90%^5=59%，至少会经历一次 &gt; P90响应时间的概率是 100%-59%=41%，如果你的P90=10s，那么就意味着用户有41%的概率会在加载页面的时候超过10s，是不是很惊人？如果你的P99=10s，那么用户只有5%的概率会在访问页面的时候超过10s。如果P99.9=10s，则有0.4%的概率。 关于如何正确测量系统可以看 “How NOT to Measure Latency” by Gil Tene 下面同样是把结果与Tomcat基准值做对比： 可以看到几个很有趣的现象： Haproxy、Nginx的P50、P90、P99、P99.9、Max都是逐渐递增的。 Netty的P50、P90、P99、P99.9是很平坦的，Max则为基准值的207%。 Spring Cloud Gateway和Zuul2则是相反的，它们的平面呈现下降趋势。Spring Cloud Gateway的Max甚至还比基准值低了一点点（94%），我相信这只是一个随机出现的数字，不要太在意。 结论Nginx、Haproxy、Netty三者的表现均很不错，其对于吞吐量和响应时间的性能损耗很低，可以忽略不计。 但是目前最为火热的Spring Cloud Gateway和Zuul2则表现得比较糟糕，因我没有写额外的业务逻辑这，可以推测这和它们的内置逻辑有关，那么大致有这么几种可能： 内置逻辑比较多 内置逻辑算法存在问题，占用了太多CPU时间 内置逻辑存在阻塞 内置逻辑没有用正确姿势使用Netty（两者皆基于Netty） 不管是上面的哪一种都需要再后续分析。 不过话说回来考虑选用那种作为API网关（的基础技术）不光要看性能，还要看： 是否易于扩展自己的业务逻辑 API使用的便利性 代码的可维护性 文档是否齐全 … 性能只是我们手里的一个筹码，当我们知道这个东西性能到底几何后，才可以与上面的这些做交换（trade-off）。比如Nginx和Haproxy的可扩展性很差，那么我们可以使用Netty。如果你觉得Netty的API太底层了太难用了，那么可以考虑Spring Cloud Gateway或Zuul2。前提是你知道你会失去多少性能。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://vincentruan.github.io/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://vincentruan.github.io/tags/微服务/"},{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/tags/架构设计/"},{"name":"API网关","slug":"API网关","permalink":"https://vincentruan.github.io/tags/API网关/"}]},{"title":"数据库软件架构设计","slug":"数据库软件架构设计","date":"2020-02-26T03:28:47.000Z","updated":"2020-02-26T09:53:39.957Z","comments":true,"path":"2020/02/26/数据库软件架构设计/","link":"","permalink":"https://vincentruan.github.io/2020/02/26/数据库软件架构设计/","excerpt":"基本概念概念一：单库 概念二：分片 分片解决“数据量太大”这一问题，也就是通常说的“水平切分”。 一旦引入分片，势必面临“数据路由”的新问题，数据到底要访问哪个库。路由规则通常有3种方法：","text":"基本概念概念一：单库 概念二：分片 分片解决“数据量太大”这一问题，也就是通常说的“水平切分”。 一旦引入分片，势必面临“数据路由”的新问题，数据到底要访问哪个库。路由规则通常有3种方法： （1）范围：range优点：简单，容易扩展。 缺点：各库压力不均（新号段更活跃）。 （2）哈希：hash优点：简单，数据均衡，负载均匀。 缺点：迁移麻烦（2库扩3库数据要迁移）。 （3）统一路由服务：router-config-server优点：灵活性强，业务与路由算法解耦。 缺点：每次访问数据库前多一次查询。 大部分互联网公司采用的方案二：哈希路由。 概念三：分组分组解决“可用性，性能提升”这一问题，分组通常通过主从复制的方式实现。 互联网公司数据库实际软件架构是“既分片，又分组”： 数据库软件架构，究竟设计些什么呢，至少要考虑以下四点： 如何保证数据可用性 如何提高数据库读性能（大部分应用读多写少，读会先成为瓶颈） 如何保证一致性 如何提高扩展性 如何保证数据的可用性？解决可用性问题的思路是：冗余。 如何保证站点的可用性？冗余站点。如何保证服务的可用性？冗余服务。如何保证数据的可用性？冗余数据。 数据的冗余，会带来一个副作用：一致性问题。 如何保证数据库“读”高可用？ 冗余读库 冗余读库带来什么副作用？ 读写有延时，数据可能不一致。 上图是很多互联网公司mysql的架构，写仍然是单点，不能保证写高可用。 如何保证数据库“写”高可用？ 冗余写库。 采用双主互备的方式，可以冗余写库。 冗余写库带来什么副作用？ 双写同步，数据可能冲突（例如“自增id”同步冲突）。 如何解决同步冲突，有两种常见解决方案：（1）两个写库使用不同的初始值，相同的步长来增加id：1写库的id为0,2,4,6…；2写库的id为1,3,5,7…；（2）不使用数据的id，业务层自己生成唯一的id，保证数据不冲突； 阿里云的RDS服务号称写高可用，是如何实现的呢？ 他们采用的就是类似于“双主同步”的方式（不再有从库了）。 仍是双主，但只有一个主提供读写服务，另一个主是“shadow-master”，只用来保证高可用，平时不提供服务。 master挂了，shadow-master顶上，虚IP漂移，对业务层透明，不需要人工介入。 这种方式的好处：（1）读写没有延时，无一致性问题；（2）读写高可用； 不足是：（1）不能通过加从库的方式扩展读性能；（2）资源利用率为50%，一台冗余主没有提供服务； 画外音：所以，高可用RDS还挺贵的。 如何扩展读性能？提高读性能的方式大致有三种， 第一种是增加索引。这种方式不展开，要提到的一点是，不同的库可以建立不同的索引。 如上图： （1）写库不建立索引；（2）线上读库建立线上访问索引，例如uid；（3）线下读库建立线下访问索引，例如time； 第二种扩充读性能的方式是，增加从库。这种方法大家用的比较多，存在两个缺点： （1）从库越多，同步越慢；（2）同步越慢，数据不一致窗口越大； 第三种增加系统读性能的方式是，增加缓存。常见的缓存架构如下： （1）上游是业务应用；（2）下游是主库，从库（读写分离），缓存； 如果系统架构实施了服务化： （1）上游是业务应用；（2）中间是服务；（3）下游是主库，从库，缓存； 业务层不直接面向db和cache，服务层屏蔽了底层db、cache的复杂性。 不管采用主从的方式扩展读性能，还是缓存的方式扩展读性能，数据都要复制多份（主+从，db+cache），一定会引发一致性问题。 如何保证一致性？主从数据库的一致性，通常有两种解决方案： 中间件如果某一个key有写操作，在不一致时间窗口内，中间件会将这个key的读操作也路由到主库上。 强制读主“双主高可用”的架构，主从一致性的问题能够大大缓解。 第二类不一致，是db与缓存间的不一致。 这一类不一致，《缓存架构，一篇足够？》里有非常详细的叙述，本文不再展开。 另外建议，所有允许cache miss的业务场景，缓存中的KEY都设置一个超时时间，这样即使出现不一致，有机会得到自修复。 如何保障数据库的扩展性？秒级成倍数据库扩容《亿级数据DB秒级平滑扩容》 一步一步，娓娓道来。 一般来说，并发量大，吞吐量大的互联网分层架构是怎么样的？ 数据库上层都有一个微服务，服务层记录“业务库”与“数据库实例配置”的映射关系，通过数据库连接池向数据库路由sql语句。 如上图所示，服务层配置用户库user对应的数据库实例ip。 画外音：其实是一个内网域名。 该分层架构，如何应对数据库的高可用？数据库高可用，很常见的一种方式，使用双主同步+keepalived+虚ip的方式进行。 如上图所示，两个相互同步的主库使用相同的虚ip。 当主库挂掉的时候，虚ip自动漂移到另一个主库，整个过程对调用方透明，通过这种方式保证数据库的高可用。 画外音：关于高可用，《互联网分层架构如何保证“高可用“？》专题介绍过，本文不再展开。 该分层架构，如何应对数据量的暴增？随着数据量的增大，数据库要进行水平切分，分库后将数据分布到不同的数据库实例（甚至物理机器）上，以达到降低数据量，增强性能的扩容目的。 如上图所示，用户库user分布在两个实例上，ip0和ip1，服务层通过用户标识uid取模的方式进行寻库路由，模2余0的访问ip0上的user库，模2余1的访问ip1上的user库。 画外音：此时，水平切分集群的读写实例加倍，单个实例的数据量减半，性能增长可不止一倍。 综上三点所述，大数据量，高可用的互联网微服务分层的架构如下： 既有水平切分，又保证高可用。 如果数据量持续增大，2个库性能扛不住了，该怎么办呢？ 此时，需要继续水平拆分，拆成更多的库，降低单库数据量，增加库主库实例（机器）数量，提高性能。 新的问题来了，分成n个库后，随着数据量的增加，要增加到2*n个库，数据库如何扩容，数据能否平滑迁移，能够持续对外提供服务，保证服务的可用性？ 画外音：你遇到过类似的问题么？ 停服扩容，是最容易想到的方案？ 在讨论秒级平滑扩容方案之前，先简要说明下停服务扩容的方案的步骤： （1）站点挂一个公告“为了为广大用户提供更好的服务，本站点/游戏将在今晚00:00-2:00之间升级，届时将不能登录，用户周知”； 画外音：见过这样的公告么，实际上在迁移数据。 （2）微服务停止服务，数据库不再有流量写入； （3）新建2*n个新库，并做好高可用； （4）写一个小脚本进行数据迁移，把数据从n个库里select出来，insert到2*n个库里； （5）修改微服务的数据库路由配置，模n变为模2*n； （6）微服务重启，连接新库重新对外提供服务； 整个过程中，最耗时的是第四步数据迁移。 如果出现问题，如何进行回滚？ 如果数据迁移失败，或者迁移后测试失败，则将配置改回旧库，恢复服务即可。 停服方案有什么优劣？ 优点：简单。 缺点： （1）需要停止服务，方案不高可用； （2）技术同学压力大，所有工作要在规定时间内完成，根据经验，压力越大约容易出错； 画外音：这一点很致命。 （3）如果有问题第一时间没检查出来，启动了服务，运行一段时间后再发现有问题，则难以回滚，如果回档会丢失一部分数据； 有没有秒级实施、更平滑、更帅气的方案呢？ 再次看一眼扩容前的架构，分两个库，假设每个库1亿数据量，如何平滑扩容，增加实例数，降低单库数据量呢？三个简单步骤搞定。 步骤一：修改配置 主要修改两处： 数据库实例所在的机器做双虚ip： （1）原%2=0的库是虚ip0，现增加一个虚ip00； （2）原%2=1的库是虚ip1，现增加一个虚ip11； 修改服务的配置，将2个库的数据库配置，改为4个库的数据库配置，修改的时候要注意旧库与新库的映射关系： （1）%2=0的库，会变为%4=0与%4=2； （2）%2=1的部分，会变为%4=1与%4=3； 画外音：这样能够保证，依然路由到正确的数据。 步骤二：reload配置，实例扩容 服务层reload配置，reload可能是这么几种方式： （a）比较原始的，重启服务，读新的配置文件；（b）高级一点的，配置中心给服务发信号，重读配置文件，重新初始化数据库连接池； 不管哪种方式，reload之后，数据库的实例扩容就完成了，原来是2个数据库实例提供服务，现在变为4个数据库实例提供服务，这个过程一般可以在秒级完成。 整个过程可以逐步重启，对服务的正确性和可用性完全没有影响： （a）即使%2寻库和%4寻库同时存在，也不影响数据的正确性，因为此时仍然是双主数据同步的；（b）即使%4=0与%4=2的寻库落到同一个数据库实例上，也不影响数据的正确性，因为此时仍然是双主数据同步的； 完成了实例的扩展，会发现每个数据库的数据量依然没有下降，所以第三个步骤还要做一些收尾工作。 画外音：这一步，数据库实例个数加倍了。 步骤三：收尾工作，数据收缩 有这些一些收尾工作： （a）把双虚ip修改回单虚ip； （b）解除旧的双主同步，让成对库的数据不再同步增加； （c）增加新的双主同步，保证高可用； （d）删除掉冗余数据，例如：ip0里%4=2的数据全部删除，只为%4=0的数据提供服务； 画外音：这一步，数据库单实例数据量减半了。 总结 互联网大数据量，高吞吐量，高可用微服务分层架构，数据库实现秒级平滑扩容的三个步骤为： （1）修改配置（双虚ip，微服务数据库路由）； （2）reload配置，实例增倍完成； （3）删除冗余数据等收尾工作，数据量减半完成； 思路比结论重要，希望大家有收获。 100亿数据，非“双倍”扩容，如何不影响服务，数据平滑迁移？如果不是成倍扩容： 《100亿数据平滑数据迁移,不影响服务》 如果不是“双倍”扩容，能否做到平滑迁移，不影响服务呢？ 适用什么场景？互联网有很多“数据量较大，并发量较大，业务复杂度较高”的业务场景，其典型系统分层架构如下： （1）上游是业务层biz，实现个性化的业务逻辑；（2）中游是服务层service，封装数据访问；（3）下游是数据层db，存储固化的业务数据； 服务化分层架构的好处是，服务层屏蔽下游数据层的复杂性，例如缓存、分库分表、存储引擎等存储细节不需要向调用方暴露，而只向上游提供方便的RPC访问接口，当有一些数据层变化的时候，所有的调用方也不需要升级，只需要服务层升级即可。 互联网架构，很多时候面临着这样一些需求： （1）底层表结构变更：数据量非常大的情况下，数据表增加了一些属性，删除了一些属性，修改了一些属性。 （2）分库个数变化：由于数据量的持续增加，底层分库个数非成倍增加。 （3）底层存储介质变化：底层存储引擎由一个数据库换为另一个数据库。 种种需求，都需要进行数据迁移，如何平滑迁移数据，迁移过程不停机，保证系统持续服务，是文本将要讨论的问题。 方案一：停机方案在讨论平滑迁移数据方案之前，先看下不平滑的停机数据迁移方案，主要分三个步骤。 步骤一：挂一个类似“为了给广大用户提供更好的服务，服务器会在凌晨0:00-0:400进行停机维护”的公告，并在对应时段进行停机，这个时段系统没有流量进入。 步骤二：停机后，研发一个离线的数据迁移工具，进行数据迁移。针对第一节的三类需求，会分别开发不同的数据迁移工具。 （1）底层表结构变更需求：开发旧表导新表的工具； （2）分库个数变换需求：开发2库导3库的工具； （3）底层存储介质变换需求：开发Mongo导Mysql工具； 步骤三：恢复服务，并将流量切到新库，不同的需求，可能会涉及不同服务升级。 （1）底层表结构变更需求：服务要升级到访问新表；（2）分库个数变换需求：服务不需要升级，只需要改寻库路由配置；（3）底层存储介质变换需求：服务升级到访问新的存储介质； 总的来说，停机方案是相对直观和简单的，但对服务的可用性有影响，许多游戏公司的服务器升级，游戏分区与合区，可能会采用类似的方案。 除了影响服务的可用性，这个方案还有一个缺点，就是必须在指定时间完成升级，这个对研发、测试、运维同学来说，压力会非常大，一旦出现问题例如数据不一致，必须在规定时间内解决，否则只能回滚。根据经验，人压力越大越容易出错，这个缺点一定程度上是致命的。 无论如何，停机方案并不是今天要讨论的重点，接下来看一下常见的平滑数据迁移方案。 方案二：追日志方案追日志方案，是一个高可用的平滑迁移方案，这个方案主要分为五个步骤。 数据迁移前，上游业务应用通过旧的服务访问旧的数据。 步骤一：服务进行升级，记录“对旧库上的数据修改”的日志（这里的修改，为数据的insert, delete, update），这个日志不需要记录详细数据，主要记录： （1）被修改的库；（2）被修改的表；（3）被修改的唯一主键； 具体新增了什么行，修改后的数据格式是什么，不需要详细记录。这样的好处是，不管业务细节如何变化，日志的格式是固定的，这样能保证方案的通用性。 这个服务升级风险较小： （1）写接口是少数接口，改动点较少；（2）升级只是增加了一些日志，对业务功能没有任何影响； 步骤二：研发一个数据迁移工具，进行数据迁移。这个数据迁移工具和离线迁移工具一样，把旧库中的数据转移到新库中来。 这个小工具的风险较小： （1）整个过程依然是旧库对线上提供服务；（2）小工具的复杂度较低；（3）任何时间发现问题，都可以把新库中的数据干掉重来；（4）可以限速慢慢迁移，技术同学没有时间压力； 数据迁移完成之后，就能够切到新库提供服务了么？ 答案是否定的，在数据迁移的过程中，旧库依然对线上提供着服务，库中的数据随时可能变化，这个变化并没有反映到新库中来，于是旧库和新库的数据并不一致，所以不能直接切库，需要将数据追平。 哪些数据发生了变化呢？ 步骤一中日志里记录的，正是变化的数据。 步骤三：研发一个读取日志并迁移数据的小工具，要把步骤二迁移数据过程中产生的差异数据追平。这个小工具需要做的是：（1）读取日志，得到哪个库、哪个表、哪个主键发生了变化；（2）把旧库中对应主键的记录读取出来；（3）把新库中对应主键的记录替换掉； 无论如何，原则是数据以旧库为准。 这个小工具的风险也很小：（1）整个过程依然是旧库对线上提供服务；（2）小工具的复杂度较低；（3）任何时间发现问题，大不了从步骤二开始重来；（4）可以限速慢慢重放日志，技术同学没有时间压力； 日志重放之后，就能够切到新库提供服务了么？ 答案依然是否定的，在日志重放的过程中，旧库中又可能有数据发生了变化，导致数据不一致，所以还是不能切库，需要进一步读取日志，追平记录。可以看到，重放日志追平数据的程序是一个while(1)的程序，新库与旧库中的数据追平也会是一个“无限逼近”的过程。 什么时候数据会完全一致呢？ 步骤四：在持续重放日志，追平数据的过程中，研发一个数据校验的小工具，将旧库和新库中的数据进行比对，直到数据完全一致。 这个小工具的风险依旧很小：（1）整个过程依然是旧库对线上提供服务；（2）小工具的复杂度较低；（3）任何时间发现问题，大不了从步骤二开始重来；（4）可以限速慢慢比对数据，技术同学没有时间压力； 步骤五：在数据比对完全一致之后，将流量迁移到新库，新库提供服务，完成迁移。 如果步骤四数据一直是99.9%的一致，不能完全一致，也是正常的，可以做一个秒级的旧库readonly，等日志重放程序完全追上数据后，再进行切库切流量。 至此，升级完毕，整个过程能够持续对线上提供服务，不影响服务的可用性。 方案三：双写方案双写方案，也是一个高可用的平滑迁移方案，这个方案主要分为四个步骤。 数据迁移前，上游业务应用通过旧的服务访问旧的数据。 步骤一：服务进行升级，对“对旧库上的数据修改”（这里的修改，为数据的insert, delete, update），在新库上进行相同的修改操作，这就是所谓的“双写”，主要修改操作包括：（1）旧库与新库的同时insert；（2）旧库与新库的同时delete；（3）旧库与新库的同时update； 由于新库中此时是没有数据的，所以双写旧库与新库中的affect rows可能不一样，不过这完全不影响业务功能，只要不切库，依然是旧库提供业务服务。 这个服务升级风险较小：（1）写接口是少数接口，改动点较少；（2）新库的写操作执行成功与否，对业务功能没有任何影响； 步骤二：研发一个数据迁移工具，进行数据迁移。这个数据迁移工具在本文中已经出现第三次了，把旧库中的数据转移到新库中来。 这个小工具的风险较小：（1）整个过程依然是旧库对线上提供服务；（2）小工具的复杂度较低；（3）任何时间发现问题，都可以把新库中的数据干掉重来；（4）可以限速慢慢迁移，技术同学没有时间压力； 数据迁移完成之后，就能够切到新库提供服务了么？ 答案是肯定的，因为前置步骤进行了双写，所以理论上数据迁移完之后，新库与旧库的数据应该完全一致。 由于迁移数据的过程中，旧库新库双写操作在同时进行，怎么证明数据迁移完成之后数据就完全一致了呢？ 如上图所示： （1）左侧是旧库中的数据，右侧是新库中的数据； （2）按照primary key从min到max的顺序，分段，限速进行数据的迁移，假设已经迁移到now这个数据段，数据迁移过程中的修改操作分别讨论： 假设迁移过程中进行了一个双insert操作，旧库新库都插入了数据，数据一致性没有被破坏 假设迁移过程中进行了一个双delete操作，这又分为两种情况 情况一：假设这delete的数据属于[min,now]范围，即已经完成迁移，则旧库新库都删除了数据，数据一致性没有被破坏；情况二：假设这delete的数据属于[now,max]范围，即未完成迁移，则旧库中删除操作的affect rows为1，新库中删除操作的affect rows为0，但是数据迁移工具在后续数据迁移中，并不会将这条旧库中被删除的数据迁移到新库中，所以数据一致性仍没有被破坏； 假设迁移过程中进行了一个双update操作，可以认为update操作是一个delete加一个insert操作的复合操作，所以数据仍然是一致的 除非，在一种非常极限的情况下：（1）date-migrate-tool刚好从旧库中将某一条数据X取出；（2）在X插入到新库中之前，旧库与新库中刚好对X进行了双delete操作；（3）date-migrate-tool再将X插入到新库中； 这样，会出现新库比旧库多出一条数据X。 但无论如何，为了保证数据的一致性，切库之前，还是需要进行数据校验的。 步骤三：在数据迁移完成之后，需要使用数据校验的小工具，将旧库和新库中的数据进行比对，完全一致则符合预期，如果出现步骤二中的极限不一致情况，则以旧库中的数据为准。 这个小工具的风险依旧很小：（1）整个过程依然是旧库对线上提供服务；（2）小工具的复杂度较低；（3）任何时间发现问题，大不了从步骤二开始重来；（4）可以限速慢慢比对数据，技术同学没有时间压力； 步骤四：数据完全一致之后，将流量切到新库，完成平滑数据迁移。 至此，升级完毕，整个过程能够持续对线上提供服务，不影响服务的可用性。 总结针对互联网很多“数据量较大，并发量较大，业务复杂度较高”的业务场景，在：（1）底层表结构变更；（2）分库个数变化；（3）底层存储介质变化； 的众多需求下，需要进行数据迁移，完成“平滑迁移数据，迁移过程不停机，保证系统持续服务”有两种常见的解决方案。 追日志方案，五个步骤：（1）服务进行升级，记录“对旧库上的数据修改”的日志；（2）研发一个数据迁移小工具，进行数据迁移；（3）研发一个读取日志小工具，追平数据差异；（4）研发一个数据比对小工具，校验数据一致性；（5）流量切到新库，完成平滑迁移； 双写方案，四个步骤：（1）服务进行升级，记录“对旧库上的数据修改”进行新库的双写；（2）研发一个数据迁移小工具，进行数据迁移；（3）研发一个数据比对小工具，校验数据一致性；（4）流量切到新库，完成平滑迁移； 思路比结论重要。 1万属性，100亿数据，每秒10万吞吐，架构如何设计？也可能，是要对字段进行扩展：《1万属性，100亿数据，架构设计？》，如下： 有一类业务场景，没有固定的schema存储，却有着海量的数据行数，架构上如何来实现这类业务的存储与检索呢？58最核心的数据“帖子”的架构实现技术细节，今天和大家聊一聊。 背景描述及业务介绍什么是58最核心的数据？ 58是一个信息平台，有很多垂直品类：招聘、房产、二手物品、二手车、黄页等等，每个品类又有很多子品类，不管哪个品类，最核心的数据都是“帖子信息”。 画外音：像不像一个大论坛？ 各分类帖子的信息有什么特点？ 逛过58的朋友很容易了解到，这里的帖子信息：（1）各品类的属性千差万别，招聘帖子和二手帖子属性完全不同，二手手机和二手家电的属性又完全不同，目前恐怕有近万个属性；（2）数据量巨大，100亿级别；（3）每个属性上都有查询需求，各组合属性上都可能有组合查询需求，招聘要查职位/经验/薪酬范围，二手手机要查颜色/价格/型号，二手要查冰箱/洗衣机/空调；（4）吞吐量很大，每秒几十万吞吐； 如何解决100亿数据量，1万属性，多属性组合查询，10万并发查询的技术难题呢？一步步来。 最容易想到的方案每个公司的发展都是一个从小到大的过程，撇开并发量和数据量不谈，先看看（1）如何实现属性扩展性需求；（2）多属性组合查询需求；画外音：公司初期并发量和数据量都不大，必须先解决业务问题。 如何满足业务的存储需求呢？ 最开始，业务只有一个招聘品类，那帖子表可能是这么设计的：tiezi(tid, uid, c1, c2, c3); 那如何满足各属性之间的组合查询需求呢？ 最容易想到的是通过组合索引满足查询需求：123index_1(c1, c2)index_2(c2, c3)index_3(c1, c3) 随着业务的发展，又新增了一个房产类别，存储问题又该如何解决呢？ 可以新增若干属性满足存储需求，于是帖子表变成了：1tiezi(tid, uid, c1, c2, c3, c10, c11, c12, c13); 其中： c1,c2,c3是招聘类别属性 c10,c11,c12,c13是房产类别属性 通过扩展属性，可以解决存储的问题。 查询需求，又该如何满足呢？ 首先，跨业务属性一般没有组合查询需求。只能建立了若干组合索引，满足房产类别的查询需求。 画外音：不敢想有多少个索引能覆盖所有两属性查询，三属性查询。 当业务越来越多时，是不是发现玩不下去了？ 垂直拆分是一个思路新增属性是一种扩展方式，新增表也是一种方式，垂直拆分也是常见的存储扩展方案。 如何按照业务进行垂直拆分？ 可以这么玩：123tiezi_zhaopin(tid, uid, c1, c2, c3);tiezi_fangchan(tid, uid, c10, c11, c12, c13); 在业务各异，数据量和吞吐量都巨大的情况下，垂直拆分会遇到什么问题呢？ 这些表，以及对应的服务维护在不同的部门，看上去各业务灵活性强，研发闭环，这恰恰是悲剧的开始：（1）tid如何规范？（2）属性如何规范？（3）按照uid来查询怎么办（查询自己发布的所有帖子）？（4）按照时间来查询怎么办（最新发布的帖子）？（5）跨品类查询怎么办（例如首页搜索框）？（6）技术范围的扩散，有的用mongo存储，有的用mysql存储，有的自研存储；（7）重复开发了不少组件；（8）维护成本过高；（9）… 画外音：想想看，电商的商品表，不可能一个类目一个表的。 58的玩法：三大中心服务第一：统一帖子中心服务平台型创业型公司，可能有多个品类，各品类有很多异构数据的存储需求，到底是分还是合，无需纠结：基础数据基础服务的统一，是一个很好的实践。 画外音：这里说的是平台型业务。 如何将不同品类，异构的数据统一存储起来呢？ （1）全品类通用属性统一存储；（2）单品类特有属性，品类类型与通用属性json来进行存储； 更具体的： tiezi(tid, uid, time, title, cate, subcate, xxid, ext); （1）一些通用的字段抽取出来单独存储；（2）通过cate, subcate, xxid等来定义ext是何种含义； （3）通过ext来存储不同业务线的个性化需求 例如： 招聘的帖子，ext为：1&#123;“job”:”driver”,”salary”:8000,”location”:”bj”&#125; 而二手的帖子，ext为：1&#123;”type”:”iphone”,”money”:3500&#125; 帖子数据，100亿的数据量，分256库，通过ext存储异构业务数据，使用mysql存储，上层架了一个帖子中心服务，使用memcache做缓存，就是这样一个并不复杂的架构，解决了业务的大问题。这是58最核心的帖子中心服务IMC（Info Management Center）。 画外音：该服务的底层存储在16年全面切换为了自研存储引擎，替换了mysql，但架构理念仍未变。 解决了海量异构数据的存储问题，遇到的新问题是： （1）每条记录ext内key都需要重复存储，占据了大量的空间，能否压缩存储；（2）cateid已经不足以描述ext内的内容，品类有层级，深度不确定，ext能否具备自描述性；（3）随时可以增加属性，保证扩展性； 解决完海量异构数据的存储问题，接下来，要解决的是类目的扩展性问题。 第二：统一类目属性服务每个业务有多少属性，这些属性是什么含义，值的约束等，**耦合到帖子服务里**显然是不合理的，那怎么办呢？ 抽象出一个统一的类目、属性服务，单独来管理这些信息，而帖子库ext字段里json的key，统一由数字来表示，减少存储空间。 画外音：帖子表只存元信息，不管业务含义。 如上图所示，json里的key不再是”salary” ”location” ”money” 这样的长字符串了，取而代之的是数字1,2,3,4，这些数字是什么含义，属于哪个子分类，值的校验约束，统一都存储在类目、属性服务里。 画外音：类目表存业务信息，以及约束信息，与帖子表解耦。 这个表里对帖子中心服务里ext字段里的数字key进行了解释：（1）1代表job，属于招聘品类下100子品类，其value必须是一个小于32的[a-z]字符；（2）4代表type，属于二手品类下200子品类，其value必须是一个short； 这样就对原来帖子表ext扩展属性：123&#123;“1”:”driver”,”2”:8000,”3”:”bj”&#125;&#123;”4”:”iphone”,”5”:3500&#125; key和value都做了统一约束。 除此之外，如果ext里某个key的value不是正则校验的值，而是枚举值时，需要有一个对值进行限定的枚举表来进行校验： 这个枚举校验，说明key=4的属性（对应属性表里二手，手机类型字段），其值不只是要进行“short类型”校验，而是value必须是固定的枚举值。1&#123;”4”:”iphone”,”5”:3500&#125; 这个ext就是不合法的，key=4的value=iphone不合法，而应该是枚举属性，合法的应该为：1&#123;”4”:”5”,”5”:3500&#125; 此外，类目属性服务还能记录类目之间的层级关系：（1）一级类目是招聘、房产、二手…（2）二手下有二级类目二手家具、二手手机…（3）二手手机下有三级类目二手iphone，二手小米，二手三星…（4）… 类目服务解释了帖子数据，描述品类层级关系，保证各类目属性扩展性，保证各属性值合理性校验，就是58另一个统一的核心服务CMC（Category Management Center）。 画外音：类目、属性服务像不像电商系统里的SKU扩展服务？（1）品类层级关系，对应电商里的类别层级体系；（2）属性扩展，对应电商里各类别商品SKU的属性；（3）枚举值校验，对应属性的枚举值，例如颜色：红，黄，蓝； 通过品类服务，解决了key压缩，key描述，key扩展，value校验，品类层级的问题，还有这样的一个问题没有解决：每个品类下帖子的属性各不相同，查询需求各不相同，如何解决100亿数据量，1万属性的检索与联合检索需求呢？ 第三：统一检索服务数据量很大的时候，不同属性上的查询需求，不可能通过组合索引来满足所有查询需求，“外置索引，统一检索服务”是一个很常用的实践： （1）数据库提供“帖子id”的正排查询需求；（2）所有非“帖子id”的个性化检索需求，统一走外置索引； 元数据与索引数据的操作遵循：（1）对帖子进行tid正排查询，直接访问帖子服务；（2）对帖子进行修改，帖子服务通知检索服务，同时对索引进行修改；（3）对帖子进行复杂查询，通过检索服务满足需求； 画外音：这个检索服务，扛起了58同城80%的请求（不管来自PC还是APP，不管是主页、城市页、分类页、列表页、详情页，最终都会转化为一个检索请求），它就是58另一个统一的核心服务E-search，这个搜索引擎，是完全自研的。 对于这个内核自研服务的搜索引擎架构，简单说明一下： 为应对100亿级别数据量、几十万级别的吞吐量，业务线各种复杂的复杂检索查询，扩展性是设计重点：（1）统一的代理层，作为入口，其无状态性能够保证增加机器就能扩充系统性能；（2）统一的结果聚合层，其无状态性也能够保证增加机器就能扩充系统性能；（3）搜索内核检索层，服务和索引数据部署在同一台机器上，服务启动时可以加载索引数据到内存，请求访问时从内存中load数据，访问速度很快： 为了满足数据容量的扩展性，索引数据进行了水平切分，增加切分份数，就能够无限扩展性能 为了满足一份数据的性能扩展性，同一份数据进行了冗余，理论上做到增加机器就无限扩展性能 系统时延，100亿级别帖子检索，包含请求分合，拉链求交集，从聚合层均可以做到10ms返回。 画外音：入口层是Java研发的，聚合层与检索层都是C语言研发的。 帖子业务，一致性不是主要矛盾，E-search会定期全量重建索引，以保证即使数据不一致，也不会持续很长的时间。 总结 文章写了很长，最后做一个简单总结，面对100亿数据量，1万列属性，10万吞吐量的业务需求，可以采用了元数据服务、属性服务、搜索服务来解决： 一个解决存储问题 一个解决品类解耦问题 一个解决检索问题 任何复杂问题的解决，都是循序渐进的。 思路比结论重要，希望大家有收获。 100亿数据1万属性数据架构设计《100亿数据1万属性数据架构设计》 对于version + ext方案，还是有很多朋友质疑“线上不可能这么用”。本篇将讲述一下58同城最核心的数据“帖子”的架构实现技术细节，说明不仅不是“不可能这么用”，而是大数据，可变属性，高吞吐场景下的“常用手段”。 背景描述及业务介绍问：什么是数据库扩展的version + ext方案？ 使用ext来承载不同业务需求的个性化属性，使用version来标识ext里各个字段的含义。 例如上述user表：verion=0表示ext里是passwd/nickversion=1表示ext里是passwd/nick/age/sex 优点？ （1）可以随时动态扩展属性，扩展性好（2）新旧两种数据可以同时存在，兼容性好 不足？ （1）ext里的字段无法建立索引（2）ext里的key值有大量冗余，建议key短一些 问：什么是58同城最核心的数据？ 58同城是一个信息平台，有很多垂直品类：招聘、房产、二手物品、二手车、黄页等等，每个品类又有很多子品类，不管哪个品类，最核心的数据都是“帖子信息”（业务像一个大论坛？）。 问：帖子信息有什么特点？大家去58同城的首页上看看就知道了： （1）每个品类的属性千差万别，招聘帖子和二手帖子属性完全不同，二手手机和二手家电的属性又完全不同，目前恐怕有近万个属性（2）帖子量很大，100亿级别（3）每个属性上都有查询需求（各组合属性上都可能有组合查询需求），招聘要查职位/经验/薪酬范围，二手手机要查颜色/价格/型号，二手要查冰箱/洗衣机/空调（4）查询量很大，每秒几十万级别 如何解决100亿数据量，1万属性，多属性组合查询，10万并发查询的技术难题，是今天要讨论的内容。 最容易想到的方案每个公司的发展都是一个从小到大的过程，撇开并发量和数据量不谈，先看看 （1）如何实现属性扩展性需求（2）多属性组合查询需求 最开始，可能只有一个招聘品类，那帖子表可能是这么设计的： tiezi(tid,uid, c1, c2, c3) 那如何满足各属性之间的组合查询需求呢？ 最容易想到的是通过组合索引： index_1(c1,c2) index_2(c2, c3) index_3(c1, c3) 随着业务的发展，又新增了一个房产类别，新增了若干属性，新增了若干组合查询，于是帖子表变成了： tiezi(tid,uid, c1, c2, c3, c10, c11, c12, c13) 其中c1,c2,c3是招聘类别属性，c10,c11,c12,c13是房产类别属性，这两块属性一般没有组合查询需求 但为了满足房产类别的查询需求，又要建立了若干组合索引（不敢想有多少个索引能覆盖所有两属性查询，三属性查询） 是不是发现玩不下去了？ 友商的玩法新增属性是一种扩展方式，新增表也是一种方式，有友商是这么玩的，按照业务进行垂直拆分： tiezi_zhaopin(tid,uid, c1, c2, c3)tiezi_fangchan(tid,uid, c10, c11, c12, c13) 这些表，这些服务维护在不同的部门，不同的研发同学手里，看上去各业务线灵活性强，这恰恰是悲剧的开始： （1）tid如何规范？（2）属性如何规范？（3）按照uid来查询怎么办（查询自己发布的所有帖子）？（4）按照时间来查询怎么办（最新发布的帖子）？（5）跨品类查询怎么办（例如首页搜索框）？（6）技术范围的扩散，有的用mongo存储，有的用mysql存储，有的自研存储（7）重复开发了不少组件（8）维护成本过高（9）… 想想看，电商的商品表，不可能一个类目一个表的。 58同城的玩法【统一帖子中心服务】平台型创业型公司，可能有多个品类，例如58同城的招聘房产二手，很多异构数据的存储需求，到底是分还是合，无需纠结：基础数据基础服务的统一，无疑是58同城技术路线发展roadmap上最正确的决策之一，把这个方针坚持下来，@老崔 @晓飞 这些高瞻远瞩的先贤功不可没，业务线会有“扩展性”“灵活性”上的微词，后文看看先贤们如何通过一些巧妙的技术方案来解决的。 如何将不同品类，异构的数据统一存储起来，采用的就是类似version+ext的方式： tiezi(tid,uid, time, title, cate, subcate, xxid, ext) （1）一些通用的字段抽取出来单独存储（2）通过cate, subcate, xxid等来定义ext是何种含义（和version有点像？） （3）通过ext来存储不同业务线的个性化需求 例如招聘的帖子：1ext : &#123;“job”:”driver”,”salary”:8000,”location”:”bj”&#125; 而二手的帖子：1ext : &#123;”type”:”iphone”,”money”:3500&#125; 58同城最核心的帖子数据，100亿的数据量，分256库，异构数据mysql存储，上层架了一个服务，使用memcache做缓存，就是这样一个简单的架构，一直坚持这这么多年。上层的这个服务，就是58同城最核心的统一服务IMC（Imformation Management Center），注意这个最核心，是没有之一。 解决了海量异构数据的存储问题，遇到的新问题是： （1）每条记录ext内key都需要重复存储，占据了大量的空间，能否压缩存储（2）cateid已经不足以描述ext内的内容，品类有层级，深度不确定，ext能否具备自描述性（3）随时可以增加属性，保证扩展性 【统一类目属性服务】每个业务有多少属性，这些属性是什么含义，值的约束等揉不到帖子服务里，怎么办呢？ 58同城的先贤们抽象出一个统一的类目、属性服务，单独来管理这些信息，而帖子库ext字段里json的key，统一由数字来表示，减少存储空间。 如上图所示，json里的key不再是”salary” ”location” ”money” 这样的长字符串了，取而代之的是数字1,2,3,4，这些数字是什么含义，属于哪个子分类，值的校验约束，统一都存储在类目、属性服务里。 这个表里对帖子中心服务里ext字段里的数字key进行了解释： 1代表job，属于招聘品类下100子品类，其value必须是一个小于32的[a-z]字符 4代表type，属于二手品类下200子品类，其value必须是一个short 这样就对原来帖子表ext里的123ext : &#123;“1”:”driver”,”2”:8000,”3”:”bj”&#125;ext : &#123;”4”:”iphone”,”5”:3500&#125; key和value都做了统一约束。 除此之外，如果ext里某个key的value不是正则校验的值，而是枚举值时，需要有一个对值进行限定的枚举表来进行校验： 这个枚举校验，说明key=4的属性（对应属性表里二手，手机类型字段），其值不只是要进行“short类型”校验，而是value必须是固定的枚举值。123ext : &#123;”4”:”iphone”,”5”:3500&#125; 这个ext就是不合法的（key=4的value=iphone不合法），合法的应该为ext : &#123;”4”:”5”,”5”:3500&#125; 此外，类目属性服务还能记录类目之间的层级关系： （1）一级类目是招聘、房产、二手…（2）二手下有二级类目二手家具、二手手机…（3）二手手机下有三级类目二手iphone，二手小米，二手三星…（4）… 协助解释58同城最核心的帖子数据，描述品类层级关系，保证各类目属性扩展性，保证各属性值合理性校验，就是58同城另一个统一的核心服务CMC（Category Management Center）。 多提一句，类目、属性服务像不像电商系统里的SKU扩展服务？ （1）品类层级关系，对应电商里的类别层级体系（2）属性扩展，对应电商里各类别商品SKU的属性（3）枚举值校验，对应属性的枚举值，例如颜色：红，黄，蓝 解决了key压缩，key描述，key扩展，value校验，品类层级的问题，还有这样的一个问题没有解决：每个品类下帖子的属性各不相同，查询需求各不相同，如何解决100亿数据量，1万属性的查询需求，是58同城面临的新问题。 ####【统一检索服务】 数据量很大的时候，不同属性上的查询需求，不可能通过组合索引来满足所有查询需求，怎么办呢？ 58同城的先贤们，从一早就确定了“外置索引，统一检索服务”的技术路线： （1）数据库提供“帖子id”的正排查询需求（2）所有非“帖子id”的个性化检索需求，统一走外置索引 元数据与索引数据的操作遵循： （1）对帖子进行tid正排查询，直接访问帖子服务（2）对帖子进行修改，帖子服务通知检索服务，同时对索引进行修改（3）对帖子进行复杂查询，通过检索服务满足需求 这个扛起58同城80%终端请求（不管来自PC还是APP，不管是主页、城市页、分类页、列表页、详情页，很可能这个请求最终会是一个检索请求）的服务，就是58同城另一个统一的核心服务E-search，这个搜索引擎的每一行代码都来自58同城@老崔 @老龚 等先贤们，目前系统维护者，就是“架构师之路”里屡次提到的@龙神 。 对于这个服务的架构，简单展开说明一下： 为应对100亿级别数据量、几十万级别的吞吐量，业务线各种复杂的复杂检索查询，扩展性是设计重点： （1）统一的Java代理层集群，其无状态性能够保证增加机器就能扩充系统性能（2）统一的合并层C服务集群，其无状态性也能够保证增加机器就能扩充系统性能（3）搜索内核检索层C服务集群，服务和索引数据部署在同一台机器上，服务启动时可以加载索引数据到内存，请求访问时从内存中load数据，访问速度很快（3.1）为了满足数据容量的扩展性，索引数据进行了水平切分，增加切分份数，就能够无限扩展性能（3.2）为了满足一份数据的性能扩展性，同一份数据进行了冗余，理论上做到增加机器就无限扩展性能 系统时延，100亿级别帖子检索，包含请求分合，拉链求交集，从merger层均可以做到10ms返回。 58同城的帖子业务，一致性不是主要矛盾，E-search会定期全量重建索引，以保证即使数据不一致，也不会持续很长的时间。 总结 文章写了很长，最后做一个简单总结，面对100亿数据量，1万列属性，10万吞吐量的业务需求，58同城的经验，是采用了元数据服务、属性服务、搜索服务来解决的。 总结数据库软件架构，到底要设计些什么？ 可用性 读性能 一致性 扩展性 转载自数据库软件架构，到底要设计些什么？，在原文基础上有修改","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentruan.github.io/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://vincentruan.github.io/tags/数据库/"},{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/tags/架构设计/"}]},{"title":"【转载】多次尝试学习，终于搞懂了微服务架构","slug":"【转载】多次尝试学习，终于搞懂了微服务架构","date":"2020-02-25T07:40:45.000Z","updated":"2020-02-25T15:09:15.056Z","comments":true,"path":"2020/02/25/【转载】多次尝试学习，终于搞懂了微服务架构/","link":"","permalink":"https://vincentruan.github.io/2020/02/25/【转载】多次尝试学习，终于搞懂了微服务架构/","excerpt":"什么是微服务?微服务 Microservices 之父，马丁.福勒，对微服务大概的概述如下： 就目前而言，对于微服务业界并没有一个统一的、标准的定义(While there is no precise definition of this architectural style ) 。 但通常在其而言，微服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分成一组小的服务，每个服务运行独立的自己的进程中，服务之间互相协调、互相配合，为用户提供最终价值。 服务之间采用轻量级的通信机制互相沟通(通常是基于 HTTP 的 RESTful API ) 。每个服务都围绕着具体业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。 另外，应尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务。可以使用不同的语言来编写服务，也可以使用不同的数据存储。","text":"什么是微服务?微服务 Microservices 之父，马丁.福勒，对微服务大概的概述如下： 就目前而言，对于微服务业界并没有一个统一的、标准的定义(While there is no precise definition of this architectural style ) 。 但通常在其而言，微服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分成一组小的服务，每个服务运行独立的自己的进程中，服务之间互相协调、互相配合，为用户提供最终价值。 服务之间采用轻量级的通信机制互相沟通(通常是基于 HTTP 的 RESTful API ) 。每个服务都围绕着具体业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。 另外，应尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务。可以使用不同的语言来编写服务，也可以使用不同的数据存储。 根据马丁.福勒的描述，我总结了以下几点： 小服务小服务，没有特定的标准或者规范，但他在总体规范上一定是小的。 进程独立每一组服务都是独立运行的，可能我这个服务运行在 Tomcat 容器，而另一个服务运行在 Jetty 上。可以通过进程方式，不断的横向扩展整个服务。 通信过去的协议都是很重的，就像 ESB，就像 SOAP，轻通信，这意味着相比过去更智能更轻量的服务相互调用，就所谓 smart endpoints and dumb pipes。 这些 Endpoint 都是解耦的，完成一个业务通信调用串起这些 Micro Service 就像是 Linux 系统中通过管道串起一系列命令业务。 过去的业务，我们通常会考虑各种各样的依赖关系，考虑系统耦合带来的问题。微服务，可以让开发者更专注于业务的逻辑开发。 部署不止业务要独立，部署也要独立。不过这也意味着，传统的开发流程会出现一定程度的改变，开发的适合也要有一定的运维职责。 管理传统的企业级 SOA 服务往往很大，不易于管理，耦合性高，团队开发成本比较大。 微服务，可以让团队各思其政的选择技术实现，不同的 Service 可以根据各自的需要选择不同的技术栈来实现其业务逻辑。 微服务的利与弊为什么用微服务呢?因为好玩?不是的。下面是我从网络上找到说的比较全的优点： 优点是每个服务足够内聚，足够小，代码容易理解这样能聚焦一个指定的业务功能或业务需求。 开发简单、开发效率提高，一个服务可能就是专一的只干一件事。 微服务能够被小团队单独开发，这个小团队是 2 到 5 人的开发人员组成。 微服务是松耦合的，是有功能意义的服务，无论是在开发阶段或部署阶段都是独立的。 微服务能使用不同的语言开发。 易于和第三方集成，微服务允许容易且灵活的方式集成自动部署，通过持续集成工具，如 Jenkins，Hudson，bamboo。 微服务易于被一个开发人员理解，修改和维护，这样小团队能够更关注自己的工作成果。无需通过合作才能体现价值。微服务允许你利用融合最新技术。 微服务只是业务逻辑的代码，不会和 HTML，CSS 或其他界面组件混合。 每个微服务都有自己的存储能力，可以有自己的数据库，也可以有统一数据库。 总的来说，微服务的优势，就是在于，面对大的系统，可以有效的减少复杂程度，使服务架构的逻辑更清晰明了。 但是这样也会带来很多问题，就譬如分布式环境下的数据一致性，测试的复杂性，运维的复杂性。 什么组织适合使用微服务?微服务带了种种优点，种种弊端，那么什么组织适合使用微服务? 墨菲定律(设计系统)和康威定律(系统划分)康威定律，是一个五十多年前就被提出来的微服务概念。在康威的这篇文章中，最有名的一句话就是： Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations. -Melvin Conway(1967) 中文直译大概的意思就是：设计系统的组织，其产生的设计等同于组织之内、组织之间的沟通结构。 看看下面的图片，再想想 Apple 的产品、微软的产品设计，就能形象生动的理解这句话。 感兴趣的各位可以研究一下! 架构演化架构是不断演化出来的，微服务也是这样，当从各大科技公司，规模大到一定程度，完全需要演化成更进一步管理的技术架构体系。 传统的团队，都是面向过程化的，产品想完了去找策划，策划完了找开发，接着顺着一步一步找。 我们做技术都是为了产品的，一旦过程出来了什么问题，回溯寻找问题会非常耗时。 使用了微服务架构体系，团队组织方式需要转变成跨职能团队，即每个团队都有产品专家，策划专家，开发专家，运维专家，他们使用 API 方式发布他们的功能，而平台使用他们的功能发布产品。 微服务技术架构体系下面我分享一下大部分公司都使用的微服务技术架构体系： 服务发现主流的服务发现，分为三种： 第一种，开发人员开发了程序以后，会找运维配一个域名，服务的话通过 DNS 就能找到我们对应的服务。 缺点是，由于服务没有负载均衡功能，对负载均衡服务，可能会有相当大的性能问题。 第二种，是目前普遍的做法。可以参考 Zuul 网关，每一个服务都通过服务端内置的功能注册到注册中心，服务消费者不断轮询注册中心发现对应的服务，使用内置负载均衡调用服务。 缺点是，对多语言环境不是很好，你需要单独给消费者的客户端开发服务发现和负载均衡功能。当然了，这个方法通常都是用在 Spring Cloud 上的。 第三种，是将客户端和负载均衡放在同一个主机，而不是同一个进程内。 这种方法相对第一种第二种方法来说，改善了他们的缺点，但是会极大增加运维成本。 网关微服务的网关是什么?我们可以联系生活实际想一下。每一个大的公司，都会有一偏属于自己的建筑区，而这建筑区内，都有不少的门卫。如果有外来人员进入公司，会先和门卫打好招呼，才能进去。 将生活实际联系到微服务上，就不难理解网关的意思了： 网关的作用如下： 反向路由：很多时候，公司不想让外部人员看到我们公司的内部，就需要网关来进行反向路由。即将外部请求转换成内部具体服务调用。 安全认证：网络中会有很多恶意访问，譬如爬虫，譬如黑客攻击，网关维护安全功能。 限流熔断：当请求很多服务不堪重负，会让我们的服务自动关闭，导致不能用服务。限流熔断可以有效的避免这类问题。 日志监控：所有的外面的请求都会经过网关，这样我们就可以使用网关来记录日志信息。 灰度发布，蓝绿部署。是指能够平滑过渡的一种发布方式。在其上可以进行 A/B testing。 即让一部分用户继续用产品特性 A，一部分用户开始用产品特性 B，如果用户对 B 没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到 B 上面来。 开源网关 Zuul 架构： Zuul 网关核心其实是一个 Servlet，所有请求都会经过 Zuul Servlet 传到 ZuulFilter Runner，然后分发到三种过滤器。 先说说架构图左半部分，分别是使用 Groovy 实现的前置路由过滤器，路由过滤器，后置路由过滤器。 一般请求都会先经过前置路由过滤器处理，一般的自定义 Java 封装逻辑也会在这里实现。 路由过滤器，实现的是找到对应的微服务进行调用。调用完了，响应回来，会经过后置路由过滤器，通过后置路由过滤器我们可以封装日志审计的处理。 可以说 Zuul 网关最大的特色就是它的三层过滤器。架构图右半部分，是 Zuul 网关设计的自定义过滤器加载机制。 网关内部会有生产者消费者模型，自动的将过滤器脚本发布到 Zuul 网关读取加载运行。 配置中心以前，开发人员把配置文件放在开发文件里面，这样会有很多隐患。譬如，配置规范不同，无法追溯配置人员。 一旦需要大规模改动配置，改动时间会很长，无法追溯配置人员，从而影响整个产品，后果是我们承担不起的。 因此就有配置中心这个喽!现在的开源中心有百度配置中心 Disconf，Spring Cloud Config，Apollo。 今天重点说说现在应用质量不错的配置中心，携程开源的阿波罗(Apollo)： Apollo 的配置中心规模比较大，本地应用会有响应的配置中心客户端，可以定时同步配置中心里的配置。如果配置中心怠机，会使用缓存来进行配置。 通讯方式关于通讯方式，一般市面也就是两种远程调用方式，我整理了一个表格： 监控预警监控预警对于微服务很重要，一个可靠的监控预警体系对微服务运行至关重要。 一般监控分为如下层次： 从基础设施到用户端，层层有监控，全方位，多角度，每一个层面都很重要。 总体来说，微服务可分为 5 个监控点： 日志监控 Metrics 监控 健康检查 调用链检查 告警系统 监控架构下面的图是大部分公司的一种监控架构图。每一个服务都有一个 Agent，Agent 收集到关键信息，会传到一些 MQ 中，为了解耦。 同时将日志传入 ELK，将 Metrics 传入 InfluxDB 时间序列库。而像 Nagios，可以定期向 Agent 发起信息检查微服务。 调用链监控 APM很多公司都有调用链监控，就譬如阿里有鹰眼监控，点评的 Cat，大部分调用链监控(没错，我指的 Zipkin)架构是这样的： 当请求进入 Web 容器的时候，会经过创建 Tracer，连接 Spans(模拟潜在的分布式工作的延迟，该模块还包含在系统网络间传递跟踪上下文信息的工具包，如通过 HTTP Headers)。 Spans 有一个上下文，其中包含 Tracer 标识符，将其放在表示分布式操作的树的正确位置。 当我们把图中的各种 Span 放到后端的时候，我们的服务调用链会动态的生成调用链。 下面是一些市场上用的比较多的调用链监控对比： 熔断、隔离、限流、降级面对巨大的突发流量下，大型公司一般会采用一系列的熔断(系统自动将服务关闭防止让出现的问题最大化)、隔离(将服务和服务隔离，防止一个服务挂了其他服务不能访问)、限流(单位时间内之允许一定数量用户访问)、降级(当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，我们可以将一些不重要或不紧急的服务或任务进行服务的延迟使用或暂停使用)措施。 下面介绍一下 Hystrix 的运行流程： 每一个微服务调用时，都会使用 Hystrix 的 Command 方式(上图的左上角那个)，然后使用 Command 同步的，或者是响应式的，或者是异步的，判断电路是否熔断(顺着图从左往右看)，如果断路则走降级 Fallback。 如果这个线闭合着，但是线程资源没了，队列满了，则走限流措施(看图的第 5 步)。 如果走完了，执行成功了，则走 run() 方法，获取 Response，但是这个过程如果出错了，则继续走降级 Fallback。 同时，看图最上面有一个后缀是 Health 的，这是一个计算整个链路是否健康的组件，每一步操作都被它记录着。 容器与服务编排引擎从物理机到虚拟机，从虚拟机到容器;从物理集群到 OpenStack，OpenStack 到 Kubernetes;科技不断的变化，我们的认知也没刷新。 我们从容器开始说起，它首先是一个相对独立的运行环境，在这一点有点类似于虚拟机，但是不像虚拟机那样彻底。 虚拟机会将虚拟硬件、内核(即操作系统)以及用户空间打包在新虚拟机当中，虚拟机能够利用“虚拟机管理程序”运行在物理设备之上。 虚拟机依赖于 Hypervisor，其通常被安装在“裸金属”系统硬件之上，这导致 Hypervisor 在某些方面被认为是一种操作系统。 一旦 Hypervisor 安装完成， 就可以从系统可用计算资源当中分配虚拟机实例了，每台虚拟机都能够获得唯一的操作系统和负载(应用程序)。 简言之，虚拟机先需要虚拟一个物理环境，然后构建一个完整的操作系统，再搭建一层 Runtime，然后供应用程序运行。 对于容器环境来说，不需要安装主机操作系统，直接将容器层(比如 LXC 或 Libcontainer)安装在主机操作系统(通常是 Linux 变种)之上。 在安装完容器层之后，就可以从系统可用计算资源当中分配容器实例了，并且企业应用可以被部署在容器当中。 但是，每个容器化应用都会共享相同的操作系统(单个主机操作系统)。容器可以看成一个装好了一组特定应用的虚拟机，它直接利用了宿主机的内核，抽象层比虚拟机更少，更加轻量化，启动速度极快。 相比于虚拟机，容器拥有更高的资源使用效率，因为它并不需要为每个应用分配单独的操作系统——实例规模更小、创建和迁移速度也更快。这意味着相比于虚拟机，单个操作系统能够承载更多的容器。 云提供商十分热衷于容器技术，因为在相同的硬件设备当中，可以部署数量更多的容器实例。 此外，容器易于迁移，但是只能被迁移到具有兼容操作系统内核的其他服务器当中，这样就会给迁移选择带来限制。 因为容器不像虚拟机那样同样对内核或者虚拟硬件进行打包，所以每套容器都拥有自己的隔离化用户空间，从而使得多套容器能够运行在同一主机系统之上。 我们可以看到全部操作系统层级的架构都可实现跨容器共享，惟一需要独立构建的就是二进制文件与库。 正因为如此，容器才拥有极为出色的轻量化特性。我们最常用的容器是 Docker。 容器编排过去虚拟机可以通过云平台 OpenStack 管理虚拟化，容器时代如何管理容器呢?这就要看看容器编排引擎了。 Apache Mesos：Mesos 是基于 Master，Slave 架构，框架决定如何利用资源，Master 负责管理机器，Slave 会定期的将机器情况报告给 Master，Master 再将信息给框架。Master 是高可用的，因为 ZK，也有 Leader 的存在。 下面是架构图： Kubernetes：Kubernetes 是最近十分火热的开源容器编排引擎，具体可以参考前几天分享的一篇文章《我花了10个小时，写出了这篇K8S架构解析》 Kubernetes 设计理念和功能其实就是一个类似 Linux 的分层架构，先说说每一个 Kubernetes 节点内部，kubelet 管理全局全局 pod，而每一个 pod 承载着一个或多个容器，kube-proxy 负责网络代理和负载均衡。 Kubernetes 节点外部，则是对应的控制管理服务器，负责统一管理各个节点调度分配与运行。 服务网格化关于服务网络化，后面会更加深入的为大家进行讲解。 资料与文献 马丁.福勒对微服务的描述 微服务架构的理论基础 - 康威定律 调用链选型之Zipkin，Pinpoint，SkyWalking，CAT 原文转载自多次尝试学习，终于搞懂了微服务架构","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/categories/架构设计/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://vincentruan.github.io/tags/微服务/"}]},{"title":"【转载】我花了10个小时，写出了这篇K8S架构解析","slug":"【转载】我花了10个小时，写出了这篇K8S架构解析","date":"2020-02-25T07:40:31.000Z","updated":"2020-02-25T15:09:15.057Z","comments":true,"path":"2020/02/25/【转载】我花了10个小时，写出了这篇K8S架构解析/","link":"","permalink":"https://vincentruan.github.io/2020/02/25/【转载】我花了10个小时，写出了这篇K8S架构解析/","excerpt":"互联网技术飞速发展的今天，为了承载请求的高并发和业务的多样性，微服务的架构成了各个公司的标配。 每个微服务通过 Docker 进行发布，随着业务的发展，系统中遍布着各种各样的容器。于是，容器的资源调度，部署运行，扩容缩容就是我们要面临的问题。 基于 Kubernetes 作为容器集群的管理平台被广泛应用，今天我们一起来看看 Kubernetes 的架构中有那些常用的组件以及运行原理。","text":"互联网技术飞速发展的今天，为了承载请求的高并发和业务的多样性，微服务的架构成了各个公司的标配。 每个微服务通过 Docker 进行发布，随着业务的发展，系统中遍布着各种各样的容器。于是，容器的资源调度，部署运行，扩容缩容就是我们要面临的问题。 基于 Kubernetes 作为容器集群的管理平台被广泛应用，今天我们一起来看看 Kubernetes 的架构中有那些常用的组件以及运行原理。 Kubernetes 架构概述Kubernetes 是用来管理容器集群的平台。既然是管理集群，那么就存在被管理节点，针对每个 Kubernetes 集群都由一个 Master 负责管理和控制集群节点。 我们通过 Master 对每个节点 Node 发送命令。简单来说，Master 就是管理者，Node 就是被管理者。 Node 可以是一台机器或者一台虚拟机。在 Node 上面可以运行多个 Pod，Pod 是 Kubernetes 管理的最小单位，同时每个 Pod 可以包含多个容器（Docker）。 通过下面的 Kubernetes 架构简图可以看到 Master 和 Node 之间的关系： Kubernetes 架构简图通常我们都是通过 kubectl 对 Kubernetes 下命令的，它通过 APIServer 去调用各个进程来完成对 Node 的部署和控制。 APIServer 的核心功能是对核心对象（例如：Pod，Service，RC）的增删改查操作，同时也是集群内模块之间数据交换的枢纽。 它包括了常用的 API，访问（权限）控制，注册，信息存储（etcd）等功能。在它的下面我们可以看到 Scheduler，它将待调度的 Pod 绑定到 Node 上，并将绑定信息写入 etcd 中。 etcd 包含在 APIServer 中，用来存储资源信息。接下来就是 Controller Manager 了，如果说 Kubernetes 是一个自动化运行的系统，那么就需要有一套管理规则来控制这套系统。 Controller Manager 就是这个管理者，或者说是控制者。它包括 8 个 Controller，分别对应着副本，节点，资源，命名空间，服务等等。 紧接着，Scheduler 会把 Pod 调度到 Node 上，调度完以后就由 kubelet 来管理 Node 了。 kubelet 用于处理 Master 下发到 Node 的任务（即 Scheduler 的调度任务），同时管理 Pod 及 Pod 中的容器。 在完成资源调度以后，kubelet 进程也会在 APIServer 上注册 Node 信息，定期向 Master 汇报 Node 信息，并通过 cAdvisor 监控容器和节点资源。 由于，微服务的部署都是分布式的，所以对应的 Pod 以及容器的部署也是。为了能够方便地找到这些 Pod 或者容器，引入了 Service（kube-proxy）进程，它来负责反向代理和负载均衡的实施。 上面就是 Kubernetes 架构的简易说明，涉及到了一些核心概念以及简单的信息流动。 将一些功能收录到了 APIServer 中，这个简图比官网的图显得简单一些，主要是方便大家记忆。 后面我们会用一个简单的例子，带大家把 Kubernetes 的概念的由来做深入的了解。 从一个例子开始假设使用 Kubernetes 部署 Tomcat 和 MySQL 服务到两个 Node 上面。其中 Tomcat 服务生成两个实例也就是生成两个 Pod，用来对其做水平扩展。 MySQL 只部署一个实例，也就是一个 Pod。可以通过外网访问 Tomcat，而 Tomcat 可以在内网访问 MySQL。 例子示意图这里我们假设 Kubernetes 和 Docker 的安装都已经完成，并且镜像文件都已经准备好了。重点看 Kubernetes 如何部署和管理容器。 kubectl 和 APIServer既然我们要完成上面的例子，接下来就要部署两个应用。 首先，根据要部署的应用建立 Replication Controller（RC）。RC 是用来声明应用副本的个数，也就是 Pod 的个数。 按照上面的例子，Tomcat 的 RC 就是 2，MySQL 的 RC 就是 1。 由于 kubectl 作为用户接口向 Kubernetes 下发指令，那么指令是通过“.yaml”的配置文件编写的。 定义 ysql-rc.yaml 的配置文件来描述 MySQL 的 RC： 123456789101112131415161718192021apiVersion: V1kind: ReplicationControllermetadata: name: mysql#RC的名称，全局唯一spec: replicas:1 #Pod 副本的期待数量selector :app: mysql template: #Pod模版，用这个模版来创建Podmetadata: labels:app:mysql#Pod副本的标签spec: containers:#容器定义部分 -name:mysqlImage:mysql#容器对应的DockerImage Ports: -containerPort:3306#容器应用监听的端口号 Env:#注入容器的环境变量 -name:MYSQL_ROOT_PASSWORD Value:”123456” 从上面的配置文件可以看出，需要对这个 RC 定义一个名字，以及期望的副本数，以及容器中的镜像文件。然后通过 kubectl 作为客户端的 cli 工具，执行这个配置文件。 通过 kubectl 执行 RC 配置文件执行了上面的命令以后，Kubernetes 会帮助我们部署副本 MySQL 的 Pod 到 Node。 此时先不着急看结果，回到最开始的架构图，可以看到 kubectl 会向 Master 中的 APIServer 发起命令，看看 APIServer 的结构和信息的传递吧。 Kubernetes API Server 通过一个名为 kube-apiserver 的进程提供服务，该进程运行在 Master 上。 可以通过 Master 的 8080 端口访问 kube-apiserver 进程，它提供 REST 服务。 因此可以通过命令行工具 kubectl 来与 Kubernetes APIServer 交互，它们之间的接口是 RESTful API。 APIServer 的架构从上到下分为四层： API 层：主要以 REST 方式提供各种 API 接口，针对 Kubernetes 资源对象的 CRUD 和 Watch 等主要 API，还有健康检查、UI、日志、性能指标等运维监控相关的 API。 访问控制层：负责身份鉴权，核准用户对资源的访问权限，设置访问逻辑（Admission Control）。 注册表层：选择要访问的资源对象。PS：Kubernetes 把所有资源对象都保存在注册表（Registry）中，例如：Pod，Service，Deployment 等等。 etcd 数据库：保存创建副本的信息。用来持久化 Kubernetes 资源对象的 Key-Value 数据库。 APIServer 分层架构图当 kubectl 用 Create 命令建立 Pod 时，是通过 APIServer 中的 API 层调用对应的 RESTAPI 方法。 之后会进入权限控制层，通过 Authentication 获取调用者身份，Authorization 获取权限信息。 AdmissionControl 中可配置权限认证插件，通过插件来检查请求约束。例如：启动容器之前需要下载镜像，或者检查具备某命名空间的资源。 还记得 mysql-rc.yaml 中配置需要生成的 Pod 的个数为 1。到了 Registry 层会从 CoreRegistry 资源中取出 1 个 Pod 作为要创建的 Kubernetes 资源对象。 然后将 Node，Pod 和 Container 信息保存在 etcd 中去。这里的 etcd 可以是一个集群，由于里面保存集群中各个 Node/Pod/Container 的信息，所以必要时需要备份，或者保证其可靠性。 Controller Manager，Scheduler 和 kubelet前面通过 kubectl 根据配置文件，向 APIServer 发送命令，在 Node 上面建立 Pod 和 Container。 在 APIServer，经过 API 调用，权限控制，调用资源和存储资源的过程。实际上还没有真正开始部署应用。 这里需要 Controller Manager，Scheduler 和 kubelet 的协助才能完成整个部署过程。 在介绍他们协同工作之前，要介绍一下在 Kubernetes 中的监听接口。从上面的操作知道，所有部署的信息都会写到 etcd 中保存。 实际上 etcd 在存储部署信息的时候，会发送 Create 事件给 APIServer，而 APIServer 会通过监听（Watch）etcd 发过来的事件。其他组件也会监听（Watch）APIServer 发出来的事件。 Kubernetes 就是用这种 List-Watch 的机制保持数据同步的，如上图： 这里有三个 List-Watch，分别是 kube-controller-manager（运行在Master），kube-scheduler（运行在 Master），kublete（运行在 Node）。他们在进程已启动就会监听（Watch）APIServer 发出来的事件。 kubectl 通过命令行，在 APIServer 上建立一个 Pod 副本。 这个部署请求被记录到 etcd 中，存储起来。 当 etcd 接受创建 Pod 信息以后，会发送一个 Create 事件给 APIServer。 由于 Kubecontrollermanager 一直在监听 APIServer 中的事件。此时 APIServer 接受到了 Create 事件，又会发送给 Kubecontrollermanager。 Kubecontrollermanager 在接到 Create 事件以后，调用其中的 Replication Controller 来保证 Node 上面需要创建的副本数量。 上面的例子 MySQL 应用是 1 个副本，Tomcat 应用是两个副本。一旦副本数量少于 RC 中定义的数量，Replication Controller 会自动创建副本。总之它是保证副本数量的 Controller。PS：扩容缩容的担当。 在 Controller Manager 创建 Pod 副本以后，APIServer 会在 etcd 中记录这个 Pod 的详细信息。例如在 Pod 的副本数，Container 的内容是什么。 同样的 etcd 会将创建 Pod 的信息通过事件发送给 APIServer。 由于 Scheduler 在监听（Watch）APIServer，并且它在系统中起到了“承上启下”的作用，“承上”是指它负责接收创建的 Pod 事件，为其安排 Node；“启下”是指安置工作完成后，Node 上的 kubelet 服务进程接管后继工作，负责 Pod 生命周期中的“下半生”。 换句话说，Scheduler 的作用是将待调度的 Pod 按照调度算法和策略绑定到集群中 Node 上，并将绑定信息写入 etcd 中。 Scheduler 调度完毕以后会更新 Pod 的信息，此时的信息更加丰富了。除了知道 Pod 的副本数量，副本内容。还知道部署到哪个 Node 上面了。 同样，将上面的 Pod 信息更新到 etcd 中，保存起来。 etcd 将更新成功的事件发送给 APIServer。 注意这里的 kubelet 是在 Node 上面运行的进程，它也通过 List-Watch 的方式监听（Watch）APIServer 发送的 Pod 更新的事件。实际上，在第 9 步的时候创建 Pod 的工作就已经完成了。 为什么 kubelete 还要一直监听呢？原因很简单，假设这个时候 kubectl 发命令，需要把原来的 MySQL 的 1 个 RC 副本扩充成 2 个。那么这个流程又会触发一遍。 作为 Node 的管理者 kubelet 也会根据最新的 Pod 的部署情况调整 Node 端的资源。 又或者 MySQL 应用的 RC 个数没有发生变化，但是其中的镜像文件升级了，kubelet 也会自动获取最新的镜像文件并且加载。 通过上面 List-Watch 的介绍大家发现了，除了之前引入的 kubectl 和 APIServer 以外又引入了 Controller Manager，Scheduler 和 kubelet。 这里给大家介绍一下他们的作用和原理： 聚焦 Scheduler，Controller Manager，kubelet Controller ManagerKubernetes 需要管理集群中的不同资源，所以针对不同的资源要建立不同的 Controller。 每个 Controller 通过监听机制获取 APIServer 中的事件（消息），它们通过 API Server 提供的（List-Watch）接口监控集群中的资源，并且调整资源的状态。 可以把它想象成一个尽职的管理者，随时管理和调整资源。比如 MySQL 所在的 Node 意外宕机了，Controller Manager 中的 Node Controller 会及时发现故障，并执行修复流程。 在部署了成百上千微服务的系统中，这个功能极大地协助了运维人员。从此可以看出，Controller Manager 是 Kubernetes 资源的管理者，是运维自动化的核心。 它分为 8 个 Controller，上面我们介绍了 Replication Controller，这里我们把其他几个都列出来，就不展开描述了。 Controller Manager 中不同的 Controller 负责对不同资源的监控和管理 Scheduler 与 kubeletScheduler 的作用是，将待调度的 Pod 按照算法和策略绑定到 Node 上，同时将信息保存在 etcd 中。 如果把 Scheduler 比作调度室，那么这三件事就是它需要关注的，待调度的 Pod、可用的 Node，调度算法和策略。 简单地说，就是通过调度算法/策略把 Pod 放到合适的 Node 中去。此时 Node 上的 kubelet 通过 APIServer 监听到 Scheduler 产生的 Pod 绑定事件，然后通过 Pod 的描述装载镜像文件，并且启动容器。 也就是说 Scheduler 负责思考，Pod 放在哪个 Node，然后将决策告诉 kubelet，kubelet 完成 Pod 在 Node 的加载工作。 说白了，Scheduler 是 boss，kubelet 是干活的工人，他们都通过 APIServer 进行信息交换。 Scheduler 与 kubelet 协同工作图 Service 和 kubelet经历上面一系列的过程，终于将 Pod 和容器部署到 Node 上了。 MySQL 部署成功作为部署在 Kubernetes 中，Pod 如何访问其他的 Pod 呢？答案是通过 Kubernetes 的 Service 机制。 在 Kubernetes 中的 Service 定义了一个服务的访问入口地址（IP+Port）。Pod 中的应用通过这个地址访问一个或者一组 Pod 副本。 Service 与后端 Pod 副本集群之间是通过 Label Selector 来实现连接的。Service 所访问的这一组 Pod 都会有同样的 Label，通过这样的方法知道这些 Pod 属于同一个组。 Pod 通过 Service 访问其他 Pod写 MySQL 服务的配置文件（mysql-svc.yaml）如下： 123456789apiVersion : v1kind: Service #说明创建资源对象的类型是Servicemetadata: name: mysql#Service全局唯一名称spec:prots:-port: 3306#Service的服务端口号 selector:#Service对应的Pod标签，用来给Pod分类 app: mysql 按照惯例运行 kubectl，创建 Service： 再用 getsvc 命令检查 Service 信息： 这里的 Cluster-IP 169.169.253.143 是由 Kubernetes 自动分配的。当一个 Pod 需要访问其他的 Pod 的时候就需要通过 Service 的 Cluster-IP 和 Port。 也就是说 Cluster-IP 和 Port 是 Kubernetes 集群的内部地址，是提供给集群内的 Pod 之间访问使用的，外部系统是无法通过这个 Cluster-IP 来访问 Kubernetes 中的应用的。 上面提到的 Service 只是一个概念，而真正将 Service 落实的是 kube-proxy。 只有理解了 kube-proxy 的原理和机制，我们才能真正理解 Service 背后的实现逻辑。 在 Kubernetes 集群的每个 Node 上都会运行一个 kube-proxy 服务进程，我们可以把这个进程看作 Service 的负载均衡器，其核心功能是将到 Service 的请求转发到后端的多个 Pod 上。 此外，Service 的 Cluster-IP 与 NodePort 是 kube-proxy 服务通过 iptables 的 NAT 转换实现的。kube-proxy 在运行过程中动态创建与 Service 相关的 iptables 规则。 由于 iptables 机制针对的是本地的 kube-proxy 端口，所以在每个 Node 上都要运行 kube-proxy 组件。 因此在 Kubernetes 集群内部，可以在任意 Node 上发起对 Service 的访问请求。 集群内部通过 kube-proxy（Service）访问其他 Pod正如 MySQL 服务，可以被 Kubernetes 内部的 Tomcat 调用，那么 Tomcat 如何被 Kubernetes 外部调用？ 先生成配置文件，myweb-rc.yaml 看看： 123456789101112131415161718apiVersion: V1kind: ReplicationControllermetadata: name: myweb#RC的名称，全局唯一spec: replicas:2#Pod 副本的期待数量，这里的数量是2，需要建立两个Tomcat的副本selector :app: myweb template: #Pod模版，用这个模版来创建Podmetadata: labels:app:myweb#Pod副本的标签spec: containers: #容器定义部分 -name:mysqlImage:kubeguide/tomcat-app:v1#容器对应的DockerImage Ports: -containerPort:8080#容器应用监听的端口号 在 kubectl 中使用 Create 建立 myweb 副本。 副本创建完毕以后，创建对应的服务配置文件 myweb-svc.yaml。 12345678910apiVersion : v1kind: Service #说明创建资源对象的类型是Servicemetadata: name: myweb#Service全局唯一名称spec:prots:-port: 8080#Service的服务端口号nodePort: 30001#这个就是外网访问Kubernetes内部应用的端口。 selector: #Service对应的Pod标签，用来给Pod分类 app: myweb 同样在 kubectl 中运行 Create 命令，建立 Service 资源。 从上面的配置文件可以看出，Tomcat 的 Service 中多了一个 nodePort 的配置，值为 30001。 也就是说外网通过 30001 这个端口加上 NodeIP 就可以访问 Tomcat 了。 运行命令之后，得到一个提示，大致意思是“如果你要将服务暴露给外网使用，你需要设置防火墙规则让 30001 端口能够通行。” 由于 Cluster-IP 是一个虚拟的 IP，仅供 Kubernetes 内部的 Pod 之间的通信。 Node 作为一个物理节点，因此需要使用 Node-IP 和 nodePort 的组合来从 Kubernetes 外面访问内部的应用。 如果按照上面的配置，部署了两个 Tomcat 应用，当外网访问时选择那个 Pod 呢？这里需要通过 Kubernetes 之外的负载均衡器来实现的。 Kubernetes 之外的负载均衡器可以通过 Kubernetes 的 LoadBlancerService 组件来协助实现。通过云平台申请创建负载均衡器，向外暴露服务。 目前 LoadBlancerService 组件支持的云平台比较完善，比如国外的 GCE、DigitalOcean，国内的阿里云，私有云 OpenStack 等等。 从用法上只要把 Service 的 type=NodePort 改为 type=LoadBalancer，Kubernetes 就会自动创建一个对应的 Load Balancer 实例并返回它的 IP 地址供外部客户端使用。 至此，MySQL（RC 1）和 Tomcat（RC 2）已经在 Kubernetes 部署了。并在 Kubernetes 内部 Pod 之间是可以互相访问的，在外网也可以访问到 Kubernetes 内部的 Pod。 Pod 在 Kubernetes 内互相访问，外网访问 Pod另外，作为资源监控 Kubernetes 在每个 Node 和容器上都运行了 cAdvisor。它是用来分析资源使用率和性能的工具，支持 Docker 容器。 kubelet 通过 cAdvisor 获取其所在 Node 及容器（Docker）的数据。cAdvisor 自动采集 CPU、内存、文件系统和网络使用的统计信息。 kubelet 作为 Node 的管理者，把 cAdvisor 采集上来的数据通过 RESTAPI 的形式暴露给 Kubernetes 的其他资源，让他们知道 Node/Pod 中的资源使用情况。 总结由于微服务的迅猛发展，Kubernetes 作为微服务治理平台被广泛应用。由于其发展时间长，包含服务功能多我们无法一一列出。 因此，从一个简单的创建应用副本的例子入手，介绍了各个重要组件的概念和基本原理。 Kubernetes 是用来管理容器集群的，Master 作为管理者，包括 APIServer，Scheduler，Controller Manager。 Node作为副本部署的载体，包含多个 Pod，每个 Pod 又包含多个容器（container）。用户通过 kubectl 给 Master 中的 APIServer 下部署命令。 命令主体是以“.yaml”结尾的配置文件，包含副本的类型，副本个数，名称，端口，模版等信息。 APIServer 接受到请求以后，会分别进行以下操作：权限验证（包括特殊控制），取出需要创建的资源，保存副本信息到etcd。 APIServer 和 Controller Manager，Scheduler 以及 kubelete 之间通过 List-Watch 方式通信（事件发送与监听）。 Controller Manager 通过 etcd 获取需要创建资源的副本数，交由 Scheduler 进行策略分析。 最后 kubelet 负责最终的 Pod 创建和容器加载。部署好容器以后，通过 Service 进行访问，通过 cAdvisor 监控资源。 原文转载自51CTO技术栈，崔皓，我花了10个小时，写出了这篇K8S架构解析","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/categories/架构设计/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://vincentruan.github.io/tags/架构/"},{"name":"微服务","slug":"微服务","permalink":"https://vincentruan.github.io/tags/微服务/"},{"name":"k8s","slug":"k8s","permalink":"https://vincentruan.github.io/tags/k8s/"}]},{"title":"【转载】神一样的CAP理论被应用在何方","slug":"【转载】神一样的CAP理论被应用在何方","date":"2020-02-24T13:39:19.000Z","updated":"2020-02-25T15:09:15.058Z","comments":true,"path":"2020/02/24/【转载】神一样的CAP理论被应用在何方/","link":"","permalink":"https://vincentruan.github.io/2020/02/24/【转载】神一样的CAP理论被应用在何方/","excerpt":"对于开发或设计分布式系统的架构师工程师来说，CAP是必须要掌握的理论。 （but：这个文章的重点并不是讨论CAP理论和细节，重点是说说CAP在微服务中的开发怎么起到一个指引作用，会通过几个微服务开发的例子说说明，尽量的去贴近开发） CAP定理又被成为布鲁尔定理，是加州大学计算机科学家埃里克·布鲁尔提出来的猜想，后来被证明成为分布式计算领域公认的定理。不过布鲁尔在出来CAP的时候并没有对CAP三者（Consistency，Availability，Partition tolerance）进行详细的定义，所以在网上也出现了不少对CAP不同解读的声音。","text":"对于开发或设计分布式系统的架构师工程师来说，CAP是必须要掌握的理论。 （but：这个文章的重点并不是讨论CAP理论和细节，重点是说说CAP在微服务中的开发怎么起到一个指引作用，会通过几个微服务开发的例子说说明，尽量的去贴近开发） CAP定理又被成为布鲁尔定理，是加州大学计算机科学家埃里克·布鲁尔提出来的猜想，后来被证明成为分布式计算领域公认的定理。不过布鲁尔在出来CAP的时候并没有对CAP三者（Consistency，Availability，Partition tolerance）进行详细的定义，所以在网上也出现了不少对CAP不同解读的声音。 CAP 定理CAP定理在发展中存在过两个版本，我们以第二个版本为准 在一个分布式系统中（指互相连接并共享数据的节点集合）中，当涉及到读写操作时，只能保证一致性（Consistence）、可用性(Availability）、分区容错性（Partition Tolerance）三者中的两个，另外一个必须被牺牲。 这个版本的CAP理论在探讨分布式系统，更加强调两点是互联和共享数据，其实也是理清楚了第一个版本中三选二的一些缺陷，分布式系统不一定都存在互联和共享数据，例如memcached集群相互间就没有存在连接和共享数据，所以memcached集群这类的分布式系统并不在CAP理论讨论的范围，而想Mysql集群就是互联和数据共享复制，因此mysql集群式属于CAP理论讨论的对象。 一致性（Consistency）一致性意思就是写操作之后进行读操作无论在哪个节点都需要返回写操作的值 可用性(Availability）非故障的节点在合理的时间内返回合理的响应 分区容错性(Partition Tolerance)当网络出现分区后，系统依然能够继续旅行社职责 在分布式的环境下，网络无法做到100%可靠，有可能出现故障，因此分区是一个必须的选项，如果选择了CA而放弃了P，若发生分区现象，为了保证C，系统需要禁止写入，此时就与A发生冲突，如果是为了保证A，则会出现正常的分区可以写入数据，有故障的分区不能写入数据，则与C就冲突了。因此分布式系统理论上不可能选择CA架构，而必须选择CP或AP架构。 分布式事务BASE理论BASE理论是对CAP的延伸和补充，是对CAP中的AP方案的一个补充，即使在选择AP方案的情况下，如何更好的最终达到C。 BASE是基本可用，柔性状态，最终一致性三个短语的缩写，核心的思想是即使无法做到强一致性，但应用可以采用适合的方式达到最终一致性。 CAP在服务中实际的应用例子 理解貌似讲多了，项目的CAP可以参考下李运华的《从零开始学架构》的书，里面的21，22章比较详细的描绘了CAP的理论细节和CAP的版本演化过程。 这里着重的讲解的是神一样的CAP在我们的微服务中怎么去指导和应用起来，大概会举几个平时常见的例子 服务注册中心，是选择AP还是选择CP ？服务注册中心解决的问题在讨论CAP之前先明确下服务注册中心主要是解决什么问题：一个是服务注册，一个是服务发现。 服务注册：实例将自身服务信息注册到注册中心，这部分信息包括服务的主机IP和服务的Port，以及暴露服务自身状态和访问协议信息等。 服务发现：实例请求注册中心所依赖的服务信息，服务实例通过注册中心，获取到注册到其中的服务实例的信息，通过这些信息去请求它们提供的服务。 目前作为注册中心的一些组件大致有：dubbo的zookeeper，springcloud的eureka，consul，rocketMq的nameServer，hdfs的nameNode。目前微服务主流是dubbo和springcloud，使用最多是zookeeper和eureka，我们就来看看应该根据CAP理论应该怎么去选择注册中心。（springcloud也可以用zk，不过不是主流不讨论）。 zookeeper选择CPzookeep保证CP，即任何时刻对zookeeper的访问请求能得到一致性的数据结果，同时系统对网络分割具备容错性，但是它不能保证每次服务的可用性。从实际情况来分析，在使用zookeeper获取服务列表时，如果zk正在选举或者zk集群中半数以上的机器不可用，那么将无法获取数据。所以说，zk不能保证服务可用性。 eureka选择APeureka保证AP，eureka在设计时优先保证可用性，每一个节点都是平等的，一部分节点挂掉不会影响到正常节点的工作，不会出现类似zk的选举leader的过程，客户端发现向某个节点注册或连接失败，会自动切换到其他的节点，只要有一台eureka存在，就可以保证整个服务处在可用状态，只不过有可能这个服务上的信息并不是最新的信息。 zookeeper和eureka的数据一致性问题先要明确一点，eureka的创建初心就是为一个注册中心，但是zk更多是作为分布式协调服务的存在，只不过因为它的特性被dubbo赋予了注册中心，它的职责更多是保证数据（配置数据，状态数据）在管辖下的所有服务之间保持一致，所有这个就不难理解为何zk被设计成CP而不是AP，zk最核心的算法ZAB，就是为了解决分布式系统下数据在多个服务之间一致同步的问题。 更深层的原因，zookeeper是按照CP原则构建，也就是说它必须保持每一个节点的数据都保持一致，如果zookeeper下节点断开或者集群中出现网络分割（例如交换机的子网间不能互访），那么zk会将它们从自己的管理范围中剔除，外界不能访问这些节点，即使这些节点是健康的可以提供正常的服务，所以导致这些节点请求都会丢失。 而eureka则完全没有这方面的顾虑，它的节点都是相对独立，不需要考虑数据一致性的问题，这个应该是eureka的诞生就是为了注册中心而设计，相对zk来说剔除了leader节点选取和事务日志极致，这样更有利于维护和保证eureka在运行的健壮性。 再来看看，数据不一致性在注册服务中中会给eureka带来什么问题，无非就是某一个节点被注册的服务多，某个节点注册的服务少，在某一个瞬间可能导致某些ip节点被调用数少，某些ip节点调用数少的问题。也有可能存在一些本应该被删除而没被删除的脏数据。 小结：服务注册应该选择AP还是CP对于服务注册来说，针对同一个服务，即使注册中心的不同节点保存的服务注册信息不相同，也并不会造成灾难性的后果，对于服务消费者来说，能消费才是最重要的，就算拿到的数据不是最新的数据，消费者本身也可以进行尝试失败重试。总比为了追求数据的一致性而获取不到实例信息整个服务不可用要好。 所以，对于服务注册来说，可用性比数据一致性更加的重要，选择AP。 分布式锁，是选择AP还是选择CP ？这里实现分布式锁的方式选取了三种： 基于数据库实现分布式锁 基于redis实现分布式锁 基于zookeeper实现分布式锁 基于数据库实现分布式锁构建表结构 利用表的 UNIQUE KEY idx_lock (method_lock) 作为唯一主键，当进行上锁时进行insert动作，数据库成功录入则以为上锁成功，当数据库报出 Duplicate entry 则表示无法获取该锁。 不过这种方式对于单主却无法自动切换主从的mysql来说，基本就无法现实P分区容错性，（Mysql自动主从切换在目前并没有十分完美的解决方案）。可以说这种方式强依赖于数据库的可用性，数据库写操作是一个单点，一旦数据库挂掉，就导致锁的不可用。这种方式基本不在CAP的一个讨论范围。 基于redis实现分布式锁redis单线程串行处理天然就是解决串行化问题，用来解决分布式锁是再适合不过。 实现方式： 123setnx key value Expire_time获取到锁 返回 1 ， 获取失败 返回 0复制代码 为了解决数据库锁的无主从切换的问题，可以选择redis集群，或者是 sentinel 哨兵模式，实现主从故障转移，当master节点出现故障，哨兵会从slave中选取节点，重新变成新的master节点。 哨兵模式故障转移是由sentinel集群进行监控判断，当maser出现异常即复制中止，重新推选新slave成为master，sentinel在重新进行选举并不在意主从数据是否复制完毕具备一致性。 所以redis的复制模式是属于AP的模式。保证可用性，在主从复制中“主”有数据，但是可能“从”还没有数据，这个时候，一旦主挂掉或者网络抖动等各种原因，可能会切换到“从”节点，这个时候可能会导致两个业务县城同时获取得两把锁 这个过程如下： 业务线程-1 向主节点请求锁 业务线程-1 获取锁 业务线程-1 获取到锁并开始执行业务 这个时候redis刚生成的锁在主从之间还未进行同步 redis这时候主节点挂掉了 redis的从节点升级为主节点 业务线程-2 想新的主节点请求锁 业务线程-2 获取到新的主节点返回的锁 业务线程-2 获取到锁开始执行业务 这个时候 业务线程-1 和 业务线程-2 同时在执行任务 上述的问题其实并不是redis的缺陷，只是redis采用了AP模型，它本身无法确保我们对一致性的要求。redis官方推荐redlock算法来保证，问题是redlock至少需要三个redis主从实例来实现，维护成本比较高，相当于redlock使用三个redis集群实现了自己的另一套一致性算法，比较繁琐，在业界也使用得比较少。 能否使用redis作为分布式锁？能不能使用redis作为分布式锁，这个本身就不是redis的问题，还是取决于业务场景，我们先要自己确认我们的场景是适合 AP 还是 CP ， 如果在社交发帖等场景下，我们并没有非常强的事务一致性问题，redis提供给我们高性能的AP模型是非常适合的，但如果是交易类型，对数据一致性非常敏感的场景，我们可能要寻在一种更加适合的 CP 模型 基于zookeeper实现分布式锁刚刚也分析过，redis其实无法确保数据的一致性，先来看zookeeper是否合适作为我们需要的分布式锁，首先zk的模式是CP模型，也就是说，当zk锁提供给我们进行访问的时候，在zk集群中能确保这把锁在zk的每一个节点都存在。 （这个实际上是zk的leader通过二阶段提交写请求来保证的，这个也是zk的集群规模大了的一个瓶颈点） zk锁实现的原理说zk的锁问题之前先看看zookeeper中几个特性，这几个特性构建了zk的一把分布式锁 特性： 有序节点 当在一个父目录下如 /lock 下创建 有序节点，节点会按照严格的先后顺序创建出自节点 lock000001,lock000002,lock0000003,以此类推，有序节点能严格保证各个自节点按照排序命名生成。 临时节点 客户端建立了一个临时节点，在客户端的会话结束或会话超时，zookepper会自动删除该解ID那。 事件监听 在读取数据时，我们可以对节点设置监听，当节点的数据发生变化（1 节点创建 2 节点删除 3 节点数据变成 4 自节点变成）时，zookeeper会通知客户端。 结合这几个特点，来看下zk是怎么组合分布式锁。 业务线程-1 业务线程-2 分别向zk的/lock目录下，申请创建有序的临时节点 业务线程-1 抢到/lock0001 的文件，也就是在整个目录下最小序的节点，也就是线程-1获取到了锁 业务线程-2 只能抢到/lock0002的文件，并不是最小序的节点，线程2未能获取锁 业务线程-1 与 lock0001 建立了连接，并维持了心跳，维持的心跳也就是这把锁的租期 当业务线程-1 完成了业务，将释放掉与zk的连接，也就是释放了这把锁 zk分布式锁的代码实现zk官方提供的客户端并不支持分布式锁的直接实现，我们需要自己写代码去利用zk的这几个特性去进行实现。 小结：究竟该用CP还是AP的分布式锁首先得了解清楚我们使用分布式锁的场景，为何使用分布式锁，用它来帮我们解决什么问题，先聊场景后聊分布式锁的技术选型。 无论是redis，zk，例如redis的AP模型会限制很多使用场景，但它却拥有了几者中最高的性能，zookeeper的分布式锁要比redis可靠很多，但他繁琐的实现机制导致了它的性能不如redis，而且zk会随着集群的扩大而性能更加下降。 简单来说，先了解业务场景，后进行技术选型。 分布式事务，是怎么从ACID解脱，投身CAP/BASE如果说到事务，ACID是传统数据库常用的设计理念，追求强一致性模型，关系数据库的ACID模型拥有高一致性+可用性，所以很难进行分区，所以在微服务中ACID已经是无法支持，我们还是回到CAP去寻求解决方案，不过根据上面的讨论，CAP定理中，要么只能CP，要么只能AP，如果我们追求数据的一致性而忽略可用性这个在微服务中肯定是行不通的，如果我们追求可用性而忽略一致性，那么在一些重要的数据（例如支付，金额）肯定出现漏洞百出，这个也是无法接受。所以我们既要一致性，也要可用性。 都要是无法实现的，但我们能不能在一致性上作出一些妥协，不追求强一致性，转而追求最终一致性，所以引入BASE理论，在分布式事务中，BASE最重要是为CAP提出了最终一致性的解决方案，BASE强调牺牲高一致性，从而获取肯用性，数据允许在一段时间内不一致，只要保证最终一致性就可以了。 实现最终一致性弱一致性：系统不能保证后续访问返回更新的值。需要在一些条件满足之后，更新的值才能返回。从更新操作开始，到系统保证任何观察者总是看到更新的值的这期间被称为不一致窗口。 最终一致性：这是弱一致性的特殊形式；存储系统保证如果没有对某个对象的新更新操作，最终所有的访问将返回这个对象的最后更新的值。 BASE模型BASE模型是传统ACID模型的反面，不同与ACID，BASE强调牺牲高一致性，从而获得可用性，数据允许在一段时间内的不一致，只要保证最终一致就可以了。 BASE模型反ACID模型，完全不同ACID模型，牺牲高一致性，获得可用性或可靠性： Basically Available基本可用。支持分区失败(e.g. sharding碎片划分数据库) Soft state软状态 状态可以有一段时间不同步，异步。 Eventually consistent最终一致，最终数据是一致的就可以了，而不是时时一致。 分布式事务在分布式系统中，要实现分布式事务，无外乎几种解决方案。方案各有不同，不过其实都是遵循BASE理论，是最终一致性模型。 两阶段提交（2PC） 补偿事务（TCC） 本地消息表 MQ事务消息 两阶段提交（2PC）其实还有一个数据库的XA事务，不过目前在真正的互联网中实际的应用基本很少，两阶段提交就是使用XA原理。 在 XA 协议中分为两阶段： 事务管理器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是否可以提交。 事务协调器要求每个数据库提交数据，或者回滚数据。 说一下，为何在互联网的系统中没被改造过的两阶段提交基本很少被业界应用，最最大的缺点就是同步阻塞问题，在资源准备就绪之后，资源管理器中的资源就一直处于阻塞，直到提交完成之后，才进行资源释放。这个在互联网高并发大数据的今天，两阶段的提交是不能满足现在互联网的发展。 还有就是两阶段提交协议虽然为分布式数据强一致性所设计，但仍然存在数据不一致性的可能，例如： 比如在第二阶段中，假设协调者发出了事务 Commit 的通知，但是因为网络问题该通知仅被一部分参与者所收到并执行了 Commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。 补偿事务（TCC）TCC是服务化的两阶段变成模型，每个业务服务都必须实现 try，confirm，calcel三个方法，这三个方式可以对应到SQL事务中Lock，Commit，Rollback。 相比两阶段提交，TCC解决了几个问题 同步阻塞，引入了超时机制，超时后进行补偿，并不会像两阶段提交锁定了整个资源，将资源转换为业务逻辑形式，粒度变小。 因为有了补偿机制，可以由业务活动管理器进行控制，保证数据一致性。 1). try阶段 try只是一个初步的操作，进行初步的确认，它的主要职责是完成所有业务的检查，预留业务资源 2). confirm阶段 confirm是在try阶段检查执行完毕后，继续执行的确认操作，必须满足幂等性操作，如果confirm中执行失败，会有事务协调器触发不断的执行，直到满足为止 3). cancel是取消执行，在try没通过并释放掉try阶段预留的资源，也必须满足幂等性，跟confirm一样有可能被不断执行 一个下订单，生成订单扣库存的例子： 接下来看看，我们的下单扣减库存的流程怎么加入TCC 在try的时候，会让库存服务预留n个库存给这个订单使用，让订单服务产生一个“未确认”订单，同时产生这两个预留的资源， 在confirm的时候，会使用在try预留的资源，在TCC事务机制中认为，如果在try阶段能正常预留的资源，那么在confirm一定能完整的提交 在try的时候，有任务一方为执行失败，则会执行cancel的接口操作，将在try阶段预留的资源进行释放。 这个并不是重点要论tcc事务是怎么实现，重点还是讨论分布式事务在CAP+BASE理论的应用。实现可以参考：github.com/changmingxi… 本地消息表本地消息表这个方案最初是 eBay 提出的，eBay 的完整方案 queue.acm.org/detail.cfm?… 本地消息表这种实现方式应该是业界使用最多的，其核心思想是将分布式事务拆分成本地事务进行处理。 对于本地消息队列来说，核心就是将大事务转变为小事务，还是用上面下订单扣库存的例子说说明 当我们去创建订单的时候，我们新增一个本地消息表，把创建订单和扣减库存写入到本地消息表，放在同一个事务（依靠数据库本地事务保证一致性） 配置一个定时任务去轮训这个本地事务表，扫描这个本地事务表，把没有发送出去的消息，发送给库存服务，当库存服务收到消息后，会进行减库存，并写入服务器的事务表，更新事务表的状态。 库存服务器通过定时任务或直接通知订单服务，订单服务在本地消息表更新状态。 这里须注意的是，对于一些扫描发送未成功的任务，会进行重新发送，所以必须保证接口的幂等性。 本地消息队列是BASE理论，是最终一致性模型，适用对一致性要求不高的情况。 MQ事务RocketMq在4.3版本已经正式宣布支持分布式事务，在选择Rokcetmq做分布式事务请务必选择4.3以上的版本。 RocketMQ中实现了分布式事务，实际上是对本地消息表的一个封装，将本地消息表移动到了MQ内部。 事务消息作为一种异步确保型事务， 将两个事务分支通过 MQ 进行异步解耦，RocketMQ 事务消息的设计流程同样借鉴了两阶段提交理论，整体交互流程如下图所示： MQ事务是对本地消息表的一层封装，将本地消息表移动到了MQ内部，所以也是基于BASE理论，是最终一致性模式，对强一致性要求不那么高的事务适用，同时MQ事务将整个流程异步化了，也非常适合在高并发情况下使用。 RocketMQ选择异步/同步刷盘，异步/同步复制，背后的CP和AP思考虽然同步刷盘/异步刷盘，同步/异步复制，并没有对cAP直接的应用，但在配置的过程中也一样涉及到可用性和一致性的考虑 同步刷盘/异步刷盘RocketMQ的消息是可以做到持久化的，数据会持久化到磁盘，RocketMQ为了提高性能，尽可能保证磁盘的顺序写入，消息在Producer写入RocketMq的时候，有两种写入磁盘方式： 异步刷盘： 消息快速写入到内存的pagecache，就立马返回写成功状态，当内存的消息累计到一定程度的时候，会触发统一的写磁盘操作。这种方式可以保证大吞吐量，但也存在着消息可能未存入磁盘丢失的风险。 同步刷盘： 消息快速写入内存的pagecahe，立刻通知刷盘线程进行刷盘，等待刷盘完成之后，唤醒等待的线程，返回消息写成功的状态。 同步复制/异步复制一个broker组有Master和Slave，消息需要从Master复制到Slave上，所以有同步和异步两种复制方式。 同步复制： 是等Master和Slave均写成功后才反馈给客户端写成功状态。 异步复制： 是只要Master写成功即可反馈给客户端写成功状态。 异步复制的优点是可以提高响应速度，但牺牲了一致性 ，一般实现该类协议的算法需要增加额外的补偿机制。同步复制的优点是可以保证一致性(一般通过两阶段提交协议)，但是开销较大，可用性不好(参见CAP定理)，带来了更多的冲突和死锁等问题。值得一提的是Lazy+Primary/Copy的复制协议在实际生产环境中是非常实用的。 RocketMQ的设置要结合业务场景，合理设置刷盘方式和主从复制方式，尤其是SYNC_FLUSH方式，由于频繁的触发写磁盘动作，会明显降低性能。通常情况下，应该把Master和Slave设置成ASYNC_FLUSH的刷盘方式，主从之间配置成SYNC_MASTER的复制方式，这样即使有一台机器出故障，仍然可以保证数据不丢。 总结在微服务的构建中，永远都逃离不了CAP理论，因为网络永远不稳定，硬件总会老化，软件会可能出现bug，所以分区容错性在微服务中是躲不过的命题，可以这么说，只要是分布式，只要是集群都面临着AP或者CP的选择，但你很贪心的时候，既要一致性又要可用性，那只能对一致性作出一点妥协，也就是引入了BASE理论，在业务允许的情况下实现最终一致性。 究竟是选AP还是选CP，真的在于对业务的了解，例如金钱，库存相关会优先考虑CP模型，例如社区发帖相关可以优先选择AP模型，这个说白了其实基于对业务的了解是一个选择和妥协的过程。 转载自陈于喆 - 神一样的CAP理论被应用在何方，原文地址https://juejin.im/post/5d720e86f265da03cc08de74","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/categories/架构设计/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://vincentruan.github.io/tags/架构/"},{"name":"CAP","slug":"CAP","permalink":"https://vincentruan.github.io/tags/CAP/"}]},{"title":"【转载】30张图带你彻底理解红黑树","slug":"30张图带你彻底理解红黑树","date":"2020-02-24T12:44:16.000Z","updated":"2020-02-25T15:09:15.020Z","comments":true,"path":"2020/02/24/30张图带你彻底理解红黑树/","link":"","permalink":"https://vincentruan.github.io/2020/02/24/30张图带你彻底理解红黑树/","excerpt":"在10亿数据中只需要进行10几次比较就能查找到目标时，不禁感叹编程之魅力！人类之伟大呀！ &gt; - 学红黑树有感。 终于，在学习了几天的红黑树相关的知识后，我想把我所学所想和所感分享给大家。红黑树是一种比较难的数据结构，要完全搞懂非常耗时耗力，红黑树怎么自平衡？什么时候需要左旋或右旋？插入和删除破坏了树的平衡后怎么处理？等等一连串的问题在学习前困扰着我。如果你在学习过程中也会存在我的疑问，那么本文对你会有帮助，本文帮助你全面、彻底地理解红黑树！","text":"在10亿数据中只需要进行10几次比较就能查找到目标时，不禁感叹编程之魅力！人类之伟大呀！ &gt; - 学红黑树有感。 终于，在学习了几天的红黑树相关的知识后，我想把我所学所想和所感分享给大家。红黑树是一种比较难的数据结构，要完全搞懂非常耗时耗力，红黑树怎么自平衡？什么时候需要左旋或右旋？插入和删除破坏了树的平衡后怎么处理？等等一连串的问题在学习前困扰着我。如果你在学习过程中也会存在我的疑问，那么本文对你会有帮助，本文帮助你全面、彻底地理解红黑树！ 本文将通过图文的方式讲解红黑树的知识点，并且不会涉及到任何代码，相信我，在懂得红黑树实现原理前，看代码会一头雾水的，当原理懂了，代码也就按部就班写而已，没任何难度。 阅读本文你需具备知识点： 二叉查找树 完美平衡二叉树 事不宜迟，让我们进入正题吧。 正文红黑树也是二叉查找树，我们知道，二叉查找树这一数据结构并不难，而红黑树之所以难是难在它是自平衡的二叉查找树，在进行插入和删除等可能会破坏树的平衡的操作时，需要重新自处理达到平衡状态。现在在脑海想下怎么实现？是不是太多情景需要考虑了？啧啧，先别急，通过本文的学习后，你会觉得，其实也不过如此而已。好吧，我们先来看下红黑树的定义和一些基本性质。 红黑树定义和性质红黑树是一种含有红黑结点并能自平衡的二叉查找树。它必须满足下面性质： 性质1：每个节点要么是黑色，要么是红色。 性质2：根节点是黑色。 性质3：每个叶子节点（NIL）是黑色。 性质4：每个红色结点的两个子结点一定都是黑色。 性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。 从性质5又可以推出： 性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点 图1就是一颗简单的红黑树。其中Nil为叶子结点，并且它是黑色的。(值得提醒注意的是，在Java中，叶子结点是为null的结点。) 图1 一颗简单的红黑树红黑树并不是一个完美平衡二叉查找树，从图1可以看到，根结点P的左子树显然比右子树高，但左子树和右子树的黑结点的层数是相等的，也即任意一个结点到到每个叶子结点的路径都包含数量相同的黑结点(性质5)。所以我们叫红黑树这种平衡为黑色完美平衡。 介绍到此，为了后面讲解不至于混淆，我们还需要来约定下红黑树一些结点的叫法，如图2所示。 图2 结点叫法约定我们把正在处理(遍历)的结点叫做当前结点，如图2中的D，它的父亲叫做父结点，它的父亲的另外一个子结点叫做兄弟结点，父亲的父亲叫做祖父结点。 前面讲到红黑树能自平衡，它靠的是什么？三种操作：左旋、右旋和变色。 左旋：以某个结点作为支点(旋转结点)，其右子结点变为旋转结点的父结点，右子结点的左子结点变为旋转结点的右子结点，左子结点保持不变。如图3。 右旋：以某个结点作为支点(旋转结点)，其左子结点变为旋转结点的父结点，左子结点的右子结点变为旋转结点的左子结点，右子结点保持不变。如图4。 变色：结点的颜色由红变黑或由黑变红。 图3 左旋 图4 右旋上面所说的旋转结点也即旋转的支点，图4和图5中的P结点。我们先忽略颜色，可以看到旋转操作不会影响旋转结点的父结点，父结点以上的结构还是保持不变的。左旋只影响旋转结点和其右子树的结构，把右子树的结点往左子树挪了。右旋只影响旋转结点和其左子树的结构，把左子树的结点往右子树挪了。 所以旋转操作是局部的。另外可以看出旋转能保持红黑树平衡的一些端详了：当一边子树的结点少了，那么向另外一边子树“借”一些结点；当一边子树的结点多了，那么向另外一边子树“租”一些结点。 但要保持红黑树的性质，结点不能乱挪，还得靠变色了。怎么变？具体情景又不同变法，后面会具体讲到，现在只需要记住红黑树总是通过旋转和变色达到自平衡。 balabala了这么多，相信你对红黑树有一定印象了，那么现在来考考你： 思考题1：黑结点可以同时包含一个红子结点和一个黑子结点吗？ (答案见文末) 接下来先讲解红黑树的查找热热身。 红黑树查找因为红黑树是一颗二叉平衡树，并且查找不会破坏树的平衡，所以查找跟二叉平衡树的查找无异： 从根结点开始查找，把根结点设置为当前结点； 若当前结点为空，返回null； 若当前结点不为空，用当前结点的key跟查找key作比较； 若当前结点key等于查找key，那么该key就是查找目标，返回当前结点； 若当前结点key大于查找key，把当前结点的左子结点设置为当前结点，重复步骤2； 若当前结点key小于查找key，把当前结点的右子结点设置为当前结点，重复步骤2； 如图5所示。 图5 二叉树查找流程图非常简单，但简单不代表它效率不好。正由于红黑树总保持黑色完美平衡，所以它的查找最坏时间复杂度为O(2lgN)，也即整颗树刚好红黑相隔的时候。能有这么好的查找效率得益于红黑树自平衡的特性，而这背后的付出，红黑树的插入操作功不可没～ 红黑树插入插入操作包括两部分工作：一查找插入的位置；二插入后自平衡。查找插入的父结点很简单，跟查找操作区别不大： 从根结点开始查找； 若根结点为空，那么插入结点作为根结点，结束。 若根结点不为空，那么把根结点作为当前结点； 若当前结点为null，返回当前结点的父结点，结束。 若当前结点key等于查找key，那么该key所在结点就是插入结点，更新结点的值，结束。 若当前结点key大于查找key，把当前结点的左子结点设置为当前结点，重复步骤4； 若当前结点key小于查找key，把当前结点的右子结点设置为当前结点，重复步骤4； 如图6所示。 图6 红黑树插入位置查找ok，插入位置已经找到，把插入结点放到正确的位置就可以啦，但插入结点是应该是什么颜色呢？答案是红色。理由很简单，红色在父结点（如果存在）为黑色结点时，红黑树的黑色平衡没被破坏，不需要做自平衡操作。但如果插入结点是黑色，那么插入位置所在的子树黑色结点总是多1，必须做自平衡。 所有插入情景如图7所示。 图7 红黑树插入情景嗯，插入情景很多呢，8种插入情景！但情景1、2和3的处理很简单，而情景4.2和情景4.3只是方向反转而已，懂得了一种情景就能推出另外一种情景，所以总体来看，并不复杂，后续我们将一个一个情景来看，把它彻底搞懂。 另外，根据二叉树的性质，除了情景2，所有插入操作都是在叶子结点进行的。这点应该不难理解，因为查找插入位置时，我们就是在找子结点为空的父结点的。 在开始每个情景的讲解前，我们还是先来约定下，如图8所示。 图8 插入操作结点的叫法约定图8的字母并不代表结点Key的大小。I表示插入结点，P表示插入结点的父结点，S表示插入结点的叔叔结点，PP表示插入结点的祖父结点。 好了，下面让我们一个一个来分析每个插入的情景以其处理。 插入情景1：红黑树为空树最简单的一种情景，直接把插入结点作为根结点就行，但注意，根据红黑树性质2：根节点是黑色。还需要把插入结点设为黑色。 处理：把插入结点作为根结点，并把结点设置为黑色。 插入情景2：插入结点的Key已存在插入结点的Key已存在，既然红黑树总保持平衡，在插入前红黑树已经是平衡的，那么把插入结点设置为将要替代结点的颜色，再把结点的值更新就完成插入。 处理： 把I设为当前结点的颜色 更新当前结点的值为插入结点的值 插入情景3：插入结点的父结点为黑结点由于插入的结点是红色的，当插入结点的黑色时，并不会影响红黑树的平衡，直接插入即可，无需做自平衡。 处理：直接插入。 插入情景4：插入结点的父结点为红结点再次回想下红黑树的性质2：根结点是黑色。如果插入的父结点为红结点，那么该父结点不可能为根结点，所以插入结点总是存在祖父结点。这点很重要，因为后续的旋转操作肯定需要祖父结点的参与。 情景4又分为很多子情景，下面将进入重点部分，各位看官请留神了。 插入情景4.1：叔叔结点存在并且为红结点 从红黑树性质4可以，祖父结点肯定为黑结点，因为不可以同时存在两个相连的红结点。那么此时该插入子树的红黑层数的情况是：黑红红。显然最简单的处理方式是把其改为：红黑红。如图9和图10所示。 处理： 将P和S设置为黑色 将PP设置为红色 把PP设置为当前插入结点 图9 插入情景4.1_1 图10 插入情景4.1_2可以看到，我们把PP结点设为红色了，如果PP的父结点是黑色，那么无需再做任何处理；但如果PP的父结点是红色，根据性质4，此时红黑树已不平衡了，所以还需要把PP当作新的插入结点，继续做插入操作自平衡处理，直到平衡为止。 试想下PP刚好为根结点时，那么根据性质2，我们必须把PP重新设为黑色，那么树的红黑结构变为：黑黑红。换句话说，从根结点到叶子结点的路径中，黑色结点增加了。这也是唯一一种会增加红黑树黑色结点层数的插入情景。 我们还可以总结出另外一个经验：红黑树的生长是自底向上的。这点不同于普通的二叉查找树，普通的二叉查找树的生长是自顶向下的。 插入情景4.2：叔叔结点不存在或为黑结点，并且插入结点的父亲结点是祖父结点的左子结点 单纯从插入前来看，也即不算情景4.1自底向上处理时的情况，叔叔结点非红即为叶子结点(Nil)。因为如果叔叔结点为黑结点，而父结点为红结点，那么叔叔结点所在的子树的黑色结点就比父结点所在子树的多了，这不满足红黑树的性质5。后续情景同样如此，不再多做说明了。 前文说了，需要旋转操作时，肯定一边子树的结点多了或少了，需要租或借给另一边。插入显然是多的情况，那么把多的结点租给另一边子树就可以了。 插入情景4.2.1：插入结点是其父结点的左子结点 处理： 将P设为黑色 将PP设为红色 对PP进行右旋 图11 插入情景4.2.1由图11可得，左边两个红结点，右边不存在，那么一边一个刚刚好，并且因为为红色，肯定不会破坏树的平衡。 咦，可以把P设为红色，I和PP设为黑色吗？答案是可以！看过《算法：第4版》的同学可能知道，书中讲解的就是把P设为红色，I和PP设为黑色。但把P设为红色，显然又会出现情景4.1的情况，需要自底向上处理，做多了无谓的操作，既然能自己消化就不要麻烦祖辈们啦～ 插入情景4.2.2：插入结点是其父结点的右子结点 这种情景显然可以转换为情景4.2.1，如图12所示，不做过多说明了。 处理： 对P进行左旋 把P设置为插入结点，得到情景4.2.1 进行情景4.2.1的处理 图12 插入情景4.2.2插入情景4.3：叔叔结点不存在或为黑结点，并且插入结点的父亲结点是祖父结点的右子结点 该情景对应情景4.2，只是方向反转，不做过多说明了，直接看图。 插入情景4.3.1：插入结点是其父结点的右子结点 处理： 将P设为黑色 将PP设为红色 对PP进行左旋 图13 插入情景4.3.1插入情景4.3.2：插入结点是其父结点的右子结点 处理： 对P进行右旋 把P设置为插入结点，得到情景4.3.1 进行情景4.3.1的处理 图14 插入情景4.3.2好了，讲完插入的所有情景了。可能又同学会想：上面的情景举例的都是第一次插入而不包含自底向上处理的情况，那么上面所说的情景都适合自底向上的情况吗？答案是肯定的。理由很简单，但每棵子树都能自平衡，那么整棵树最终总是平衡的。好吧，在出个习题，请大家拿出笔和纸画下试试（请务必动手画下，加深印象）： 习题1：请画出图15的插入自平衡处理过程。（答案见文末） 图15 习题1红黑树删除红黑树插入已经够复杂了，但删除更复杂，也是红黑树最复杂的操作了。但稳住，胜利的曙光就在前面了！ 红黑树的删除操作也包括两部分工作：一查找目标结点；而删除后自平衡。查找目标结点显然可以复用查找操作，当不存在目标结点时，忽略本次操作；当存在目标结点时，删除后就得做自平衡处理了。删除了结点后我们还需要找结点来替代删除结点的位置，不然子树跟父辈结点断开了，除非删除结点刚好没子结点，那么就不需要替代。 二叉树删除结点找替代结点有3种情情景： 情景1：若删除结点无子结点，直接删除 情景2：若删除结点只有一个子结点，用子结点替换删除结点 情景3：若删除结点有两个子结点，用后继结点（大于删除结点的最小结点）替换删除结点 补充说明下，情景3的后继结点是大于删除结点的最小结点，也是删除结点的右子树种最左结点。那么可以拿前继结点（删除结点的左子树最左结点）替代吗？可以的。但习惯上大多都是拿后继结点来替代，后文的讲解也是用后继结点来替代。另外告诉大家一种找前继和后继结点的直观的方法（不知为何没人提过，大家都知道？）：把二叉树所有结点投射在X轴上，所有结点都是从左到右排好序的，所有目标结点的前后结点就是对应前继和后继结点。如图16所示。 图16 二叉树投射x轴后有序接下来，讲一个重要的思路：删除结点被替代后，在不考虑结点的键值的情况下，对于树来说，可以认为删除的是替代结点！话很苍白，我们看图17。在不看键值对的情况下，图17的红黑树最终结果是删除了Q所在位置的结点！这种思路非常重要，大大简化了后文讲解红黑树删除的情景！ 图17 删除结点换位思路基于此，上面所说的3种二叉树的删除情景可以相互转换并且最终都是转换为情景1！ 情景2：删除结点用其唯一的子结点替换，子结点替换为删除结点后，可以认为删除的是子结点，若子结点又有两个子结点，那么相当于转换为情景3，一直自顶向下转换，总是能转换为情景1。（对于红黑树来说，根据性质5.1，只存在一个子结点的结点肯定在树末了） 情景3：删除结点用后继结点（肯定不存在左结点），如果后继结点有右子结点，那么相当于转换为情景2，否则转为为情景1。 二叉树删除结点情景关系图如图18所示。 图18 二叉树删除情景转换综上所述，删除操作删除的结点可以看作删除替代结点，而替代结点最后总是在树末。有了这结论，我们讨论的删除红黑树的情景就少了很多，因为我们只考虑删除树末结点的情景了。 同样的，我们也是先来总体看下删除操作的所有情景，如图19所示。 图19 红黑树删除情景哈哈，是的，即使简化了还是有9种情景！但跟插入操作一样，存在左右对称的情景，只是方向变了，没有本质区别。同样的，我们还是来约定下，如图20所示。 图20 删除操作结点的叫法约定图20的字母并不代表结点Key的大小。R表示替代结点，P表示替代结点的父结点，S表示替代结点的兄弟结点，SL表示兄弟结点的左子结点，SR表示兄弟结点的右子结点。灰色结点表示它可以是红色也可以是黑色。 值得特别提醒的是，R是即将被替换到删除结点的位置的替代结点，在删除前，它还在原来所在位置参与树的子平衡，平衡后再替换到删除结点的位置，才算删除完成。 万事具备，我们进入最后的也是最难的讲解。 删除情景1：替换结点是红色结点我们把替换结点换到了删除结点的位置时，由于替换结点时红色，删除也了不会影响红黑树的平衡，只要把替换结点的颜色设为删除的结点的颜色即可重新平衡。 处理：颜色变为删除结点的颜色 删除情景2：替换结点是黑结点当替换结点是黑色时，我们就不得不进行自平衡处理了。我们必须还得考虑替换结点是其父结点的左子结点还是右子结点，来做不同的旋转操作，使树重新平衡。 删除情景2.1：替换结点是其父结点的左子结点 删除情景2.1.1：替换结点的兄弟结点是红结点 若兄弟结点是红结点，那么根据性质4，兄弟结点的父结点和子结点肯定为黑色，不会有其他子情景，我们按图21处理，得到删除情景2.1.2.3（后续讲解，这里先记住，此时R仍然是替代结点，它的新的兄弟结点SL和兄弟结点的子结点都是黑色）。 处理： 将S设为黑色 将P设为红色 对P进行左旋，得到情景2.1.2.3 进行情景2.1.2.3的处理 图21 删除情景2.1.1删除情景2.1.2：替换结点的兄弟结点是黑结点 当兄弟结点为黑时，其父结点和子结点的具体颜色也无法确定（如果也不考虑自底向上的情况，子结点非红即为叶子结点Nil，Nil结点为黑结点），此时又得考虑多种子情景。 删除情景2.1.2.1：替换结点的兄弟结点的右子结点是红结点，左子结点任意颜色 即将删除的左子树的一个黑色结点，显然左子树的黑色结点少1了，然而右子树又又红色结点，那么我们直接向右子树“借”个红结点来补充黑结点就好啦，此时肯定需要用旋转处理了。如图22所示。 处理： 将S的颜色设为P的颜色 将P设为黑色 将SR设为黑色 对P进行左旋 图22 删除情景2.1.2.1平衡后的图怎么不满足红黑树的性质？前文提醒过，R是即将替换的，它还参与树的自平衡，平衡后再替换到删除结点的位置，所以R最终可以看作是删除的。另外图2.1.2.1是考虑到第一次替换和自底向上处理的情况，如果只考虑第一次替换的情况，根据红黑树性质，SL肯定是红色或为Nil，所以最终结果树是平衡的。如果是自底向上处理的情况，同样，每棵子树都保持平衡状态，最终整棵树肯定是平衡的。后续的情景同理，不做过多说明了。 删除情景2.1.2.2：替换结点的兄弟结点的右子结点为黑结点，左子结点为红结点 兄弟结点所在的子树有红结点，我们总是可以向兄弟子树借个红结点过来，显然该情景可以转换为情景2.1.2.1。图如23所示。 处理： 将S设为红色 将SL设为黑色 对S进行右旋，得到情景2.1.2.1 进行情景2.1.2.1的处理 图23 删除情景2.1.2.2删除情景2.1.2.3：替换结点的兄弟结点的子结点都为黑结点 好了，此次兄弟子树都没红结点“借”了，兄弟帮忙不了，找父母呗，这种情景我们把兄弟结点设为红色，再把父结点当作替代结点，自底向上处理，去找父结点的兄弟结点去“借”。但为什么需要把兄弟结点设为红色呢？显然是为了在P所在的子树中保证平衡（R即将删除，少了一个黑色结点，子树也需要少一个），后续的平衡工作交给父辈们考虑了，还是那句，当每棵子树都保持平衡时，最终整棵总是平衡的。 处理： 将S设为红色 把P作为新的替换结点 重新进行删除结点情景处理 图24 情景2.1.2.3删除情景2.2：替换结点是其父结点的右子结点 好啦，右边的操作也是方向相反，不做过多说明了，相信理解了删除情景2.1后，肯定可以理解2.2。 删除情景2.2.1：替换结点的兄弟结点是红结点 处理： 将S设为黑色 将P设为红色 对P进行右旋，得到情景2.2.2.3 进行情景2.2.2.3的处理 图25 删除情景2.2.1删除情景2.2.2：替换结点的兄弟结点是黑结点 删除情景2.2.2.1：替换结点的兄弟结点的左子结点是红结点，右子结点任意颜色 处理： 将S的颜色设为P的颜色 将P设为黑色 将SL设为黑色 对P进行右旋 图26 删除情景2.2.2.1删除情景2.2.2.2：替换结点的兄弟结点的左子结点为黑结点，右子结点为红结点 处理： 将S设为红色 将SR设为黑色 对S进行左旋，得到情景2.2.2.1 进行情景2.2.2.1的处理 图27 删除情景2.2.2.2删除情景2.2.2.3：替换结点的兄弟结点的子结点都为黑结点 处理： 将S设为红色 把P作为新的替换结点 重新进行删除结点情景处理 图28 删除情景2.2.2.3综上，红黑树删除后自平衡的处理可以总结为： 自己能搞定的自消化（情景1） 自己不能搞定的叫兄弟帮忙（除了情景1、情景2.1.2.3和情景2.2.2.3） 兄弟都帮忙不了的，通过父母，找远方亲戚（情景2.1.2.3和情景2.2.2.3） 哈哈，是不是跟现实中很像，当我们有困难时，首先先自己解决，自己无力了总兄弟姐妹帮忙，如果连兄弟姐妹都帮不上，再去找远方的亲戚了。这里记忆应该会好记点～ 最后再做个习题加深理解（请不熟悉的同学务必动手画下）： 习题2：请画出图29的删除自平衡处理过程。 习题2写在后面耗时良久，终于写完了～自己加深了红黑树的理解的同时，也希望能帮助大家。如果你之前没学习过红黑树，看完这篇文章后可能还存在很多疑问，如果有疑问可以在评论区写出来，我会尽自己所能解答。另外给大家推荐一个支持红黑树在线生成的网站，来做各种情景梳理很有帮助：在线生成红黑树。（删除操作那个把替代结点看作删除结点思路就是我自己在用这个网站时自己顿悟的，我觉得这样讲解更容易理解。） 少了代码是不是觉得有点空虚？哈哈，后续我会写关于Java和HashMap和TreeMap的文章，里面都有红黑树相关的知识。相信看了这篇文章后，再去看Java和HashMap和TreeMap的源码绝对没难度！ 最后来看下思考题和习题的答案吧。 思考题和习题答案思考题1：黑结点可以同时包含一个红子结点和一个黑子结点吗？ 答：可以。如下图的F结点： 习题1：请画出图15的插入自平衡处理过程。 答： 习题2：请画出图29的删除自平衡处理过程。 答： 转载自30张图带你彻底理解红黑树","categories":[{"name":"算法","slug":"算法","permalink":"https://vincentruan.github.io/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://vincentruan.github.io/tags/算法/"},{"name":"红黑树","slug":"红黑树","permalink":"https://vincentruan.github.io/tags/红黑树/"}]},{"title":"[译]StackOverflow: 你没见过的七个最好的Java答案","slug":"译-StackOverflow-你没见过的七个最好的Java答案","date":"2020-02-24T07:25:22.000Z","updated":"2020-02-25T15:09:15.071Z","comments":true,"path":"2020/02/24/译-StackOverflow-你没见过的七个最好的Java答案/","link":"","permalink":"https://vincentruan.github.io/2020/02/24/译-StackOverflow-你没见过的七个最好的Java答案/","excerpt":"StackOverflow(后边简称so)发展到目前，已经成为了全球开发者的金矿。它能够帮助我们找到在各个领域遇到的问题的最有用的解决方案，同时我们也会从中学习到很多新的东西。这篇文章是在我们审阅了so上最流行的Java问题以及答案后从中挑出来的。即使你是一个有丰富经验的开发者，也能从中学到不少东西。","text":"StackOverflow(后边简称so)发展到目前，已经成为了全球开发者的金矿。它能够帮助我们找到在各个领域遇到的问题的最有用的解决方案，同时我们也会从中学习到很多新的东西。这篇文章是在我们审阅了so上最流行的Java问题以及答案后从中挑出来的。即使你是一个有丰富经验的开发者，也能从中学到不少东西。 分支预测SO上最多投票的一个Java问题是：为什么处理一个排序数组要比非排序数组快的多。为了回答这个问题，你需要使用分支预测(branch prediction)。分支预测是一种架构，旨在通过在真实的路径发生前猜测某一分支的下一步来提升处理过程。 分支在这里即一个if语句。这样的话，如果是一个排序数组，那么分支预测将会进行，否则不会进行。Mysticial(so上的一个回答者)试图使用铁路和火车来简单介绍这个概念。假设你在铁轨连接处要决定火车要走哪条路，你会选择左边还是右边？你可以拦住火车，然后问司机该往那里，但是这样会让整个过程变慢。因此你只能去猜正确的方向，那么如何去猜呢？最好的办法就是通过观察目前这个火车每次经过时的路线，推测出正确的方向。 这就是分支预测：识别模式并使用它。 不幸的是，这个问题的提问者是分支预测失败的受害者。因为他的分支没有任何可以识别出的模式，所以预测出的行为是随机的。 Java中的安全另一个流行的Java问题是：为什么在Java中有关密码的地方更加喜欢使用char[]而不是String？其实原始的问题更加具体一些，就是问的在Swing中，password控件有一个getPassword方法(返回char[]而不是getText()返回的String)。 其实这里不用惊讶-这是一个安全问题。String是不可变的，意味着一旦它被创建了，那么你就不可能去修改它。这也意味着在GC之前，你对这些数据不能做任何处理。因此，只要有人能够访问你的内存，那么String就有可能被他获取到。 这也就是为什么要使用char数组。你可以显示地清除数据或者覆盖它。这样密码这种敏感数据即使GC还没有进行也不会再在系统留下痕迹。 异常即使很多开发者倾向于忽略对受检异常的处理，SO上仍然有很多关于异常的问题。其中一个最流行的问题是：什么是NullPointerException，我该怎么处理它？对此，我们并没有感到惊讶，因为这个问题也是在生产环境的Java应用中排名第一的异常。 实际上，当NullPointerException(或者其他exception)在系统出现的时候，我们可以发出一个告警。因为这种异常一般情况下都是业务代码逻辑有问题造成(笔者注)。 为什么这段代码使用随机字符串打印出了”hello world”问题链接：http://stackoverflow.com/questions/15182496/why-does-this-code-using-random-strings-print-hello-world 这个问题给出了下面的代码，并打印出了”hello world”。 12345678910111213141516System.out.println(randomString(-229985452) + \" \" + randomString(-147909649));public static String randomString(int i)&#123; Random ran = new Random(i); StringBuilder sb = new StringBuilder(); while (true) &#123; int k = ran.nextInt(27); if (k == 0) break; sb.append((char)('`' + k)); &#125; return sb.toString();&#125; 其实，选择一组随机的整数并不是随机的。给定一个seed参数(在这个例子中是-229985452和-147909649), 那么每次随机，同样的seed则会产生同样的输出。 Random(-229985452).nextInt(27)产生的前六个数字：8, 5, 12, 12, 15, 0 Random(-147909649).nextInt(27)产生的前六个数字：23, 15, 18, 12, 4, 0 这样，最终输出的就是”hello world”。 为什么两个时间戳相减(in 1927)得出一个奇怪的结果？问题链接：http://stackoverflow.com/questions/6841333/why-is-subtracting-these-two-times-in-1927-giving-a-strange-result 12345678910public static void main(String[] args) throws ParseException &#123; SimpleDateFormat sf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String str3 = \"1927-12-31 23:54:07\"; String str4 = \"1927-12-31 23:54:08\"; Date sDt3 = sf.parse(str3); Date sDt4 = sf.parse(str4); long ld3 = sDt3.getTime() /1000; long ld4 = sDt4.getTime() /1000; System.out.println(ld4-ld3);&#125; 按说上面的代码最后的结果应该是1，但实际的输出却是353。其实，这是一个时区的问题。1927年12月31号24:00，上海时间往回调整了5分钟52秒，因此”1927-12-31 23:54:08”发生了两次，Java将后面一次实例化成了本地的这个时间。因此和前一秒的差距成了353。 我们需要指出，如果你试着来运行这段代码，结果并不一定是353。Jon Skeet指出了这一点，在时区数据库项目2014版中，这个改变的时间点改到了1900-12-31，因此成了344秒的差距。 无法被捕获的ChuckNorrisException问题链接：http://stackoverflow.com/questions/13883166/uncatchable-chucknorrisexception 这里有一个很明显的问题：如果有exception被抛出，但是没有任何办法去catch，那么应用会崩溃吗？或者如这个问题所问：是否可以写一段Java代码让一个假设的java.lang.ChuckNorrisException无法被捕获。 答案是可以，但是这里有一个”但是”。你可以编译一段代码抛出一个ChuckNorrisException，但是在Runtime时动态生成一个并不继承于Throwable接口的ChuckNorrisException类。当然，为了让这个过程可以进行，你需要关闭掉字节码验证。jtahlborn给出了完整的解决办法。 哈希表哈希表是另外一个在SO上流行的问题系列。许多用户都想要知道所有集合类之间的区别，什么时候该使用哪种集合。 迭代顺序是主要考虑的因素。使用HashMap则忽略了所有的顺序信息，也就是获取元素的顺序和你插入元素的顺序是没有任何关系的；使用TreeMap则会得到一个排序好的迭代集合；使用LinkedHashMap则是一个FIFO的顺序。 如果你还是对这些感到困惑，这里有一个相关说明的图表可以参考(Rebel Labs制作)。 总结对于Java，其实关键的不在于你懂多少，而是在于你可以一直学到更多的东西。StackOverflow不仅在code上的一些问题可以帮助我们，也有助于我们回过头来去深入地学习一些我们已经知道的知识。 转载文章原文：https://dzone.com/articles/stackoverflow-7-of-the-best-java-answers-that-you译文: https://www.rowkey.me/blog/2016/08/03/so-java-7-answers/","categories":[{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/tags/Java/"},{"name":"StackOverflow","slug":"StackOverflow","permalink":"https://vincentruan.github.io/tags/StackOverflow/"}]},{"title":"Java性能优化和JVM GC（垃圾回收机制）详解","slug":"Java性能优化和JVM-GC（垃圾回收机制）详解","date":"2020-02-24T06:42:01.000Z","updated":"2020-02-25T15:09:15.043Z","comments":true,"path":"2020/02/24/Java性能优化和JVM-GC（垃圾回收机制）详解/","link":"","permalink":"https://vincentruan.github.io/2020/02/24/Java性能优化和JVM-GC（垃圾回收机制）详解/","excerpt":"Java的性能优化，JVM GC（垃圾回收机制）在学习Java GC 之前，我们需要记住一个单词：stop-the-world 。它会在任何一种GC算法中发生。stop-the-world 意味着JVM因为需要执行GC而停止了应用程序的执行。当stop-the-world 发生时，除GC所需的线程外，所有的线程都进入等待状态，直到GC任务完成。GC优化很多时候就是减少stop-the-world 的发生。","text":"Java的性能优化，JVM GC（垃圾回收机制）在学习Java GC 之前，我们需要记住一个单词：stop-the-world 。它会在任何一种GC算法中发生。stop-the-world 意味着JVM因为需要执行GC而停止了应用程序的执行。当stop-the-world 发生时，除GC所需的线程外，所有的线程都进入等待状态，直到GC任务完成。GC优化很多时候就是减少stop-the-world 的发生。 JVM GC回收哪个区域内的垃圾？需要注意的是，JVM GC只回收堆区和方法区内的对象。而栈区的数据，在超出作用域后会被JVM自动释放掉，所以其不在JVM GC的管理范围内。 JVM GC怎么判断对象可以被回收了？ 对象没有引用 作用域发生未捕获异常 程序在作用域正常执行完毕 程序执行了System.exit() 程序发生意外终止（被杀线程等） 在Java程序中不能显式的分配和注销缓存，因为这些事情JVM都帮我们做了，那就是GC。 有些时候我们可以将相关的对象设置成null 来试图显示的清除缓存，但是并不是设置为null 就会一定被标记为可回收，有可能会发生逃逸。 将对象设置成null 至少没有什么坏处，但是使用System.gc() 便不可取了，使用System.gc() 时候并不是马上执行GC操作，而是会等待一段时间，甚至不执行，而且System.gc() 如果被执行，会触发Full GC ，这非常影响性能。 JVM GC什么时候执行？eden区空间不够存放新对象的时候，执行Minro GC。升到老年代的对象大于老年代剩余空间的时候执行Full GC，或者小于的时候被HandlePromotionFailure 参数强制Full GC 。调优主要是减少 Full GC 的触发次数，可以通过 NewRatio 控制新生代转老年代的比例，通过MaxTenuringThreshold 设置对象进入老年代的年龄阀值（后面会介绍到）。 按代的垃圾回收机制新生代（Young generation）：绝大多数最新被创建的对象都会被分配到这里，由于大部分在创建后很快变得不可达，很多对象被创建在新生代，然后“消失”。对象从这个区域“消失”的过程我们称之为：Minor GC 。 老年代（Old generation）：对象没有变得不可达，并且从新生代周期中存活了下来，会被拷贝到这里。其区域分配的空间要比新生代多。也正由于其相对大的空间，发生在老年代的GC次数要比新生代少得多。对象从老年代中消失的过程，称之为：Major GC 或者 Full GC。 持久代（Permanent generation）也称之为 方法区（Method area）：用于保存类常量以及字符串常量。注意，这个区域不是用于存储那些从老年代存活下来的对象，这个区域也可能发生GC。发生在这个区域的GC事件也被算为 Major GC 。只不过在这个区域发生GC的条件非常严苛，必须符合以下三种条件才会被回收： 所有实例被回收 加载该类的ClassLoader 被回收 Class 对象无法通过任何途径访问（包括反射） 可能我们会有疑问： 如果老年代的对象需要引用新生代的对象，会发生什么呢？ 为了解决这个问题，老年代中存在一个 card table ，它是一个512byte大小的块。所有老年代的对象指向新生代对象的引用都会被记录在这个表中。当针对新生代执行GC的时候，只需要查询 card table 来决定是否可以被回收，而不用查询整个老年代。这个 card table 由一个write barrier 来管理。write barrier给GC带来了很大的性能提升，虽然由此可能带来一些开销，但完全是值得的。 默认的新生代（Young generation）、老年代（Old generation）所占空间比例为 1 : 2 。 新生代空间的构成与逻辑为了更好的理解GC，我们来学习新生代的构成，它用来保存那些第一次被创建的对象，它被分成三个空间： 一个伊甸园空间（Eden） 两个幸存者空间（Fron Survivor、To Survivor） 默认新生代空间的分配：Eden : Fron : To = 8 : 1 : 1 每个空间的执行顺序如下： 绝大多数刚刚被创建的对象会存放在伊甸园空间（Eden）。 在伊甸园空间执行第一次GC（Minor GC）之后，存活的对象被移动到其中一个幸存者空间（Survivor）。 此后，每次伊甸园空间执行GC后，存活的对象会被堆积在同一个幸存者空间。 当一个幸存者空间饱和，还在存活的对象会被移动到另一个幸存者空间。然后会清空已经饱和的哪个幸存者空间。 在以上步骤中重复N次（N = MaxTenuringThreshold（年龄阀值设定，默认15））依然存活的对象，就会被移动到老年代。 从上面的步骤可以发现，两个幸存者空间，必须有一个是保持空的。如果两个两个幸存者空间都有数据，或两个空间都是空的，那一定是你的系统出现了某种错误。 我们需要重点记住的是，对象在刚刚被创建之后，是保存在伊甸园空间的（Eden）。那些长期存活的对象会经由幸存者空间（Survivor）转存到老年代空间（Old generation）。 也有例外出现，对于一些比较大的对象（需要分配一块比较大的连续内存空间）则直接进入到老年代。一般在Survivor 空间不足的情况下发生。 老年代空间的构成与逻辑老年代空间的构成其实很简单，它不像新生代空间那样划分为几个区域，它只有一个区域，里面存储的对象并不像新生代空间绝大部分都是朝闻道，夕死矣。这里的对象几乎都是从Survivor 空间中熬过来的，它们绝不会轻易的狗带。因此，Full GC（Major GC）发生的次数不会有Minor GC 那么频繁，并且做一次Major GC 的时间比Minor GC 要更长（约10倍）。 JVM GC 算法讲解根搜索算法根搜索算法是从离散数学中的图论引入的，程序把所有引用关系看作一张图，从一个节点GC ROOT 开始，寻找对应的引用节点，找到这个节点后，继续寻找这个节点的引用节点。当所有的引用节点寻找完毕后，剩余的节点则被认为是没有被引用到的节点，即无用的节点。 上图红色为无用的节点，可以被回收。 目前Java中可以作为GC ROOT的对象有： 虚拟机栈中引用的对象（本地变量表） 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈中引用的对象（Native对象） 基本所有GC算法都引用根搜索算法这种概念。 标记 - 清除算法标记-清除算法采用从根集合进行扫描，对存活的对象进行标记，标记完毕后，再扫描整个空间中未被标记的对象进行直接回收，如上图。 标记-清除算法不需要进行对象的移动，并且仅对不存活的对象进行处理，在存活的对象比较多的情况下极为高效，但由于标记-清除算法直接回收不存活的对象，并没有对还存活的对象进行整理，因此会导致内存碎片。 复制算法复制算法将内存划分为两个区间，使用此算法时，所有动态分配的对象都只能分配在其中一个区间（活动区间），而另外一个区间（空间区间）则是空闲的。 复制算法采用从根集合扫描，将存活的对象复制到空闲区间，当扫描完毕活动区间后，会的将活动区间一次性全部回收。此时原本的空闲区间变成了活动区间。下次GC时候又会重复刚才的操作，以此循环。 复制算法在存活对象比较少的时候，极为高效，但是带来的成本是牺牲一半的内存空间用于进行对象的移动。所以复制算法的使用场景，必须是对象的存活率非常低才行，而且最重要的是，我们需要克服50%内存的浪费。 标记 - 整理算法标记-整理算法采用 标记-清除 算法一样的方式进行对象的标记、清除，但在回收不存活的对象占用的空间后，会将所有存活的对象往左端空闲空间移动，并更新对应的指针。标记-整理 算法是在标记-清除 算法之上，又进行了对象的移动排序整理，因此成本更高，但却解决了内存碎片的问题。 JVM为了优化内存的回收，使用了分代回收的方式，对于新生代内存的回收（Minor GC）主要采用复制算法。而对于老年代的回收（Major GC），大多采用标记-整理算法。 垃圾回收器简介需要注意的是，每一个回收器都存在Stop The World 的问题，只不过各个回收器在Stop The World 时间优化程度、算法的不同，可根据自身需求选择适合的回收器。 Serial（-XX:+UseSerialGC）从名字我们可以看出，这是一个串行收集器。 Serial收集器是Java虚拟机中最基本、历史最悠久的收集器。在JDK1.3之前是Java虚拟机新生代收集器的唯一选择。目前也是ClientVM下ServerVM 4核4GB以下机器默认垃圾回收器。Serial收集器并不是只能使用一个CPU进行收集，而是当JVM需要进行垃圾回收的时候，需暂停所有的用户线程，直到回收结束。 使用算法：复制算法 JVM中文名称为Java虚拟机，因此它像一台虚拟的电脑在工作，而其中的每一个线程都被认为是JVM的一个处理器，因此图中的CPU0、CPU1实际上为用户的线程，而不是真正的机器CPU，不要误解哦。 Serial收集器虽然是最老的，但是它对于限定单个CPU的环境来说，由于没有线程交互的开销，专心做垃圾收集，所以它在这种情况下是相对于其他收集器中最高效的。 SerialOld（-XX:+UseSerialGC）SerialOld是Serial收集器的老年代收集器版本，它同样是一个单线程收集器，这个收集器目前主要用于Client模式下使用。如果在Server模式下，它主要还有两大用途：一个是在JDK1.5及之前的版本中与Parallel Scavenge收集器搭配使用，另外一个就是作为CMS收集器的后备预案，如果CMS出现Concurrent Mode Failure，则SerialOld将作为后备收集器。 使用算法：标记 - 整理算法 运行示意图与上图一致。 ParNew（-XX:+UseParNewGC）ParNew其实就是Serial收集器的多线程版本。除了Serial收集器外，只有它能与CMS收集器配合工作。 使用算法：复制算法 ParNew是许多运行在Server模式下的JVM首选的新生代收集器。但是在单CPU的情况下，它的效率远远低于Serial收集器，所以一定要注意使用场景。 ParallelScavenge（-XX:+UseParallelGC）ParallelScavenge又被称为吞吐量优先收集器，和ParNew 收集器类似，是一个新生代收集器。 使用算法：复制算法 ParallelScavenge收集器的目标是达到一个可控件的吞吐量，所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量 = 运行用户代码时间 / （运行用户代码时间 + 垃圾收集时间）。如果虚拟机总共运行了100分钟，其中垃圾收集花了1分钟，那么吞吐量就是99% 。 ParallelOld（-XX:+UseParallelOldGC）ParallelOld是并行收集器，和SerialOld一样，ParallelOld是一个老年代收集器，是老年代吞吐量优先的一个收集器。这个收集器在JDK1.6之后才开始提供的，在此之前，ParallelScavenge只能选择SerialOld来作为其老年代的收集器，这严重拖累了ParallelScavenge整体的速度。而ParallelOld的出现后，“吞吐量优先”收集器才名副其实！ 使用算法：标记 - 整理算法 在注重吞吐量与CPU数量大于1的情况下，都可以优先考虑ParallelScavenge + ParalleloOld收集器。 CMS （-XX:+UseConcMarkSweepGC）CMS是一个老年代收集器，全称 Concurrent Low Pause Collector，是JDK1.4后期开始引用的新GC收集器，在JDK1.5、1.6中得到了进一步的改进。它是对于响应时间的重要性需求大于吞吐量要求的收集器。对于要求服务器响应速度高的情况下，使用CMS非常合适。 CMS的一大特点，就是用两次短暂的暂停来代替串行或并行标记整理算法时候的长暂停。 使用算法：标记 - 清理 CMS的执行过程如下： · 初始标记（STW initial mark） 在这个阶段，需要虚拟机停顿正在执行的应用线程，官方的叫法STW（Stop Tow World）。这个过程从根对象扫描直接关联的对象，并作标记。这个过程会很快的完成。 · 并发标记（Concurrent marking） 这个阶段紧随初始标记阶段，在“初始标记”的基础上继续向下追溯标记。注意这里是并发标记，表示用户线程可以和GC线程一起并发执行，这个阶段不会暂停用户的线程哦。 · 并发预清理（Concurrent precleaning） 这个阶段任然是并发的，JVM查找正在执行“并发标记”阶段时候进入老年代的对象（可能这时会有对象从新生代晋升到老年代，或被分配到老年代）。通过重新扫描，减少在一个阶段“重新标记”的工作，因为下一阶段会STW。 · 重新标记（STW remark） 这个阶段会再次暂停正在执行的应用线程，重新重根对象开始查找并标记并发阶段遗漏的对象（在并发标记阶段结束后对象状态的更新导致），并处理对象关联。这一次耗时会比“初始标记”更长，并且这个阶段可以并行标记。 · 并发清理（Concurrent sweeping） 这个阶段是并发的，应用线程和GC清除线程可以一起并发执行。 · 并发重置（Concurrent reset） 这个阶段任然是并发的，重置CMS收集器的数据结构，等待下一次垃圾回收。 CMS的缺点： 1、内存碎片。由于使用了 标记-清理 算法，导致内存空间中会产生内存碎片。不过CMS收集器做了一些小的优化，就是把未分配的空间汇总成一个列表，当有JVM需要分配内存空间的时候，会搜索这个列表找到符合条件的空间来存储这个对象。但是内存碎片的问题依然存在，如果一个对象需要3块连续的空间来存储，因为内存碎片的原因，寻找不到这样的空间，就会导致Full GC。 2、需要更多的CPU资源。由于使用了并发处理，很多情况下都是GC线程和应用线程并发执行的，这样就需要占用更多的CPU资源，也是牺牲了一定吞吐量的原因。 3、需要更大的堆空间。因为CMS标记阶段应用程序的线程还是执行的，那么就会有堆空间继续分配的问题，为了保障CMS在回收堆空间之前还有空间分配给新加入的对象，必须预留一部分空间。CMS默认在老年代空间使用68%时候启动垃圾回收。可以通过-XX:CMSinitiatingOccupancyFraction=n来设置这个阀值。 GarbageFirst（G1）这是一个新的垃圾回收器，既可以回收新生代也可以回收老年代，SunHotSpot1.6u14以上EarlyAccess版本加入了这个回收器，Sun公司预期SunHotSpot1.7发布正式版本。通过重新划分内存区域，整合优化CMS，同时注重吞吐量和响应时间。杯具的是Oracle收购这个收集器之后将其用于商用收费版收集器。因此目前暂时没有发现哪个公司使用它，这个放在之后再去研究吧。 整理一下新生代和老年代的收集器。 新生代收集器： Serial （-XX:+UseSerialGC） ParNew（-XX:+UseParNewGC） ParallelScavenge（-XX:+UseParallelGC） G1 收集器 老年代收集器： SerialOld（-XX:+UseSerialOldGC） ParallelOld（-XX:+UseParallelOldGC） CMS（-XX:+UseConcMarkSweepGC） G1 收集器 调优jvm参数介绍堆设置 -Xmx3550m：设置JVM最大堆内存 为3550M。 -Xms3550m：设置JVM初始堆内存 为3550M。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。 -Xss128k：设置每个线程的栈 大小。JDK5.0以后每个线程栈大小为1M，之前每个线程栈大小为256K。应当根据应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能 生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 -Xmn2g：设置堆内存年轻代 大小为2G。整个堆内存大小 = 年轻代大小 + 年老代大小 + 持久代大小 。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 -XX:PermSize=256M：设置堆内存持久代 初始值为256M。(貌似是Eclipse等IDE的初始化参数) -XX:MaxNewSize=size：新生成的对象能占用内存的最大值。 -XX:MaxPermSize=512M：设置持久代最大值为512M。 -XX:NewRatio=4：设置堆内存年轻代（包括Eden和两个Survivor区）与堆内存年老代的比值（除去持久代） 。设置为4，则年轻代所占与年老代所占的比值为1:4。 -XX:SurvivorRatio=4：设置堆内存年轻代中Eden区与Survivor区大小的比值 。设置为4，则两个Survivor区（JVM堆内存年轻代中默认有2个Survivor区）与一个Eden区的比值为2:4，一个Survivor区占 整个年轻代的1/6。 -XX:MaxTenuringThreshold=7：表示一个对象如果在救助空间（Survivor区）移动7次还没有被回收就放入年老代。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代，对于年老代比较多的应用，这样做可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象在年轻代存活时间，增加对象在年轻代即被回收的概率。 回收器选择JVM给了三种选择：串行收集器、并行收集器、并发收集器，但是串行收集器只适用于小数据量的情况，所以这里的选择主要针对并行收集器和并发收集器。 默认情况下，JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行智能判断。 串行收集器 -XX:+UseSerialGC：设置串行收集器 并行收集器(吞吐量优先) -XX:+UseParallelGC：选择垃圾收集器为并行收集器。此配置仅对年轻代有效。即上述配置下，年轻代使用并发收集，而年老代仍旧使用串行收集。 -XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。 -XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0支持对年老代并行收集。 -XX:MaxGCPauseMillis=100：设置每次年轻代垃圾回收的最长时间（单位毫秒），如果无法满足此时间，JVM会自动调整年轻代大小，以满足此值。 -XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低响应时间或者收集频率等。 此参数建议使用并行收集器时，一直打开。 并发收集器(响应时间优先) -XX:+UseParNewGC：设置年轻代为并发收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。 CMS全称Concurrent Low Pause Collector，是jdk1.4后期版本开始引入的新gc算法，在jdk5和jdk6中得到了进一步改进，它的主要适合场景是对响应时间的重要性需求 大于对吞吐量的要求，能够承受垃圾回收线程和应用线程共享处理器资源，并且应用中存在比较多的长生命周期的对象的应用。CMS是用于对tenured generation的回收，也就是年老代的回收，目标是尽量减少应用的暂停时间，减少FullGC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代。 -XX:+UseConcMarkSweepGC：设置年老代为并发收集。测试中配置这个以后，-XX:NewRatio=4的配置失效了。所以，此时年轻代大小最好用-Xmn设置。 -XX:CMSFullGCsBeforeCompaction=：由于并发收集器不对内存空间进行压缩、整理，所以运行一段时间以后会产生“碎片”，使得运行效率降低。此参数设置运行次FullGC以后对内存空间进行压缩、整理。 -XX:+UseCMSCompactAtFullCollection：打开对年老代的压缩。可能会影响性能，但是可以消除内存碎片。 -XX:+CMSIncrementalMode：设置为增量收集模式。一般适用于单CPU情况。 -XX:CMSInitiatingOccupancyFraction=70：表示年老代空间到70%时就开始执行CMS，确保年老代有足够的空间接纳来自年轻代的对象。 注：如果使用 throughput collector 和 concurrent low pause collector 这两种垃圾收集器，需要适当的挺高内存大小，为多线程做准备。 其它 -XX:+ScavengeBeforeFullGC：新生代GC优先于Full GC执行。 -XX:-DisableExplicitGC：禁止调用System.gc()，但JVM的gc仍然有效。 -XX:+MaxFDLimit：最大化文件描述符的数量限制。 -XX:+UseThreadPriorities：启用本地线程优先级API，即使 java.lang.Thread.setPriority() 生效，反之无效。 -XX:SoftRefLRUPolicyMSPerMB=0：“软引用”的对象在最后一次被访问后能存活0毫秒（默认为1秒）。 -XX:TargetSurvivorRatio=90：允许90%的Survivor空间被占用（默认为50%）。提高对于Survivor的使用率——超过就会尝试垃圾回收。 辅助信息 -XX:-CITime：打印消耗在JIT编译的时间 -XX:ErrorFile=./hs_err_pid.log：保存错误日志或者数据到指定文件中 -XX:-ExtendedDTraceProbes：开启solaris特有的dtrace探针 -XX:HeapDumpPath=./java_pid.hprof：指定导出堆信息时的路径或文件名 -XX:-HeapDumpOnOutOfMemoryError：当首次遭遇内存溢出时导出此时堆中相关信息 -XX:OnError=”;”：出现致命ERROR之后运行自定义命令 -XX:OnOutOfMemoryError=”;”：当首次遭遇内存溢出时执行自定义命令 -XX:-PrintClassHistogram：遇到Ctrl-Break后打印类实例的柱状信息，与jmap -histo功能相同 -XX:-PrintConcurrentLocks：遇到Ctrl-Break后打印并发锁的相关信息，与jstack -l功能相同 -XX:-PrintCommandLineFlags：打印在命令行中出现过的标记 -XX:-PrintCompilation：当一个方法被编译时打印相关信息 -XX:-PrintGC：每次GC时打印相关信息 -XX:-PrintGC Details：每次GC时打印详细信息 -XX:-PrintGCTimeStamps：打印每次GC的时间戳 -XX:-TraceClassLoading：跟踪类的加载信息 -XX:-TraceClassLoadingPreorder：跟踪被引用到的所有类的加载信息 -XX:-TraceClassResolution：跟踪常量池 -XX:-TraceClassUnloading：跟踪类的卸载信息 -XX:-TraceLoaderConstraints：跟踪类加载器约束的相关信息 JVM服务调优实战服务器：8 cup, 8G mem e.g. java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0 调优方案：-Xmx5g：设置JVM最大可用内存为5G。 -Xms5g：设置JVM初始内存为5G。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。 -Xmn2g：设置年轻代大小为2G。整个堆内存大小 = 年轻代大小 + 年老代大小 + 持久代大小 。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 -XX:+UseParNewGC：设置年轻代为并行收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。 -XX:ParallelGCThreads=8：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。 -XX:SurvivorRatio=6：设置年轻代中Eden区与Survivor区的大小比值。根据经验设置为6，则两个Survivor区与一个Eden区的比值为2:6，一个Survivor区占整个年轻代的1/8。 -XX:MaxTenuringThreshold=30：设置垃圾最大年龄（次数）。如果设置为0的话，则年轻代对象不经过Survivor区直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值 设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概率。设置为30表示 一个对象如果在Survivor空间移动30次还没有被回收就放入年老代。 -XX:+UseConcMarkSweepGC：设置年老代为并发收集。测试配置这个参数以后，参数-XX:NewRatio=4就失效了，所以，此时年轻代大小最好用-Xmn设置，因此这个参数不建议使用。 参考资料 - JVM堆内存的分代虚拟机的堆内存共划分为三个代：年轻代（Young Generation）、年老代（Old Generation）和持久代（Permanent Generation）。其中持久代主要存放的是Java类的类信息，与垃圾收集器要收集的Java对象关系不大。所以，年轻代和年老代的划分才是对垃圾 收集影响比较大的。 年轻代所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。年轻代分三个区。一个Eden区，两个 Survivor区(一般而言)。 大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区（两个中的一个），当一个Survivor区满 时，此区的存活对象将被复制到另外一个Survivor区，当另一个Survivor区也满了的时候，从前一个Survivor区复制过来的并且此时还存 活的对象，将被复制“年老区(Tenured)”。 需要注意，两个Survivor区是对称的，没先后关系，所以同一个Survivor区中可能同时存在从Eden区复制过来对象，和从另一个 Survivor区复制过来的对象；而复制到年老区的只有从前一个Survivor区（相对的）过来的对象。而且，Survivor区总有一个是空的。特 殊的情况下，根据程序需要，Survivor区是可以配置为多个的（多于两个），这样可以增加对象在年轻代中的存在时间，减少被放到年老代的可能。 年老代在年轻代中经历了N（可配置）次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 持久代用于存放静态数据，如 Java Class, Method 等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些Class，例如 Hibernate 等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中动态增加的类型。持久代大小通过 -XX:MaxPermSize= 进行设置。1.8已经移除改为metaspace。","categories":[{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://vincentruan.github.io/tags/JVM/"}]},{"title":"zookeeper入门摘要","slug":"zookeeper入门摘要","date":"2020-02-14T10:01:16.000Z","updated":"2020-02-25T15:09:15.055Z","comments":true,"path":"2020/02/14/zookeeper入门摘要/","link":"","permalink":"https://vincentruan.github.io/2020/02/14/zookeeper入门摘要/","excerpt":"1.ZooKeeper是什么？ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了监听器，这个监听器也是由所连接的zookeeper机器来处理。对于写请求，这些请求会同时发给其他zookeeper机器并且达成一致后，请求才会返回成功。因此，随着zookeeper的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。 有序性是zookeeper中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为zxid（Zookeeper Transaction Id）。而读请求只会相对于更新有序，也就是读请求的返回结果中会带有这个zookeeper最新的zxid。","text":"1.ZooKeeper是什么？ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了监听器，这个监听器也是由所连接的zookeeper机器来处理。对于写请求，这些请求会同时发给其他zookeeper机器并且达成一致后，请求才会返回成功。因此，随着zookeeper的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。 有序性是zookeeper中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为zxid（Zookeeper Transaction Id）。而读请求只会相对于更新有序，也就是读请求的返回结果中会带有这个zookeeper最新的zxid。 2.ZooKeeper提供了什么？1、文件系统 2、通知机制 3.Zookeeper文件系统Zookeeper提供一个多层级的节点命名空间（节点称为znode）。与文件系统不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可以存放数据而目录节点不行。Zookeeper为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，这种特性使得Zookeeper不能用于存放大量的数据，每个节点的存放数据上限为1M。 4.四种类型的znode1、PERSISTENT-持久化目录节点客户端与zookeeper断开连接后，该节点依旧存在 2、PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 3、EPHEMERAL-临时目录节点客户端与zookeeper断开连接后，该节点被删除 4、EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号 5.Zookeeper通知机制client端会对某个znode建立一个watcher事件，当该znode发生变化时，这些client会收到zk的通知，然后client可以根据znode变化来做出业务上的改变等。 6.Zookeeper做了什么？1、命名服务 2、配置管理 3、集群管理 4、分布式锁 5、队列管理 7.zk的命名服务（文件系统）命名服务是指通过指定的名字来获取资源或者服务的地址，利用zk创建一个全局的路径，即是唯一的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。 8.zk的配置管理（文件系统、通知机制）程序分布式的部署在不同的机器上，将程序的配置信息放在zk的znode下，当有配置发生改变时，也就是znode发生变化时，可以通过改变zk中某个目录节点的内容，利用watcher通知给各个客户端，从而更改配置。 9.Zookeeper集群管理（文件系统、通知机制）所谓集群管理无在乎两点：是否有机器退出和加入、选举master。 对于第一点，所有机器约定在父目录下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。 新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount又有了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。 10.Zookeeper分布式锁（文件系统、通知机制）有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。 对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的distribute_lock 节点就释放出锁。 对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。 11.获取分布式锁的流程 在获取分布式锁的时候在locker节点下创建临时顺序节点，释放锁的时候删除该临时节点。客户端调用createNode方法在locker下创建临时顺序节点，然后调用getChildren(“locker”)来获取locker下面的所有子节点，注意此时不用设置任何Watcher。客户端获取到所有的子节点path之后，如果发现自己创建的节点在所有创建的子节点序号最小，那么就认为该客户端获取到了锁。如果发现自己创建的节点并非locker所有子节点中最小的，说明自己还没有获取到锁，此时客户端需要找到比自己小的那个节点，然后对其调用exist()方法，同时对其注册事件监听器。之后，让这个被关注的节点删除，则客户端的Watcher会收到相应通知，此时再次判断自己创建的节点是否是locker子节点中序号最小的，如果是则获取到了锁，如果不是则重复以上步骤继续获取到比自己小的一个节点并注册监听。当前这个过程中还需要许多的逻辑判断。 代码的实现主要是基于互斥锁，获取分布式锁的重点逻辑在于BaseDistributedLock，实现了基于Zookeeper实现分布式锁的细节。 12.Zookeeper队列管理（文件系统、通知机制）两种类型的队列： 1、同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。 2、队列按照 FIFO 方式进行入队和出队操作。 第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。在特定的目录下创建PERSISTENT_SEQUENTIAL节点，创建成功时Watcher通知等待的队列，队列删除序列号最小的节点用以消费。此场景下Zookeeper的znode用于消息存储，znode存储的数据就是消息队列中的消息内容，SEQUENTIAL序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，所以不必担心队列消息的丢失问题。 13.Zookeeper数据复制Zookeeper作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处： 1、容错：一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作； 2、提高系统的扩展能力 ：把负载分布到多个节点上，或者增加节点来提高系统的负载能力； 3、提高性能：让客户端本地访问就近的节点，提高用户访问速度。 从客户端读写访问的透明度来看，数据复制集群系统分下面两种： 1、写主(WriteMaster) ：对数据的修改提交给指定的节点。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离； 2、写任意(Write Any)：对数据的修改可提交给任意的节点，跟读一样。这种情况下，客户端对集群节点的角色与变化透明。 对zookeeper来说，它采用的方式是写任意。通过增加机器，它的读吞吐能力和响应能力扩展性非常好，而写，随着机器的增多吞吐能力肯定下降（这也是它建立observer的原因），而响应能力则取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。 14.Zookeeper工作原理Zookeeper 的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。 15.zookeeper是如何保证事务的顺序一致性的？zookeeper采用了递增的事务Id来标识，所有的proposal（提议）都在被提出的时候加上了zxid，zxid实际上是一个64位的数字，高32位是epoch（时期; 纪元; 世; 新时代）用来标识leader是否发生改变，如果有新的leader产生出来，epoch会自增，低32位用来递增计数。当新产生proposal的时候，会依据数据库的两阶段过程，首先会向其他的server发出事务执行请求，如果超过半数的机器都能执行并且能够成功，那么就会开始执行。 16.Zookeeper 下 Server工作状态每个Server在工作过程中有三种状态： LOOKING：当前Server不知道leader是谁，正在搜寻 LEADING：当前Server即为选举出来的leader FOLLOWING：leader已经选举出来，当前Server与之同步 17.zookeeper是如何选取主leader的？当leader崩溃或者leader失去大多数的follower，这时zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的Server都恢复到一个正确的状态。Zk的选举算法有两种：一种是基于basic paxos实现的，另外一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。 1、Zookeeper选主流程(basic paxos) （1）选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的Server； （2）选举线程首先向所有Server发起一次询问(包括自己)； （3）选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(id,zxid)，并将这些信息存储到当次选举的投票记录表中； （4）收到所有Server回复以后，就计算出zxid最大的那个Server，并将这个Server相关信息设置成下一次要投票的Server； （5）线程将当前zxid最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n/2 + 1的Server票数，设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态，否则，继续这个过程，直到leader被选举出来。通过流程分析我们可以得出：要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1，且存活的Server的数目不得少于n+1. 每个Server启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的server还会从磁盘快照中恢复数据和会话信息，zk会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。 2、Zookeeper选主流程(basic paxos) fast paxos流程是在选举过程中，某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和 zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。 18.Zookeeper同步流程选完Leader以后，zk就进入状态同步过程。 1、Leader等待server连接； 2、Follower连接leader，将最大的zxid发送给leader； 3、Leader根据follower的zxid确定同步点； 4、完成同步后通知follower 已经成为uptodate状态； 5、Follower收到uptodate消息后，又可以重新接受client的请求进行服务了。 sequenceDiagram participant L as Leader participant F as Follower F->>L: 1.Fllower连接Leader，发送最大zxid L->>F: 2.Leader确定同步点，发送同步消息 F->>L: 3.完成同步，通知Leader，并修改自身状态 19.分布式通知和协调对于系统调度来说：操作人员发送通知实际是通过控制台改变某个节点的状态，然后zk将这些变化发送给注册了这个节点的watcher的所有客户端。 对于执行情况汇报：每个工作进程都在某个目录下创建一个临时节点。并携带工作的进度数据，这样汇总的进程可以监控目录子节点的变化获得工作进度的实时的全局情况。 20.机器中为什么会有leader？在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果，这样可以大大减少重复计算，提高性能，于是就需要进行leader选举。 21.zk节点宕机如何处理？Zookeeper本身也是集群，推荐配置不少于3个服务器。Zookeeper自身也要保证当一个节点宕机时，其他节点会继续提供服务。 如果是一个Follower宕机，还有2台服务器提供访问，因为Zookeeper上的数据是有多个副本的，数据并不会丢失； 如果是一个Leader宕机，Zookeeper会选举出新的Leader。 ZK集群的机制是只要超过半数的节点正常，集群就能正常提供服务。只有在ZK节点挂得太多，只剩一半或不到一半节点能工作，集群才失效。 所以 3个节点的cluster可以挂掉1个节点(leader可以得到2票&gt;1.5) 2个节点的cluster就不能挂掉任何1个节点了(leader可以得到1票&lt;=1) 22.zookeeper负载均衡和nginx负载均衡区别zk的负载均衡是可以调控，nginx只是能调权重，其他需要可控的都需要自己写插件；但是nginx的吞吐量比zk大很多，应该说按业务选择用哪种方式。 23.zookeeper watch机制Watch机制官方声明：一个Watch事件是一个一次性的触发器，当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端，以便通知它们。 Zookeeper机制的特点： 1、一次性触发数据发生改变时，一个watcher event会被发送到client，但是client只会收到一次这样的信息。 2、watcher event异步发送watcher的通知事件从server发送到client是异步的，这就存在一个问题，不同的客户端和服务器之间通过socket进行通信，由于网络延迟或其他因素导致客户端在不通的时刻监听到事件，由于Zookeeper本身提供了ordering guarantee，即客户端监听事件后，才会感知它所监视znode发生了变化。所以我们使用Zookeeper不能期望能够监控到节点每次的变化。Zookeeper只能保证最终的一致性，而无法保证强一致性。 3、数据监视Zookeeper有数据监视和子数据监视getdata() and exists()设置数据监视，getchildren()设置了子节点监视。 4、注册watcher getData、exists、getChildren 5、触发watcher create、delete、setData 6、setData()会触发znode上设置的data watch（如果set成功的话）。一个成功的create() 操作会触发被创建的znode上的数据watch，以及其父节点上的child watch。而一个成功的delete()操作将会同时触发一个znode的data watch和child watch（因为这样就没有子节点了），同时也会触发其父节点的child watch。 7、当一个客户端连接到一个新的服务器上时，watch将会被以任意会话事件触发。当与一个服务器失去连接的时候，是无法接收到watch的。而当client重新连接时，如果需要的话，所有先前注册过的watch，都会被重新注册。通常这是完全透明的。只有在一个特殊情况下，watch可能会丢失：对于一个未创建的znode的exist watch，如果在客户端断开连接期间被创建了，并且随后在客户端连接上之前又删除了，这种情况下，这个watch事件可能会被丢失。 8、Watch是轻量级的，其实就是本地JVM的Callback，服务器端只是存了是否有设置了Watcher的布尔类型","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/categories/架构设计/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://vincentruan.github.io/tags/zookeeper/"},{"name":"分布式","slug":"分布式","permalink":"https://vincentruan.github.io/tags/分布式/"}]},{"title":"MyBatis中的九种设计模式","slug":"MyBatis中的九种设计模式","date":"2020-02-12T08:54:07.000Z","updated":"2020-02-25T15:09:15.047Z","comments":true,"path":"2020/02/12/MyBatis中的九种设计模式/","link":"","permalink":"https://vincentruan.github.io/2020/02/12/MyBatis中的九种设计模式/","excerpt":"虽然我们都知道有26个设计模式，但是大多停留在概念层面，真实开发中很少遇到，Mybatis源码中使用了大量的设计模式，阅读源码并观察设计模式在其中的应用，能够更深入的理解设计模式。","text":"虽然我们都知道有26个设计模式，但是大多停留在概念层面，真实开发中很少遇到，Mybatis源码中使用了大量的设计模式，阅读源码并观察设计模式在其中的应用，能够更深入的理解设计模式。 Mybatis至少遇到了以下的设计模式的使用： Builder模式，例如SqlSessionFactoryBuilder、XMLConfigBuilder、XMLMapperBuilder、XMLStatementBuilder、CacheBuilder； 工厂模式，例如SqlSessionFactory、ObjectFactory、MapperProxyFactory； 单例模式，例如ErrorContext和LogFactory； 代理模式，Mybatis实现的核心，比如MapperProxy、ConnectionLogger，用的jdk的动态代理；还有executor.loader包使用了cglib或者javassist达到延迟加载的效果； 组合模式，例如SqlNode和各个子类ChooseSqlNode等； 模板方法模式，例如BaseExecutor和SimpleExecutor，还有BaseTypeHandler和所有的子类例如IntegerTypeHandler； 适配器模式，例如Log的Mybatis接口和它对jdbc、log4j等各种日志框架的适配实现； 装饰者模式，例如Cache包中的cache.decorators子包中等各个装饰者的实现； 迭代器模式，例如迭代器模式PropertyTokenizer； 1、Builder模式Builder模式的定义是“将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。”，它属于创建类模式，一般来说，如果一个对象的构建比较复杂，超出了构造函数所能包含的范围，就可以使用工厂模式和Builder模式，相对于工厂模式会产出一个完整的产品，Builder应用于更加复杂的对象的构建，甚至只会构建产品的一个部分。 在Mybatis环境的初始化过程中，SqlSessionFactoryBuilder会调用XMLConfigBuilder读取所有的MybatisMapConfig.xml和所有的*Mapper.xml文件，构建Mybatis运行的核心对象Configuration对象，然后将该Configuration对象作为参数构建一个SqlSessionFactory对象。 其中XMLConfigBuilder在构建Configuration对象时，也会调用XMLMapperBuilder用于读取*Mapper文件，而XMLMapperBuilder会使用XMLStatementBuilder来读取和build所有的SQL语句。 在这个过程中，有一个相似的特点，就是这些Builder会读取文件或者配置，然后做大量的XpathParser解析、配置或语法的解析、反射生成对象、存入结果缓存等步骤，这么多的工作都不是一个构造函数所能包括的，因此大量采用了Builder模式来解决。 对于builder的具体类，方法都大都用build*开头，比如SqlSessionFactoryBuilder为例，它包含以下方法： 即根据不同的输入参数来构建SqlSessionFactory这个工厂对象。 2、工厂模式在Mybatis中比如SqlSessionFactory使用的是工厂模式，该工厂没有那么复杂的逻辑，是一个简单工厂模式。 简单工厂模式(Simple Factory Pattern)：又称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。 SqlSession可以认为是一个Mybatis工作的核心的接口，通过这个接口可以执行执行SQL语句、获取Mappers、管理事务。类似于连接MySQL的Connection对象。 可以看到，该Factory的openSession方法重载了很多个，分别支持autoCommit、Executor、Transaction等参数的输入，来构建核心的SqlSession对象。 在DefaultSqlSessionFactory的默认工厂实现里，有一个方法可以看出工厂怎么产出一个产品： 123456789101112131415private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; 这是一个openSession调用的底层方法，该方法先从configuration读取对应的环境配置，然后初始化TransactionFactory获得一个Transaction对象，然后通过Transaction获取一个Executor对象，最后通过configuration、Executor、是否autoCommit三个参数构建了SqlSession。 在这里其实也可以看到端倪，SqlSession的执行，其实是委托给对应的Executor来进行的。 而对于LogFactory，它的实现代码： 123456789101112131415161718192021public final class LogFactory &#123; private static Constructor&lt;? extends Log&gt; logConstructor; private LogFactory() &#123; // disable construction &#125; public static Log getLog(Class&lt;?&gt; aClass) &#123; return getLog(aClass.getName()); &#125; public static Log getLog(String logger) &#123; try &#123; return logConstructor.newInstance(logger); &#125; catch (Throwable t) &#123; throw new LogException(\"Error creating logger for logger \" + logger + \". Cause: \" + t, t); &#125; &#125;&#125; 这里有个特别的地方，是Log变量的的类型是Constructor，也就是说该工厂生产的不只是一个产品，而是具有Log公共接口的一系列产品，比如Log4jImpl、Slf4jImpl等很多具体的Log。 3、单例模式单例模式(Singleton Pattern)：单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。 单例模式的要点有三个：一是某个类只能有一个实例；二是它必须自行创建这个实例；三是它必须自行向整个系统提供这个实例。单例模式是一种对象创建型模式。单例模式又名单件模式或单态模式。 在Mybatis中有两个地方用到单例模式，ErrorContext和LogFactory，其中ErrorContext是用在每个线程范围内的单例，用于记录该线程的执行环境错误信息，而LogFactory则是提供给整个Mybatis使用的日志工厂，用于获得针对项目配置好的日志对象。 ErrorContext的单例实现代码： 1234567891011121314151617public class ErrorContext &#123; private static final ThreadLocal&lt;ErrorContext&gt; LOCAL = new ThreadLocal&lt;ErrorContext&gt;(); private ErrorContext() &#123; &#125; public static ErrorContext instance() &#123; ErrorContext context = LOCAL.get(); if (context == null) &#123; context = new ErrorContext(); LOCAL.set(context); &#125; return context; &#125;&#125; 构造函数是private修饰，具有一个static的局部instance变量和一个获取instance变量的方法，在获取实例的方法中，先判断是否为空如果是的话就先创建，然后返回构造好的对象。 只是这里有个有趣的地方是，LOCAL的静态实例变量使用了ThreadLocal修饰，也就是说它属于每个线程各自的数据，而在instance()方法中，先获取本线程的该实例，如果没有就创建该线程独有的ErrorContext。 4、代理模式代理模式可以认为是Mybatis的核心使用的模式，正是由于这个模式，我们只需要编写Mapper.java接口，不需要实现，由Mybatis后台帮我们完成具体SQL的执行。 代理模式(Proxy Pattern) ：给某一个对象提供一个代 理，并由代理对象控制对原对象的引用。代理模式的英 文叫做Proxy或Surrogate，它是一种对象结构型模式。 代理模式包含如下角色： Subject: 抽象主题角色 Proxy: 代理主题角色 RealSubject: 真实主题角色 这里有两个步骤，第一个是提前创建一个Proxy，第二个是使用的时候会自动请求Proxy，然后由Proxy来执行具体事务； 当我们使用Configuration的getMapper方法时，会调用mapperRegistry.getMapper方法，而该方法又会调用mapperProxyFactory.newInstance(sqlSession)来生成一个具体的代理： 12345678910111213141516171819202122232425262728public class MapperProxyFactory&lt;T&gt; &#123; private final Class&lt;T&gt; mapperInterface; private final Map&lt;Method, MapperMethod&gt; methodCache = new ConcurrentHashMap&lt;Method, MapperMethod&gt;(); public MapperProxyFactory(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; public Class&lt;T&gt; getMapperInterface() &#123; return mapperInterface; &#125; public Map&lt;Method, MapperMethod&gt; getMethodCache() &#123; return methodCache; &#125; @SuppressWarnings(\"unchecked\") protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy); &#125; public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &#125;&#125; 在这里，先通过T newInstance(SqlSession sqlSession)方法会得到一个MapperProxy对象，然后调用T newInstance(MapperProxy mapperProxy)生成代理对象然后返回。 而查看MapperProxy的代码，可以看到如下内容： 123456789101112131415161718public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else if (isDefaultMethod(method)) &#123; return invokeDefaultMethod(proxy, method, args); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); &#125;&#125; 非常典型的，该MapperProxy类实现了InvocationHandler接口，并且实现了该接口的invoke方法。 通过这种方式，我们只需要编写Mapper.java接口类，当真正执行一个Mapper接口的时候，就会转发给MapperProxy.invoke方法，而该方法则会调用后续的sqlSession.cud&gt;executor.execute&gt;prepareStatement等一系列方法，完成SQL的执行和返回。 5、组合模式组合模式组合多个对象形成树形结构以表示“整体-部分”的结构层次。 组合模式对单个对象(叶子对象)和组合对象(组合对象)具有一致性，它将对象组织到树结构中，可以用来描述整体与部分的关系。同时它也模糊了简单元素(叶子对象)和复杂元素(容器对象)的概念，使得客户能够像处理简单元素一样来处理复杂元素，从而使客户程序能够与复杂元素的内部结构解耦。 在使用组合模式中需要注意一点也是组合模式最关键的地方：叶子对象和组合对象实现相同的接口。这就是组合模式能够将叶子节点和对象节点进行一致处理的原因。 Mybatis支持动态SQL的强大功能，比如下面的这个SQL： 123456789101112131415&lt;update id=\"update\" parameterType=\"org.format.dynamicproxy.mybatis.bean.User\"&gt; UPDATE users &lt;trim prefix=\"SET\" prefixOverrides=\",\"&gt; &lt;if test=\"name != null and name != ''\"&gt; name = #&#123;name&#125; &lt;/if&gt; &lt;if test=\"age != null and age != ''\"&gt; , age = #&#123;age&#125; &lt;/if&gt; &lt;if test=\"birthday != null and birthday != ''\"&gt; , birthday = #&#123;birthday&#125; &lt;/if&gt; &lt;/trim&gt; where id = $&#123;id&#125;&lt;/update&gt; 在这里面使用到了trim、if等动态元素，可以根据条件来生成不同情况下的SQL； 在DynamicSqlSource.getBoundSql方法里，调用了rootSqlNode.apply(context)方法，apply方法是所有的动态节点都实现的接口： 123public interface SqlNode&#123; booleanapply(DynamicContext context);&#125; 对于实现该SqlSource接口的所有节点，就是整个组合模式树的各个节点： 组合模式的简单之处在于，所有的子节点都是同一类节点，可以递归的向下执行，比如对于TextSqlNode，因为它是最底层的叶子节点，所以直接将对应的内容append到SQL语句中： 123456@Overridepublic boolean apply(DynamicContext context) &#123; GenericTokenParser parser = createParser(new BindingTokenParser(context, injectionFilter)); context.appendSql(parser.parse(text)); return true;&#125; 但是对于IfSqlNode，就需要先做判断，如果判断通过，仍然会调用子元素的SqlNode，即contents.apply方法，实现递归的解析。 12345678@Overridepublic boolean apply(DynamicContext context) &#123; if (evaluator.evaluateBoolean(test, context.getBindings())) &#123; contents.apply(context); return true; &#125; return false;&#125; 6、模板方法模式模板方法模式是所有模式中最为常见的几个模式之一，是基于继承的代码复用的基本技术。 模板方法模式需要开发抽象类和具体子类的设计师之间的协作。一个设计师负责给出一个算法的轮廓和骨架，另一些设计师则负责给出这个算法的各个逻辑步骤。代表这些具体逻辑步骤的方法称做基本方法(primitive method)；而将这些基本方法汇总起来的方法叫做模板方法(template method)，这个设计模式的名字就是从此而来。 模板类定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 在Mybatis中，sqlSession的SQL执行，都是委托给Executor实现的，Executor包含以下结构： 其中的BaseExecutor就采用了模板方法模式，它实现了大部分的SQL执行逻辑，然后把以下几个方法交给子类定制化完成： 12345protected abstract int doUpdate(MappedStatement ms, Object parameter) throws SQLException; protected abstract List&lt;BatchResult&gt; doFlushStatements(boolean isRollback) throws SQLException; protected abstract &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException; 该模板方法类有几个子类的具体实现，使用了不同的策略： 简单SimpleExecutor：每执行一次update或select，就开启一个Statement对象，用完立刻关闭Statement对象。（可以是Statement或PrepareStatement对象） 重用ReuseExecutor：执行update或select，以sql作为key查找Statement对象，存在就使用，不存在就创建，用完后，不关闭Statement对象，而是放置于Map内，供下一次使用。（可以是Statement或PrepareStatement对象） 批量BatchExecutor：执行update（没有select，JDBC批处理不支持select），将所有sql都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个Statement对象，每个Statement对象都是addBatch()完毕后，等待逐一执行executeBatch()批处理的；BatchExecutor相当于维护了多个桶，每个桶里都装了很多属于自己的SQL，就像苹果蓝里装了很多苹果，番茄蓝里装了很多番茄，最后，再统一倒进仓库。（可以是Statement或PrepareStatement对象） 比如在SimpleExecutor中这样实现update方法： 12345678910111213@Overridepublic int doUpdate(MappedStatement ms, Object parameter) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(this, ms, parameter, RowBounds.DEFAULT, null, null); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.update(stmt); &#125; finally &#123; closeStatement(stmt); &#125;&#125; 7、适配器模式适配器模式(Adapter Pattern) ：将一个接口转换成客户希望的另一个接口，适配器模式使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。 在Mybatsi的logging包中，有一个Log接口： 1234567891011121314151617public interface Log &#123; boolean isDebugEnabled(); boolean isTraceEnabled(); void error(String s, Throwable e); void error(String s); void debug(String s); void trace(String s); void warn(String s);&#125; 该接口定义了Mybatis直接使用的日志方法，而Log接口具体由谁来实现呢？Mybatis提供了多种日志框架的实现，这些实现都匹配这个Log接口所定义的接口方法，最终实现了所有外部日志框架到Mybatis日志包的适配： 比如对于Log4jImpl的实现来说，该实现持有了org.apache.log4j.Logger的实例，然后所有的日志方法，均委托该实例来实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Log4jImpl implements Log &#123; private static final String FQCN = Log4jImpl.class.getName(); private final Logger log; public Log4jImpl(String clazz) &#123; log = Logger.getLogger(clazz); &#125; @Override public boolean isDebugEnabled() &#123; return log.isDebugEnabled(); &#125; @Override public boolean isTraceEnabled() &#123; return log.isTraceEnabled(); &#125; @Override public void error(String s, Throwable e) &#123; log.log(FQCN, Level.ERROR, s, e); &#125; @Override public void error(String s) &#123; log.log(FQCN, Level.ERROR, s, null); &#125; @Override public void debug(String s) &#123; log.log(FQCN, Level.DEBUG, s, null); &#125; @Override public void trace(String s) &#123; log.log(FQCN, Level.TRACE, s, null); &#125; @Override public void warn(String s) &#123; log.log(FQCN, Level.WARN, s, null); &#125;&#125; 8、装饰者模式装饰模式(Decorator Pattern) ：动态地给一个对象增加一些额外的职责(Responsibility)，就增加对象功能来说，装饰模式比生成子类实现更为灵活。其别名也可以称为包装器(Wrapper)，与适配器模式的别名相同，但它们适用于不同的场合。根据翻译的不同，装饰模式也有人称之为“油漆工模式”，它是一种对象结构型模式。 在mybatis中，缓存的功能由根接口Cache（org.apache.ibatis.cache.Cache）定义。整个体系采用装饰器设计模式，数据存储和缓存的基本功能由PerpetualCache（org.apache.ibatis.cache.impl.PerpetualCache）永久缓存实现，然后通过一系列的装饰器来对PerpetualCache永久缓存进行缓存策略等方便的控制。如下图： 用于装饰PerpetualCache的标准装饰器共有8个（全部在org.apache.ibatis.cache.decorators包中）： FifoCache：先进先出算法，缓存回收策略 LoggingCache：输出缓存命中的日志信息 LruCache：最近最少使用算法，缓存回收策略 ScheduledCache：调度缓存，负责定时清空缓存 SerializedCache：缓存序列化和反序列化存储 SoftCache：基于软引用实现的缓存管理策略 SynchronizedCache：同步的缓存装饰器，用于防止多线程并发访问 WeakCache：基于弱引用实现的缓存管理策略 另外，还有一个特殊的装饰器TransactionalCache：事务性的缓存 正如大多数持久层框架一样，mybatis缓存同样分为一级缓存和二级缓存 一级缓存，又叫本地缓存，是PerpetualCache类型的永久缓存，保存在执行器中（BaseExecutor），而执行器又在SqlSession（DefaultSqlSession）中，所以一级缓存的生命周期与SqlSession是相同的。 二级缓存，又叫自定义缓存，实现了Cache接口的类都可以作为二级缓存，所以可配置如encache等的第三方缓存。二级缓存以namespace名称空间为其唯一标识，被保存在Configuration核心配置对象中。 二级缓存对象的默认类型为PerpetualCache，如果配置的缓存是默认类型，则mybatis会根据配置自动追加一系列装饰器。 Cache对象之间的引用顺序为： SynchronizedCache–&gt;LoggingCache–&gt;SerializedCache–&gt;ScheduledCache–&gt;LruCache–&gt;PerpetualCache 9、迭代器模式迭代器（Iterator）模式，又叫做游标（Cursor）模式。GOF给出的定义为：提供一种方法访问一个容器（container）对象中各个元素，而又不需暴露该对象的内部细节。 Java的Iterator就是迭代器模式的接口，只要实现了该接口，就相当于应用了迭代器模式： 比如Mybatis的PropertyTokenizer是property包中的重量级类，该类会被reflection包中其他的类频繁的引用到。这个类实现了Iterator接口，在使用时经常被用到的是Iterator接口中的hasNext这个函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class PropertyTokenizer implements Iterator&lt;PropertyTokenizer&gt; &#123; private String name; private String indexedName; private String index; private String children; publicPropertyTokenizer(String fullname) &#123; int delim = fullname.indexOf('.'); if (delim &gt; -1) &#123; name = fullname.substring(0, delim); children = fullname.substring(delim + 1); &#125; else &#123; name = fullname; children = null; &#125; indexedName = name; delim = name.indexOf('['); if (delim &gt; -1) &#123; index = name.substring(delim + 1, name.length() - 1); name = name.substring(0, delim); &#125; &#125; public String getName() &#123; return name; &#125; public String getIndex() &#123; return index; &#125; public String getIndexedName() &#123; return indexedName; &#125; public String getChildren() &#123; return children; &#125; @Override publicbooleanhasNext() &#123; return children != null; &#125; @Override public PropertyTokenizer next() &#123; return new PropertyTokenizer(children); &#125; @Override publicvoidremove() &#123; throw new UnsupportedOperationException( \"Remove is not supported, as it has no meaning in the context of properties.\"); &#125;&#125; 可以看到，这个类传入一个字符串到构造函数，然后提供了iterator方法对解析后的子串进行遍历，是一个很常用的方法类。 参考资料： 图说设计模式 http://design-patterns.readthedocs.io/zh_CN/latest/index.html 深入浅出Mybatis系列（十）—SQL执行流程分析（源码篇） http://www.cnblogs.com/dongying/p/4142476.html 设计模式读书笔记—–组合模式 http://www.cnblogs.com/chenssy/p/3299719.html Mybatis3.3.x技术内幕（四）：五鼠闹东京之执行器Executor设计原本 http://blog.csdn.net/wagcy/article/details/32963235 mybatis缓存机制详解（一）——Cache https://my.oschina.net/lixin91/blog/620068 转载自http://www.crazyant.net/2022.html","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/tags/JAVA/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://vincentruan.github.io/tags/Mybatis/"},{"name":"设计模式","slug":"设计模式","permalink":"https://vincentruan.github.io/tags/设计模式/"}]},{"title":"不可不说的Java锁事","slug":"不可不说的Java锁事","date":"2020-02-12T08:39:06.000Z","updated":"2020-02-25T15:09:15.060Z","comments":true,"path":"2020/02/12/不可不说的Java锁事/","link":"","permalink":"https://vincentruan.github.io/2020/02/12/不可不说的Java锁事/","excerpt":"前言Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。本文旨在对锁相关源码（本文中的源码来自JDK 8和Netty 3.10.6）、使用场景进行举例，为读者介绍主流锁的知识点，以及不同的锁的适用场景。","text":"前言Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。本文旨在对锁相关源码（本文中的源码来自JDK 8和Netty 3.10.6）、使用场景进行举例，为读者介绍主流锁的知识点，以及不同的锁的适用场景。 JAVA主流锁Java中往往是按照是否含有某一特性来定义锁，我们通过特性将锁进行分组归类，再使用对比的方式进行介绍，帮助大家更快捷的理解相关知识。下面给出本文内容的总体分类目录： 1. 乐观锁 VS 悲观锁乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。 先说概念。对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。 而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。 乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。 根据从上面的概念描述我们可以发现： 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。 光说概念有些抽象，我们来看下乐观锁和悲观锁的调用方式示例： 12345678910111213141516// ------------------------- 悲观锁的调用方式 -------------------------// synchronizedpublic synchronized void testMethod() &#123; // 操作同步资源&#125;// ReentrantLockprivate ReentrantLock lock = new ReentrantLock(); // 需要保证多个线程使用的是同一个锁public void modifyPublicResources() &#123; lock.lock(); // 操作同步资源 lock.unlock();&#125;// ------------------------- 乐观锁的调用方式 -------------------------private AtomicInteger atomicInteger = new AtomicInteger(); // 需要保证多个线程使用的是同一个AtomicIntegeratomicInteger.incrementAndGet(); //执行自增1 通过调用方式示例，我们可以发现悲观锁基本都是在显式的锁定之后再操作同步资源，而乐观锁则直接去操作同步资源。那么，为何乐观锁能够做到不锁定同步资源也可以正确的实现线程同步呢？我们通过介绍乐观锁的主要实现方式 “CAS” 的技术原理来为大家解惑。 CAS全称 Compare And Swap（比较与交换），是一种无锁算法。在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。java.util.concurrent包中的原子类就是通过CAS来实现了乐观锁。 CAS算法涉及到三个操作数： 需要读写的内存值 V。 进行比较的值 A。 要写入的新值 B。 当且仅当 V 的值等于 A 时，CAS通过原子方式用新值B来更新V的值（“比较+更新”整体是一个原子操作），否则不会执行任何操作。一般情况下，“更新”是一个不断重试的操作。 之前提到java.util.concurrent包中的原子类，就是通过CAS来实现了乐观锁，那么我们进入原子类AtomicInteger的源码，看一下AtomicInteger的定义： 123456789101112131415public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; 根据定义我们可以看出各属性的作用： unsafe： 获取并操作内存的数据。 valueOffset： 存储value在AtomicInteger中的偏移量。 value： 存储AtomicInteger的int值，该属性需要借助volatile关键字保证其在线程间是可见的。 接下来，我们查看AtomicInteger的自增函数incrementAndGet()的源码时，发现自增函数底层调用的是unsafe.getAndAddInt()。但是由于JDK本身只有Unsafe.class，只通过class文件中的参数名，并不能很好的了解方法的作用，所以我们通过OpenJDK 8 来查看Unsafe的源码： 123456789101112131415161718192021222324// ------------------------- JDK 8 -------------------------// AtomicInteger 自增方法public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125;// Unsafe.classpublic final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125;// ------------------------- OpenJDK 8 -------------------------// Unsafe.javapublic final int getAndAddInt(Object o, long offset, int delta) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!compareAndSwapInt(o, offset, v, v + delta)); return v;&#125; 根据OpenJDK 8的源码我们可以看出，getAndAddInt()循环获取给定对象o中的偏移量处的值v，然后判断内存值是否等于v。如果相等则将内存值设置为 v + delta，否则返回false，继续循环进行重试，直到设置成功才能退出循环，并且将旧值返回。整个“比较+更新”操作封装在compareAndSwapInt()中，在JNI里是借助于一个CPU指令完成的，属于原子操作，可以保证多个线程都能够看到同一个变量的修改值。 后续JDK通过CPU的cmpxchg指令，去比较寄存器中的 A 和 内存中的值 V。如果相等，就把要写入的新值 B 存入内存中。如果不相等，就将内存值 V 赋值给寄存器中的值 A。然后通过Java代码中的while循环再次调用cmpxchg指令进行重试，直到设置成功为止。 CAS虽然很高效，但是它也存在三大问题，这里也简单说一下： ABA问题 。CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。 JDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。 循环时间长开销大。CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。 只能保证一个共享变量的原子操作 。对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。 Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。 2. 自旋锁 VS 适应性自旋锁在介绍自旋锁前，我们需要介绍一些前提知识来帮助大家明白自旋锁的概念。 阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。 在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。 而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。 自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。 自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。 123456789// sun.misc.Unsafe#getAndAddIntpublic final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。 自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。 在自旋锁中 另有三种常见的锁形式:TicketLock、CLHlock和MCSlock，本文中仅做名词介绍，不做深入讲解，感兴趣的同学可以自行查阅相关资料。 3. 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁这四种锁是指锁的状态，专门针对synchronized的。在介绍这四种锁状态之前还需要介绍一些额外的知识。 首先为什么Synchronized能实现线程同步？ 在回答这个问题之前我们需要了解两个重要的概念：“Java对象头”、“Monitor”。 Java对象头synchronized是悲观锁，在操作同步资源之前需要给同步资源先加锁，这把锁就是存在Java对象头里的，而Java对象头又是什么呢？ 我们以Hotspot虚拟机为例，Hotspot的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。 Mark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。 Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 MonitorMonitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。 Monitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。 现在话题回到synchronized，synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。 如同我们在自旋锁中提到的“阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长”。这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。 所以目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。 通过上面的介绍，我们对synchronized的加锁机制以及相关知识有了一个了解，那么下面我们给出四种锁状态对应的的Mark Word内容，然后再分别讲解四种锁状态的思路以及特点： 锁状态 存储内容 存储内容 无锁 对象的hashCode、对象分代年龄、是否是偏向锁（0） 01 偏向锁 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1） 01 轻量级锁 指向栈中锁记录的指针 00 重量级锁 指向互斥量（重量级锁）的指针 10 无锁 无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。 无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 偏向锁 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。 在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。 当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。 偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。 轻量级锁 是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。 如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。 若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。 重量级锁 升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 整体的锁状态升级流程如下： 综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 4. 公平锁 VS 非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。 非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。 直接用语言描述可能有点抽象，这里作者用从别处看到的一个例子来讲述一下公平锁和非公平锁。 如上图所示，假设有一口水井，有管理员看守，管理员有一把锁，只有拿到锁的人才能够打水，打完水要把锁还给管理员。每个过来打水的人都要管理员的允许并拿到锁之后才能去打水，如果前面有人正在打水，那么这个想要打水的人就必须排队。管理员会查看下一个要去打水的人是不是队伍里排最前面的人，如果是的话，才会给你锁让你去打水；如果你不是排第一的人，就必须去队尾排队，这就是公平锁。 但是对于非公平锁，管理员对打水的人没有要求。即使等待队伍里有排队等待的人，但如果在上一个人刚打完水把锁还给管理员而且管理员还没有允许等待队伍里下一个人去打水时，刚好来了一个插队的人，这个插队的人是可以直接从管理员那里拿到锁去打水，不需要排队，原本排队等待的人只能继续等待。如下图所示： 接下来我们通过ReentrantLock的源码来讲解公平锁和非公平锁。 根据代码可知，ReentrantLock里面有一个内部类Sync，Sync继承AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在Sync中实现的。它有公平锁FairSync和非公平锁NonfairSync两个子类。ReentrantLock默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。 下面我们来看一下公平锁与非公平锁的加锁方法的源码: 通过上图中的源代码对比，我们可以明显的看出公平锁与非公平锁的lock()方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件：hasQueuedPredecessors()。 再进入hasQueuedPredecessors()，可以看到该方法主要做一件事情：主要是判断当前线程是否位于同步队列中的第一个。如果是则返回true，否则返回false。 综上，公平锁就是通过同步队列来实现多个线程按照申请锁的顺序来获取锁，从而实现公平的特性。非公平锁加锁时不考虑排队等待问题，直接尝试获取锁，所以存在后申请却先获得锁的情况。 5. 可重入锁 VS 非可重入锁可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。下面用示例代码来进行分析： 12345678910public class Widget &#123; public synchronized void doSomething() &#123; System.out.println(\"方法1执行...\"); doOthers(); &#125; public synchronized void doOthers() &#123; System.out.println(\"方法2执行...\"); &#125;&#125; 在上面的代码中，类中的两个方法都是被内置锁synchronized修饰的，doSomething()方法中调用doOthers()方法。因为内置锁是可重入的，所以同一个线程在调用doOthers()时可以直接获得当前对象的锁，进入doOthers()进行操作。 如果是一个不可重入锁，那么当前线程在调用doOthers()之前需要将执行doSomething()时获取当前对象的锁释放掉，实际上该对象锁已被当前线程所持有，且无法释放。所以此时会出现死锁。 而为什么可重入锁就可以在嵌套调用时可以自动获得锁呢？我们通过图示和源码来分别解析一下。 还是打水的例子，有多个人在排队打水，此时管理员允许锁和同一个人的多个水桶绑定。这个人用多个水桶打水时，第一个水桶和锁绑定并打完水之后，第二个水桶也可以直接和锁绑定并开始打水，所有的水桶都打完水之后打水人才会将锁还给管理员。这个人的所有打水流程都能够成功执行，后续等待的人也能够打到水。这就是可重入锁。 但如果是非可重入锁的话，此时管理员只允许锁和同一个人的一个水桶绑定。第一个水桶和锁绑定打完水之后并不会释放锁，导致第二个水桶不能和锁绑定也无法打水。当前线程出现死锁，整个等待队列中的所有线程都无法被唤醒。 之前我们说过ReentrantLock和synchronized都是重入锁，那么我们通过重入锁ReentrantLock以及非可重入锁NonReentrantLock的源码来对比分析一下为什么非可重入锁在重复调用同步资源时会出现死锁。 首先ReentrantLock和NonReentrantLock都继承父类AQS，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。 当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞。 释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。 6. 独享锁 VS 共享锁独享锁和共享锁同样是一种概念。我们先介绍一下具体的概念，然后通过ReentrantLock和ReentrantReadWriteLock的源码来介绍独享锁和共享锁。 独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。 共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 下图为ReentrantReadWriteLock的部分源码： 我们看到ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。 在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。 那读锁和写锁的具体加锁方式有什么区别呢？在了解源码之前我们需要回顾一下其他知识。 在最开始提及AQS的时候我们也提到了state字段（int类型，32位），该字段用来描述有多少线程获持有锁。 在独享锁中这个值通常是0或者1（如果是重入锁的话state值就是重入的次数），在共享锁中state就是持有锁的数量。但是在ReentrantReadWriteLock中有读、写两把锁，所以需要在一个整型变量state上分别描述读锁和写锁的数量（或者也可以叫状态）。于是将state变量“按位切割”切分成了两个部分，高16位表示读锁状态（读锁个数），低16位表示写锁状态（写锁个数）。如下图所示： 了解了概念之后我们再来看代码，先看写锁的加锁源码： 12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); // 取到当前锁的个数 int w = exclusiveCount(c); // 取写锁的个数w if (c != 0) &#123; // 如果已经有线程持有了锁(c!=0) // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) // 如果写线程数（w）为0（换言之存在读锁） 或者持有锁的线程不是当前线程就返回失败 return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) // 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。 throw new Error(\"Maximum lock count exceeded\"); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) // 如果当且写线程数为0，并且当前线程需要阻塞那么就返回失败；或者如果通过CAS增加写线程数失败也返回失败。 return false; setExclusiveOwnerThread(current); // 如果c=0，w=0或者c&gt;0，w&gt;0（重入），则设置当前线程或锁的拥有者 return true;&#125; 这段代码首先取到当前锁的个数c，然后再通过c来获取写锁的个数w。因为写锁是低16位，所以取低16位的最大值与当前的c做与运算（ int w = exclusiveCount©; ），高16位和0与运算后是0，剩下的就是低位运算的值，同时也是持有写锁的线程数目。 在取到写锁线程的数目后，首先判断是否已经有线程持有了锁。如果已经有线程持有了锁(c!=0)，则查看当前写锁线程的数目，如果写线程数为0（即此时存在读锁）或者持有锁的线程不是当前线程就返回失败（涉及到公平锁和非公平锁的实现）。 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。 如果当且写线程数为0（那么读线程也应该为0，因为上面已经处理c!=0的情况），并且当前线程需要阻塞那么就返回失败；如果通过CAS增加写线程数失败也返回失败。 如果c=0,w=0或者c&gt;0,w&gt;0（重入），则设置当前线程或锁的拥有者，返回成功！ tryAcquire()除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：必须确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。 因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，然后等待的读写线程才能够继续访问读写锁，同时前次写线程的修改对后续的读写线程可见。 接着是读锁的代码： 123456789101112131415161718192021222324252627protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态 int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 可以看到在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是“1&lt;&lt;16”。所以读写锁才能实现读读的过程共享，而读写、写读、写写的过程互斥。 此时，我们再回头看一下互斥锁ReentrantLock中公平锁和非公平锁的加锁源码： 我们发现在ReentrantLock虽然有公平锁和非公平锁两种，但是它们添加的都是独享锁。根据源码所示，当某一个线程调用lock方法获取锁时，如果同步资源没有被其他线程锁住，那么当前线程在使用CAS更新state成功后就会成功抢占该资源。而如果公共资源被占用且不是被当前线程占用，那么就会加锁失败。所以可以确定ReentrantLock无论读操作还是写操作，添加的锁都是都是独享锁。 其他锁细节synchronizedsynchronized 关键字是一把经典的锁，也是我们平时用得最多的。在 JDK1.6 之前， syncronized 是一把重量级的锁，不过随着 JDK 的升级，也在对它进行不断的优化，如今它变得不那么重了，甚至在某些场景下，它的性能反而优于轻量级锁。在加了 syncronized 关键字的方法、代码块中，一次只允许一个线程进入特定代码段，从而避免多线程同时修改同一数据。 synchronized 锁有如下几个特点： 有锁升级过程 在 JDK1.5 (含)之前， synchronized 的底层实现是重量级的，所以之前一致称呼它为”重量级锁”，在 JDK1.5 之后，对 synchronized 进行了各种优化，它变得不那么重了，实现原理就是锁升级的过程。我们先聊聊 1.5 之后的 synchronized 实现原理是怎样的。说到 synchronized 加锁原理，就不得不先说 Java 对象在内存中的布局， Java 对象内存布局如下: 如上图所示，在创建一个对象后，在 JVM 虚拟机( HotSpot )中，对象在 Java 内存中的存储布局 可分为三块: 对象头区域此处存储的信息包括两部分： 1、对象自身的运行时数据( MarkWord ) 存储 hashCode、GC 分代年龄、锁类型标记、偏向锁线程 ID 、 CAS 锁指向线程 LockRecord 的指针等， synconized 锁的机制与这个部分( markwork )密切相关，用 markword 中最低的三位代表锁的状态，其中一位是偏向锁位，另外两位是普通锁位。 2、对象类型指针( Class Pointer ) 对象指向它的类元数据的指针、 JVM 就是通过它来确定是哪个 Class 的实例。 实例数据区域 此处存储的是对象真正有效的信息，比如对象中所有字段的内容 对齐填充区域 JVM 的实现 HostSpot 规定对象的起始地址必须是 8 字节的整数倍，换句话来说，现在 64 位的 OS 往外读取数据的时候一次性读取 64bit 整数倍的数据，也就是 8 个字节，所以 HotSpot 为了高效读取对象，就做了”对齐”，如果一个对象实际占的内存大小不是 8byte 的整数倍时，就”补位”到 8byte 的整数倍。所以对齐填充区域的大小不是固定的。 当线程进入到 synchronized 处尝试获取该锁时， synchronized 锁升级流程如下： 如上图所示， synchronized 锁升级的顺序为：偏向锁-&gt;轻量级锁-&gt;重量级锁，每一步触发锁升级的情况如下： 偏向锁在 JDK1.8 中，其实默认是轻量级锁，但如果设定了 -XX:BiasedLockingStartupDelay = 0 ，那在对一个 Object 做 syncronized 的时候，会立即上一把偏向锁。当处于偏向锁状态时， markwork 会记录当前线程 ID 。 升级到轻量级锁当下一个线程参与到偏向锁竞争时，会先判断 markword 中保存的线程 ID 是否与这个线程 ID 相等，如果不相等，会立即撤销偏向锁，升级为轻量级锁。每个线程在自己的线程栈中生成一个 LockRecord ( LR )，然后每个线程通过 CAS (自旋)的操作将锁对象头中的 markwork 设置为指向自己的 LR 的指针，哪个线程设置成功，就意味着获得锁。关于 synchronized 中此时执行的 CAS 操作是通过 native 的调用 HotSpot 中 bytecodeInterpreter.cpp 文件 C++ 代码实现的，有兴趣的可以继续深挖。 升级到重量级锁如果锁竞争加剧(如线程自旋次数或者自旋的线程数超过某阈值， JDK1.6 之后，由 JVM 自己控制该规则)，就会升级为重量级锁。此时就会向操作系统申请资源，线程挂起，进入到操作系统内核态的等待队列中，等待操作系统调度，然后映射回用户态。在重量级锁中，由于需要做内核态到用户态的转换，而这个过程中需要消耗较多时间，也就是”重”的原因之一。 可重入synchronized 拥有强制原子性的内部锁机制，是一把可重入锁。因此，在一个线程使用 synchronized 方法时调用该对象另一个 synchronized 方法，即一个线程得到一个对象锁后再次请求该对象锁，是永远可以拿到锁的。在 Java 中线程获得对象锁的操作是以线程为单位的，而不是以调用为单位的。 synchronized 锁的对象头的 markwork 中会记录该锁的线程持有者和计数器，当一个线程请求成功后， JVM 会记下持有锁的线程，并将计数器计为1。此时其他线程请求该锁，则必须等待。而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增。当线程退出一个 synchronized 方法/块时，计数器会递减，如果计数器为 0 则释放该锁锁。 悲观锁(互斥锁、排他锁) synchronized 是一把悲观锁(独占锁)，当前线程如果获取到锁，会导致其它所有需要锁该的线程等待，一直等待持有锁的线程释放锁才继续进行锁的争抢。 ReentrantLockReentrantLock 从字面可以看出是一把可重入锁，这点和 synchronized 一样，但实现原理也与 syncronized 有很大差别，它是基于经典的 AQS(AbstractQueueSyncronized) 实现的, AQS 是基于 volitale 和 CAS 实现的，其中 AQS 中维护一个 valitale 类型的变量 state 来做一个可重入锁的重入次数，加锁和释放锁也是围绕这个变量来进行的。 ReentrantLock 也提供了一些 synchronized 没有的特点，因此比 synchronized 好用。 AQS模型如下图： ReentrantLock 有如下特点： 可重入 ReentrantLock 和 syncronized 关键字一样，都是可重入锁，不过两者实现原理稍有差别， RetrantLock 利用 AQS 的的 state 状态来判断资源是否已锁，同一线程重入加锁， state 的状态 +1 ; 同一线程重入解锁, state 状态 -1 (解锁必须为当前独占线程，否则异常); 当 state 为 0 时解锁成功。 需要手动加锁、解锁synchronized 关键字是自动进行加锁、解锁的，而 ReentrantLock 需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成，来手动加锁、解锁。 支持设置锁的超时时间 synchronized 关键字无法设置锁的超时时间，如果一个获得锁的线程内部发生死锁，那么其他线程就会一直进入阻塞状态，而 ReentrantLock 提供 tryLock 方法，允许设置线程获取锁的超时时间，如果超时，则跳过，不进行任何操作，避免死锁的发生。 支持公平/非公平锁synchronized 关键字是一种非公平锁，先抢到锁的线程先执行。而 ReentrantLock 的构造方法中允许设置 true/false 来实现公平、非公平锁，如果设置为 true ，则线程获取锁要遵循”先来后到”的规则，每次都会构造一个线程 Node ，然后到双向链表的”尾巴”后面排队，等待前面的 Node 释放锁资源。 可中断锁 ReentrantLock 中的 lockInterruptibly() 方法使得线程可以在被阻塞时响应中断，比如一个线程 t1 通过 lockInterruptibly() 方法获取到一个可重入锁，并执行一个长时间的任务，另一个线程通过 interrupt() 方法就可以立刻打断 t1 线程的执行，来获取t1持有的那个可重入锁。而通过 ReentrantLock 的 lock() 方法或者 Synchronized 持有锁的线程是不会响应其他线程的 interrupt() 方法的，直到该方法主动释放锁之后才会响应 interrupt() 方法。 ReentrantReadWriteLockReentrantReadWriteLock (读写锁)其实是两把锁，一把是 WriteLock (写锁)，一把是读锁， ReadLock 。读写锁的规则是：读读不互斥、读写互斥、写写互斥。在一些实际的场景中，读操作的频率远远高于写操作，如果直接用一般的锁进行并发控制的话，就会读读互斥、读写互斥、写写互斥，效率低下，读写锁的产生就是为了优化这种场景的操作效率。一般情况下独占锁的效率低来源于高并发下对临界区的激烈竞争导致线程上下文切换。因此当并发不是很高的情况下，读写锁由于需要额外维护读锁的状态，可能还不如独占锁的效率高，因此需要根据实际情况选择使用。 ReentrantReadWriteLock 的原理也是基于 AQS 进行实现的，与 ReentrantLock 的差别在于 ReentrantReadWriteLock 锁拥有共享锁、排他锁属性。读写锁中的加锁、释放锁也是基于 Sync (继承于 AQS )，并且主要使用 AQS 中的 state 和 node 中的 waitState 变量进行实现的。实现读写锁与实现普通互斥锁的主要区别在于需要分别记录读锁状态及写锁状态，并且等待队列中需要区别处理两种加锁操作。 ReentrantReadWriteLock 中将 AQS 中的 int 类型的 state 分为高 16 位与第 16 位分别记录读锁和写锁的状态，如下图所示： WriteLock(写锁)是悲观锁(排他锁、互斥锁) 通过计算 state&amp;((1&lt;&lt;16)-1) ，将 state 的高 16 位全部抹去，因此 state 的低位记录着写锁的重入计数。 获取写锁源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889/** * 获取写锁 Acquires the write lock. * 如果此时没有任何线程持有写锁或者读锁，那么当前线程执行CAS操作更新status， * 若更新成功，则设置读锁重入次数为1，并立即返回 * &lt;p&gt;Acquires the write lock if neither the read nor write lock * are held by another thread * and returns immediately, setting the write lock hold count to * one. * 如果当前线程已经持有该写锁，那么将写锁持有次数设置为1，并立即返回 * &lt;p&gt;If the current thread already holds the write lock then the * hold count is incremented by one and the method returns * immediately. * 如果该锁已经被另外一个线程持有，那么停止该线程的CPU调度并进入休眠状态， * 直到该写锁被释放，且成功将写锁持有次数设置为1才表示获取写锁成功 * &lt;p&gt;If the lock is held by another thread then the current * thread becomes disabled for thread scheduling purposes and * lies dormant until the write lock has been acquired, at which * time the write lock hold count is set to one. */ public void lock() &#123; sync.acquire(1); &#125;/** * 该方法为以独占模式获取锁，忽略中断 * 如果调用一次该“tryAcquire”方法更新status成功，则直接返回，代表抢锁成功 * 否则，将会进入同步队列等待，不断执行“tryAcquire”方法尝试CAS更新status状态，直到成功抢到锁 * 其中“tryAcquire”方法在NonfairSync(公平锁)中和FairSync(非公平锁)中都有各自的实现 * * Acquires in exclusive mode, ignoring interrupts. Implemented * by invoking at least once &#123;@link #tryAcquire&#125;, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking &#123;@link * #tryAcquire&#125; until success. This method can be used * to implement method &#123;@link Lock#lock&#125;. * * @param arg the acquire argument. This value is conveyed to * &#123;@link #tryAcquire&#125; but is otherwise uninterpreted and * can represent anything you like. */ public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; protected final boolean tryAcquire(int acquires) &#123; /* * Walkthrough: * 1、如果读写锁的计数不为0，且持有锁的线程不是当前线程，则返回false * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2、如果持有锁的计数不为0且计数总数超过限定的最大值，也返回false * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3、如果该锁是可重入或该线程在队列中的策略是允许它尝试抢锁，那么该线程就能获取锁 * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); //获取读写锁的状态 int c = getState(); //获取该写锁重入的次数 int w = exclusiveCount(c); //如果读写锁状态不为0，说明已经有其他线程获取了读锁或写锁 if (c != 0) &#123; //如果写锁重入次数为0，说明有线程获取到读锁，根据“读写锁互斥”原则，返回false //或者如果写锁重入次数不为0，且获取写锁的线程不是当前线程，根据\"写锁独占\"原则，返回false // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; //如果写锁可重入次数超过最大次数（65535），则抛异常 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); //到这里说明该线程是重入写锁，更新重入写锁的计数(+1)，返回true // Reentrant acquire setState(c + acquires); return true; &#125; //如果读写锁状态为0,说明读锁和写锁都没有被获取，会走下面两个分支： //如果要阻塞或者执行CAS操作更新读写锁的状态失败，则返回false //如果不需要阻塞且CAS操作成功，则当前线程成功拿到锁，设置锁的owner为当前线程，返回true if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; &#125; 释放写锁源码： 123456789101112131415161718192021/* * Note that tryRelease and tryAcquire can be called by * Conditions. So it is possible that their arguments contain * both read and write holds that are all released during a * condition wait and re-established in tryAcquire. */ protected final boolean tryRelease(int releases) &#123; //若锁的持有者不是当前线程，抛出异常 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //写锁的可重入计数减掉releases个 int nextc = getState() - releases; //如果写锁重入计数为0了，则说明写锁被释放了 boolean free = exclusiveCount(nextc) == 0; if (free) //若写锁被释放，则将锁的持有者设置为null，进行GC setExclusiveOwnerThread(null); //更新写锁的重入计数 setState(nextc); return free; &#125; ReadLock(读锁)是共享锁(乐观锁) 通过计算 state&gt;&gt;&gt;16 进行无符号补 0 ，右移 16 位，因此 state 的高位记录着写锁的重入计数. 读锁获取锁的过程比写锁稍微复杂些，首先判断写锁是否为 0 并且当前线程不占有独占锁，直接返回；否则，判断读线程是否需要被阻塞并且读锁数量是否小于最大值并且比较设置状态成功，若当前没有读锁，则设置第一个读线程 firstReader 和 firstReaderHoldCount ；若当前线程线程为第一个读线程，则增加 firstReaderHoldCount ；否则，将设置当前线程对应的 HoldCounter 对象的值，更新成功后会在 firstReaderHoldCount 中 readHolds ( ThreadLocal 类型的)的本线程副本中记录当前线程重入数，这是为了实现 JDK1.6 中加入的 getReadHoldCount ()方法的，这个方法能获取当前线程重入共享锁的次数( state 中记录的是多个线程的总重入次数)，加入了这个方法让代码复杂了不少，但是其原理还是很简单的：如果当前只有一个线程的话，还不需要动用 ThreadLocal ，直接往 firstReaderHoldCount 这个成员变量里存重入数，当有第二个线程来的时候，就要动用 ThreadLocal 变量 readHolds 了，每个线程拥有自己的副本，用来保存自己的重入数。 获取读锁源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166/** * 获取读锁 * Acquires the read lock. * 如果写锁未被其他线程持有，执行CAS操作更新status值，获取读锁后立即返回 * &lt;p&gt;Acquires the read lock if the write lock is not held by * another thread and returns immediately. * * 如果写锁被其他线程持有，那么停止该线程的CPU调度并进入休眠状态，直到该读锁被释放 * &lt;p&gt;If the write lock is held by another thread then * the current thread becomes disabled for thread scheduling * purposes and lies dormant until the read lock has been acquired. */ public void lock() &#123; sync.acquireShared(1); &#125; /** * 该方法为以共享模式获取读锁，忽略中断 * 如果调用一次该“tryAcquireShared”方法更新status成功，则直接返回，代表抢锁成功 * 否则，将会进入同步队列等待，不断执行“tryAcquireShared”方法尝试CAS更新status状态，直到成功抢到锁 * 其中“tryAcquireShared”方法在NonfairSync(公平锁)中和FairSync(非公平锁)中都有各自的实现 * (看这注释是不是和写锁很对称) * Acquires in shared mode, ignoring interrupts. Implemented by * first invoking at least once &#123;@link #tryAcquireShared&#125;, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking &#123;@link * #tryAcquireShared&#125; until success. * * @param arg the acquire argument. This value is conveyed to * &#123;@link #tryAcquireShared&#125; but is otherwise uninterpreted * and can represent anything you like. */ public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; protected final int tryAcquireShared(int unused) &#123; /* * Walkthrough: * 1、如果已经有其他线程获取到了写锁，根据“读写互斥”原则，抢锁失败，返回-1 * 1.If write lock held by another thread, fail. * 2、如果该线程本身持有写锁，那么看一下是否要readerShouldBlock，如果不需要阻塞， * 则执行CAS操作更新state和重入计数。 * 这里要注意的是，上面的步骤不检查是否可重入(因为读锁属于共享锁，天生支持可重入) * 2. Otherwise, this thread is eligible for * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3、如果因为CAS更新status失败或者重入计数超过最大值导致步骤2执行失败 * 那就进入到fullTryAcquireShared方法进行死循环，直到抢锁成功 * 3. If step 2 fails either because thread * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ //当前尝试获取读锁的线程 Thread current = Thread.currentThread(); //获取该读写锁状态 int c = getState(); //如果有线程获取到了写锁 ，且获取写锁的不是当前线程则返回失败 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; //获取读锁的重入计数 int r = sharedCount(c); //如果读线程不应该被阻塞，且重入计数小于最大值，且CAS执行读锁重入计数+1成功，则执行线程重入的计数加1操作，返回成功 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; //如果还未有线程获取到读锁，则将firstReader设置为当前线程，firstReaderHoldCount设置为1 if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; //如果firstReader是当前线程，则将firstReader的重入计数变量firstReaderHoldCount加1 firstReaderHoldCount++; &#125; else &#123; //否则说明有至少两个线程共享读锁，获取共享锁重入计数器HoldCounter //从HoldCounter中拿到当前线程的线程变量cachedHoldCounter，将此线程的重入计数count加1 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; //如果上面的if条件有一个都不满足，则进入到这个方法里进行死循环重新获取 return fullTryAcquireShared(current); &#125; /** * 用于处理CAS操作state失败和tryAcquireShared中未执行获取可重入锁动作的full方法(补偿方法？) * Full version of acquire for reads, that handles CAS misses * and reentrant reads not dealt with in tryAcquireShared. */ final int fullTryAcquireShared(Thread current) &#123; /* * 此代码与tryAcquireShared中的代码有部分相似的地方， * 但总体上更简单，因为不会使tryAcquireShared与重试和延迟读取保持计数之间的复杂判断 * This code is in part redundant with that in * tryAcquireShared but is simpler overall by not * complicating tryAcquireShared with interactions between * retries and lazily reading hold counts. */ HoldCounter rh = null; //死循环 for (;;) &#123; //获取读写锁状态 int c = getState(); //如果有线程获取到了写锁 if (exclusiveCount(c) != 0) &#123; //如果获取写锁的线程不是当前线程，返回失败 if (getExclusiveOwnerThread() != current) return -1; // else we hold the exclusive lock; blocking here // would cause deadlock. &#125; else if (readerShouldBlock()) &#123;//如果没有线程获取到写锁，且读线程要阻塞 // Make sure we're not acquiring read lock reentrantly //如果当前线程为第一个获取到读锁的线程 if (firstReader == current) &#123; // assert firstReaderHoldCount &gt; 0; &#125; else &#123; //如果当前线程不是第一个获取到读锁的线程(也就是说至少有有一个线程获取到了读锁) // if (rh == null) &#123; rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) &#123; rh = readHolds.get(); if (rh.count == 0) readHolds.remove(); &#125; &#125; if (rh.count == 0) return -1; &#125; &#125; /** *下面是既没有线程获取写锁，当前线程又不需要阻塞的情况 */ //重入次数等于最大重入次数，抛异常 if (sharedCount(c) == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); //如果执行CAS操作成功将读写锁的重入计数加1，则对当前持有这个共享读锁的线程的重入计数加1，然后返回成功 if (compareAndSetState(c, c + SHARED_UNIT)) &#123; if (sharedCount(c) == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; cachedHoldCounter = rh; // cache for release &#125; return 1; &#125; &#125; &#125; 释放读锁源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100/** * Releases in shared mode. Implemented by unblocking one or more * threads if &#123;@link #tryReleaseShared&#125; returns true. * * @param arg the release argument. This value is conveyed to * &#123;@link #tryReleaseShared&#125; but is otherwise uninterpreted * and can represent anything you like. * @return the value returned from &#123;@link #tryReleaseShared&#125; */public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123;//尝试释放一次共享锁计数 doReleaseShared();//真正释放锁 return true; &#125; return false;&#125;/** *此方法表示读锁线程释放锁。 *首先判断当前线程是否为第一个读线程firstReader， *若是，则判断第一个读线程占有的资源数firstReaderHoldCount是否为1， 若是，则设置第一个读线程firstReader为空，否则，将第一个读线程占有的资源数firstReaderHoldCount减1； 若当前线程不是第一个读线程， 那么首先会获取缓存计数器（上一个读锁线程对应的计数器 ）， 若计数器为空或者tid不等于当前线程的tid值，则获取当前线程的计数器， 如果计数器的计数count小于等于1，则移除当前线程对应的计数器， 如果计数器的计数count小于等于0，则抛出异常，之后再减少计数即可。 无论何种情况，都会进入死循环，该循环可以确保成功设置状态state */protected final boolean tryReleaseShared(int unused) &#123; // 获取当前线程 Thread current = Thread.currentThread(); if (firstReader == current) &#123; // 当前线程为第一个读线程 // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) // 读线程占用的资源数为1 firstReader = null; else // 减少占用的资源 firstReaderHoldCount--; &#125; else &#123; // 当前线程不为第一个读线程 // 获取缓存的计数器 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) // 计数器为空或者计数器的tid不为当前正在运行的线程的tid // 获取当前线程对应的计数器 rh = readHolds.get(); // 获取计数 int count = rh.count; if (count &lt;= 1) &#123; // 计数小于等于1 // 移除 readHolds.remove(); if (count &lt;= 0) // 计数小于等于0，抛出异常 throw unmatchedUnlockException(); &#125; // 减少计数 --rh.count; &#125; for (;;) &#123; // 死循环 // 获取状态 int c = getState(); // 获取状态 int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) // 比较并进行设置 // Releasing the read lock has no effect on readers, // but it may allow waiting writers to proceed if // both read and write locks are now free. return nextc == 0; &#125; &#125; /**真正释放锁 * Release action for shared mode -- signals successor and ensures * propagation. (Note: For exclusive mode, release just amounts * to calling unparkSuccessor of head if it needs signal.) */private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125; &#125; 通过分析可以看出： 在线程持有读锁的情况下，该线程不能取得写锁(因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有)。 在线程持有写锁的况下，该线程可以继续获取读锁（获取读锁时如果发现写锁被占用，只有写锁没有被当前线程占用的情况才会获取失败）。 LongAdder在高并发的情况下，我们对一个 Integer 类型的整数直接进行 i++ 的时候，无法保证操作的原子性，会出现线程安全的问题。为此我们会用 juc 下的 AtomicInteger ，它是一个提供原子操作的 Interger 类，内部也是通过 CAS 实现线程安全的。但当大量线程同时去访问时，就会因为大量线程执行 CAS 操作失败而进行空旋转，导致 CPU 资源消耗过多，而且执行效率也不高。 Doug Lea 大神应该也不满意，于是在 JDK1.8 中对 CAS 进行了优化，提供了 LongAdder ，它是基于了 CAS 分段锁的思想实现的。 线程去读写一个 LongAdder 类型的变量时，流程如下： LongAdder 也是基于 Unsafe 提供的 CAS 操作 +valitale 去实现的。在 LongAdder 的父类 Striped64 中维护着一个 base 变量和一个 cell 数组，当多个线程操作一个变量的时候，先会在这个 base 变量上进行 cas 操作，当它发现线程增多的时候，就会使用 cell 数组。比如当 base 将要更新的时候发现线程增多（也就是调用 casBase 方法更新 base 值失败），那么它会自动使用 cell 数组，每一个线程对应于一个 cell ，在每一个线程中对该 cell 进行 cas 操作，这样就可以将单一 value 的更新压力分担到多个 value 中去，降低单个 value 的 “热度”，同时也减少了大量线程的空转，提高并发效率，分散并发压力。这种分段锁需要额外维护一个内存空间 cells ，不过在高并发场景下，这点成本几乎可以忽略。分段锁是一种优秀的优化思想， juc 中提供的的 ConcurrentHashMap 也是基于分段锁保证读写操作的线程安全。 结语本文Java中常用的锁以及常见的锁的概念进行了基本介绍，并从源码以及实际应用的角度进行了对比分析。限于篇幅以及个人水平，没有在本篇文章中对所有内容进行深层次的讲解。 其实Java本身已经对锁本身进行了良好的封装，降低了研发同学在平时工作中的使用难度。但是研发同学也需要熟悉锁的底层原理，不同场景下选择最适合的锁。而且源码中的思路都是非常好的思路，也是值得大家去学习和借鉴的。 参考资料 《Java并发编程艺术》 Java中的锁 Java CAS 原理剖析 Java并发——关键字synchronized解析 Java synchronized原理总结 聊聊并发（二）——Java SE1.6中的Synchronized 深入理解读写锁—ReadWriteLock源码分析 【JUC】JDK1.8源码分析之ReentrantReadWriteLock Java多线程（十）之ReentrantReadWriteLock深入分析 Java–读写锁的实现原理 转载自美团技术团队，原文地址，在原文基础上有修改.","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/tags/JAVA/"},{"name":"并发","slug":"并发","permalink":"https://vincentruan.github.io/tags/并发/"}]},{"title":"从ReentrantLock的实现看AQS的原理及应用","slug":"从ReentrantLock的实现看AQS的原理及应用","date":"2020-02-12T08:27:06.000Z","updated":"2020-02-25T15:09:15.061Z","comments":true,"path":"2020/02/12/从ReentrantLock的实现看AQS的原理及应用/","link":"","permalink":"https://vincentruan.github.io/2020/02/12/从ReentrantLock的实现看AQS的原理及应用/","excerpt":"前言Java中的大部分同步类（Lock、Semaphore、ReentrantLock等）都是基于AbstractQueuedSynchronizer（简称为AQS）实现的。AQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。本文会从应用层逐渐深入到原理层，并通过ReentrantLock的基本特性和ReentrantLock与AQS的关联，来深入解读AQS相关独占锁的知识点，同时采取问答的模式来帮助大家理解AQS。由于篇幅原因，本篇文章主要阐述AQS中独占锁的逻辑和Sync Queue，不讲述包含共享锁和Condition Queue的部分（本篇文章核心为AQS原理剖析，只是简单介绍了ReentrantLock，感兴趣同学可以阅读一下ReentrantLock的源码）。 下面列出本篇文章的大纲和思路，以便于大家更好地理解：","text":"前言Java中的大部分同步类（Lock、Semaphore、ReentrantLock等）都是基于AbstractQueuedSynchronizer（简称为AQS）实现的。AQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。本文会从应用层逐渐深入到原理层，并通过ReentrantLock的基本特性和ReentrantLock与AQS的关联，来深入解读AQS相关独占锁的知识点，同时采取问答的模式来帮助大家理解AQS。由于篇幅原因，本篇文章主要阐述AQS中独占锁的逻辑和Sync Queue，不讲述包含共享锁和Condition Queue的部分（本篇文章核心为AQS原理剖析，只是简单介绍了ReentrantLock，感兴趣同学可以阅读一下ReentrantLock的源码）。 下面列出本篇文章的大纲和思路，以便于大家更好地理解： 1 ReentrantLock1.1 ReentrantLock特性概览ReentrantLock意思为可重入锁，指的是一个线程能够对一个临界资源重复加锁。为了帮助大家更好地理解ReentrantLock的特性，我们先将ReentrantLock跟常用的Synchronized进行比较，其特性如下（蓝色部分为本篇文章主要剖析的点）： 下面通过伪代码，进行更加直观的比较： 1234567891011121314151617181920212223242526272829// **************************Synchronized的使用方式**************************// 1.用于代码块synchronized (this) &#123;&#125;// 2.用于对象synchronized (object) &#123;&#125;// 3.用于方法public synchronized void test () &#123;&#125;// 4.可重入for (int i = 0; i &lt; 100; i++) &#123; synchronized (this) &#123;&#125;&#125;// **************************ReentrantLock的使用方式**************************public void test () throw Exception &#123; // 1.初始化选择公平锁、非公平锁 ReentrantLock lock = new ReentrantLock(true); // 2.可用于代码块 lock.lock(); try &#123; try &#123; // 3.支持多种加锁方式，比较灵活; 具有可重入特性 if(lock.tryLock(100, TimeUnit.MILLISECONDS))&#123; &#125; &#125; finally &#123; // 4.手动释放锁 lock.unlock() &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; 1.2 ReentrantLock与AQS的关联通过上文我们已经了解，ReentrantLock支持公平锁和非公平锁（关于公平锁和非公平锁的原理分析，可参考《不可不说的Java“锁”事》），并且ReentrantLock的底层就是由AQS来实现的。那么ReentrantLock是如何通过公平锁和非公平锁与AQS关联起来呢？ 我们着重从这两者的加锁过程来理解一下它们与AQS之间的关系（加锁过程中与AQS的关联比较明显，解锁流程后续会介绍）。 非公平锁源码中的加锁流程如下： 12345678910111213// java.util.concurrent.locks.ReentrantLock#NonfairSync// 非公平锁static final class NonfairSync extends Sync &#123; ... final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; ...&#125; 这块代码的含义为： 若通过CAS设置变量State（同步状态）成功，也就是获取锁成功，则将当前线程设置为独占线程。 若通过CAS设置变量State（同步状态）失败，也就是获取锁失败，则进入Acquire方法进行后续处理。 第一步很好理解，但第二步获取锁失败后，后续的处理策略是怎么样的呢？这块可能会有以下思考： 某个线程获取锁失败的后续流程是什么呢？有以下两种可能： (1) 将当前线程获锁结果设置为失败，获取锁流程结束。这种设计会极大降低系统的并发度，并不满足我们实际的需求。所以就需要下面这种流程，也就是AQS框架的处理流程。 (2) 存在某种排队等候机制，线程继续等待，仍然保留获取锁的可能，获取锁流程仍在继续。 对于问题1的第二种情况，既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢？ 处于排队等候机制中的线程，什么时候可以有机会获取锁呢？ 如果处于排队等候机制中的线程一直无法获取锁，还是需要一直等待吗，还是有别的策略来解决这一问题？ 带着非公平锁的这些问题，再看下公平锁源码中获锁的方式： 123456789// java.util.concurrent.locks.ReentrantLock#FairSyncstatic final class FairSync extends Sync &#123; ... final void lock() &#123; acquire(1); &#125; ...&#125; 看到这块代码，我们可能会存在这种疑问：Lock函数通过Acquire方法进行加锁，但是具体是如何加锁的呢？ 结合公平锁和非公平锁的加锁流程，虽然流程上有一定的不同，但是都调用了Acquire方法，而Acquire方法是FairSync和UnfairSync的父类AQS中的核心方法。 对于上边提到的问题，其实在ReentrantLock类源码中都无法解答，而这些问题的答案，都是位于Acquire方法所在的类AbstractQueuedSynchronizer中，也就是本文的核心——AQS。下面我们会对AQS以及ReentrantLock和AQS的关联做详细介绍（相关问题答案会在2.3.5小节中解答）。 2 AQS首先，我们通过下面的架构图来整体了解一下AQS框架： 上图中有颜色的为Method，无颜色的为Attribution。 总的来说，AQS框架共分为五层，自上而下由浅入深，从AQS对外暴露的API到底层基础数据。 当有自定义同步器接入时，只需重写第一层所需要的部分方法即可，不需要关注底层具体的实现流程。当自定义同步器进行加锁或者解锁操作时，先经过第一层的API进入AQS内部方法，然后经过第二层进行锁的获取，接着对于获取锁失败的流程，进入第三层和第四层的等待队列处理，而这些处理方式均依赖于第五层的基础数据提供层。 下面我们会从整体到细节，从流程到方法逐一剖析AQS框架，主要分析过程如下： 2.1 原理概览AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。 CLH：Craig、Landin and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。 主要原理图如下： AQS使用一个Volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。 2.1.1 AQS数据结构先来看下AQS中最基本的数据结构——Node，Node即为上面CLH变体队列中的节点。 解释一下几个方法和属性值的含义： 方法和属性值 含义 waitStatus 当前节点在队列中的状态 thread 表示处于该节点的线程 prev 前驱指针 predecessor 返回前驱节点，没有的话抛出npe nextWaiter 指向下一个处于CONDITION状态的节点（由于本篇文章不讲述Condition Queue队列，这个指针不多介绍） next 后继指针 线程两种锁的模式： 模式 含义 SHARED 表示线程以共享的模式等待锁 EXCLUSIVE 表示线程正在以独占的方式等待锁 waitStatus有下面几个枚举值： 枚举 含义 0 当一个Node被初始化的时候的默认值 CANCELLED 为1，表示线程获取锁的请求已经取消了 CONDITION 为-2，表示节点在等待队列中，节点线程等待唤醒 PROPAGATE 为-3，当前线程处在SHARED情况下，该字段才会使用 SIGNAL 为-1，表示线程已经准备好了，就等资源释放了 2.1.2 同步状态State在了解数据结构后，接下来了解一下AQS的同步状态——State。AQS中维护了一个名为state的字段，意为同步状态，是由Volatile修饰的，用于展示当前临界资源的获锁情况。 123// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate volatile int state; 下面提供了几个访问这个字段的方法： 方法名 描述 protected final int getState() 获取State的值 protected final void setState(int newState) 设置State的值 protected final boolean compareAndSetState(int expect, int update) 使用CAS方式更新State 这几个方法都是Final修饰的，说明子类中无法重写它们。我们可以通过修改State字段表示的同步状态来实现多线程的独占模式和共享模式（加锁过程）。 对于我们自定义的同步工具，需要自定义获取同步状态和释放状态的方式，也就是AQS架构图中的第一层：API层。 2.2 AQS重要方法与ReentrantLock的关联从架构图中可以得知，AQS提供了大量用于自定义同步器实现的Protected方法。自定义同步器实现的相关方法也只是为了通过修改State字段来实现多线程的独占模式或者共享模式。自定义同步器需要实现以下方法（ReentrantLock需要实现的方法如下，并不是全部）： 方法名 描述 protected boolean isHeldExclusively() 该线程是否正在独占资源。只有用到Condition才需要去实现它。 protected boolean tryAcquire(int arg) 独占方式。arg为获取锁的次数，尝试获取资源，成功则返回True，失败则返回False。 protected boolean tryRelease(int arg) 独占方式。arg为释放锁的次数，尝试释放资源，成功则返回True，失败则返回False。 protected int tryAcquireShared(int arg) 共享方式。arg为获取锁的次数，尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 protected boolean tryReleaseShared(int arg) 共享方式。arg为释放锁的次数，尝试释放资源，如果释放后允许唤醒后续等待结点返回True，否则返回False。 一般来说，自定义同步器要么是独占方式，要么是共享方式，它们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。ReentrantLock是独占锁，所以实现了tryAcquire-tryRelease。 以非公平锁为例，这里主要阐述一下非公平锁与AQS之间方法的关联之处，具体每一处核心方法的作用会在文章后面详细进行阐述。 为了帮助大家理解ReentrantLock和AQS之间方法的交互过程，以非公平锁为例，我们将加锁和解锁的交互流程单独拎出来强调一下，以便于对后续内容的理解。 加锁： 通过ReentrantLock的加锁方法Lock进行加锁操作。 会调用到内部类Sync的Lock方法，由于Sync#lock是抽象方法，根据ReentrantLock初始化选择的公平锁和非公平锁，执行相关内部类的Lock方法，本质上都会执行AQS的Acquire方法。 AQS的Acquire方法会执行tryAcquire方法，但是由于tryAcquire需要自定义同步器实现，因此执行了ReentrantLock中的tryAcquire方法，由于ReentrantLock是通过公平锁和非公平锁内部类实现的tryAcquire方法，因此会根据锁类型不同，执行不同的tryAcquire。 tryAcquire是获取锁逻辑，获取失败后，会执行框架AQS的后续逻辑，跟ReentrantLock自定义同步器无关。 解锁： 通过ReentrantLock的解锁方法Unlock进行解锁。 Unlock会调用内部类Sync的Release方法，该方法继承于AQS。 Release中会调用tryRelease方法，tryRelease需要自定义同步器实现，tryRelease只在ReentrantLock中的Sync实现，因此可以看出，释放锁的过程，并不区分是否为公平锁。 释放成功后，所有处理由AQS框架完成，与自定义同步器无关。 通过上面的描述，大概可以总结出ReentrantLock加锁解锁时API层核心方法的映射关系。 2.3 通过ReentrantLock理解AQSReentrantLock中公平锁和非公平锁在底层是相同的，这里以非公平锁为例进行分析。 在非公平锁中，有一段这样的代码： 123456789101112// java.util.concurrent.locks.ReentrantLockstatic final class NonfairSync extends Sync &#123; ... final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; ...&#125; 看一下这个Acquire是怎么写的： 123456// java.util.concurrent.locks.AbstractQueuedSynchronizerpublic final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 再看一下tryAcquire方法： 12345// java.util.concurrent.locks.AbstractQueuedSynchronizerprotected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; 可以看出，这里只是AQS的简单实现，具体获取锁的实现方法是由各自的公平锁和非公平锁单独实现的（以ReentrantLock为例）。如果该方法返回了True，则说明当前线程获取锁成功，就不用往后执行了；如果获取失败，就需要加入到等待队列中。下面会详细解释线程是何时以及怎样被加入进等待队列中的。 2.3.1 线程加入等待队列2.3.1.1 加入队列的时机当执行Acquire(1)时，会通过tryAcquire获取锁。在这种情况下，如果获取锁失败，就会调用addWaiter加入到等待队列中去。 2.3.1.2 如何加入队列获取锁失败后，会执行addWaiter(Node.EXCLUSIVE)加入等待队列，具体实现方法如下： 12345678910111213141516171819// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125;private final boolean compareAndSetTail(Node expect, Node update) &#123; return unsafe.compareAndSwapObject(this, tailOffset, expect, update);&#125; 主要的流程如下： 通过当前的线程和锁模式新建一个节点。 Pred指针指向尾节点Tail。 将New中Node的Prev指针指向Pred。 通过compareAndSetTail方法，完成尾节点的设置。这个方法主要是对tailOffset和Expect进行比较，如果tailOffset的Node和Expect的Node地址是相同的，那么设置Tail的值为Update的值。 12345678910111213// java.util.concurrent.locks.AbstractQueuedSynchronizerstatic &#123; try &#123; stateOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(\"state\")); headOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(\"head\")); tailOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(\"tail\")); waitStatusOffset = unsafe.objectFieldOffset(Node.class.getDeclaredField(\"waitStatus\")); nextOffset = unsafe.objectFieldOffset(Node.class.getDeclaredField(\"next\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125; 从AQS的静态代码块可以看出，都是获取一个对象的属性相对于该对象在内存当中的偏移量，这样我们就可以根据这个偏移量在对象内存当中找到这个属性。tailOffset指的是tail对应的偏移量，所以这个时候会将new出来的Node置为当前队列的尾节点。同时，由于是双向链表，也需要将前一个节点指向尾节点。 如果Pred指针是Null（说明等待队列中没有元素），或者当前Pred指针和Tail指向的位置不同（说明被别的线程已经修改），就需要看一下Enq的方法。 1234567891011121314151617// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 如果没有被初始化，需要进行初始化一个头结点出来。但请注意，初始化的头结点并不是当前线程节点，而是调用了无参构造函数的节点。如果经历了初始化或者并发导致队列中有元素，则与之前的方法相同。其实，addWaiter就是一个在双端链表添加尾节点的操作，需要注意的是，双端链表的头结点是一个无参构造函数的头结点。 总结一下，线程获取锁的时候，过程大体如下： 当没有线程获取到锁时，线程1获取锁成功。 线程2申请锁，但是锁被线程1占有。 如果再有线程要获取锁，依次在队列中往后排队即可。 回到上边的代码，hasQueuedPredecessors是公平锁加锁时判断等待队列中是否存在有效节点的方法。如果返回False，说明当前线程可以争取共享资源；如果返回True，说明队列中存在有效节点，当前线程必须加入到等待队列中。 1234567891011// java.util.concurrent.locks.ReentrantLockpublic final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; 看到这里，我们理解一下h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());为什么要判断的头结点的下一个节点？第一个节点储存的数据是什么？ 双向链表中，第一个节点为虚节点，其实并不存储任何信息，只是占位。真正的第一个有数据的节点，是在第二个节点开始的。当h != t时： 如果(s = h.next) == null，等待队列正在有线程进行初始化，但只是进行到了Tail指向Head，没有将Head指向Tail，此时队列中有元素，需要返回True（这块具体见下边代码分析）。 如果(s = h.next) != null，说明此时队列中至少有一个有效节点。如果此时s.thread == Thread.currentThread()，说明等待队列的第一个有效节点中的线程与当前线程相同，那么当前线程是可以获取资源的；如果s.thread != Thread.currentThread()，说明等待队列的第一个有效节点线程与当前线程不同，当前线程必须加入进等待队列。 123456789101112// java.util.concurrent.locks.AbstractQueuedSynchronizer#enqif (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head;&#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125;&#125; 节点入队不是原子操作，所以会出现短暂的head != tail，此时Tail指向最后一个节点，而且Tail指向Head。如果Head没有指向Tail（可见5、6、7行），这种情况下也需要将相关线程加入队列中。所以这块代码是为了解决极端情况下的并发问题。 2.3.1.3 等待队列中线程出队列时机回到最初的源码： 123456// java.util.concurrent.locks.AbstractQueuedSynchronizerpublic final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 上文解释了addWaiter方法，这个方法其实就是把对应的线程以Node的数据结构形式加入到双端队列里，返回的是一个包含该线程的Node。而这个Node会作为参数，进入到acquireQueued方法中。acquireQueued方法可以对排队中的线程进行“获锁”操作。 总的来说，一个线程获取锁失败了，被放入等待队列，acquireQueued会把放入队列中的线程不断去获取锁，直到获取成功或者不再需要获取（中断）。 下面我们从“何时出队列？”和“如何出队列？”两个方向来分析一下acquireQueued源码： 1234567891011121314151617181920212223242526272829// java.util.concurrent.locks.AbstractQueuedSynchronizerfinal boolean acquireQueued(final Node node, int arg) &#123; // 标记是否成功拿到资源 boolean failed = true; try &#123; // 标记等待过程中是否中断过 boolean interrupted = false; // 开始自旋，要么获取锁，要么中断 for (;;) &#123; // 获取当前节点的前驱节点 final Node p = node.predecessor(); // 如果p是头结点，说明当前节点在真实数据队列的首部，就尝试获取锁（别忘了头结点是虚节点） if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 获取锁成功，头指针移动到当前node setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 说明p为头节点且当前没有获取到锁（可能是非公平锁被抢占了）或者是p不为头结点，这个时候就要判断当前node是否要被阻塞（被阻塞条件：前驱节点的waitStatus为-1），防止无限循环浪费资源。具体两个方法下面细细分析 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 注：setHead方法是把当前节点置为虚节点，但并没有修改waitStatus，因为它是一直需要用的数据。 123456789101112131415161718192021222324252627282930// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null;&#125;// java.util.concurrent.locks.AbstractQueuedSynchronizer// 靠前驱节点判断当前线程是否应该被阻塞private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 获取头结点的节点状态 int ws = pred.waitStatus; // 说明头结点处于唤醒状态 if (ws == Node.SIGNAL) return true; // 通过枚举值我们知道waitStatus&gt;0是取消状态 if (ws &gt; 0) &#123; do &#123; // 循环向前查找取消节点，把取消节点从队列中剔除 node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 设置前任节点等待状态为SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; parkAndCheckInterrupt主要用于挂起当前线程，阻塞调用栈，返回当前线程的中断状态。 123456// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 上述方法的流程图如下： 从上图可以看出，跳出当前循环的条件是当“前置节点是头结点，且当前线程获取锁成功”。为了防止因死循环导致CPU资源被浪费，我们会判断前置节点的状态来决定是否要将当前线程挂起，具体挂起流程用流程图表示如下（shouldParkAfterFailedAcquire流程）： 从队列中释放节点的疑虑打消了，那么又有新问题了： shouldParkAfterFailedAcquire中取消节点是怎么生成的呢？什么时候会把一个节点的waitStatus设置为-1？ 是在什么时间释放节点通知到被挂起的线程呢？ 2.3.2 CANCELLED状态节点生成acquireQueued方法中的Finally代码： 12345678910111213141516171819// java.util.concurrent.locks.AbstractQueuedSynchronizerfinal boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; ... for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; ... failed = false; ... &#125; ... &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 通过cancelAcquire方法，将Node的状态标记为CANCELLED。接下来，我们逐行来分析这个方法的原理： 123456789101112131415161718192021222324252627282930313233343536// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate void cancelAcquire(Node node) &#123; // 将无效节点过滤 if (node == null) return; // 设置该节点不关联任何线程，也就是虚节点 node.thread = null; Node pred = node.prev; // 通过前驱节点，跳过取消状态的node while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // 获取过滤后的前驱节点的后继节点 Node predNext = pred.next; // 把当前node的状态设置为CANCELLED node.waitStatus = Node.CANCELLED; // 如果当前节点是尾节点，将从后往前的第一个非取消状态的节点设置为尾节点 // 更新失败的话，则进入else，如果更新成功，将tail的后继节点设置为null if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; int ws; // 如果当前节点不是head的后继节点，1:判断当前节点前驱节点的是否为SIGNAL，2:如果不是，则把前驱节点设置为SINGAL看是否成功 // 如果1和2中有一个为true，再判断当前节点的线程是否为null // 如果上述条件都满足，把当前节点的前驱节点的后继指针指向当前节点的后继节点 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; // 如果当前节点是head的后继节点，或者上述条件不满足，那就唤醒当前节点的后继节点 unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125; 当前的流程： 获取当前节点的前驱节点，如果前驱节点的状态是CANCELLED，那就一直往前遍历，找到第一个waitStatus &lt;= 0的节点，将找到的Pred节点和当前Node关联，将当前Node设置为CANCELLED。 根据当前节点的位置，考虑以下三种情况： (1) 当前节点是尾节点。 (2) 当前节点是Head的后继节点。 (3) 当前节点不是Head的后继节点，也不是尾节点。 根据上述第二条，我们来分析每一种情况的流程。 当前节点是尾节点。 当前节点是Head的后继节点。 当前节点不是Head的后继节点，也不是尾节点。 通过上面的流程，我们对于CANCELLED节点状态的产生和变化已经有了大致的了解，但是为什么所有的变化都是对Next指针进行了操作，而没有对Prev指针进行操作呢？什么情况下会对Prev指针进行操作？ 执行cancelAcquire的时候，当前节点的前置节点可能已经从队列中出去了（已经执行过Try代码块中的shouldParkAfterFailedAcquire方法了），如果此时修改Prev指针，有可能会导致Prev指向另一个已经移除队列的Node，因此这块变化Prev指针不安全。 shouldParkAfterFailedAcquire方法中，会执行下面的代码，其实就是在处理Prev指针。shouldParkAfterFailedAcquire是获取锁失败的情况下才会执行，进入该方法后，说明共享资源已被获取，当前节点之前的节点都不会出现变化，因此这个时候变更Prev指针比较安全。 1234&gt; do &#123;&gt; node.prev = pred = pred.prev;&gt; &#125; while (pred.waitStatus &gt; 0);&gt; 2.3.3 如何解锁我们已经剖析了加锁过程中的基本流程，接下来再对解锁的基本流程进行分析。由于ReentrantLock在解锁的时候，并不区分公平锁和非公平锁，所以我们直接看解锁的源码： 12345// java.util.concurrent.locks.ReentrantLockpublic void unlock() &#123; sync.release(1);&#125; 可以看到，本质释放锁的地方，是通过框架来完成的。 1234567891011// java.util.concurrent.locks.AbstractQueuedSynchronizerpublic final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 在ReentrantLock里面的公平锁和非公平锁的父类Sync定义了可重入锁的释放锁机制。 123456789101112131415161718// java.util.concurrent.locks.ReentrantLock.Sync// 方法返回当前锁是不是没有被线程持有protected final boolean tryRelease(int releases) &#123; // 减少可重入次数 int c = getState() - releases; // 当前线程不是持有锁的线程，抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 如果持有线程全部释放，将当前独占锁所有线程设置为null，并更新state if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 我们来解释下述源码： 1234567891011121314// java.util.concurrent.locks.AbstractQueuedSynchronizerpublic final boolean release(int arg) &#123; // 上边自定义的tryRelease如果返回true，说明该锁没有被任何线程持有 if (tryRelease(arg)) &#123; // 获取头结点 Node h = head; // 头结点不为空并且头结点的waitStatus不是初始化节点情况，解除线程挂起状态 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 这里的判断条件为什么是h != null &amp;&amp; h.waitStatus != 0？ h == null Head还没初始化。初始情况下，head == null，第一个节点入队，Head会被初始化一个虚拟节点。所以说，这里如果还没来得及入队，就会出现head == null 的情况。 h != null &amp;&amp; waitStatus == 0 表明后继节点对应的线程仍在运行中，不需要唤醒。 h != null &amp;&amp; waitStatus &lt; 0 表明后继节点可能被阻塞了，需要唤醒。 再看一下unparkSuccessor方法： 123456789101112131415161718192021// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate void unparkSuccessor(Node node) &#123; // 获取头结点waitStatus int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 获取当前节点的下一个节点 Node s = node.next; // 如果下个节点是null或者下个节点被cancelled，就找到队列最开始的非cancelled的节点 if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 就从尾部节点开始找，到队首，找到队列第一个waitStatus&lt;0的节点。 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 如果当前节点的下个节点不为空，而且状态&lt;=0，就把当前节点unpark if (s != null) LockSupport.unpark(s.thread);&#125; 为什么要从后往前找第一个非Cancelled的节点呢？原因如下。 之前的addWaiter方法： 12345678910111213141516// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 我们从这里可以看到，节点入队并不是原子操作，也就是说，node.prev = pred; compareAndSetTail(pred, node) 这两个地方可以看作Tail入队的原子操作，但是此时pred.next = node;还没执行，如果这个时候执行了unparkSuccessor方法，就没办法从前往后找了，所以需要从后往前找。还有一点原因，在产生CANCELLED状态节点的时候，先断开的是Next指针，Prev指针并未断开，因此也是必须要从后往前遍历才能够遍历完全部的Node。 综上所述，如果是从前往后找，由于极端情况下入队的非原子操作和CANCELLED节点产生过程中断开Next指针的操作，可能会导致无法遍历所有的节点。所以，唤醒对应的线程后，对应的线程就会继续往下执行。继续执行acquireQueued方法以后，中断如何处理？ 2.3.4 中断恢复后的执行流程唤醒后，会执行return Thread.interrupted();，这个函数返回的是当前执行线程的中断状态，并清除。 123456// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 再回到acquireQueued代码，当parkAndCheckInterrupt返回True或者False的时候，interrupted的值不同，但都会执行下次循环。如果这个时候获取锁成功，就会把当前interrupted返回。 12345678910111213141516171819202122// java.util.concurrent.locks.AbstractQueuedSynchronizerfinal boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 如果acquireQueued为True，就会执行selfInterrupt方法。 12345// java.util.concurrent.locks.AbstractQueuedSynchronizerstatic void selfInterrupt() &#123; Thread.currentThread().interrupt();&#125; 该方法其实是为了中断线程。但为什么获取了锁以后还要中断线程呢？这部分属于Java提供的协作式中断知识内容，感兴趣同学可以查阅一下。这里简单介绍一下： 当中断线程被唤醒时，并不知道被唤醒的原因，可能是当前线程在等待中被中断，也可能是释放了锁以后被唤醒。因此我们通过Thread.interrupted()方法检查中断标记（该方法返回了当前线程的中断状态，并将当前线程的中断标识设置为False），并记录下来，如果发现该线程被中断过，就再中断一次。 线程在等待资源的过程中被唤醒，唤醒后还是会不断地去尝试获取锁，直到抢到锁为止。也就是说，在整个流程中，并不响应中断，只是记录中断记录。最后抢到锁返回了，那么如果被中断过的话，就需要补充一次中断。 这里的处理方式主要是运用线程池中基本运作单元Worder中的runWorker，通过Thread.interrupted()进行额外的判断处理，感兴趣的同学可以看下ThreadPoolExecutor源码。 2.3.5 小结我们在1.3小节中提出了一些问题，现在来回答一下。 Q：某个线程获取锁失败的后续流程是什么呢？ A：存在某种排队等候机制，线程继续等待，仍然保留获取锁的可能，获取锁流程仍在继续。 Q：既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢？ A：是CLH变体的FIFO双端队列。 Q：处于排队等候机制中的线程，什么时候可以有机会获取锁呢？ A：可以详细看下2.3.1.3小节。 Q：如果处于排队等候机制中的线程一直无法获取锁，需要一直等待么？还是有别的策略来解决这一问题？ A：线程所在节点的状态会变成取消状态，取消状态的节点会从队列中释放，具体可见2.3.2小节。 Q：Lock函数通过Acquire方法进行加锁，但是具体是如何加锁的呢？ A：AQS的Acquire会调用tryAcquire方法，tryAcquire由各个自定义同步器实现，通过tryAcquire完成加锁过程。 3 AQS应用3.1 ReentrantLock的可重入应用ReentrantLock的可重入性是AQS很好的应用之一，在了解完上述知识点以后，我们很容易得知ReentrantLock实现可重入的方法。在ReentrantLock里面，不管是公平锁还是非公平锁，都有一段逻辑。 公平锁： 123456789101112131415// java.util.concurrent.locks.ReentrantLock.FairSync#tryAcquireif (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125;&#125;else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true;&#125; 非公平锁： 123456789101112131415// java.util.concurrent.locks.ReentrantLock.Sync#nonfairTryAcquireif (c == 0) &#123; if (compareAndSetState(0, acquires))&#123; setExclusiveOwnerThread(current); return true; &#125;&#125;else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true;&#125; 从上面这两段都可以看到，有一个同步状态State来控制整体可重入的情况。State是Volatile修饰的，用于保证一定的可见性和有序性。 123// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate volatile int state; 接下来看State这个字段主要的过程： State初始化的时候为0，表示没有任何线程持有锁。 当有线程持有该锁时，值就会在原来的基础上+1，同一个线程多次获得锁是，就会多次+1，这里就是可重入的概念。 解锁也是对这个字段-1，一直到0，此线程对锁释放。 3.2 JUC中的应用场景除了上边ReentrantLock的可重入性的应用，AQS作为并发编程的框架，为很多其他同步工具提供了良好的解决方案。下面列出了JUC中的几种同步工具，大体介绍一下AQS的应用场景： 同步工具 同步工具与AQS的关联 ReentrantLock 使用AQS保存锁重复持有的次数。当一个线程获取锁时，ReentrantLock记录当前获得锁的线程标识，用于检测是否重复获取，以及错误线程试图解锁操作时异常情况的处理。 Semaphore 使用AQS同步状态来保存信号量的当前计数。tryRelease会增加计数，acquireShared会减少计数。 CountDownLatch 使用AQS同步状态来表示计数。计数为0时，所有的Acquire操作（CountDownLatch的await方法）才可以通过。 ReentrantReadWriteLock 使用AQS同步状态中的16位保存写锁持有的次数，剩下的16位用于保存读锁的持有次数。 ThreadPoolExecutor Worker利用AQS同步状态实现对独占线程变量的设置（tryAcquire和tryRelease）。 3.3 自定义同步工具了解AQS基本原理以后，按照上面所说的AQS知识点，自己实现一个同步工具。 123456789101112131415161718192021222324252627282930public class LeeLock &#123; private static class Sync extends AbstractQueuedSynchronizer &#123; @Override protected boolean tryAcquire (int arg) &#123; return compareAndSetState(0, 1); &#125; @Override protected boolean tryRelease (int arg) &#123; setState(0); return true; &#125; @Override protected boolean isHeldExclusively () &#123; return getState() == 1; &#125; &#125; private Sync sync = new Sync(); public void lock () &#123; sync.acquire(1); &#125; public void unlock () &#123; sync.release(1); &#125;&#125; 通过我们自己定义的Lock完成一定的同步功能。 1234567891011121314151617181920212223242526272829303132public class LeeMain &#123; static int count = 0; static LeeLock leeLock = new LeeLock(); public static void main (String[] args) throws InterruptedException &#123; Runnable runnable = new Runnable() &#123; @Override public void run () &#123; try &#123; leeLock.lock(); for (int i = 0; i &lt; 10000; i++) &#123; count++; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; leeLock.unlock(); &#125; &#125; &#125;; Thread thread1 = new Thread(runnable); Thread thread2 = new Thread(runnable); thread1.start(); thread2.start(); thread1.join(); thread2.join(); System.out.println(count); &#125;&#125; 上述代码每次运行结果都会是20000。通过简单的几行代码就能实现同步功能，这就是AQS的强大之处。 总结我们日常开发中使用并发的场景太多，但是对并发内部的基本框架原理了解的人却不多。由于篇幅原因，本文仅介绍了可重入锁ReentrantLock的原理和AQS原理，希望能够成为大家了解AQS和ReentrantLock等同步器的“敲门砖”。 参考资料 Lea D. The java. util. concurrent synchronizer framework[J]. Science of Computer Programming, 2005, 58(3): 293-309. 《Java并发编程实战》 不可不说的Java“锁”事 转载自美团技术团队 https://tech.meituan.com/2019/12/05/aqs-theory-and-apply.html","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/tags/JAVA/"},{"name":"并发","slug":"并发","permalink":"https://vincentruan.github.io/tags/并发/"},{"name":"ReentrantLock","slug":"ReentrantLock","permalink":"https://vincentruan.github.io/tags/ReentrantLock/"},{"name":"AQS","slug":"AQS","permalink":"https://vincentruan.github.io/tags/AQS/"}]},{"title":"MySQL增删改查都会用到什么锁?","slug":"MySQL增删改查都会用到什么锁","date":"2020-02-12T07:11:11.000Z","updated":"2020-02-26T03:28:53.200Z","comments":true,"path":"2020/02/12/MySQL增删改查都会用到什么锁/","link":"","permalink":"https://vincentruan.github.io/2020/02/12/MySQL增删改查都会用到什么锁/","excerpt":"日常的操作中，增删改查都会使用什么类型的锁？其实这个问题，可以分为两个方面，一方面是读，一方面是写。 读（select） 我们先来看读的部分。读的操作，其实分为两种，分别是一致性读和锁定读， 这里我们温习一下，一致性读其实就是利用事务的MVCC机制，来读取一份数据的快照，所以有的书上也称之为快照读，一致性读是不加锁的，其他的事务是可以对表中的数据记录进行改动的。一般情况下，常见的读，例如： select * from table； select * from table left join table2; 这种操作，在RU，RC，RR隔离级别下都是采用一直性读，不加锁的操作。这种情况下，读的并发可以非常高。 再来看看锁定读，如果我们的表当中有索引，我们想在读取记录的时候，获取某一条记录的锁，禁止别的事务对这条记录进行修改，那么我们可以使用下面的语句来对读取的记录加锁：","text":"日常的操作中，增删改查都会使用什么类型的锁？其实这个问题，可以分为两个方面，一方面是读，一方面是写。 读（select） 我们先来看读的部分。读的操作，其实分为两种，分别是一致性读和锁定读， 这里我们温习一下，一致性读其实就是利用事务的MVCC机制，来读取一份数据的快照，所以有的书上也称之为快照读，一致性读是不加锁的，其他的事务是可以对表中的数据记录进行改动的。一般情况下，常见的读，例如： select * from table； select * from table left join table2; 这种操作，在RU，RC，RR隔离级别下都是采用一直性读，不加锁的操作。这种情况下，读的并发可以非常高。 再来看看锁定读，如果我们的表当中有索引，我们想在读取记录的时候，获取某一条记录的锁，禁止别的事务对这条记录进行修改，那么我们可以使用下面的语句来对读取的记录加锁： select … lock in share mode;加共享锁。(其他事务可读，不可写) select … for update;加排它锁。(其他事务不可读，不可写)，这样，其他事务就不能对这条记录进行读取和更改了。 关于读操作的是否加锁，还有以下几点需要注意： 1、在Serializable这种事务的隔离级别下，普通的select操作会升级为select…in share mode；的模式。 2、在唯一索引上使用唯一的查询条件，会使用记录锁，而不会封锁记录之间的间隔，即不会使用间隙锁。 3、其他类型的索引使用范围的查询条件或者唯一的查询条件，innodb会自动锁定被扫描的范围，避免索引范围区间内插入新的记录。这块儿可能比较模糊，文章最后面给出各种类型下的加锁测试结果。 写（update、delete、insert）关于delete 对一条数据做delete的过程实际上是要先在索引的B+树上获取该记录的位置，然后再这个记录所在的位置加X锁，也就是排它锁。 如果对某个范围内的数据做delete操作，则会在索引B+树上对范围内符合查询条件的记录以及记录之前的区间加next-key锁(本质是记录锁和间隙锁的组合，后面的文章会讲到)。 加完锁之后，再进行delete操作。这个delete操作的本质，其实是先将delete的标识为标识为1，而不是真正进行删除，如果下次这块空间可以复用，则innodb会直接进行复用。 更多详情请见：Innodb数据页简介 关于update 对一条记录做update的时候，我们知道，如果该要更新的列在更新前后的存储空间没有发生变化，则会直接在该记录上进行更新操作。而如果发生了存储空间的变化，则会现将这条记录彻底删除掉，然后再插入一条新的记录。 基本上分为一下三种情况： 1、如果update操作没有更新索引键值并且没有导致存储空间变化，则会直接在索引B+树上使用X锁来锁定update的记录。 2、如果update操作没有更新索引键值但却导致了数据的存储空间发生变化，则会现将这表数据记录删除掉，然后再插入一条新的记录，在这个过程中，先会获取索引B+树的X锁，然后insert过程会使用隐式锁来进行保护。 3、如果update修改了某条记录的索引键值，则需要先进行delete，然后再进行一次insert，加锁的规则就和delete以及insert一样了。 这里有几点需要注意： 1、如果在唯一索引上使用唯一的查询条件来进行update和delete操作，那么这个过程中只会对记录加锁。 2、除了第一种情况之外，都会加排他的next-key锁，来锁定记录和记录之前的范围。 3、如果update的是主键的记录，则对应的普通索引的记录也会被隐式加锁，这是因为innodb中的普通索引会存储主键的值，检索普通索引本质上要进行回表操作，二次扫描聚集索引。 关于insert insert操作会用排它锁封锁被插入的索引记录，而不会封锁记录之前的范围。除此之外，会在插入区间加入插入意向锁 最后，今天我做了一点测试，测试的数据太多了，不方便整理，这里把测试结果放在这里，大家可以看看，和自己设想的情况一样不一样： （注意：所有测试均在RR隔离级别下，RC隔离级别下只有记录锁，没有间隙锁，相对比较简单，大家可以自行研究） RR隔离级别下，如果会话1锁定了一个空的记录，例如id=6的记录，表中只有id=5和id=9的值，那么会话2中不能插入id=6、7、8的值，因为这个间隙已经被锁定。其中，id可以是主键或者唯一索引。 RR隔离级别下，如果会话1锁定了一个存在记录，例如id=5的记录，表中有id=5的值，那么会话2中可以插入id=4、6、7、8的值，间隙没有锁定。其中，id可以是主键或者唯一索引。 RR隔离级别下，如果会话1锁定了一个范围记录，例如id&lt;6的记录，表中有id=5的值和id=9的值，那么会话2中不能插入id=6、7、8的值，间隙被锁定。其中，id可以是主键或者唯一索引。 RR隔离级别下，如果会话1锁定了一个范围记录，例如id&gt;6 and id &lt;11的记录，表中有id=5的值和id=9的值，那么会话2中不能插入id=6、7、8的值以及id大于9的所有值，间隙被锁定。其中，id可以是主键或者唯一索引。 RR隔离级别下，如果会话1锁定了一个空的记录，例如id=6的记录，表中有id=5的值和id=9的值，那么会话2中不能插入id=5、6、7、8的值，间隙被锁定。但是可以插入9的值，其中，id是普通索引。 RR隔离级别下，如果会话1锁定了一个存在记录，例如id=5的记录，表中有id=5的值和id=9的值，那么会话2中不能插入id=4、6、7、8的值，但是可以插入9的值。间隙被锁定。其中，id是普通索引。 RR隔离级别下，如果会话1锁定了一个范围记录，例如id&lt;6的记录，表中有id=5的值和id=9的值，那么会话2中不能插入id=4、6、7、8的值，但是可以插入9的值，间隙被锁定。其中，id是普通索引**。** RR隔离级别下，如果会话1锁定了一个范围记录，例如id&gt;6 and id&lt;11的记录，表中有id=5的值和id=9的值，那么会话2中不能插入所有值的记录，所有**间隙被锁定，类似全表锁。其中，id是普通索引**。 附录关于MySQL锁的两个知识点MySQL快照读和当前读 当我们对数据库中的表进行select、update、delete以及insert的时候，innodb存储引擎会根据操作类型的不同来给这些操作添加具体的锁。 在MySQL中，读操作可以分成两类：快照读 (snapshot read)与当前读 (current read)。快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。当前读，读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。 这里我们首先给出快照读和当前读的例子： 快照读：简单的select操作，属于快照读，不加锁。(当然，也有例外，下面会分析) 1select * from table where id&gt;10; 当前读：特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。 12345select * from table where id&gt;10 lock in share mode;select * from table where id&gt;10 for update;insert into table values (…);update table set id=11 where id=10;delete from table where id&gt;10; 读取之后，需要保证其他并发事务不能修改当前记录，对读取记录加锁。其中，除了第一条语句明确指出了lock in share mode之外，也就是对读取记录加S锁 (共享锁)外，其他的操作，都加的是X锁 (排它锁)。 这里我们给出一个update操作过程中，mysql server和innodb存储引擎进行交互的过程如下： 从上图中，我们可以看出一个update操作的具体流程。当update SQL被发给MySQL后，MySQL Server会根据where条件，读取第一条满足条件的记录，然后InnoDB引擎会将第一条记录返回，并加锁 (current read)。待MySQL Server收到这条加锁的记录之后，会再发起一个update请求，更新这条记录。一条记录操作完成，再读取下一条记录，直至没有满足条件的记录为止。因此，update操作内部，就包含了一个当前读。同理，delete操作也一样。insert操作会稍微有些不同，简单来说，就是insert操作可能会触发Unique Key的冲突检查，也会进行一个当前读。 关于死锁 死锁是指两个或者两个以上的事务在执行的过程中，因争夺资源而造成的一种互相等待的现象。若无外力作用，这两个事务将保持等待状态，无法推进下去。很明显，这是我们不想看到的。 从上面的概念可以看出，死锁的关键点在于互相等待，如果我们要解决死锁的问题，就要从“等待”这个关键词上面入手，如果我们将等待都转化为回滚操作，并且事务都重新开始，这种方法无疑可以避免死锁问题的产生。但是会导致数据库并发性能的降低，这样的问题也是我们无法接受的。 为了解决这一问题，我们采用一种超时的方法进行折中进行处理，超时是指当两个事务互相等待时，当某一方的等待时间超过一个阈值，我们将它进行回滚，这样，另一个事务就能够继续进行，在innodb存储引擎中，我们使用参数innodb_lock_wait_timeout来设置超时时间，这个参数如下： 1234567mysql&gt; show variables like \"innodb_lock_wait_timeout\";+--------------------------+-------+| Variable_name | Value |+--------------------------+-------+| innodb_lock_wait_timeout | 50 |+--------------------------+-------+1 row in set, 1 warning (0.11 sec) 为了加深印象，我们模拟一个死锁的现象，让大家感受一下。 首先，要模拟死锁，程序必须并发运行，串行的方法是无法模拟死锁的，这里我们采用两个连接会话进行模拟： 会话A 我们先开启事务，然后锁定id=3的行； 12345678910111213141516171819202122mysql&gt; select * from t;+----+-----+| id | age |+----+-----+| 1 | 5 || 2 | 4 || 3 | 3 || 4 | 2 || 5 | 1 |+----+-----+5 rows in set (0.00 sec)mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from t where id=3 for update;+----+-----+| id | age |+----+-----+| 3 | 3 |+----+-----+1 row in set (0.02 sec) 会话B 在会话B上锁定id=2的行 12345678910mysql&gt; begin -&gt; ;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from t where id=2 for update;+----+-----+| id | age |+----+-----+| 2 | 4 |+----+-----+1 row in set (0.00 sec) 会话A 我们在会话A上获取id=2的记录的锁，发现无法获取，产生了等待： 1234mysql&gt; select * from t where id=2 for update;##产生等待mysql&gt; 会话B 在会话A进行等待的过程中，我们在会话B上面获取id=3的记录的锁，我们发现了两个变化： 第一、会话B上输出了死锁的提示信息，如下； 1234mysql&gt; select * from t where id=3 for update;ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting tractionmysql&gt; 第二、会话A上输出了id=2的记录，也就是A会话得到了特定的资源，但是产生了9s的延迟，如下； 会话A 123456789mysql&gt; select * from t where id=2 for update;+----+-----+| id | age |+----+-----+| 2 | 4 |+----+-----+1 row in set (9.04 sec)mysql&gt; 在上述操作中，会话B抛出了1213这个错误状态码，它代表事务发生了死锁，死锁的原因是会话A和B的资源进行了相互等待，但是此时我们发现会话B中抛出死锁提示信息之后会话A中立即得到了记录为2的这个资源，这其实是因为会话B中的事务发生了回滚，否则的话，会话A中的事务是不可能得到相应的资源的。 这里又不得不提innodb的一个特性，那就是它会回滚死锁情况下的一个事务，因此当我们在程序中捕获了一个1213的错误，其实不需要我们手动进行回滚。 Innodb数据页简介 页是内存和磁盘交互的基本单位，它的大小一般是16KB，可以被分为如下几个部分： 上次的文章里面，我们对这几个部分大概做了介绍，今天我们说说上面数据页的蓝色部分。 该部分保存的是数据页中真正的数据记录，也就是用户存储的记录。当我们一开始生成页的时候，其实并没有蓝色的Record部分，而是随着我们不断给数据库中插入记录，才逐渐从Free Space中划分出来的空间。用示意图来描述就是： 如果Free Space中的数据页被分配完了，则去申请新的数据页。 为了方便理解，我们现在创建一个表进行演示： 1234567CREATE TABLE test( -&gt; c1 INT, -&gt; c2 INT, -&gt; c3 VARCHAR(1000), -&gt; PRIMARY KEY (c1) -&gt; ) engine=innodb charset=utf8;Query OK, 0 rows affected (0.03 sec) 现在我们给这个表里面插入几条数据： 12345insert into test values(1,2,'a'),(2,3,'bb'),(3,4,'ccc'),(4,5,'dddd'); 我们可以把上面的数据页结构简单表示如下： 我们可以看到，每条记录由三个部分构成，分别是记录头、记录数据以及其他信息，其中记录头里面包含很多字段来表示该条记录的信息，这些字段我们会逐渐进行讲解。目前4条记录都已经插入到record部分了，在实际过程中这四条记录是通过链表的方式进行连接的，如下： 在第一张图的数据页中，蓝色部分还有一部分是infimum和supermun，它们是两条伪记录，它们分别是这个数据页中”指定的”最大的记录和最小的记录。它们的作用是作为当前数据页内数据链表的首末两端。这样，数据页中的数据就可以被我们排列成下面的样子： 我们已经可以看到，我们的主键按照从大到小的顺序形成了一个链表，链表的首末位置分别是两条伪记录。 当我们对数据记录中id=2的一条记录进行删除时，实际上，在数据记录链表里面发生的变化如下： 可以看出，实际上并没有删除那条记录，而是通过将头信息中的delete标识位改为1、偏移量改为0来实现的，也就是说，这条记录所占用的空间并没有还给Free Space，当下一次插入id=2的记录的时候，这块空间还可以接着使用。 在这个过程中，我们加入了record_type字段，这两条伪记录和正常记录的区别之处在于数据记录的头信息里面的record_type字段，最小记录的record_type为2，最大记录的record为3，正常记录的record_type为0，record_type为1的记录，稍后我们会进行解释。 到现在为止，我们已经知道了头信息中的3个字段，分别是next_record和record_type以及delete字段，next_record保存的是下一条数据记录的真是数据的偏移量，record_type代表的是数据记录的类型，delete标示的是该字段是否被删除。除此之外，我们还需要知道记录头信息里面的另外一个字段n_owned，这个字段保存的是改组内一共有多少个数据记录，在上述删除的操作中，最大记录中该字段的变化过程如下： 关于这个初始值为何是5，后续的文章中我们会说明。至此，我们已经了解到，一个数据页，大概可以描述成如下形式： MySQL锁优化MySQL 锁分类当多个事务或者进程访问同一个资源的时候，为了保证数据的一致性，就需要用到锁机制。 从锁定资源的角度来看，MySQL 中的锁分为： 表级锁 行级锁 页面锁 表级锁：对整张表加锁。开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 行级锁：对某行记录加锁。开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 在实际开发过程中，主要会使用到表级锁和行级锁两种。既然锁是针对资源的，那么这些资源就是数据，在 MySQL 提供插件式存储引擎对数据进行存储。 插件式存储引擎的好处是，开发人员可以根据需要选择适合的存储引擎。 在众多的存储引擎中，有两种引擎被比较多的使用，他们分别是： MyISAM 存储引擎，它不支持事务、表锁设计，支持全文索引，主要面向一些在线分析处理（OLAP）数据库应用。说白了主要就是查询数据，对数据的插入，更新操作比较少。 InnoDB 存储引擎，它支持事务，其设计目标主要面向在线事务处理（OLTP）的应用。 其特点是行锁设计、支持外键，并支持类似于 Oracle 的非锁定读，即默认读取操作不会产生锁。 简单来说，就是对数据的插入，更新操作比较多。从 MySQL 数据库 5.5.8 版本开始，InnoDB 存储引擎是默认的存储引擎。 上面两种存储引擎在处理多进程数据操作的时候是如何表现的，就是我们接下来要讨论的问题。 为了让整个描述更加清晰，我们将表级锁和行级锁以及 MyISAM，InnoDB 存储引擎，就形成了一个 2*2 的象限。 2\\2 表行锁，MyISAM，InnoDB 示意图由于 MyISAM 存储引擎不支持行级锁，实际上后面讨论的问题会围绕三个象限的讨论展开。从内容上来看，InnoDB 作为使用最多的存储引擎遇到的问题和值得注意的地方较多，也是本文的重点。MyISAM 存储引擎和表级锁首先，来看第一象限的内容：2*2 表行锁，MyISAM，InnoDB 示意图-第一象限MyISAM 存储引擎支持表级锁，并且支持两种锁模式：- 对 MyISAM 表的读操作（共享锁），不会阻塞其他进程对同一表的读请求，但会阻塞对其的写请求。当读锁释放后，才会执行其他进程的写操作。- 对 MyISAM 表的写操作（排他锁），会阻塞其他进程对同一表的读写操作，当该锁释放后，才会执行其他进程的读写操作。### MyISAM 优化建议在使用 MyISAM 存储引擎时。执行 SQL 语句，会自动为 SELECT 语句加上共享锁，为 UDI（更新，删除，插入）操作加上排他锁。由于这个特性在多进程并发插入同一张表的时候，就会因为排他锁而进行等待。因此可以通过配置 concurrent_insert 系统变量，来控制其并发的插入行为。①concurrent_insert=0 时，不允许并发插入。②concurrent_insert=1 时，如果 MyISAM 表中没有空洞（即表中没有被删除的行），允许一个进程读表时，另一个进程向表的尾部插入记录（MySQL 默认设置）。&gt; 注：空洞是行记录被删除以后，只是被标记为“已删除”其存储空间没有被回收，也就是说没有被物理删除。由另外一个进程，异步对这个数据进行删除。&gt;&gt; 因为空间长度问题，删除以后的物理空间不能被新的记录所使用，从而形成了空洞。③concurrent_insert=2 时，无论 MyISAM 表中有没有空洞，都允许在表尾并发插入记录。如果在数据插入的时候，没有并发删除操作的话，可以尝试把 concurrent_insert 设置为 1。反之，在数据插入的时候有删除操作且量较大时，也就是会产生“空洞”的时候，就需要把 concurrent_insert 设置为 2。另外，当一个进程请求某个 MyISAM 表的读锁，另一个进程也请求同一表的写锁。即使读请求先到达，写请求后到达，写请求也会插到读请求之前。因为 MySQL 的默认设置认为，写请求比读请求重要。我们可以通过 low_priority_updates 来调节读写行为的优先级：- 数据库以读为主时，要优先保证查询性能时，可通过 low_priority_updates=1 设置读优先级高于写优先级。- 数据库以写为主时，则不用设置 low_priority_updates 参数。### InnoDB 存储引擎和表级锁再来看看第二象限的内容：2*2 表行锁，MyISAM，InnoDB 示意图-第二象限* InnoDB 存储引擎表锁。当没有对数据表中的索引数据进行查询时，会执行表锁操作。 上面是 InnoDB 实现行锁，同时它也可以实现表锁。其方式就是意向锁（Intention Locks）。 这里介绍两种意向锁： 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前，必须先取得该表的 IS 锁。 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前，必须先取得该表的 IX 锁。 注：意向共享锁和意向排他锁是数据库主动加的，不需要我们手动处理。对于 UPDATE、DELETE 和 INSERT 语句，InnoDB 会自动给数据集加排他锁。 InnoDB表锁的实现方式：假设有一个表 test2，有两个字段分别是 id 和 name。 没有设置主键同时也没有设置任何索引（index）如下： InnoDB 表锁实现方式图### InnoDB 存储引擎和行级锁第四象限我们使用的比较多，讨论的内容也相对多些：2\\2 表行锁，MyISAM，InnoDB 示意图-第四象限* InnoDB 存储引擎行锁，当数据查询时针对索引数据进行时，会使用行级锁。 共享锁（S）：当一个事务读取一条记录的时候，不会阻塞其他事务对同一记录的读请求，但会阻塞对其的写请求。当读锁释放后，才会执行其他事务的写操作。 例如：select … lock in share mode 排他锁（X）：当一个事务对一条记录进行写操作时，会阻塞其他事务对同一表的读写操作，当该锁释放后，才会执行其他事务的读写操作。 例如：select … for update 行锁的实现方式：假设有一个表 test1，有两个字段分别是 id 和 name。 id 作为主键同时也是 table 的索引（index）如下： InnoDB 行锁实现方式图 在高并发的情况下，多个事务同时请求更新数据，由于资源被占用等待事务增多。 如此，会造成性能问题，可以通过 innodb_lock_wait_timeout 来解决。innodb_lock_wait_timeout 是事务等待获取资源的最长时间，单位为秒。如果超过时间还未分配到资源，则会返回应用失败。 四种锁的兼容情况 共享锁，排他锁，意向共享锁，意向排他锁兼容图例 如果一个事务请求的锁模式与当前的锁兼容， InnoDB 就将请求的锁授予该事务；反之， 如果两者不兼容，该事务就要等待锁释放。 间隙锁前面谈到行锁是针对一条记录进行加锁。当对一个范围内的记录加锁的时候，我们称之为间隙锁。 当使用范围条件索引数据时，InnoDB 会对符合条件的数据索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB 也会对这个“间隙”加锁，这就是间隙锁。间隙锁和行锁合称（Next-Key锁）。 如果表中只有 11 条记录，其 id 的值分别是 1,2,…,10，11 下面的 SQL： 1Select * from table_gapwhere id &gt; 10 for update; 这是一个范围条件的检索，InnoDB 不仅会对符合条件的 id 值为 10 的记录加锁，会对 id 大于 10 的“间隙”加锁，即使大于 10 的记录不存在，例如 12，13。 InnoDB 使用间隙锁的目的： 一方面是为了防止幻读。对于上例，如果不使用间隙锁，其他事务插入了 id 大于 10 的任何记录，本事务再次执行 select 语句，就会发生幻读。 另一方面，也是为了满足恢复和复制的需要。 间隙锁图 死锁两个事务都需要获得对方持有的排他锁才能继续完成任务，这种互相等待对方释放资源的情况就是死锁。 死锁图 检测死锁：InnoDB 存储引擎能检测到死锁的循环依赖并立即返回一个错误。 死锁恢复：死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁。 InnoDB 方法是，将持有最少行级排他锁的事务回滚。在应用程序设计时必须考虑处理死锁，多数情况下重新执行因死锁回滚的事务即可。 避免死锁： 在事务开始时，如果有记录要修改，先使用 SELECT… FOR UPDATE 语句获取锁，即使这些修改语句是在后面执行。 在事务中，如果要更新记录，直接申请排他锁。而不是查询时申请共享锁、更新时再申请排他锁。 这样做会导致，当申请排他锁时，其他事务可能已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。 简单来说，如果你要更新记录要做两步操作，第一步查询，第二步更新。就不要第一步上共享锁，第二部上排他锁了，直接在第一步就上排他锁，抢占先机。 如果事务需要锁定多个表，那么尽量按照相同的顺序使用加锁语句，可以降低产生死锁的机会。 通过 SELECT … LOCK INSHARE MODE（共享锁）获取行的读锁后，如果当前事务再需要对该记录进行更新操作，则很有可能造成死锁。所以，如果要对行记录进行修改，直接上排他锁。 改变事务隔离级别（事务隔离级别在后面详细说明）。 MySQL 锁定情况的查询在实际开发中无法避免数据被锁的问题，那么我们可以通过哪些手段来查询锁呢？ 表级锁可以通过两个变量的查询： Table_locks_immediate，产生表级锁的次数。 Table_locks_waited，数显表级锁而等待的次数。 行级锁可以通过下面几个变量查询： Innodb_row_lock_current_waits，当前正在等待锁定的数量。 Innodb_row_lock_time（重要），从系统启动到现在锁定总时长。 Innodb_row_lock_time_avg（重要），每次等待所花平均时间。 Innodb_row_lock_time_max，从系统启动到现在等待最长的一次花费时间。 Innodb_row_lock_waits（重要），从系统启动到现在总共等待的次数。 MySQL 事务隔离级别 前面讲的死锁是因为并发访问数据库造成。当多个事务同时访问数据库，做并发操作的时候会发生以下问题。 脏读（dirty read），一个事务在处理过程中，读取了另外一个事务未提交的数据。未提交的数据称之为脏数据。 脏读例子 不可重复读（non-repeatable read），在事务范围内，多次查询某条记录，每次得到不同的结果。 第一个事务中的两次读取数据之间，由于第二个事务的修改，第一个事务两次读到的数据可能不一样。 不可重复读例子幻读（phantom read），是事务非独立执行时发生的一种现象。幻读的例子在同一时间点，数据库允许多个并发事务，同时对数据进行读写操作，会造成数据不一致性。四种隔离级别，解决事务并发问题对照图隔离性就是用来防止这种数据不一致的。事务隔离根据级别不同，从低到高包括：- 读未提交（read uncommitted）：它是最低的事务隔离级别，一个事务还没提交时，它做的变更就能被别的事务看到。有脏读的可能性。- 读提交（read committed）：保证一个事物提交后才能被另外一个事务读取。另外一个事务不能读取该事物未提交的数据。可避免脏读的发生，但是可能会造成不可重复读。- 可重复读（repeatable read MySQL 默认方式）：多次读取同一范围的数据会返回第一次查询的快照，即使其他事务对该数据做了更新修改。事务在执行期间看到的数据前后必须是一致的。- 串行化（serializable）：是最可靠的事务隔离级别。“写”会加“排他锁”，“读”会加“共享锁”。 当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，所以事务执行是串行的。可避免脏读、不可重复读、幻读。### InnoDB 优化建议从锁机制的实现方面来说，InnoDB 的行级锁带来的性能损耗可能比表级锁要高一点，但在并发方面的处理能力远远优于 MyISAM 的表级锁。这也是大多数公司的 MySQL 都是使用 InnoDB 模式的原因。但是，InnoDB 也有脆弱的一面，下面提出几个优化建议供大家参考：- 尽可能让数据检索通过索引完成，避免 InnoDB 因为无法通过索引加行锁，而导致升级为表锁的情况。换句话说就是，多用行锁，少用表锁。- 加索引的时候尽量准确，避免造成不必要的锁定影响其他查询。- 尽量减少给予范围的数据检索（间隙锁），避免因为间隙锁带来的影响，锁定了不该锁定的记录。- 尽量控制事务的大小，减少锁定的资源量和锁定时间。- 尽量使用较低级别的事务隔离，减少 MySQL 因为事务隔离带来的成本。### 总结MySQL 数据库锁的思维导图 MySQL 的锁主要分为表级锁和行级锁。MyISAM 引擎使用的是表级锁，针对表级的共享锁和排他锁，可以通过 concurrent_insert 和 low_priority_updates 参数来优化。 InnoDB 支持表锁和行锁，根据索引来判断如何选择。行锁有，行共享锁和行排他锁；表锁有，意向共享锁，意向排他锁，表锁是系统自己加上的；锁范围的是间隙锁。遇到死锁，我们如何检测，恢复以及如何避免。 MySQL 有四个事务级别分别是，读未提交，读提交，可重复读，串行化。他们的隔离级别依次升高。 通过隔离级别的设置，可以避免，脏读，不可重复读和幻读的情况。最后，对于使用比较多的 InnoDB 引擎，提出了一些优化建议。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentruan.github.io/categories/MySQL/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://vincentruan.github.io/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"https://vincentruan.github.io/tags/MySQL/"},{"name":"锁","slug":"锁","permalink":"https://vincentruan.github.io/tags/锁/"}]},{"title":"Linux实用的服务异常处理指南","slug":"JAVA实用的服务异常处理指南","date":"2020-02-12T02:49:31.000Z","updated":"2020-02-26T03:27:42.508Z","comments":true,"path":"2020/02/12/JAVA实用的服务异常处理指南/","link":"","permalink":"https://vincentruan.github.io/2020/02/12/JAVA实用的服务异常处理指南/","excerpt":"服务异常的处理流程","text":"服务异常的处理流程 CPU负载说明针对应用程序，我们通常关注的是内核CPU调度器功能和性能。 线程的状态分析主要是分析线程的时间用在什么地方，而线程状态的分类一般分为： a. on-CPU：执行中，执行中的时间通常又分为用户态时间user和系统态时间sys。 b. off-CPU：等待下一轮上CPU，或者等待I/O、锁、换页等等，其状态可以细分为可执行、匿名换页、睡眠、锁、空闲等状态。 如果大量时间花在CPU上，对CPU的剖析能够迅速解释原因；如果系统时间大量处于off-cpu状态，定位问题就会费时很多。但是仍然需要清楚一些概念： 处理器 核 硬件线程 CPU内存缓存 时钟频率 每指令周期数CPI和每周期指令数IPC CPU指令 使用率 用户时间／内核时间 调度器 运行队列 抢占 多进程 多线程 字长 分析工具 工具 描述 uptime 平均负载 vmstat 包括系统范围的cpu平均负载 mpstat 查看所有cpu核信息 top 监控每个进程cpu用量 sar -u 查看cpu信息 pidstat 每个进程cpu用量分解 perf cpu剖析和跟踪，性能计数分析 说明: uptime,vmstat,mpstat,top,pidstat只能查询到cpu及负载的的使用情况。 perf可以跟着到进程内部具体函数耗时情况，并且可以指定内核函数进行统计，指哪打哪。 使用方式1234567891011121314//查看系统cpu使用情况top//查看所有cpu核信息mpstat -P ALL 1//查看cpu使用情况以及平均负载vmstat 1//进程cpu的统计信息pidstat -u 1 -p pid//跟踪进程内部函数级cpu使用情况perf top -p pid -e cpu-clock 查看机器 cpu 的负载1top -b -n 1 |grep java|awk '&#123;print \"VIRT:\"$5,\"RES:\"$6,\"cpu:\"$9\"%\",\"mem:\"$10\"%\"&#125;' 查找 cpu 占用率高的线程1234top -p 25603 -Hprintf 0x%x 25842jstack 25603 | grep 0x64f2cat /proc/interrupts （1）CPU（2）Memory（3）IO（4）Network 可以从以下几个方面监控CPU的信息：（1）中断；（2）上下文切换；（3）可运行队列；（4）CPU 利用率 内存说明内存是为提高效率而生，实际分析问题的时候，内存出现问题可能不只是影响性能，而是影响服务或者引起其他问题。同样对于内存有些概念需要清楚： 主存 虚拟内存 常驻内存 地址空间 OOM 页缓存 缺页 换页 交换空间 交换 用户分配器libc、glibc、libmalloc和mtmalloc LINUX内核级SLUB分配器 分析工具 工具 描述 free 缓存容量统计信息 vmstat 虚拟内存统计信息 top 监视每个进程的内存使用情况 pidstat 显示活动进程的内存使用统计 pmap 查看进程的内存映像信息 sar -r 查看内存 dtrace 动态跟踪 valgrind 分析程序性能及程序中的内存泄露错误 说明： free,vmstat,top,pidstat,pmap只能统计内存信息以及进程的内存使用情况。 valgrind可以分析内存泄漏问题。 dtrace动态跟踪。需要对内核函数有很深入的了解，通过D语言编写脚本完成跟踪。 使用方式1234567891011121314151617//查看系统内存使用情况free -m//虚拟内存统计信息vmstat 1//查看系统内存情况top//1s采集周期，获取内存的统计信息pidstat -p pid -r 1//查看进程的内存映像信息pmap -d pid//检测程序内存问题valgrind --tool=memcheck --leak-check=full --log-file=./log.txt ./程序名 系统内存free 命令123456[root@server ~]# free total used free shared buffers cachedMem: 3266180 3250000 10000 0 201000 3002000-/+ buffers/cache: 47000 3213000Swap: 2048276 80160 1968116 这里的默认显示单位是kb。各项指标解释 total:总计物理内存的大小。 used:已使用多大。 free:可用有多少。 Shared:多个进程共享的内存总额。 buffers: 磁盘缓存的大小。 cache:磁盘缓存的大小。 -/+ buffers/cached): used:已使用多大，free:可用有多少。 已用内存 = 系统used memory - buffers - cached（47000 = 3250000-201000-3002000） 可用内存 = 系统free memory + buffers + cached（3213000 = 10000+201000+3002000） 什么是buffer/cache？ buffer 指 Linux 内存的：Buffer cache，缓冲区缓 cache 指 Linux内存中的：Page cache，页面缓存 page cachepage cache 主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有 read／write 操作的时候。如果你仔细想想的话，作为可以映射文件到内存的系统调用：mmap是不是很自然的也应该用到 page cache？在当前的系统实现里，page cache 也被作为其它文件类型的缓存设备来用，所以事实上 page cache 也负责了大部分的块设备文件的缓存工作。 buffer cachebuffer cache 主要用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。这意味着某些对块的操作会使用 buffer cache 进行缓存，比如我们在格式化文件系统的时候。一般情况下两个缓存系统是一起配合使用的，比如当我们对一个文件进行写操作的时候，page cache 的内容会被改变，而 buffer cache 则可以用来将 page 标记为不同的缓冲区，并记录是哪一个缓冲区被修改了。这样，内核在后续执行脏数据的回写（writeback）时，就不用将整个 page 写回，而只需要写回修改的部分即可。 在当前的内核中，page cache 是针对内存页的缓存，说白了就是，如果有内存是以page进行分配管理的，都可以使用page cache作为其缓存来管理使用。当然，不是所有的内存都是以页（page）进行管理的，也有很多是针对块（block）进行管理的，这部分内存使用如果要用到 cache 功能，则都集中到buffer cache中来使用。（从这个角度出发，是不是buffer cache改名叫做block cache更好？）然而，也不是所有块（block）都有固定长度，系统上块的长度主要是根据所使用的块设备决定的，而页长度在X86上无论是32位还是64位都是4k。 系统如何回收cache？Linux内核会在内存将要耗尽的时候，触发内存回收的工作，以便释放出内存给急需内存的进程使用。一般情况下，这个操作中主要的内存释放都来自于对buffer／cache的释放。尤其是被使用更多的cache空间。既然它主要用来做缓存，只是在内存够用的时候加快进程对文件的读写速度，那么在内存压力较大的情况下，当然有必要清空释放cache，作为free空间分给相关进程使用。所以一般情况下，我们认为buffer/cache空间可以被释放，这个理解是正确的。 但是这种清缓存的工作也并不是没有成本。理解cache是干什么的就可以明白清缓存必须保证cache中的数据跟对应文件中的数据一致，才能对cache进行释放。所以伴随着cache清除的行为的，一般都是系统IO飙高。因为内核要对比cache中的数据和对应硬盘文件上的数据是否一致，如果不一致需要写回，之后才能回收。 在系统中除了内存将被耗尽的时候可以清缓存以外，我们还可以人工触发缓存清除的操作。 进程内存进程内存统计/proc/[pid]/status通过/proc//status可以查看进程的内存使用情况，包括虚拟内存大小（VmSize），物理内存大小（VmRSS），数据段大小（VmData），栈的大小（VmStk），代码段的大小（VmExe），共享库的代码段大小（VmLib）等等。 cat /proc/[pid]/status 1234567891011121314151617Name: gedit /*进程的程序名*/State: S (sleeping) /*进程的状态信息,具体参见http://blog.chinaunix.net/u2/73528/showart_1106510.html*/Tgid: 9744 /*线程组号*/Pid: 9744 /*进程pid*/PPid: 7672 /*父进程的pid*/TracerPid: 0 /*跟踪进程的pid*/VmPeak: 60184 kB /*进程地址空间的大小*/VmSize: 60180 kB /*进程虚拟地址空间的大小reserved_vm：进程在预留或特殊的内存间的物理页*/VmLck: 0 kB /*进程已经锁住的物理内存的大小.锁住的物理内存不能交换到硬盘*/VmHWM: 18020 kB /*文件内存映射和匿名内存映射的大小*/VmRSS: 18020 kB /*应用程序正在使用的物理内存的大小，就是用ps命令的参数rss的值 (rss)*/VmData: 12240 kB /*程序数据段的大小（所占虚拟内存的大小），存放初始化了的数据*/VmStk: 84 kB /*进程在用户态的栈的大小*/VmExe: 576 kB /*程序所拥有的可执行虚拟内存的大小,代码段,不包括任务使用的库 */VmLib: 21072 kB /*被映像到任务的虚拟内存空间的库的大小*/VmPTE: 56 kB /*该进程的所有页表的大小*/Threads: 1 /*共享使用该信号描述符的任务的个数*/ JVM 内存分配java内存组成介绍：堆(Heap)和非堆(Non-heap)内存 按照官方的说法：“Java 虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在 Java 虚拟机启动时创建的。”“在JVM中堆之外的内存称为非堆内存(Non-heap memory)”。可以看出JVM主要管理两种类型的内存：堆和非堆。 简单来说堆就是Java代码可及的内存，是留给开发人员使用的；非堆就是JVM留给 自己用的，所以方法区、JVM内部处理或优化所需的内存(如JIT编译后的代码缓存)、每个类结构(如运行时常数池、字段和方法数据)以及方法和构造方法 的代码都在非堆内存中。 JVM本身需要的内存，包括其加载的第三方库以及这些库分配的内存 NIO的DirectBuffer是分配的native memory 内存映射文件，包括JVM加载的一些JAR和第三方库，以及程序内部用到的。上面 pmap 输出的内容里，有一些静态文件所占用的大小不在Java的heap里，因此作为一个Web服务器，赶紧把静态文件从这个Web服务器中人移开吧，放到nginx或者CDN里去吧。 JIT， JVM会将Class编译成native代码，这些内存也不会少，如果使用了Spring的AOP，CGLIB会生成更多的类，JIT的内存开销也会随之变大，而且Class本身JVM的GC会将其放到Perm Generation里去，很难被回收掉，面对这种情况，应该让JVM使用ConcurrentMarkSweep GC，并启用这个GC的相关参数允许将不使用的class从Perm Generation中移除， 参数配置： -XX:+UseConcMarkSweepGC -X:+CMSPermGenSweepingEnabled -X:+CMSClassUnloadingEnabled，如果不需要移除而Perm Generation空间不够，可以加大一点： -X:PermSize=256M -X:MaxPermSize=512M JNI，一些JNI接口调用的native库也会分配一些内存，如果遇到JNI库的内存泄露，可以使用valgrind等内存泄露工具来检测 线程栈，每个线程都会有自己的栈空间，如果线程一多，这个的开销就很明显了 jmap/jstack 采样，频繁的采样也会增加内存占用，如果你有服务器健康监控，记得这个频率别太高，否则健康监控变成致病监控了。 方法区也称”永久代” 、“非堆”，它用于存储虚拟机加载的类信息、常量、静态变量、是各个线程共享的内存区域。默认最小值为16MB，最大值为64MB，可以通过-XX:PermSize 和 -XX:MaxPermSize 参数限制方法区的大小。 运行时常量池：是方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译器生成的各种符号引用，这部分内容将在类加载后放到方法区的运行时常量池中。 虚拟机栈描述的是java 方法执行的内存模型：每个方法被执行的时候 都会创建一个“栈帧”用于存储局部变量表(包括参数)、操作栈、方法出口等信息。每个方法被调用到执行完的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。声明周期与线程相同，是线程私有的。 局部变量表存放了编译器可知的各种基本数据类型(boolean、byte、char、short、int、float、long、double)、对象引用(引用指针，并非对象本身)，其中64位长度的long和double类型的数据会占用2个局部变量的空间，其余数据类型只占1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量是完全确定的，在运行期间栈帧不会改变局部变量表的大小空间。 本地方法栈与虚拟机栈基本类似，区别在于虚拟机栈为虚拟机执行的java方法服务，而本地方法栈则是为Native方法服务。 堆也叫做java 堆、GC堆是java虚拟机所管理的内存中最大的一块内存区域，也是被各个线程共享的内存区域，在JVM启动时创建。该内存区域存放了对象实例及数组(所有new的对象)。其大小通过-Xms(最小值)和-Xmx(最大值)参数设置，-Xms为JVM启动时申请的最小内存，默认为操作系统物理内存的1/64但小于1G，-Xmx为JVM可申请的最大内存，默认为物理内存的1/4但小于1G，默认当空余堆内存小于40%时，JVM会增大Heap到-Xmx指定的大小，可通过-XX:MinHeapFreeRation=来指定这个比列；当空余堆内存大于70%时，JVM会减小heap的大小到-Xms指定的大小，可通过XX:MaxHeapFreeRation=来指定这个比列，对于运行系统，为避免在运行时频繁调整Heap的大小，通常-Xms与-Xmx的值设成一样。 由于现在收集器都是采用分代收集算法，堆被划分为新生代和老年代。新生代主要存储新创建的对象和尚未进入老年代的对象。老年代存储经过多次新生代GC(Minor GC)任然存活的对象。 程序计数器是最小的一块内存区域，它的作用是当前线程所执行的字节码的行号指示器，在虚拟机的模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、异常处理、线程恢复等基础功能都需要依赖计数器完成。 直接内存直接内存并不是虚拟机内存的一部分，也不是Java虚拟机规范中定义的内存区域。jdk1.4中新加入的NIO，引入了通道与缓冲区的IO方式，它可以调用Native方法直接分配堆外内存，这个堆外内存就是本机内存，不会影响到堆内存的大小。 JVM 内存分析查看 JVM 堆内存情况jmap -heap [pid] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@server ~]$ jmap -heap 837Attaching to process ID 837, please wait...Debugger attached successfully.Server compiler detected.JVM version is 24.71-b01using thread-local object allocation.Parallel GC with 4 thread(s)//GC 方式Heap Configuration: //堆内存初始化配置 MinHeapFreeRatio = 0 //对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40) MaxHeapFreeRatio = 100 //对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70) MaxHeapSize = 2082471936 (1986.0MB) //对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小 NewSize = 1310720 (1.25MB)//对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小 MaxNewSize = 17592186044415 MB//对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小 OldSize = 5439488 (5.1875MB)//对应jvm启动参数-XX:OldSize=&lt;value&gt;:设置JVM堆的‘老生代’的大小 NewRatio = 2 //对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率 SurvivorRatio = 8 //对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值 PermSize = 21757952 (20.75MB) //对应jvm启动参数-XX:PermSize=&lt;value&gt;:设置JVM堆的‘永生代’的初始大小 MaxPermSize = 85983232 (82.0MB)//对应jvm启动参数-XX:MaxPermSize=&lt;value&gt;:设置JVM堆的‘永生代’的最大大小 G1HeapRegionSize = 0 (0.0MB)Heap Usage://堆内存使用情况PS Young GenerationEden Space://Eden区内存分布 capacity = 33030144 (31.5MB)//Eden区总容量 used = 1524040 (1.4534378051757812MB) //Eden区已使用 free = 31506104 (30.04656219482422MB) //Eden区剩余容量 4.614088270399305% used //Eden区使用比率From Space: //其中一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% usedTo Space: //另一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% usedPS Old Generation //当前的Old区内存分布 capacity = 86507520 (82.5MB) used = 0 (0.0MB) free = 86507520 (82.5MB) 0.0% usedPS Perm Generation//当前的 “永生代” 内存分布 capacity = 22020096 (21.0MB) used = 2496528 (2.3808746337890625MB) free = 19523568 (18.619125366210938MB) 11.337498256138392% used670 interned Strings occupying 43720 bytes. 关于这里的几个generation网上资料一大把就不细说了，这里算一下求和可以得知前者总共给Java环境分配了644M的内存，而ps输出的VSZ和RSS分别是7.4G和2.9G，这到底是怎么回事呢？前面jmap输出的内容里，MaxHeapSize 是在命令行上配的，-Xmx4096m，这个java程序可以用到的最大堆内存。VSZ是指已分配的线性空间大小，这个大小通常并不等于程序实际用到的内存大小，产生这个的可能性很多，比如内存映射，共享的动态库，或者向系统申请了更多的堆，都会扩展线性空间大小，要查看一个进程有哪些内存映射，可以使用 pmap 命令来查看：pmap -x [pid] 12345678910111213141516[root@server ~]$ pmap -x 837837: javaAddress Kbytes RSS Dirty Mode Mapping0000000040000000 36 4 0 r-x-- java0000000040108000 8 8 8 rwx-- java00000000418c9000 13676 13676 13676 rwx-- [ anon ]00000006fae00000 83968 83968 83968 rwx-- [ anon ]0000000700000000 527168 451636 451636 rwx-- [ anon ]00000007202d0000 127040 0 0 ----- [ anon ]......00007f55ee124000 4 4 0 r-xs- az.png00007fff017ff000 4 4 0 r-x-- [ anon ]ffffffffff600000 4 0 0 r-x-- [ anon ]---------------- ------ ------ ------total kB 7796020 3037264 3023928 这里可以看到很多anon，这些表示这块内存是由mmap分配的。 RSZ是Resident Set Size，常驻内存大小，即进程实际占用的物理内存大小， 在现在这个例子当中，RSZ和实际堆内存占用差了2.3G，这2.3G的内存组成分别为： 查看 JVM 堆各个分区的内存情况jstat -gcutil [pid] 1234[root@server ~]$ jstat -gcutil 837 1000 20 S0 S1 E O P YGC YGCT FGC FGCT GCT 0.00 80.43 24.62 87.44 98.29 7101 119.652 40 19.719 139.371 0.00 80.43 33.14 87.44 98.29 7101 119.652 40 19.719 139.371 分析 JVM 堆内存中的对象查看存活的对象统计jmap -histo:live [pid] dump 内存jmap -dump:format=b,file=heapDump [pid] 然后用jhat命令可以参看jhat -port 5000 heapDump在浏览器中访问：http://localhost:5000/ 查看详细信息 磁盘IO说明磁盘通常是计算机最慢的子系统，也是最容易出现性能瓶颈的地方，因为磁盘离 CPU 距离最远而且 CPU 访问磁盘要涉及到机械操作，比如转轴、寻轨等。访问硬盘和访问内存之间的速度差别是以数量级来计算的，就像1天和1分钟的差别一样。要监测 IO 性能，有必要了解一下基本原理和 Linux 是如何处理硬盘和内存之间的 IO 的。 在理解磁盘IO之前，同样我们需要理解一些概念，例如： 文件系统 VFS 文件系统缓存 页缓存page cache 缓冲区高速缓存buffer cache 目录缓存 inode inode缓存 noop调用策略 分析工具 工具 描述 iostat 磁盘详细统计信息 iotop 按进程查看磁盘IO的使用情况 pidstat 按进程查看磁盘IO的使用情况 perf 动态跟踪工具 使用方式12345678910111213//查看系统io信息iotop//统计io详细信息iostat -d -x -k 1 10//查看进程级io的信息pidstat -d 1 -p pid//查看系统IO的请求，比如可以在发现系统IO异常时，可以使用该命令进行调查，就能指定到底是什么原因导致的IO异常perf record -e block:block_rq_issue -ag^Cperf report 网络说明网络的监测是所有 Linux 子系统里面最复杂的，有太多的因素在里面，比如：延迟、阻塞、冲突、丢包等，更糟的是与 Linux 主机相连的路由器、交换机、无线信号都会影响到整体网络并且很难判断是因为 Linux 网络子系统的问题还是别的设备的问题，增加了监测和判断的复杂度。现在我们使用的所有网卡都称为自适应网卡，意思是说能根据网络上的不同网络设备导致的不同网络速度和工作模式进行自动调整。 分析工具 工具 描述 ping 主要透过 ICMP 封包 来进行整个网络的状况报告 traceroute 用来检测发出数据包的主机到目标主机之间所经过的网关数量的工具 netstat 用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况 ss 可以用来获取socket统计信息，而且比netstat更快速更高效 host 可以用来查出某个主机名的 IP,跟nslookup作用一样 tcpdump 是以包为单位进行输出的，阅读起来不是很方便 tcpflow 是面向tcp流的, 每个tcp传输会保存成一个文件,很方便的查看 sar -n DEV 网卡流量情况 sar -n SOCK 查询网络以及tcp，udp状态信息 使用方式1234567891011121314151617181920212223242526272829303132//显示网络统计信息netstat -s//显示当前UDP连接状况netstat -nu//显示UDP端口号的使用情况netstat -apu//统计机器中网络连接各个状态个数netstat -a | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;'//显示TCP连接ss -t -a//显示sockets摘要信息ss -s//显示所有udp socketsss -u -a//tcp,etcp状态sar -n TCP,ETCP 1//查看网络IOsar -n DEV 1//抓包以包为单位进行输出tcpdump -i eth1 host 192.168.1.1 and port 80 //抓包以流为单位显示数据内容tcpflow -cp host 192.168.1.1 服务指标响应时间(RT)响应时间是指系统对请求作出响应的时间。直观上看，这个指标与人对软件性能的主观感受是非常一致的，因为它完整地记录了整个计算机系统处理请求的时间。由于一个系统通常会提供许多功能，而不同功能的处理逻辑也千差万别，因而不同功能的响应时间也不尽相同，甚至同一功能在不同输入数据的情况下响应时间也不相同。所以，在讨论一个系统的响应时间时，人们通常是指该系统所有功能的平均时间或者所有功能的最大响应时间。当然，往往也需要对每个或每组功能讨论其平均响应时间和最大响应时间。 对于单机的没有并发操作的应用系统而言，人们普遍认为响应时间是一个合理且准确的性能指标。需要指出的是，响应时间的绝对值并不能直接反映软件的性能的高低，软件性能的高低实际上取决于用户对该响应时间的接受程度。对于一个游戏软件来说，响应时间小于100毫秒应该是不错的，响应时间在1秒左右可能属于勉强可以接受，如果响应时间达到3秒就完全难以接受了。而对于编译系统来说，完整编译一个较大规模软件的源代码可能需要几十分钟甚至更长时间，但这些响应时间对于用户来说都是可以接受的。 吞吐量(Throughput)吞吐量是指系统在单位时间内处理请求的数量。对于无并发的应用系统而言，吞吐量与响应时间成严格的反比关系，实际上此时吞吐量就是响应时间的倒数。前面已经说过，对于单用户的系统，响应时间（或者系统响应时间和应用延迟时间）可以很好地度量系统的性能，但对于并发系统，通常需要用吞吐量作为性能指标。 对于一个多用户的系统，如果只有一个用户使用时系统的平均响应时间是t，当有你n个用户使用时，每个用户看到的响应时间通常并不是n×t，而往往比n×t小很多（当然，在某些特殊情况下也可能比n×t大，甚至大很多）。这是因为处理每个请求需要用到很多资源，由于每个请求的处理过程中有许多不走难以并发执行，这导致在具体的一个时间点，所占资源往往并不多。也就是说在处理单个请求时，在每个时间点都可能有许多资源被闲置，当处理多个请求时，如果资源配置合理，每个用户看到的平均响应时间并不随用户数的增加而线性增加。实际上，不同系统的平均响应时间随用户数增加而增长的速度也不大相同，这也是采用吞吐量来度量并发系统的性能的主要原因。一般而言，吞吐量是一个比较通用的指标，两个具有不同用户数和用户使用模式的系统，如果其最大吞吐量基本一致，则可以判断两个系统的处理能力基本一致。 并发用户数并发用户数是指系统可以同时承载的正常使用系统功能的用户的数量。与吞吐量相比，并发用户数是一个更直观但也更笼统的性能指标。实际上，并发用户数是一个非常不准确的指标，因为用户不同的使用模式会导致不同用户在单位时间发出不同数量的请求。一网站系统为例，假设用户只有注册后才能使用，但注册用户并不是每时每刻都在使用该网站，因此具体一个时刻只有部分注册用户同时在线，在线用户就在浏览网站时会花很多时间阅读网站上的信息，因而具体一个时刻只有部分在线用户同时向系统发出请求。这样，对于网站系统我们会有三个关于用户数的统计数字：注册用户数、在线用户数和同时发请求用户数。由于注册用户可能长时间不登陆网站，使用注册用户数作为性能指标会造成很大的误差。而在线用户数和同事发请求用户数都可以作为性能指标。相比而言，以在线用户作为性能指标更直观些，而以同时发请求用户数作为性能指标更准确些。 QPS每秒查询率(Query Per Second)每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。对应fetches/sec，即每秒的响应请求数，也即是最大吞吐能力。 从以上概念来看吞吐量和响应时间是衡量系统性能的重要指标，QPS虽然和吞吐量的计量单位不同，但应该是成正比的，任何一个指标都可以含量服务器的并行处理能力。当然Throughput更关心数据量，QPS更关心处理笔数。 CPU利用率CPU Load Average &lt; CPU个数 核数 0.7 Context Switch Rate就是Process（Thread）的切换，如果切换过多，会让CPU忙于切换，也会导致影响吞吐量。《高性能服务器架构 》这篇文章的第2节就是说的是这个问题的。究竟多少算合适？google了一大圈，没有一个确切的解释。Context Switch大体上由两个部分组成：中断和进程(包括线程)切换，一次中断（Interrupt）会引起一次切换，进程（线程）的创建、激活之类的也会引起一次切换。CS的值也和TPS（Transaction Per Second）相关的，假设每次调用会引起N次CS，那么就可以得出 Context Switch Rate = Interrupt Rate + TPS* N CSR减掉IR，就是进程/线程的切换，假如主进程收到请求交给线程处理，线程处理完毕归还给主进程，这里就是2次切换。也可以用CSR、IR、TPS的值代入公式中，得出每次事物导致的切换数。因此，要降低CSR，就必须在每个TPS引起的切换上下功夫，只有N这个值降下去，CSR就能降低，理想情况下N=0，但是无论如何如果N &gt;= 4，则要好好检查检查。另外网上说的CSR&lt;5000，我认为标准不该如此单一。 这三个指标在 LoadRunner 中可以监控到；另外，在 linux 中，也可以用 vmstat 查看r（Load Arerage），in（Interrupt）和cs（Context Switch） 工具 uptime 1234567uptime 08:21:34 up 36 min, 2 users, load average: 0.00, 0.00, 0.00 #当前服务器时间： 08:21:34#当前服务器运行时长 36 min#当前用户数 2 users#当前的负载均衡 load average 0.00, 0.00, 0.00，分别取1min,5min,15min的均值 dmesg dmesg命令用于显示开机信息。 kernel会将开机信息存储在ring buffer中。您若是开机时来不及查看信息，可利用dmesg来查看。开机信息亦保存在/var/log目录中，名称为dmesg的文件里。 语法 1dmesg [-cn][-s &lt;缓冲区大小&gt;] 参数说明： -c 显示信息后，清除ring buffer中的内容。 -s&lt;缓冲区大小&gt; 预设置为8196，刚好等于ring buffer的大小。 -n 设置记录信息的层级。 top查看进程活动状态以及一些系统状况 vmstat查看系统状态、硬件和系统信息等 iostat查看CPU 负载，硬盘状况 sar综合工具，查看系统状况 mpstat查看多处理器状况 netstat查看网络状况 iptraf实时网络状况监测 tcpdump抓取网络数据包，详细分析 mpstat查看多处理器状况 tcptrace数据包分析工具 netperf网络带宽工具 dstat综合工具，综合了 vmstat, iostat, ifstat, netstat 等多个信息 系统负载说明Load 就是对计算机干活多少的度量（WikiPedia：the system Load is a measure of the amount of work that a compute system is doing）简单的说是进程队列的长度。Load Average 就是一段时间（1分钟、5分钟、15分钟）内平均Load。 分析工具 工具 描述 top 查看系统负载情况 uptime 查看系统负载情况 strace 统计跟踪内核态信息 vmstat 查看负载情况 dmesg 查看内核日志信息 使用方式123456789101112131415//查看负载情况uptimetopvmstat//统计系统调用耗时情况strace -c -p pid//跟踪指定的系统操作例如epoll_waitstrace -T -e epoll_wait -p pid//查看内核日志信息dmesg 实战场景一某Java服务（假设PID=10765）出现了OOM，最常见的原因为： 有可能是内存分配确实过小，而正常业务使用了大量内存 某一个对象被频繁申请，却没有释放，内存不断泄漏，导致内存耗尽 某一个资源被频繁申请，系统资源耗尽，例如：不断创建线程，不断发起网络连接 更具体的，可以使用以下工具逐一排查。 确认是不是内存本身就分配过小 方法：jmap -heap 10765 如上图，可以查看新生代，老生代堆内存的分配大小以及使用情况，看是否本身分配过小。 找到最耗内存的对象 方法：jmap -histo:live 10765 | more 如上图，输入命令后，会以表格的形式显示存活对象的信息，并按照所占内存大小排序： 实例数 所占内存大小 类名 是不是很直观？对于实例数较多，占用内存大小较多的实例/类，相关的代码就要针对性review了。 上图中占内存最多的对象是RingBufferLogEvent，共占用内存18M，属于正常使用范围。 如果发现某类对象占用内存很大（例如几个G），很可能是类对象创建太多，且一直未释放。例如： 申请完资源后，未调用close()或dispose()释放资源 消费者消费速度慢（或停止消费了），而生产者不断往队列中投递任务，导致队列中任务累积过多 ps：线上执行该命令会强制执行一次fgc。另外还可以dump内存进行分析。 确认是否是资源耗尽工具： pstree netstat 查看进程创建的线程数，以及网络连接数，如果资源耗尽，也可能出现OOM。 这里介绍另一种方法，通过 /proc/${PID}/fd /proc/${PID}/task 可以分别查看句柄详情和线程数。 例如，某一台线上服务器的sshd进程PID是9339，查看 ll /proc/9339/fd ll /proc/9339/task 如上图，sshd共占用了四个句柄 0 -&gt; 标准输入 1 -&gt; 标准输出 2 -&gt; 标准错误输出 3 -&gt; socket（容易想到是监听端口） sshd只有一个主线程PID为9339，并没有多线程。 所以，只要 ll /proc/${PID}/fd | wc -l ll /proc/${PID}/task | wc -l （效果等同pstree -p | wc -l） 就能知道进程打开的句柄数和线程数。 Reference http://tmq.qq.com/2016/07/it-is-necessary-to-know-the-background-performance-test/ https://www.ibm.com/developerworks/java/library/j-nativememory-linux/ http://www.oracle.com/technetwork/java/javase/index-137495.html http://www.hollischuang.com/archives/303 https://www.jianshu.com/p/0bbac570fa4c","categories":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/tags/Linux/"},{"name":"异常处理","slug":"异常处理","permalink":"https://vincentruan.github.io/tags/异常处理/"},{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/tags/Java/"}]},{"title":"操作系统基础概念简述","slug":"操作系统基础概念简述","date":"2020-02-11T13:35:14.000Z","updated":"2020-02-25T15:09:15.069Z","comments":true,"path":"2020/02/11/操作系统基础概念简述/","link":"","permalink":"https://vincentruan.github.io/2020/02/11/操作系统基础概念简述/","excerpt":"操作系统概念大部分操作系统提供了特定的基础概念和抽象，例如进程、地址空间、文件等，它们是需要理解的核心内容。下面我们会简要介绍一些基本概念，为了说明这些概念，我们会不时的从 UNIX 中提出示例，相同的示例也会存在于其他系统中，我们后面会进行介绍。","text":"操作系统概念大部分操作系统提供了特定的基础概念和抽象，例如进程、地址空间、文件等，它们是需要理解的核心内容。下面我们会简要介绍一些基本概念，为了说明这些概念，我们会不时的从 UNIX 中提出示例，相同的示例也会存在于其他系统中，我们后面会进行介绍。 进程操作系统一个很关键的概念就是 进程(Process)。进程的本质就是操作系统执行的一个程序。与每个进程相关的是地址空间(address space)，这是从某个最小值的存储位置(通常是零)到某个最大值的存储位置的列表。在这个地址空间中，进程可以进行读写操作。地址空间中存放有可执行程序，程序所需要的数据和它的栈。与每个进程相关的还有资源集，通常包括寄存器(registers)（寄存器一般包括程序计数器(program counter)和堆栈指针(stack pointer)）、打开文件的清单、突发的报警、有关的进程清单和其他需要执行程序的信息。你可以把进程看作是容纳运行一个程序所有信息的一个容器。 对进程建立一种直观感觉的方式是考虑建立一种多程序的系统。考虑下面这种情况：用户启动一个视频编辑程序，指示它按照某种格式转换视频，然后再去浏览网页。同时，一个检查电子邮件的后台进程被唤醒并开始运行，这样，我们目前就会有三个活动进程：视频编辑器、Web 浏览器和电子邮件接收程序。操作系统周期性的挂起一个进程然后启动运行另一个进程，这可能是由于过去一两秒钟程序用完了 CPU 分配的时间片，而 CPU 转而运行另外的程序。 像这样暂时中断进程后，下次应用程序在此启动时，必须要恢复到与中断时刻相同的状态，这在我们用户看起来是习以为常的事情，但是操作系统内部却做了巨大的事情。这就像和足球比赛一样，一场完美精彩的比赛是可以忽略裁判的存在的。这也意味着在挂起时该进程的所有信息都要被保存下来。例如，进程可能打开了多个文件进行读取。与每个文件相关联的是提供当前位置的指针（即下一个需要读取的字节或记录的编号）。当进程被挂起时，必须要保存这些指针，以便在重新启动进程后执行的 read调用将能够正确的读取数据。在许多操作系统中，与一个进程有关的所有信息，除了该进程自身地址空间的内容以外，均存放在操作系统的一张表中，称为 进程表(process table)，进程表是数组或者链表结构，当前存在每个进程都要占据其中的一项。 所以，一个挂起的进程包括：进程的地址空间（往往称作磁芯映像， core image，纪念过去的磁芯存储器），以及对应的进程表项（其中包括寄存器以及稍后启动该进程所需要的许多其他信息）。 与进程管理有关的最关键的系统调用往往是决定着进程的创建和终止的系统调用。考虑一个典型的例子，有一个称为 命令解释器(command interpreter) 或 shell 的进程从终端上读取命令。此时，用户刚键入一条命令要求编译一个程序。shell 必须先创建一个新进程来执行编译程序，当编译程序结束时，它执行一个系统调用来终止自己的进程。 如果一个进程能够创建一个或多个进程（称为子进程），而且这些进程又可以创建子进程，则很容易找到进程数，如下所示 上图表示一个进程树的示意图，进程 A 创建了两个子进程 B 和进程 C，子进程 B 又创建了三个子进程 D、E、F。 合作完成某些作业的相关进程经常需要彼此通信来完成作业，这种通信称为进程间通信(interprocess communication)。我们在后面会探讨进程间通信。 其他可用的进程系统调用包括：申请更多的内存（或释放不再需要的内存），等待一个子进程结束，用另一个程序覆盖该程序。 有时，需要向一个正在运行的进程传递信息，而该进程并没有等待接收信息。例如，一个进程通过网络向另一台机器上的进程发送消息进行通信。为了保证一条消息或消息的应答不丢失。发送者要求它所在的操作系统在指定的若干秒后发送一个通知，这样如果对方尚未收到确认消息就可以进行重新发送。在设定该定时器后，程序可以继续做其他工作。 在限定的时间到达后，操作系统会向进程发送一个 警告信号(alarm signal)。这个信号引起该进程暂时挂起，无论该进程正在做什么，系统将其寄存器的值保存到堆栈中，并开始重新启动一个特殊的信号处理程，比如重新发送可能丢失的消息。这些信号是软件模拟的硬件中断，除了定时器到期之外，该信号可以通过各种原因产生。许多由硬件检测出来的陷阱，如执行了非法指令或使用了无效地址等，也被转换成该信号并交给这个进程。 系统管理器授权每个进程使用一个给定的 UID(User IDentification)。每个启动的进程都会有一个操作系统赋予的 UID，子进程拥有与父进程一样的 UID。用户可以是某个组的成员，每个组也有一个 GID(Group IDentification)。 在 UNIX 操作系统中，有一个 UID 是 超级用户(superuser)，或者 Windows 中的管理员(administrator)，它具有特殊的权利，可以违背一些保护规则。在大型系统中，只有系统管理员掌握着那些用户可以称为超级用户。 地址空间每台计算机都有一些主存用来保存正在执行的程序。在一个非常简单的操作系统中，仅仅有一个应用程序运行在内存中。为了运行第二个应用程序，需要把第一个应用程序移除才能把第二个程序装入内存。 复杂一些的操作系统会允许多个应用程序同时装入内存中运行。为了防止应用程序之间相互干扰（包括操作系统），需要有某种保护机制。虽然此机制是在硬件中实现，但却是由操作系统控制的。 上述观点涉及对计算机主存的管理和保护。另一种同等重要并与存储器有关的内容是管理进程的地址空间。通常，每个进程有一些可以使用的地址集合，典型值从 0 开始直到某个最大值。一个进程可拥有的最大地址空间小于主存。在这种情况下，即使进程用完其地址空间，内存也会有足够的内存运行该进程。 但是，在许多 32 位或 64 位地址的计算机中，分别有 2^32 或 2^64 字节的地址空间。如果一个进程有比计算机拥有的主存还大的地址空间，而且该进程希望使用全部的内存，那该怎么处理？在早期的计算机中是无法处理的。但是现在有了一种虚拟内存的技术，正如前面讲到过的，操作系统可以把部分地址空间装入主存，部分留在磁盘上，并且在需要时来回交换它们。 文件几乎所有操作系统都支持的另一个关键概念就是文件系统。如前所述，操作系统的一项主要功能是屏蔽磁盘和其他 I/O 设备的细节特性，给程序员提供一个良好、清晰的独立于设备的抽象文件模型。创建文件、删除文件、读文件和写文件 都需要系统调用。在文件可以读取之前，必须先在磁盘上定位和打开文件，在文件读过之后应该关闭该文件，有关的系统调用则用于完成这类操作。 为了提供保存文件的地方，大多数个人计算机操作系统都有目录(directory) 的概念，从而可以把文件分组。比如，学生可以给每个课程都创建一个目录，用于保存该学科的资源，另一个目录可以存放电子邮件，再有一个目录可以存放万维网主页。这就需要系统调用创建和删除目录、将已有文件放入目录中，从目录中删除文件等。目录项可以是文件或者目录，目录和目录之间也可以嵌套，这样就产生了文件系统 进程和文件层次都是以树状的结构组织，但这两种树状结构有不少不同之处。一般进程的树状结构层次不深（很少超过三层），而文件系统的树状结构要深一些，通常会到四层甚至五层。进程树层次结构是暂时的，通常最多存在几分钟，而目录层次则可能存在很长时间。进程和文件在权限保护方面也是有区别的。一般来说，父进程能控制和访问子进程，而在文件和目录中通常存在一种机制，使文件所有者之外的其他用户也能访问该文件。 目录层结构中的每一个文件都可以通过从目录的顶部即 根目录(Root directory) 开始的路径名(path name) 来确定。绝对路径名包含了从根目录到该文件的所有目录清单，它们之间用斜杠分隔符分开，在上面的大学院系文件系统中，文件 CS101 的路径名是 /Faculty/Prof.Brown/Courses/CS101。最开始的斜杠分隔符代表的是根目录 /，也就是文件系统的绝对路径。 出于历史原因，Windows 下面的文件系统以 \\ 来作为分隔符，但是 Linux 会以 / 作为分隔符。 在上面的系统中，每个进程会有一个 工作目录(working directory)，对于没有以斜线开头给出绝对地址的路径，将在这个工作目录下寻找。如果 /Faculty/Prof.Brown 是工作目录，那么 /Courses/CS101 与上面给定的绝对路径名表示的是同一个文件。进程可以通过使用系统调用指定新的工作目录，从而变更其工作目录。 在读写文件之前，首先需要打开文件，检查其访问权限。若权限许可，系统将返回一个小整数，称作文件描述符(file descriptor)，供后续操作使用。若禁止访问，系统则返回一个错误码。 在 UNIX 中，另一个重要的概念是 特殊文件(special file)。提供特殊文件是为了使 I/O 设备看起来像文件一般。这样，就像使用系统调用读写文件一样，I/O 设备也可以通过同样的系统调用进行读写。特殊文件有两种，一种是块儿特殊文件(block special file) 和 字符特殊文件(character special file)。块特殊文件指那些由可随机存取的块组成的设备，如磁盘等。比如打开一个块特殊文件，然后读取第4块，程序可以直接访问设备的第4块而不必考虑存放在该文件的文件系统结构。类似的，字符特殊文件用于打印机、调制解调器和其他接受或输出字符流的设备。按照惯例，特殊文件保存在 /dev 目录中。例如，/devv/lp 是打印机。 还有一种与进程和文件相关的特性是管道，管道(pipe) 是一种虚文件，他可以连接两个进程 如果 A 和 B 希望通过管道对话，他们必须提前设置管道。当进程 A 相对进程 B 发送数据时，它把数据写到管道上，相当于管道就是输出文件。这样，在 UNIX 中两个进程之间的通信就非常类似于普通文件的读写了。 保护计算机中含有大量的信息，用户希望能够对这些信息中有用而且重要的信息加以保护，这些信息包括电子邮件、商业计划等，管理这些信息的安全性完全依靠操作系统来保证。例如，文件提供授权用户访问。 比如 UNIX 操作系统，UNIX 操作系统通过对每个文件赋予一个 9 位二进制保护代码，对 UNIX 中的文件实现保护。该保护代码有三个位子段，一个用于所有者，一个用于与所有者同组（用户被系统管理员划分成组）的其他成员，一个用于其他人。每个字段中有一位用于读访问，一位用于写访问，一位用于执行访问。这些位就是著名的 rwx位。例如，保护代码rwxr-x--x 的含义是所有者可以读、写或执行该文件，其他的组成员可以读或执行（但不能写）此文件、而其他人可以执行（但不能读和写）该文件。 shell操作系统是执行系统调用的代码。编辑器、编译器、汇编程序、链接程序、使用程序以及命令解释符等，尽管非常重要，非常有用，但是它们确实不是操作系统的组成部分。下面我们着重介绍一下 UNIX 下的命令提示符，也就是 shell，shell 虽然有用，但它也不是操作系统的一部分，然而它却能很好的说明操作系统很多特性，下面我们就来探讨一下。 shell 有许多种，例如 sh、csh、ksh 以及 bash等，它们都支持下面这些功能，最早起的 shell 可以追溯到 sh 用户登录时，会同时启动一个 shell，它以终端作为标准输入和标准输出。首先显示提示符(prompt)，它可能是一个美元符号($)，提示用户 shell 正在等待接收命令，假如用户输入 1date shell 会创建一个子进程，并运行 date 做为子进程。在该子进程运行期间，shell 将等待它结束。在子进程完成时，shell 会显示提示符并等待下一行输入。 用户可以将标准输出重定向到一个文件中，例如 1date &gt; file 同样的，也可以将标准输入作为重定向 1sort &lt;file1&gt; file2 这会调用 sort 程序来接收 file1 的内容并把结果输出到 file2。 可以将一个应用程序的输出通过管道作为另一个程序的输入，因此有 1cat file1 file2 file3 | sort &gt; /dev/lp 这会调用 cat 应用程序来合并三个文件，将其结果输送到 sort 程序中并按照字典进行排序。sort 应用程序又被重定向到 /dev/lp ，显然这是一个打印操作。 系统调用我们已经可以看到操作系统提供了两种功能：为用户提供应用程序抽象和管理计算机资源。对于大部分在应用程序和操作系统之间的交互主要是应用程序的抽象，例如创建、写入、读取和删除文件。计算机的资源管理对用户来说基本上是透明的。因此，用户程序和操作系统之间的接口主要是处理抽象。为了真正理解操作系统的行为，我们必须仔细的分析这个接口。 多数现代操作系统都有功能相同但是细节不同的系统调用，引发操作系统的调用依赖于计算机自身的机制，而且必须用汇编代码表达。任何单 CPU 计算机一次执行执行一条指令。如果一个进程在用户态下运行用户程序，例如从文件中读取数据。那么如果想要把控制权交给操作系统控制，那么必须执行一个异常指令或者系统调用指令。操作系统紧接着需要参数检查找出所需要的调用进程。操作系统紧接着进行参数检查找出所需要的调用进程。然后执行系统调用，把控制权移交给系统调用下面的指令。大致来说，系统调用就像是执行了一个特殊的过程调用，但是只有系统调用能够进入内核态而过程调用则不能进入内核态。 为了能够了解具体的调用过程，下面我们以 read 方法为例来看一下调用过程。像上面提到的那样，会有三个参数，第一个参数是指定文件、第二个是指向缓冲区、第三个参数是给定需要读取的字节数。就像几乎所有系统调用一样，它通过使用与系统调用相同的名称来调用一个函数库，从而从C程序中调用：read。 1count = read(fd,buffer,nbytes); 系统调用在 count 中返回实际读出的字节数。这个值通常与 nbytes 相同，但也可能更小。比如在读过程中遇到了文件尾的情况。 如果系统调用不能执行，不管是因为无效的参数还是磁盘错误，count 的值都会被置成 -1，然后在全局变量 errno 中放入错误信号。程序应该进场检查系统调用的结果以了解是否出错。 系统调用是通过一系列的步骤实现的，为了更清楚的说明这个概念，我们还以 read 调用为例，在准备系统调用前，首先会把参数压入堆栈，如下所示 C 和 C++ 编译器使用逆序（必须把第一个参数赋值给 printf(格式字符串)，放在堆栈的顶部）。第一个参数和第三个参数都是值调用，但是第二个参数通过引用传递，即传递的是缓冲区的地址（由 &amp; 指示），而不是缓冲的内容。然后是 C 调用系统库的 read 函数，这也是第四步。 在由汇编语言写成的库过程中，一般把系统调用的编号放在操作系统所期望的地方，如寄存器（第五步）。然后执行一个 TRAP 指令，将用户态切换到内核态，并在内核中的一个固定地址开始执行第六步。TRAP 指令实际上与过程调用指令非常相似，它们后面都跟随一个来自远处位置的指令，以及供以后使用的一个保存在栈中的返回地址。 TRAP 指令与过程调用指令存在两个方面的不同 TRAP 指令会改变操作系统的状态，由用户态切换到内核态，而过程调用不改变模式 其次，TRAP 指令不能跳转到任意地址上。根据机器的体系结构，要么跳转到一个单固定地址上，或者指令中有一 8 位长的字段，它给定了内存中一张表格的索引，这张表格中含有跳转地址，然后跳转到指定地址上。 跟随在 TRAP 指令后的内核代码开始检查系统调用编号，然后dispatch给正确的系统调用处理器，这通常是通过一张由系统调用编号所引用的、指向系统调用处理器的指针表来完成第七步。此时，系统调用处理器运行第八步，一旦系统调用处理器完成工作，控制权会根据 TRAP 指令后面的指令中返回给函数调用库第九步。这个过程接着以通常的过程调用返回的方式，返回到客户应用程序，这是第十步。然后调用完成后，操作系统还必须清除用户堆栈，然后增加堆栈指针(increment stackpointer)，用来清除调用 read 之前压入的参数。从而完成整个 read 调用过程。 在上面的第九步中我们说道，控制可能返回 TRAP 指令后面的指令，把控制权再移交给调用者这个过程中，系统调用会发生阻塞，从而避免应用程序继续执行。这么做是有原因的。例如，如果试图读键盘，此时并没有任何输入，那么调用者就必须被阻塞。在这种情形下，操作系统会检查是否有其他可以运行的进程。这样，当有用户输入 时候，进程会提醒操作系统，然后返回第 9 步继续运行。 下面，我们会列出一些常用的 POSIX 系统调用，POSIX 系统调用大概有 100 多个，它们之中最重要的一些调用见下表 进程管理 调用 说明 pid = fork() 创建与父进程相同的子进程 pid = waitpid(pid, &amp;statloc,options) 等待一个子进程终止 s = execve(name,argv,environp) 替换一个进程的核心映像 exit(status) 终止进程执行并返回状态 文件管理 调用 说明 fd = open(file, how,…) 打开一个文件使用读、写 s = close(fd) 关闭一个打开的文件 n = read(fd,buffer,nbytes) 把数据从一个文件读到缓冲区中 n = write(fd,buffer,nbytes) 把数据从缓冲区写到一个文件中 position = iseek(fd,offset,whence) 移动文件指针 s = stat(name,&amp;buf) 取得文件状态信息 目录和文件系统管理 调用 说明 s = mkdir(nname,mode) 创建一个新目录 s = rmdir(name) 删去一个空目录 s = link(name1,name2) 创建一个新目录项 name2,并指向 name1 s = unlink(name) 删去一个目录项 s = mount(special,name,flag) 安装一个文件系统 s = umount(special) 卸载一个文件系统 其他 调用 说明 s = chdir(dirname) 改变工作目录 s = chmod(name,mode) 修改一个文件的保护位 s = kill(pid, signal) 发送信号给进程 seconds = time(&amp;seconds) 获取从 1970 年1月1日至今的时间 上面的系统调用参数中有一些公共部分，例如 pid 系统进程 id，fd 是文件描述符，n 是字节数，position 是在文件中的偏移量、seconds 是流逝时间。 从宏观角度上看，这些系统调所提供的服务确定了多数操作系统应该具有的功能，下面分别来对不同的系统调用进行解释 用于进程管理的系统调用在 UNIX 中，fork 是唯一可以在 POSIX 中创建进程的途径，它创建一个原有进程的副本，包括所有的文件描述符、寄存器等内容。在 fork 之后，原有进程以及副本（父与子）就分开了。在 fork 过程中，所有的变量都有相同的值，虽然父进程的数据通过复制给子进程，但是后续对其中任何一个进程的修改不会影响到另外一个。fork 调用会返回一个值，在子进程中该值为 0 ，并且在父进程中等于子进程的 进程标识符(Process IDentified,PID)。使用返回的 PID，就可以看出来哪个是父进程和子进程。 在多数情况下， 在 fork 之后，子进程需要执行和父进程不一样的代码。从终端读取命令，创建一个子进程，等待子进程执行命令，当子进程结束后再读取下一个输入的指令。为了等待子进程完成，父进程需要执行 waitpid 系统调用，父进程会等待直至子进程终止（若有多个子进程的话，则直至任何一个子进程终止）。waitpid 可以等待一个特定的子进程，或者通过将第一个参数设为 -1 的方式，等待任何一个比较老的子进程。当 waitpid 完成后，会将第二个参数 statloc 所指向的地址设置为子进程的退出状态（正常或异常终止以及退出值）。有各种可使用的选项，它们由第三个参数确定。例如，如果没有已经退出的子进程则立刻返回。 那么 shell 该如何使用 fork 呢？在键入一条命令后，shell 会调用 fork 命令创建一个新的进程。这个子进程会执行用户的指令。通过使用 execve系统调用可以实现系统执行，这个系统调用会引起整个核心映像被一个文件所替代，该文件由第一个参数给定。下面是一个简化版的例子说明 fork、waitpid 和 execve 的使用 12345678910111213#define TRUE 1while(TRUE)&#123; /* 一直循环下去 */ type_prompt(); /* 在屏幕上显示提示符 */ read_command(command,parameters) /* 从终端读取输入 */ if(fork() != 0)&#123; /* fork 子进程 */ /* 父代码 */ waitpid(-1, &amp;status, 0); /* 等待子进程执行完毕 */ &#125;else&#123; /* 子代码 */ execve(command,parameters,0) /* 执行命令 */ &#125;&#125; 一般情况下，execve 有三个参数：将要执行的文件名称，一个指向变量数组的指针，以及一个指向环境数组的指针。这里对这些参数做一个简要的说明。 先看一个 shell 指令 1cp file1 file2 此命令把 file1 复制到 file2 文件中，在 shell 执行 fork 之后，子进程定位并执行文件拷贝，并将源文件和目标文件的名称传递给它。 cp 的主程序（以及包含其他大多数 C 程序的主程序）包含声明 1main(argc,argv,envp) 其中 argc 是命令行中参数数目的计数，包括程序名称。对于上面的例子，argc 是3。第二个参数argv 是数组的指针。该数组的元素 i 是指向该命令行第 i 个字符串的指针。在上面的例子中，argv[0] 指向字符串 cp，argv[1] 指向字符串 file1，argv[2] 指向字符串 file2。main 的第三个参数是指向环境的指针，该环境是一个数组，含有 name = value 的赋值形式，用以将诸如终端类型以及根目录等信息传送给程序。这些变量通常用来确定用户希望如何完成特定的任务（例如，使用默认打印机）。在上面的例子中，没有环境参数传递给 execve ，所以环境变量是 0 ，所以 execve 的第三个参数为 0 。 可能你觉得 execve 过于复杂，这时候我要鼓励一下你，execve 可能是 POSIX 的全部系统调用中最复杂的一个了，其他都比较简单。作为一个简单的例子，我们再来看一下 exit ，这是进程在执行完成后应执行的系统调用。这个系统调用有一个参数，它的退出状态是 0 - 255 之间，它通过 waitpid 系统调用中的 statloc 返回给父级。 UNIX 中的进程将内存划分成三个部分：text segment,文本区，例如程序代码，data segment，数据区，例如变量，stack segment，栈区域。数据向上增长而堆栈向下增长，如下图所示 上图能说明三个部分的内存分配情况，夹在中间的是空闲区，也就是未分配的区域，堆栈在需要时自动的挤压空闲区域，不过数据段的扩展是显示地通过系统调用 brk 进行的，在数据段扩充后，该系统调用指向一个新地址。但是，这个调用不是 POSIX 标准中定义的，对于存储器的动态分配，鼓励程序员使用 malloc 函数，而 malloc 的内部实现则不是一个适合标准化的主题，因为几乎没有程序员直接使用它。 用于文件管理的系统调用许多系统调用都与文件系统有关，要读写一个文件，必须先将其打开。这个系统调用通过绝对路径名或指向工作目录的相对路径名指定要打开文件的名称，而代码 O_RDONLY、 O_WRONLY 或 O_RDWR 的含义分别是只读、只写或者两者都可以，为了创建一个新文件，使用 O_CREATE参数。然后可使用返回的文件描述符进行读写操作。接着，可以使用 close 关闭文件，这个调用使得文件描述符在后续的 open 中被再次使用。 最常用的调用还是 read 和 write，我们再前面探讨过 read 调用，write 具有与 read 相同的参数。 尽管多数程序频繁的读写文件，但是仍有一些应用程序需要能够随机访问一个文件的任意部分。与每个文件相关的是一个指向文件当前位置的指针。在顺序读写时，该指针通常指向要读出（写入）的下一个字节。Iseek 调用可以改变该位置指针的值，这样后续的 read 或 write 调用就可以在文件的任何地方开始。 Iseek 有三个参数，position = iseek(fd,offset,whence)，第一个是文件描述符，第二个是文件位置，第三个是说明该文件位置是相对于文件起始位置，当前位置还是文件的结尾。在修改了指针之后，Iseek 所返回的值是文件中的绝对位置。 UNIX 为每个文件保存了该文件的类型（普通文件、特殊文件、目录等）、大小，最后修改时间以及其他信息，程序可以通过 stat 系统调用查看这些信息。s = stat(name,&amp;buf)，第一个参数指定了被检查的文件；第二个参数是一个指针，该指针指向存放这些信息的结构。对于一个打开的文件而言，fstat 调用完成同样的工作。 用于目录管理的系统调用下面我们探讨目录和整个文件系统的系统调用，上面探讨的是和某个文件有关的系统调用。mkdir 和 rmdir 分别用于创建s = mkdir(nname,mode)和删除 s = rmdir(name) 空目录，下一个调用是 s = link(name1,name2) 它的作用是允许同一个文件以两个或者多个名称出现，多数情况下是在不同的目录中使用 link ，下面我们探讨一下 link 是如何工作的 图中有两个用户 ast 和 jim，每个用户都有他自己的一个目录和一些文件，如果 ast 要执行一个包含下面系统调用的应用程序 1link(\"/usr/jim/memo\", \"/usr/ast/note\"); jim 中的 memo 文件现在会进入到 ast 的目录中，在 note 名称下。此后，/usr/jim/memo和 /usr/ast/note 会有相同的名称。 用户目录是保存在 /usr，/user，/home 还是其他位置，都是由本地系统管理员决定的。 要理解 link 是如何工作的需要清楚 link 做了什么操作。UNIX 中的每个文件都有一个独一无二的版本，也称作 i - number，i-编号，它标示着不同文件的版本。这个 i - 编号是 i-nodes,i-节点 表的索引。每个文件都会表明谁拥有这个文件，这个磁盘块的位置在哪，等等。目录只是一个包含一组（i编号，ASCII名称）对应的文件。UNIX 中的第一个版本中，每个目录项都会有 16 个字节，2 个字节对应 i - 编号和 14 个字节对应其名称。现在需要一个更复杂的结构需要支持长文件名，但是从概念上讲一个目录仍是一系列（i-编号，ASCII 名称）的集合。在上图中，mail 的 i-编号为 16，依此类推。link 只是利用某个已有文件的 i-编号，创建一个新目录项（也许用一个新名称）。在上图 b 中，你会发现有两个相同的 70 i-编号的文件，因此它们需要有相同的文件。如果其中一个使用了 unlink 系统调用的话，其中一个会被移除，另一个将保留。如果两个文件都移除了，则 UNIX 会发现该文件不存在任何没有目录项（i-节点中的一个域记录着指向该文件的目录项），就会把该文件从磁盘中移除。 就像我们上面提到过的那样，mount 系统 s = mount(special,name,flag)调用会将两个文件系统合并为一个。通常的情况是将根文件系统分布在硬盘（子）分区上，并将用户文件分布在另一个（子）分区上，该根文件系统包含常用命令的二进制（可执行）版本和其他使用频繁的文件。然后，用户就会插入可读取的 USB 硬盘。 通过执行 mount 系统调用，USB 文件系统可以被添加到根文件系统中， 图 a 是安装前的系统文件，图 b 是安装后的系统文件。 如果用 C 语言来执行那就是 1mount(\"/dev/sdb0\",\"/mnt\",0) 这里，第一个参数是 USB 驱动器 0 的块特殊文件名称，第二个参数是被安装在树中的位置，第三个参数说明将要安装的文件系统是可读写的还是只读的。 当不再需要一个文件系统时，可以使用 umount 移除之。 其他系统调用除了进程、文件、目录系统调用，也存在其他系统调用的情况，下面我们来探讨一下。我们可以看到上面其他系统调用只有四种，首先来看第一个 chdir，chdir 调用更改当前工作目录，在调用 1chdir(\"/usr/ast/test\"); 后，打开 xyz 文件，会打开 /usr/ast/test/xyz 文件，工作目录的概念消除了总是需要输入长文件名的需要。 在 UNIX 系统中，每个文件都会有保护模式，这个模式会有一个读-写-执行位，它用来区分所有者、组和其他成员。chmod 系统调用提供改变文件模式的操作。例如，要使一个文件除了对所有者之外的用户可读，你可以执行 1chmod(\"file\",0644); kill 系统调用是用户和用户进程发送信号的方式，如果一个进程准备好捕捉一个特定的信号，那么在信号捕捉之前，会运行一个信号处理程序。如果进程没有准备好捕捉特定的信号，那么信号的到来会杀掉该进程（此名字的由来）。 POSIX 定义了若干时间处理的进程。例如，time 以秒为单位返回当前时间，0 对应着 1970 年 1月 1日。在一台 32 位字的计算机中，time 的最大值是 (2^32) - 1秒，这个数字对应 136 年多一点。所以在 2106 年，32 位的 UNIX 系统会发飙。如果读者现在有 32 位 UNIX 系统，建议在 2106 年更换位 64 位操作系统（偷笑～）。 Win 32 API上面我们提到的都是 UNIX 系统调用，现在我们来聊聊 Win 32 中的系统调用。Windows 和 UNIX 在各自的编程方式上有着根本的不同。UNIX 程序由执行某些操作或执行其他操作的代码组成，进行系统调用以执行某些服务。Windows 系统则不同，Windows 应用程序通常是由事件驱动的。主程序会等待一些事件发生，然后调用程序去处理。最简单的事件处理是键盘敲击和鼠标滑过，或者是鼠标点击，或者是插入 USB 驱动，然后操作系统调用处理器去处理事件，更新屏幕和更新程序内部状态。这是与 UNIX 不同的设计风格。 当然，Windows 也有系统调用。在 UNIX 中，系统调用（比如 read）和系统调用所使用的调用库（例如 read）几乎是一对一的关系。而在 Windows 中，情况则大不相同。首先，函数库的调用和实际的系统调用几乎是不对应的。微软定义了一系列过程，称为 Win32应用编程接口(Application Programming Interface)，程序员通过这套标准的接口来实现系统调用。这个接口支持从 Windows 95 版本以来所有的 Windows 版本。 Win32 API 调用的数量是非常巨大的，有数千个多。但这些调用并不都是在内核态的模式下运行时，有一些是在用户态的模型下运行。Win32 API 有大量的调用，用来管理视窗、几何图形、文本、字体、滚动条、对话框、菜单以及 GUI 的其他功能。为了使图形子系统在内核态下运行，需要系统调用，否则就只有函数库调用。 我们把关注点放在和 Win32 系统调用中来，我们可以简单看一下 Win32 API 中的系统调用和 UNIX 中有什么不同（并不是所有的系统调用） UNIX Win32 说明 fork CreateProcess 创建一个新进程 waitpid WaitForSingleObject 等待一个进程退出 execve none CraeteProcess = fork + servvice exit ExitProcess 终止执行 open CreateFile 创建一个文件或打开一个已有的文件 close CloseHandle 关闭文件 read ReadFile 从单个文件中读取数据 write WriteFile 向单个文件写数据 lseek SetFilePointer 移动文件指针 stat GetFileAttributesEx 获得不同的文件属性 mkdir CreateDirectory 创建一个新的目录 rmdir RemoveDirectory 移除一个空的目录 link none Win32 不支持 link unlink DeleteFile 销毁一个已有的文件 mount none Win32 不支持 mount umount none Win32 不支持 mount，所以也不支持mount chdir SetCurrentDirectory 切换当前工作目录 chmod none Win32 不支持安全 kill none Win32 不支持信号 time GetLocalTime 获取当前时间 上表中是 UNIX 调用大致对应的 Win32 API 系统调用，简述一下上表。CreateProcess 用于创建一个新进程，它把 UNIX 中的 fork 和 execve 两个指令合成一个，一起执行。它有许多参数用来指定新创建进程的性质。Windows 中没有类似 UNIX 中的进程层次，所以不存在父进程和子进程的概念。在进程创建之后，创建者和被创建者是平等的。WaitForSingleObject 用于等待一个事件，等待的事件可以是多种可能的事件。如果有参数指定了某个进程，那么调用者将等待指定的进程退出，这通过 ExitProcess 来完成。 然后是6个文件操作，在功能上和 UNIX 的调用类似，然而在参数和细节上是不同的。和 UNIX 中一样，文件可以打开，读取，写入，关闭。SetFilePointer 和 GetFileAttributesEx 设置文件的位置并取得文件的属性。 Windows 中有目录，目录分别用 CreateDirectory 以及 RemoveDirectoryAPI 调用创建和删除。也有对当前的目录的标记，这可以通过 SetCurrentDirectory 来设置。使用GetLocalTime 可获得当前时间。 Win32 接口中没有文件的链接、文件系统的 mount、umount 和 stat ，当然， Win32 中也有大量 UNIX 中没有的系统调用，特别是对 GUI 的管理和调用。 操作系统结构下面我们会探讨操作系统的几种结构，主要包括单体结构、分层系统、微内核、客户-服务端系统、虚拟机和外核等。下面以此来探讨一下 单体系统到目前为止，在大多数系统中，整个系统在内核态以单一程序的方式运行。整个操作系统是以程序集合来编写的，链接在一块形成一个大的二进制可执行程序。使用此技术时，如果系统中的每个过程都提供了前者所需的一些有用的计算，则它可以自由调用任何其他过程。在单体系统中，调用任何一个所需要的程序都非常高效，但是上千个不受限制的彼此调用往往非常臃肿和笨拙，而且单体系统必然存在单体问题，那就是只要系统发生故障，那么任何系统和应用程序将不可用，这往往是灾难性的。 在单体系统中构造实际目标程序时，会首先编译所有单个过程（或包含这些过程的文件），然后使用系统链接器将它们全部绑定到一个可执行文件中 对于单体系统，往往有下面几种建议 需要有一个主程序，用来调用请求服务程序 需要一套服务过程，用来执行系统调用 需要一套服务程序，用来辅助服务过程调用 在单体系统中，对于每个系统调用都会有一个服务程序来保障和运行。需要一组实用程序来弥补服务程序需要的功能，例如从用户程序中获取数据。可将各种过程划分为一个三层模型 除了在计算机初启动时所装载的核心操作系统外，许多操作系统还支持额外的扩展。比如 I/O 设备驱动和文件系统。这些部件可以按需装载。在 UNIX 中把它们叫做 共享库(shared library)，在 Windows 中则被称为 动态链接库(Dynamic Link Library,DLL)。他们的扩展名为 .dll，在 C:\\Windows\\system32 目录下存在 1000 多个 DLL 文件，所以不要轻易删除 C 盘文件，否则可能就炸了哦。 分层系统分层系统使用层来分隔不同的功能单元。每一层只与该层的上层和下层通信。每一层都使用下面的层来执行其功能。层之间的通信通过预定义的固定接口通信。 分层系统是由 E.W.Dijkstar 和他的学生在荷兰技术学院所开发的 THE 系统。 把上面单体系统进一步通用化，就变为了一个层次式结构的操作系统，它的上层软件都是在下层软件的基础之上构建的。该系统分为六层，如下所示 层号 功能 5 操作员 4 用户程序 3 输入/输出管理 2 操作员-进程通信 1 存储器和磁鼓管理 0 处理器分配和多道程序编程 处理器在 0 层运行，当中断发生或定时器到期时，由该层完成进程切换；在第 0 层之上，系统由一些连续的进程组成，编写这些进程时不用再考虑在单处理器上多进程运行的细节。内存管理在第 1 层，它分配进程的主存空间。第 1 层软件保证一旦需要访问某一页面，该页面必定已经在内存中，并且在页面不需要的时候将其移出。 第 2 层处理进程与操作员控制台（即用户）之间的通信。第 3 层管理 I/O 设备和相关的信息流缓冲区。第 4 层是用户程序层，用户程序不用考虑进程、内存、控制台或 I/O 设备管理等细节。系统操作员在第 5 层。 微内核在分层方式中，设计者要确定在哪里划分 内核-用户 的边界。传统上，所有的层都在内核中，但是这样做没有必要。事实上，尽可能减少内核态中功能可能是更好的做法。因为内核中的错误很难处理，一旦内核态中出错误会拖累整个系统。 所以，为了实现高可靠性，将操作系统划分成小的、层级之间能够更好定义的模块是很有必要的，只有一个模块 — 微内核 — 运行在内核态，其余模块可以作为普通用户进程运行。由于把每个设备驱动和文件系统分别作为普通用户进程，这些模块中的错误虽然会使这些模块崩溃，但是不会使整个系统死机。 MINIX 3 是微内核的代表作，它的具体结构如下 在内核的外部，系统的构造有三层，它们都在用户态下运行，最底层是设备驱动器。由于它们都在用户态下运行，所以不能物理的访问 I/O 端口空间，也不能直接发出 I/O 命令。相反，为了能够对 I/O 设备编程，驱动器构建一个结构，指明哪个参数值写到哪个 I/O 端口，并声称一个内核调用，这样就完成了一次调用过程。 位于用户态的驱动程序上面是服务器层，包含有服务器，它们完成操作系统的多数工作。由一个或多个文件服务器管理着文件系统，进程管理器创建、销毁和管理进程。服务器中有一个特殊的服务器称为 再生服务器(reincarnation server)，它的任务就是检查服务器和驱动程序的功能是否正确，一旦检查出来错误，它就会补上去，无需用户干预。这种方式使得系统具有可恢复性，并具有较高的可靠性。 微内核中的内核还具有一种 机制 与 策略 分离的思想。比如系统调度，一个比较简单的调度算法是，对每个进程赋予一个优先级，并让内核执行具有最高优先级的进程。这里，内核机制就是寻找最高的优先级进程并运行。而策略（赋予进程优先级）可以在用户态中的进程完成。在这种模式中，策略和机制是分离的，从而使内核变得更小。 客户-服务器模式微内核思想的策略是把进程划分为两类：服务器，每个服务器用来提供服务；客户端，使用这些服务。这个模式就是所谓的 客户-服务器模式。 客户-服务器模式会有两种载体，一种情况是一台计算机既是客户又是服务器，在这种方式下，操作系统会有某种优化；但是普遍情况下是客户端和服务器在不同的机器上，它们通过局域网或广域网连接。 客户通过发送消息与服务器通信，客户端并不需要知道这些消息是在本地机器上处理，还是通过网络被送到远程机器上处理。对于客户端而言，这两种情形是一样的：都是发送请求并得到回应。 越来越多的系统，包括家里的 PC，都成为客户端，而在某地运行的大型机器则成为服务器。许多 web 就是以这种方式运行的。一台 PC 向某个服务器请求一个 Web 页面，服务器把 Web 页面返回给客户端，这就是典型的客服-服务器模式 文章参考 《现代操作系统》 《Modern Operating System》forth edition http://faculty.cs.niu.edu/~hutchins/csci360/hchnotes/psw.htm https://www.computerhope.com/jargon/c/clockcyc.htm 转载自这些操作系统的概念，保你没听过！ 作者：cxuann","categories":[{"name":"架构","slug":"架构","permalink":"https://vincentruan.github.io/categories/架构/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://vincentruan.github.io/tags/操作系统/"}]},{"title":"14个Java并发容器","slug":"14个Java并发容器","date":"2020-02-11T09:00:26.000Z","updated":"2020-02-17T02:40:44.573Z","comments":true,"path":"2020/02/11/14个Java并发容器/","link":"","permalink":"https://vincentruan.github.io/2020/02/11/14个Java并发容器/","excerpt":"","text":"并发容器介绍 ConcurrentHashMap：并发版HashMap CopyOnWriteArrayList：并发版ArrayList CopyOnWriteArraySet：并发Set ConcurrentLinkedQueue：并发队列(基于链表) ConcurrentLinkedDeque：并发队列(基于双向链表) ConcurrentSkipListMap：基于跳表的并发Map ConcurrentSkipListSet：基于跳表的并发Set ArrayBlockingQueue：阻塞队列(基于数组) LinkedBlockingQueue：阻塞队列(基于链表) LinkedBlockingDeque：阻塞队列(基于双向链表) PriorityBlockingQueue：线程安全的优先队列 SynchronousQueue：读写成对的队列 LinkedTransferQueue：基于链表的数据交换队列 DelayQueue：延时队列 1.ConcurrentHashMap 并发版HashMap最常见的并发容器之一，可以用作并发场景下的缓存。底层依然是哈希表，但在JAVA 8中有了不小的改变，而JAVA 7和JAVA 8都是用的比较多的版本，因此经常会将这两个版本的实现方式做一些比较（比如面试中） 一个比较大的差异就是，JAVA 7中采用分段锁来减少锁的竞争，JAVA 8中放弃了分段锁，采用CAS，同时为了防止哈希冲突严重时退化成链表（冲突时会在该位置生成一个链表，哈希值相同的对象就链在一起），会在链表长度达到阈值（8）后转换成红黑树（比起链表，树的查询效率更稳定）。 2.CopyOnWriteArrayList 并发版ArrayList并发版ArrayList，底层结构也是数组，和ArrayList不同之处在于：当新增和删除元素时会创建一个新的数组，在新的数组中增加或者排除指定对象，最后用新增数组替换原来的数组。 适用场景：由于读操作不加锁，写（增、删、改）操作加锁，因此适用于读多写少的场景。 局限：由于读的时候不会加锁（读的效率高，就和普通ArrayList一样），读取的当前副本，因此可能读取到脏数据。如果介意，建议不用。 看看源码感受下： 123456789101112131415161718192021222324public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; final transient ReentrantLock lock = new ReentrantLock(); private transient volatile Object[] array; // 添加元素，有锁 public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); // 修改时加锁，保证并发安全 try &#123; Object[] elements = getArray(); // 当前数组 int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); // 创建一个新数组，比老的大一个空间 newElements[len] = e; // 要添加的元素放进新数组 setArray(newElements); // 用新数组替换原来的数组 return true; &#125; finally &#123; lock.unlock(); // 解锁 &#125; &#125; // 读元素，不加锁，因此可能读取到旧数据 public E get(int index) &#123; return get(getArray(), index); &#125;&#125; 3.CopyOnWriteArraySet 并发Set基于CopyOnWriteArrayList实现（内含一个CopyOnWriteArrayList成员变量），也就是说底层是一个数组，意味着每次add都要遍历整个集合才能知道是否存在，不存在时需要插入（加锁）。 适用场景：在CopyOnWriteArrayList适用场景下加一个，集合别太大（全部遍历伤不起）。 4.ConcurrentLinkedQueue 并发队列(基于链表)基于链表实现的并发队列，使用乐观锁(CAS)保证线程安全。因为数据结构是链表，所以理论上是没有队列大小限制的，也就是说添加数据一定能成功。 5.ConcurrentLinkedDeque 并发队列(基于双向链表)基于双向链表实现的并发队列，可以分别对头尾进行操作，因此除了先进先出(FIFO)，也可以先进后出（FILO），当然先进后出的话应该叫它栈了。 6.ConcurrentSkipListMap 基于跳表的并发MapSkipList即跳表，跳表是一种空间换时间的数据结构，通过冗余数据，将链表一层一层索引，达到类似二分查找的效果 7.ConcurrentSkipListSet 基于跳表的并发Set类似HashSet和HashMap的关系，ConcurrentSkipListSet里面就是一个ConcurrentSkipListMap，就不细说了。 8.ArrayBlockingQueue 阻塞队列(基于数组)基于数组实现的可阻塞队列，构造时必须制定数组大小，往里面放东西时如果数组满了便会阻塞直到有位置（也支持直接返回和超时等待），通过一个锁ReentrantLock保证线程安全。 用offer操作举个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; /** * 读写共用此锁，线程间通过下面两个Condition通信 * 这两个Condition和lock有紧密联系（就是lock的方法生成的） * 类似Object的wait/notify */ final ReentrantLock lock; /** 队列不为空的信号，取数据的线程需要关注 */ private final Condition notEmpty; /** 队列没满的信号，写数据的线程需要关注 */ private final Condition notFull; // 一直阻塞直到有东西可以拿出来 public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) notEmpty.await(); return dequeue(); &#125; finally &#123; lock.unlock(); &#125; &#125; // 在尾部插入一个元素，队列已满时等待指定时间，如果还是不能插入则返回 public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; checkNotNull(e); long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); // 锁住 try &#123; // 循环等待直到队列有空闲 while (count == items.length) &#123; if (nanos &lt;= 0) return false;// 等待超时，返回 // 暂时放出锁，等待一段时间（可能被提前唤醒并抢到锁，所以需要循环判断条件） // 这段时间可能其他线程取走了元素，这样就有机会插入了 nanos = notFull.awaitNanos(nanos); &#125; enqueue(e);//插入一个元素 return true; &#125; finally &#123; lock.unlock(); //解锁 &#125; &#125;&#125; 乍一看会有点疑惑，读和写都是同一个锁，那要是空的时候正好一个读线程来了不会一直阻塞吗？ 答案就在notEmpty、notFull里，这两个出自lock的小东西让锁有了类似synchronized + wait + notify的功能。 9.LinkedBlockingQueue 阻塞队列(基于链表)基于链表实现的阻塞队列，想比与不阻塞的ConcurrentLinkedQueue，它多了一个容量限制，如果不设置默认为int最大值。 10.LinkedBlockingDeque 阻塞队列(基于双向链表)类似LinkedBlockingQueue，但提供了双向链表特有的操作。 11.PriorityBlockingQueue 线程安全的优先队列构造时可以传入一个比较器，可以看做放进去的元素会被排序，然后读取的时候按顺序消费。某些低优先级的元素可能长期无法被消费，因为不断有更高优先级的元素进来。 12.SynchronousQueue 数据同步交换的队列一个虚假的队列，因为它实际上没有真正用于存储元素的空间，每个插入操作都必须有对应的取出操作，没取出时无法继续放入。 一个简单的例子感受一下： 1234567891011121314151617181920212223242526272829303132333435363738import java.util.concurrent.*;public class Main &#123; public static void main(String[] args) &#123; SynchronousQueue&lt;Integer&gt; queue = new SynchronousQueue&lt;&gt;(); new Thread(() -&gt; &#123; try &#123; // 没有休息，疯狂写入 for (int i = 0; ; i++) &#123; System.out.println(\"放入: \" + i); queue.put(i); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); new Thread(() -&gt; &#123; try &#123; // 咸鱼模式取数据 while (true) &#123; System.out.println(\"取出: \" + queue.take()); Thread.sleep((long) (Math.random() * 2000)); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125;/* 输出:放入: 0取出: 0放入: 1取出: 1放入: 2取出: 2放入: 3取出: 3*/ 可以看到，写入的线程没有任何sleep，可以说是全力往队列放东西，而读取的线程又很不积极，读一个又sleep一会。输出的结果却是读写操作成对出现。 JAVA中一个使用场景就是Executors.newCachedThreadPool()，创建一个缓存线程池。 1234567public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor( 0, // 核心线程为0，没用的线程都被无情抛弃 Integer.MAX_VALUE, // 最大线程数理论上是无限了，还没到这个值机器资源就被掏空了 60L, TimeUnit.SECONDS, // 闲置线程60秒后销毁 new SynchronousQueue&lt;Runnable&gt;()); // offer时如果没有空闲线程取出任务，则会失败，线程池就会新建一个线程&#125; 13.LinkedTransferQueue 基于链表的数据交换队列实现了接口TransferQueue，通过transfer方法放入元素时，如果发现有线程在阻塞在取元素，会直接把这个元素给等待线程。如果没有人等着消费，那么会把这个元素放到队列尾部，并且此方法阻塞直到有人读取这个元素。和SynchronousQueue有点像，但比它更强大。 14.DelayQueue 延时队列可以使放入队列的元素在指定的延时后才被消费者取出，元素需要实现Delayed接口。 总结上面简单介绍了JAVA并发包下的一些容器类，知道有这些东西，遇到合适的场景时就能想起有个现成的东西可以用了。想要知其所以然，后续还得再深入探索一番。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://vincentruan.github.io/tags/JAVA/"},{"name":"并发","slug":"并发","permalink":"https://vincentruan.github.io/tags/并发/"}]},{"title":"Java8开发的4个小技巧","slug":"Java8开发的4个小技巧","date":"2020-02-11T08:48:32.000Z","updated":"2020-02-28T08:38:44.166Z","comments":true,"path":"2020/02/11/Java8开发的4个小技巧/","link":"","permalink":"https://vincentruan.github.io/2020/02/11/Java8开发的4个小技巧/","excerpt":"OptionalOptional是一个评价过低的特性，它可以显著的降低代码抛出NullPointerException的可能。它在边界代码(你正在使用的API或者你发布的API)中特别有用。 但是对于它的不适当的使用和设计很容易使一个小的变动影响到很多的类，或者降低代码的可阅读性。这里有一些如何更加高效使用Optional的建议。","text":"OptionalOptional是一个评价过低的特性，它可以显著的降低代码抛出NullPointerException的可能。它在边界代码(你正在使用的API或者你发布的API)中特别有用。 但是对于它的不适当的使用和设计很容易使一个小的变动影响到很多的类，或者降低代码的可阅读性。这里有一些如何更加高效使用Optional的建议。 Optional应该仅仅用在返回类型中不要用在参数或者域中。阅读这篇博文可以看到如何正确使用Optional进行编码。幸运的是，IntelliJ IDEA可以打开inspections去检查你是否遵循了这些推荐规范。 要尽早在Optional出现的地方对它进行处理。IntelliJ IDEA会阻止Optional出现在你代码的各个地方，所以记住一定要在Optional出现的地方就对他进行处理。 不能简单地调用get()方法Optional是用来表示这个值是有可能为空的，让你做好应对的准备。因此，很重要的一点就是在使用这个值之前务必要检查其是否存在。简单地调用get方法而不是先调用isPresent可能会导致产生空指针异常。幸运的是，IntelliJ IDEA再一次提供了对此种方案的检查。 更加优雅的方案如下代码，isPresent和get当然能够解决这个问题。 但是这里有更加优雅的方式，你可以使用orElse来设置一个默认值。 或者你可以使用orElseGet来设置当值为null的时候去调用的方法。虽然看着和前面的方案没有什么大的不同。但是提供的方法应该仅仅在需要调用的时候才被调用。那么当这是个代价昂贵的方法时，那么使用lambda会带来更好的性能提升。 使用Lambda表达式Lambda表达式是Java8最主要的卖点。即使你现在用不到Java8，你也应该对它有了一些基本的了解。下面讲述了一种新的方式使用Java编程，虽然这并不是一个“最佳实践”，仅仅是一个使用的指导。 保持简短函数式编程对于长的lambda表达式是欢迎的，但是对于仅仅使用Java开发很多年的人发现编写短的lambda表达式会更容易一些。你甚至会想把表达式缩减到一行，也很容易把长的表达式重构成一个方法。 当然，这些甚至牵扯到了方法引用(Method References)。方法引用可能看着有点陌生，但是由于其能让代码达到更好的阅读性，还是有很大应用价值的。后面，我会讲到这个概念。 显式声明在lambda表达式中是没有类型信息的，所以你会发现在参数中包含类型信息是非常有用的。 如你所见，这会变得很笨重。所以我更喜欢赋予参数有意义的名字。当然，无论你是否这么做，Intellij IDEA都会让你可以看到参数的类型信息。 甚至lambda表示的函数接口也能看到。 设计Lambda表达式我认为lambda表达式有一点类似于泛型-我们会经常使用到泛型(例如，添加类型信息到List&lt;&gt;)，但是比较罕见的是我们去设计一个具有泛型的方法或者一个类(比如像Person)。同样的，我们经常会在使用诸如Streams API的时候传递lambda，但是却很少会创建一个需要传递lambda参数的方法。 如果你发现自己处在这样一种境况，那么这里有一些提示。 IntelliJ IDEA能够帮助你引入函数参数能够让你创建一个参数，这个参数是一个lambda而不是一个Object。这个特性的最好的一点就是它会智能建议一个匹配规格的已存在的函数接口。 使用存在的函数接口随着开发者变得对Java8越来越熟悉，当使用Supplier和Consumer这些接口时，我们将会知道什么是我们所期望的，比如创建一个ErrorMessageCreator(例子)会是令人迷惑和浪费的。可以看一下函数包获取已经存在的那些函数接口。 给你的函数接口添加@FunctionalInterface如果你确实需要创建自己的函数接口，那么用这个注解去标记它。看起来不需要这么做，但是Intellij IDEA会在你的函数接口没有符合规范时提示你。当没有方法实现这个接口时，它会提示你。 当方法太多时，也会提示你。 当你把注解应用到一个类而不是接口时，也会发出提醒。 Lambda表达式可以被用在任何有一个Single Abstract Method的接口中，但是它不能够应用到一个抽象类中。看起来没有啥逻辑，但它就是这样的。 StreamsStream API是Java8另一个最大的卖点，我认为我们到现在还是没有真的搞清楚这会如何改变我们的代码。这里有一些我自己发现很有用的东西。 将点号对齐我个人比较喜欢对齐Stream操作。当然，你不需要非得这么做，但是我发现这样还是有很大好处的。 一眼就看到所有的操作以及他们的顺序 更容易调试(虽然Intellij IDEA提供了在一行中的lambda表达式中任意地方打断点的功能，但是将他们分隔成单独的行会更简单) 可以很容易地注释掉一些操作以供测试 很容易地插入peek()供调试或者测试 这样做也会让代码看起来很舒服。当然，如果这么做，会增加代码的行数。 你可以修改一下格式化设置使点号对齐。 使用方法引用(Method References)你可能需要一会儿才能习惯这个奇怪的语法。但是，当我们能够正确地使用，它确实能够提高程序的可阅读性。考虑下面的代码： 对比一下使用新引入的Objects类的辅助方法(helper methods)： 后面的代码能够更加明显地表明它想保存的值。IntelliJ IDEA会提示你何时一个lambda可以被替换成方法引用。 当迭代一个集合，尽可能地使用Streams API使用新的集合方法：forEach。IDEA会提示你。 使用Streams API相比起使用循环和if语句更加清晰明了。例如： IDEA会建议重构为： 我做的性能测试表示这个重构是令人惊奇的-无论性能是不变、提升还是变差，都是不能被预测的。因此，当你的应用对性能要求很苛刻的话，重构的时候务必做好测试。 当遍历数组时使用循环使用Java8并不是意味着你必须到处都使用Stream和新的集合方法。IDEA会智能提示哪些地方可以转换为Stream操作，但是并不意味着你必须这么做。 特别是当遍历一个保存基本数据类型的小数组时，使用loop循环的性能是更加好的，而且更加可阅读(至少对哪些Stream的新手来说是这样的)。 以上的建议，并非是固定不变，也不是必须要遵守的。但是无论你倾向于继续使用loops做某些操作还是在能够使用的地方使用Stream API, 你都要做出你自己的决定。 附录Lambda表达式 Lambda语法一行执行语句的写法： 1(parameters) -&gt; expression 如果有多行执行语句，可以加上 {} 1(parameters) -&gt; &#123; statements; &#125; 如： 1public int add(int x, int y) &#123; return x + y;&#125; 转换成Lambda表达式有以下几种写法： 123456// 指定参数类型及return(int x, int y) -&gt; &#123; return x + y; &#125;// 指定参数类型，不指定return(int x, int y) -&gt; x + y;// 不指定参数类型和return，编译器会自动推断(x, y) -&gt; x + y; Lambda用途1、只有一个抽象方法的函数式接口Lambda表达式的目标类型是函数式接口，什么是函数式接口之后会讲。 下面拿创建线程来举例，用lambda表达式可以有以下几种写法。 1234567891011121314151617181920public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"t1\"); &#125; &#125;).start(); Runnable runnable = () -&gt; System.out.println(\"t2\"); new Thread(runnable).start(); new Thread(() -&gt; System.out.println(\"t3\")).start(); new Thread(() -&gt; run(\"t4\")).start(); new Thread(() -&gt; &#123; String str = \"t5\"; System.out.println(str); &#125;).start();&#125;private static void run(String str) &#123; System.out.println(str);&#125; 最后输出： 1t1t2t3t4t5 2、集合批量操作下面打印list集合的两种写法是等价的。 12345List&lt;String&gt; list = Arrays.asList(\"a\",\"b\",\"c\");for(String str : list) &#123; System.out.println(str);&#125;list.forEach((e) -&gt; System.out.println(e)); 3、流操作下面是流查询list集合中等于 &quot;a&quot;的数量。 1list.stream().filter((e) -&gt; \"a\".equals(e)).count(); 原文：https://dzone.com/articles/java-8-top-tips","categories":[{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/tags/Java/"},{"name":"Lambda","slug":"Lambda","permalink":"https://vincentruan.github.io/tags/Lambda/"}]},{"title":"如何提高服务器的并发处理能力","slug":"如何提高服务器的并发处理能力","date":"2020-02-11T07:22:05.000Z","updated":"2020-02-25T15:09:15.067Z","comments":true,"path":"2020/02/11/如何提高服务器的并发处理能力/","link":"","permalink":"https://vincentruan.github.io/2020/02/11/如何提高服务器的并发处理能力/","excerpt":"以下内容为入门级介绍，意在对老技术作较全的总结而不是较深的研究。主要参考《构建高性能Web站点》一书。 什么是服务器并发处理能力一台服务器在单位时间里能处理的请求越多，服务器的能力越高，也就是服务器并发处理能力越强","text":"以下内容为入门级介绍，意在对老技术作较全的总结而不是较深的研究。主要参考《构建高性能Web站点》一书。 什么是服务器并发处理能力一台服务器在单位时间里能处理的请求越多，服务器的能力越高，也就是服务器并发处理能力越强 有什么方法衡量服务器并发处理能力1. 吞吐率吞吐率，单位时间里服务器处理的最大请求数，单位req/s 从服务器角度，实际并发用户数的可以理解为服务器当前维护的代表不同用户的文件描述符总数，也就是并发连接数。 服务器一般会限制同时服务的最多用户数，比如apache的MaxClents参数。 这里再深入一下，对于服务器来说，服务器希望支持高吞吐率，对于用户来说，用户只希望等待最少的时间，显然，双方不能满足，所以双方利益的平衡点，就是我们希望的最大并发用户数。 2. 压力测试有一个原理一定要先搞清楚，假如100个用户同时向服务器分别进行10个请求，与1个用户向服务器连续进行1000次请求，对服务器的压力是一样吗？ 实际上是不一样的，因对每一个用户，连续发送请求实际上是指发送一个请求并接收到响应数据后再发送下一个请求。 这样对于1个用户向服务器连续进行1000次请求, 任何时刻服务器的网卡接收缓冲区中只有1个请求，而对于100个用户同时向服务器分别进行10个请求，服务器的网卡接收缓冲区最多有100个等待处理的请求，显然这时的服务器压力更大。 压力测试前提考虑的条件 并发用户数: 指在某一时刻同时向服务器发送请求的用户总数(HttpWatch) 总请求数 请求资源描述 请求等待时间(用户等待时间) 用户平均请求的等待时间 服务器平均请求处理的时间 硬件环境 压力测试中关心的时间又细分以下2种: 用户平均请求等待时间（这里暂不把数据在网络的传输时间，还有用户PC本地的计算时间计算入内） 服务器平均请求处理时间 用户平均请求等待时间主要用于衡量服务器在一定并发用户数下，单个用户的服务质量；而服务器平均请求处理时间就是吞吐率的倒数。 一般来说，用户平均请求等待时间 = 服务器平均请求处理时间 * 并发用户数 怎么提高服务器的并发处理能力1. 提高CPU并发计算能力服务器之所以可以同时处理多个请求，在于操作系统通过多执行流体系设计使得多个任务可以轮流使用系统资源。 这些资源包括CPU，内存以及I/O. 这里的I/O主要指磁盘I/O, 和网络I/O。 多进程 &amp; 多线程多执行流的一般便是进程，多进程的好处可以对CPU时间的轮流使用，对CPU计算和IO操作重叠利用。这里的IO主要是指磁盘IO和网络IO，相对CPU而言，它们慢的可怜。 而实际上，大多数进程的时间主要消耗在I/O操作上。 现代计算机的DMA技术可以让CPU不参与I/O操作的全过程，比如进程通过系统调用，使得CPU向网卡或者磁盘等I/O设备发出指令，然后进程被挂起，释放出CPU资源，等待I/O设备完成工作后通过中断来通知进程重新就绪。 对于单任务而言，CPU大部分时间空闲，这时候多进程的作用尤为重要。 多进程不仅能够提高CPU的并发度。其优越性还体现在独立的内存地址空间和生命周期所带来的稳定性和健壮性，其中一个进程崩溃不会影响到另一个进程。 但是进程也有如下缺点： fork()系统调用开销很大: prefork 进程间调度和上下文切换成本: 减少进程数量 庞大的内存重复：共享内存 IPC编程相对比较麻烦 减少进程切换当硬件上下文频繁装入和移出时，所消耗的时间是非常可观的。可用Nmon工具监视服务器每秒的上下文切换次数。 为了尽量减少上下文切换次数，最简单的做法就是减少进程数，尽量使用线程并配合其它I/O模型来设计并发策略。 还可以考虑使用进程绑定CPU技术，增加CPU缓存的命中率。若进程不断在各CPU上切换，这样旧的CPU缓存就会失效。 减少使用不必要的锁服务器处理大量并发请求时，多个请求处理任务时存在一些资源抢占竞争，这时一般采用“锁”机制来控制资源的占用。到底什么是重入锁附录内容推荐大家看下。 当一个任务占用资源时，我们锁住资源，这时其它任务都在等待锁的释放，这个现象称为锁竞争。 通过锁竞争的本质，我们要意识到尽量减少并发请求对于共享资源的竞争。 比如在允许情况下关闭服务器访问日志，这可以大大减少在锁等待时的延迟时间。要最大程度减少无辜的等待时间。 这里说下无锁编程，就是由内核完成这个锁机制，主要是使用原子操作替代锁来实现对共享资源的访问保护。 使用原子操作时，在进行实际的写操作时，使用了lock指令，这样就可以阻止其他任务写这块内存，避免出现数据竞争现象。原子操作速度比锁快，一般要快一倍以上。 例如fwrite(), fopen()，其是使用append方式写文件，其原理就是使用了无锁编程，无锁编程的复杂度高，但是效率快，而且发生死锁概率低。 考虑进程优先级进程调度器会动态调整运行队列中进程的优先级，通过top观察进程的PR值 考虑系统负载可在任何时刻查看/proc/loadavg, top中的load average也可看出 考虑CPU使用率除了用户空间和内核空间的CPU使用率以外，还要关注I/O wait,它是指CPU空闲并且等待I/O操作完成的时间比例（top中查看wa的值）。 2. 考虑减少内存分配和释放服务器的工作过程中，需要大量的内存，使得内存的分配和释放工作尤为重要。 可以通过改善数据结构和算法复制度来适当减少中间临时变量的内存分配及数据复制时间，而服务器本身也使用了各自的策略来提高效率。 例如Apache,在运行开始时一次申请大片的内存作为内存池，若随后需要时就在内存池中直接获取，不需要再次分配，避免了频繁的内存分配和释放引起的内存整理时间。 再如Nginx使用多线程来处理请求，使得多个线程之间可以共享内存资源，从而令它的内存总体使用量大大减少。 另外，Nginx分阶段的内存分配策略，按需分配，及时释放，使得内存使用量保持在很小的数量范围。 另外，还可以考虑共享内存。 共享内存指在多处理器的计算机系统中，可以被不同中央处理器（CPU）访问的大容量内存，也可以由不同进程共享，是非常快的进程通信方式。 但是使用共享内存也有不好的地方，就是对于多机器时数据不好统一。 shell命令ipcs可用来显示系统下共享内存的状态，函数shmget可以创建或打开一块共享内存区，函数shmat将一个存在的共享内存段连接到本进程空间, 函数shmctl可以对共享内存段进行多种操作，函数shmdt函数分离该共享内存。 3. 考虑使用持久连接持久连接也为长连接，它本身是TCP通信的一种普通方式，即在一次TCP连接中持续发送多分数据而不断开连接。 与它相反的方式称为短连接，也就是建立连接后发送一份数据就断开，然后再次建立连接发送下一份数据， 周而复始。 是否采用持久连接，完全取决于应用特点。 从性能角度看，建立TCP连接的操作本身是一项不小的开销，在允许的情况下，连接次数越少，越有利于性能的提升; 尤其对于密集型的图片或网页等小数据请求处理有明显的加速所用。 HTTP长连接需要浏览器和web服务器的共同协作，目前浏览器普遍支持长连接，表现在其发出的HTTP请求数据头中包含关于长连接的声明，如下：Connection: Keep-Alive 主流的web服务器都支持长连接，比如apache中，可以用KeepAlive off关闭长连接。 对于长连接的有效使用，还有关键一点在于长连接超时时间的设置，即长连接在什么时候关闭吗？ Apache的默认设置为5s, 若这个时间设置过长，则可能导致资源无效占有，维持大量空闲进程，影响服务器性能。 4. 改进I/O 模型I/O操作根据设备的不同分为很多类型，比如内存I/O, 网络I/O, 磁盘I/O。 对于网络I/O和磁盘I/O, 它们的速度要慢很多，尽管使用RAID磁盘阵列可通过并行磁盘磁盘来加快磁盘I/O速度，购买大连独享网络带宽以及使用高带宽网络适配器可以提高网络I/O的速度。 但这些I/O操作需要内核系统调用来完成，这些需要CPU来调度，这使得CPU不得不浪费宝贵的时间来等待慢速I/O操作。 我们希望让CPU足够少的时间在i/O操作的调度上，如何让高速的CPU和慢速的I/O设备更好地协调工作，是现代计算机一直探讨的话题。各种I/O模型的本质区别在于CPU的参与方式。 DMA技术I/O设备和内存之间的数据传输方式由DMA控制器完成。在DMA模式下，CPU只需向DMA下达命令，让DMA控制器来处理数据的传送，这样可以大大节省系统资源。 异步I/O异步I/O指主动请求数据后便可以继续处理其它任务，随后等待I/O操作的通知，这样进程在数据读写时不发生阻塞。 异步I/O是非阻塞的，当函数返回时，真正的I/O传输已经完成，这让CPU处理和I/O操作达到很好的重叠。 I/O多路复用epoll服务器同时处理大量的文件描述符是必不可少的，若采用同步非阻塞I/O模型，若同时接收TCP连接的数据，就必须轮流对每个socket调用接收数据的方法，不管这些socket有没有可接收的数据，都要询问一次。 假如大部分socket并没有数据可以接收，那么进程便会浪费很多CPU时间用于检查这些socket有没有可以接收的数据。 多路I/O就绪通知的出现，提供了对大量文件描述符就绪检查的高性能方案，它允许进程通过一种方法同时监视所有文件描述符，并可以快速获得所有就绪的文件描述符，然后只针对这些文件描述符进行数据访问。 epoll可以同时支持水平触发和边缘触发，理论上边缘触发性能更高，但是代码实现复杂，因为任何意外的丢失事件都会造成请求处理错误。 epoll主要有2大改进： epoll只告知就绪的文件描述符，而且当调用epoll_wait()获得文件描述符时，返回并不是实际的描述符，而是一个代表就绪描述符数量的值，然后只需去epoll指定的一个数组中依次取得相应数量的文件描述符即可。 这里使用了内存映射(mmap)技术，这样彻底省掉了这些文件描述符在系统调用时复制的开销。 epoll采用基于事件的就绪通知方式。其事先通过epoll_ctrl()注册每一个文件描述符，一旦某个文件描述符就绪时，内核会采用类似callback的回调机制，当进程调用epoll_wait()时得到通知 关于IO模型，可以参考笔者前面写的相关文章Java NIO.2；关于epoll，可以参考笔者前面写的文章select、poll和epoll简介。 Sendfile大多数时候，我们都向服务器请求静态文件，比如图片，样式表等。 在处理这些请求时，磁盘文件的数据先经过内核缓冲区，然后到用户内存空间，不需经过任何处理，其又被送到网卡对应的内核缓冲区，接着再被送入网卡进行发送。 Linux提供sendfile()系统调用，可以讲磁盘文件的特定部分直接传送到代表客户端的socket描述符，加快了静态文件的请求速度，同时减少CPU和内存的开销。 适用场景：对于请求较小的静态文件，sendfile发挥的作用不那么明显，因发送数据的环节在整个过程中所占时间的比例相比于大文件请求时小很多。 内存映射Linux内核提供一种访问磁盘文件的特殊方式，它可以将内存中某块地址空间和我们指定的磁盘文件相关联，从而对这块内存的访问转换为对磁盘文件的访问。这种技术称为内存映射。 多数情况下，内存映射可以提高磁盘I/O的性能，无须使用read()或write()等系统调用来访问文件，而是通过mmap()系统调用来建立内存和磁盘文件的关联，然后像访问内存一样自由访问文件。 缺点：在处理较大文件时，内存映射会导致较大的内存开销，得不偿失。 直接I/O在linux 2.6中，内存映射和直接访问文件没有本质差异，因为数据需要经过2次复制，即在磁盘与内核缓冲区之间以及在内核缓冲区与用户态内存空间。 引入内核缓冲区的目的在于提高磁盘文件的访问性能，然而对于一些复杂的应用，比如数据库服务器，它们为了进一步提高性能，希望绕过内核缓冲区，由自己在用户态空间实现并管理I/O缓冲区，比如数据库可根据更加合理的策略来提高查询缓存命中率。 另一方面，绕过内核缓冲区也可以减少系统内存的开销，因内核缓冲区本身就在使用系统内存。 Linux在open()系统调用中增加参数选项O_DIRECT,即可绕过内核缓冲区直接访问文件,实现直接I/O。 在Mysql中，对于Innodb存储引擎，自身进行数据和索引的缓存管理，可在my.cnf配置中分配raw分区跳过内核缓冲区，实现直接I/O。 5. 改进服务器并发策略服务器并发策略的目的，是让I/O操作和CPU计算尽量重叠进行，一方面让CPU在I/O等待时不要空闲，另一方面让CPU在I/O调度上尽量花最少的时间。 一个进程处理一个连接，非阻塞I/O这样会存在多个并发请求同时到达时，服务器必然要准备多个进程来处理请求。其进程的开销限制了它的并发连接数。 但从稳定性和兼容性的角度，则其相对安全，任何一个子进程的崩溃不会影响服务器本身，父进程可以创建新的子进程；这种策略典型的例子就是Apache的fork和prefork模式。 对于并发数不高（如150以内）的站点同时依赖Apache其它功能时的应用选择Apache还是可以的。 一个线程处理一个连接，非阻塞IO这种方式允许在一个进程中通过多个线程来处理多个连接，一个线程处理一个连接。Apache的worker模式就是这种典型例子，使其可支持更多的并发连接。不过这种模式的总体性能还不如prefork，所以一般不选用worker模式。 一个进程处理多个连接，异步I/O一个线程同时处理多个连接，潜在的前提条件就是使用IO多路复用就绪通知。 这种情况下，将处理多个连接的进程叫做worker进程或服务进程。worker的数量可以配置，如Nginx中的worker_processes 4。 一个线程处理多个连接，异步IO即使有高性能的IO多路复用就绪通知，但磁盘IO的等待还是无法避免的。更加高效的方法是对磁盘文件使用异步IO，目前很少有Web服务器真正意义上支持这种异步IO。 6. 改进硬件环境还有一点要提及的是硬件环境，服务器的硬件配置对应用程序的性能提升往往是最直接，也是最简单的方式，这就是所谓的scale up。这里不做论述。 附录什么是重入锁 java.util.concurrent.locks.ReentrantLock 这个是 JDK @since 1.5 添加的一种颗粒度更小的锁，它完全可以替代 synchronized 关键字来实现它的所有功能，而且 ReentrantLock 锁的灵活度要远远大于 synchronized 关键字。 从类结构图看出，ReentrantLock 实现了 Lock 接口，ReentrantLock 只是 Lock 接口的一个实现而已。 java.util.concurrent.locks.Lock 它们都是 java.util.concurrent 包里面的内容（俗称 JUC、并发包），也都是 JDK 1.5 开始加入的。 为什么叫重入锁呢？ReentrantLock，我们把它拆开来看就明了了。 Re-Entrant-Lock：即表示可重新反复进入的锁，但仅限于当前线程； 12345678910public void m() &#123; lock.lock(); lock.lock(); try &#123; // ... method body &#125; finally &#123; lock.unlock() lock.unlock() &#125;&#125; 如示例代码所示，当前线程可以反复加锁，但也需要释放同样加锁次数的锁，即重入了多少次，就要释放多少次，不然也会导入锁不被释放。 试想一下，如果不设计成可重入锁，那自己如果反复给自己加锁，不是会把自己加死锁了吗？所以，到现在，重入锁的概念大概应该清楚了吧？ 重入锁最重要的几个方法这几个方法都是 Lock 接口中定义的： 1）lock() 获取锁，有以下三种情况： 锁空闲：直接获取锁并返回，同时设置锁持有者数量为：1； 当前线程持有锁：直接获取锁并返回，同时锁持有者数量递增1； 其他线程持有锁：当前线程会休眠等待，直至获取锁为止； 2）lockInterruptibly() 获取锁，逻辑和 lock() 方法一样，但这个方法在获取锁过程中能响应中断。 3）tryLock() 从关键字字面理解，这是在尝试获取锁，获取成功返回：true，获取失败返回：false, 这个方法不会等待，有以下三种情况： 锁空闲：直接获取锁并返回：true，同时设置锁持有者数量为：1； 当前线程持有锁：直接获取锁并返回：true，同时锁持有者数量递增1； 其他线程持有锁：获取锁失败，返回：false； 4）tryLock(long timeout, TimeUnit unit) 逻辑和 tryLock() 差不多，只是这个方法是带时间的。 5）unlock() 释放锁，每次锁持有者数量递减 1，直到 0 为止。所以，现在知道为什么 lock 多少次，就要对应 unlock 多少次了吧。 6）newCondition 返回一个这个锁的 Condition 实例，可以实现 synchronized 关键字类似 wait/ notify 实现多线程通信的功能，不过这个比 wait/ notify 要更灵活，更强大！ 重入锁大概的用法12345678910111213141516class X &#123; private final ReentrantLock lock = new ReentrantLock(); // ... public void m() &#123; lock.lock(); // block until condition holds try &#123; // ... method body &#125; finally &#123; lock.unlock() &#125; &#125;&#125;&#125; 看见没有，加锁和释放锁都在方法里面进行，可以自由控制，比 synchronized 更灵活，更方便。但要注意的是，释放锁操作必须在 finally 里面，不然如果出现异常导致锁不能被正常释放，进而会卡死后续所有访问该锁的线程。 synchronized 是重入锁吗？那么问题来了，synchronized 是重入锁吗？ 你可能会说不是，因为 ReentrantLock 既然是重入锁，根据推理，相反，那 synchronized 肯定就不是重入锁，那你就错了。 答案是：yes，为什么？看下面的例子： 1234567public synchronized void operation()&#123; add();&#125;public synchronized void add()&#123;&#125; operation 方法调用了 add 方法，两个方法都是用 synchronized 修饰的，add() 方法可以成功获取当前线程 operation() 方法已经获取到的锁，说明 synchronized 就是可重入锁。 转载自www.cnblogs.com/zengjin93/p/5569556.html 原作者：潇洒一剑，在原文基础上有修改。","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/categories/架构设计/"}],"tags":[{"name":"分布式架构","slug":"分布式架构","permalink":"https://vincentruan.github.io/tags/分布式架构/"},{"name":"资源管理","slug":"资源管理","permalink":"https://vincentruan.github.io/tags/资源管理/"},{"name":"转载","slug":"转载","permalink":"https://vincentruan.github.io/tags/转载/"}]},{"title":"分布式基础要点","slug":"分布式基础要点","date":"2020-02-06T12:20:12.000Z","updated":"2020-02-25T15:09:15.064Z","comments":true,"path":"2020/02/06/分布式基础要点/","link":"","permalink":"https://vincentruan.github.io/2020/02/06/分布式基础要点/","excerpt":"概念模型节点在具体的工程项目中，一个节点往往是一个操作系统上的进程。在本文的模型中，认为节点是一个完整的、不可分的整体，如果某个程序进程实际上由若干相对独立部分构成，则在模型中可以将一个进程划分为多个节点。","text":"概念模型节点在具体的工程项目中，一个节点往往是一个操作系统上的进程。在本文的模型中，认为节点是一个完整的、不可分的整体，如果某个程序进程实际上由若干相对独立部分构成，则在模型中可以将一个进程划分为多个节点。 异常 机器宕机：机器宕机是最常见的异常之一。在大型集群中每日宕机发生的概率为千分之一左右，在实践中，一台宕机的机器恢复的时间通常认为是24 小时，一般需要人工介入重启机器。 网络异常：消息丢失，两片节点之间彼此完全无法通信，即出现了“网络分化”；消息乱序，有一定的概率不是按照发送时的顺序依次到达目的节点，考虑使用序列号等机制处理网络消息的乱序问题，使得无效的、过期的网络消息不影响系统的正确性；数据错误；不可靠的TCP，TCP 协议为应用层提供了可靠的、面向连接的传输服务，但在分布式系统的协议设计中不能认为所有网络通信都基于TCP 协议则通信就是可靠的。TCP协议只能保证同一个TCP 链接内的网络消息不乱序，TCP 链接之间的网络消息顺序则无法保证。 分布式三态：如果某个节点向另一个节点发起RPC(Remote procedure call)调用，即某个节点A 向另一个节点B 发送一个消息，节点B 根据收到的消息内容完成某些操作，并将操作的结果通过另一个消息返回给节点A，那么这个RPC 执行的结果有三种状态：“成功”、“失败”、“超时（未知）”，称之为分布式系统的三态。 存储数据丢失:对于有状态节点来说，数据丢失意味着状态丢失，通常只能从其他节点读取、恢复存储的状态。 异常处理原则\\：被大量工程实践所检验过的异常处理黄金原则是：任何在设计阶段考虑到的异常情况一定会在系统实际运行中发生，但在系统实际运行遇到的异常却很有可能在设计时未能考虑，所以，除非需求指标允许，在系统设计时不能放过任何异常情况。 副本副本（replica/copy）指在分布式系统中为数据或服务提供的冗余。对于数据副本指在不同的节点上持久化同一份数据，当出现某一个节点的存储的数据丢失时，可以从副本上读到数据。数据副本是分布式系统解决数据丢失异常的唯一手段。另一类副本是服务副本，指数个节点提供某种相同的服务，这种服务一般并不依赖于节点的本地存储，其所需数据一般来自其他节点。 副本协议是贯穿整个分布式系统的理论核心。 副本一致性分布式系统通过副本控制协议，使得从系统外部读取系统内部各个副本的数据在一定的约束条件下相同，称之为副本一致性(consistency)。副本一致性是针对分布式系统而言的，不是针对某一个副本而言。 强一致性(strong consistency)：任何时刻任何用户或节点都可以读到最近一次成功更新的副本数据。强一致性是程度最高的一致性要求，也是实践中最难以实现的一致性。 单调一致性(monotonic consistency)：任何时刻，任何用户一旦读到某个数据在某次更新后的值，这个用户不会再读到比这个值更旧的值。单调一致性是弱于强一致性却非常实用的一种一致性级别。因为通常来说，用户只关心从己方视角观察到的一致性，而不会关注其他用户的一致性情况。 会话一致性(session consistency)：任何用户在某一次会话内一旦读到某个数据在某次更新后的值，这个用户在这次会话过程中不会再读到比这个值更旧的值。会话一致性通过引入会话的概念，在单调一致性的基础上进一步放松约束，会话一致性只保证单个用户单次会话内数据的单调修改，对于不同用户间的一致性和同一用户不同会话间的一致性没有保障。实践中有许多机制正好对应会话的概念，例如php 中的session 概念。 最终一致性(eventual consistency)：最终一致性要求一旦更新成功，各个副本上的数据最终将达 到完全一致的状态，但达到完全一致状态所需要的时间不能保障。对于最终一致性系统而言，一个用户只要始终读取某一个副本的数据，则可以实现类似单调一致性的效果，但一旦用户更换读取的副本，则无法保障任何一致性。 弱一致性(week consistency)：一旦某个更新成功，用户无法在一个确定时间内读到这次更新的值，且即使在某个副本上读到了新的值，也不能保证在其他副本上可以读到新的值。弱一致性系统一般很难在实际中使用，使用弱一致性系统需要应用方做更多的工作从而使得系统可用。 衡量分布式系统的指标 性能：系统的吞吐能力，指系统在某一时间可以处理的数据总量，通常可以用系统每秒处理的总的数据量来衡量；系统的响应延迟，指系统完成某一功能需要使用的时间；系统的并发能力，指系统可以同时完成某一功能的能力，通常也用QPS(query per second)来衡量。上述三个性能指标往往会相互制约，追求高吞吐的系统，往往很难做到低延迟；系统平均响应时间较长时，也很难提高QPS。 可用性：系统的可用性(availability)指系统在面对各种异常时可以正确提供服务的能力。系统的可用性可以用系统停服务的时间与正常服务的时间的比例来衡量，也可以用某功能的失败次数与成功次数的比例来衡量。可用性是分布式的重要指标，衡量了系统的鲁棒性，是系统容错能力的体现。 可扩展性：系统的可扩展性(scalability)指分布式系统通过扩展集群机器规模提高系统性能（吞吐、延迟、并发）、存储容量、计算能力的特性。好的分布式系统总在追求“线性扩展性”，也就是使得系统的某一指标可以随着集群中的机器数量线性增长。 一致性：分布式系统为了提高可用性，总是不可避免的使用副本的机制，从而引发副本一致性的问题。越是强的一致的性模型，对于用户使用来说使用起来越简单。 分布式系统原理数据分布方式**所谓分布式系统顾名思义就是利用多台计算机协同解决单台计算机所不能解决的计算、存储等问题。单机系统与分布式系统的最大的区别在于问题的规模，即计算、存储的数据量的区别。将一个单机问题使用分布式解决，首先要解决的就是如何将问题拆解为可以使用多机分布式解决，使得分布式系统中的每台机器负责原问题的一个子集。由于无论是计算还是存储，其问题输入对象都是数据，所以如何拆解分布式系统的输入数据成为分布式系统的基本问题。 哈希方式 哈希分布数据的缺点同样明显，突出表现为可扩展性不高，一旦集群规模需要扩展，则几乎所有的数据需要被迁移并重新分布。工程中，扩展哈希分布数据的系统时，往往使得集群规模成倍扩展，按照数据重新计算哈希，这样原本一台机器上的数据只需迁移一半到另一台对应的机器上即可完成扩展。 针对哈希方式扩展性差的问题，一种思路是不再简单的将哈希值与机器做除法取模映射，而是将对应关系作为元数据由专门的元数据服务器管理.同时，哈希值取模个数往往大于机器个数，这样同一台机器上需要负责多个哈希取模的余数。但需要以较复杂的机制维护大量的元数据。哈希分布数据的另一个缺点是，一旦某数据特征值的数据严重不均，容易出现“数据倾斜”（data skew）问题。 哈希分布数据的另一个缺点是，一旦某数据特征值的数据严重不均，容易出现“数据倾斜”（data skew）问题 按数据范围分布按数据范围分布是另一个常见的数据分布式，将数据按特征值的值域范围划分为不同的区间，使得集群中每台（组）服务器处理不同区间的数据。 工程中，为了数据迁移等负载均衡操作的方便，往往利用动态划分区间的技术，使得每个区间中服务的数据量尽量的一样多。当某个区间的数据量较大时，通过将区间“分裂”的方式拆分为两个区间，使得每个数据区间中的数据量都尽量维持在一个较为固定的阈值之下。 一般的，往往需要使用专门的服务器在内存中维护数据分布信息，称这种数据的分布信息为一种元信息。甚至对于大规模的集群，由于元信息的规模非常庞大，单台 计算机无法独立维护，需要使用多台机器作为元信息服务器。 按数据量分布数据量分布数据与具体的数据特征无关，而是将数据视为一个顺序增长的文件，并将这个文件按照某一较为固定的大小划分为若干数据块（chunk），不同的数据块分布到不同的服务器上。与按数据范围分布数据的方式类似的是，按数据量分布数据也需要记录数据块的具体分布情况，并将该分布信息作为元数据使用元数据服务器管理。 由于与具体的数据内容无关，按数据量分布数据的方式一般没有数据倾斜的问题，数据总是被均匀切分并分布到集群中。当集群需要重新负载均衡时，只需通过迁移数据块即可完成。集群扩容也没有太大的限制，只需将部分数据库迁移到新加入的机器上即可以完成扩容。按数据量划分数据的缺点是需要管理较为复杂的元信息，与按范围分布数据的方式类似，当集群规模较大时，元信息的数据量也变得很大，高效的管理元信息成为新的课题。 一致性哈希一致性哈希（consistent hashing）是另一个种在工程中使用较为广泛的数据分布方式。一致性哈希最初在P2P 网络中作为分布式哈希表（DHT）的常用数据分布算法。一致性哈希的基本方式是使用一个哈希函数计算数据或数据特征的哈希值，令该哈希函数的输出值域为一个封闭的环，即哈希函数输出的最大值是最小值的前序。将节点随机分布到这个环上，每个节点负责处理从自己开始顺时针至下一个节点的全部哈希值域上的数据。 使用一致性哈希的方式需要将节点在一致性哈希环上的位置作为元信息加以管理，这点比直接使用哈希分布数据的方式要复杂。然而，节点的位置信息只于集群中的机器规模相关，其元信息的量通常比按数据范围分布数据和按数据量分布数据的元信息量要小很多。 为此一种常见的改进算法是引入虚节点（virtual node）的概念，系统初始时就创建许多虚节点，虚节点的个数一般远大于未来集群中机器的个数，将虚节点均匀分布到一致性哈希值域环上，其功能与基本一致性哈希算法中的节点相同。为每个节点分配若干虚节点。操作数据时，首先通过数据的哈希值在环上找到对应的虚节点，进而查找元数据找到对应的真实节点。使用虚节点改进有多个优点。首先，一旦某个节点不可用，该节点将使得多个虚节点不可用，从而使得多个相邻的真实节点负载失效节点的压里。同理，一旦加入一个新节点，可以分配多个虚节点，从而使得新节点可以 负载多个原有节点的压力，从全局看，较容易实现扩容时的负载均衡。 副本与数据分布分布式系统容错、提高可用性的基本手段就是使用副本。对于数据副本的分布方式主要影响系统的可扩展性。一种基本的数据副本策略是以机器为单位，若干机器互为副本，副本机器之间的数据完全相同。这种策略适用于上述各种数据分布方式。其优点是非常简单，其缺点是恢复数据的效率不高、可扩展性也不高。 更合适的做法不是以机器作为副本单位，而是将数据拆为较合理的数据段，以数据段为单位作为副本。实践中，常常使得每个数据段的大小尽量相等且控制在一定的大小以内。数据段有很多不同的称谓，segment，fragment，chunk，partition 等等。数据段的选择与数据分布方式直接相关。对于哈希分数据的方式，每个哈希分桶后的余数可以作为一个数据段，为了控制数据段的大小，常常使得分桶个数大于集群规模。一旦将数据分为数据段，则可以以数据段为单位管理副本，从而副本与机器不再硬相关，每台机器都可以负责一定数据段的副本。 一旦副本分布与机器无关，数据丢失后的恢复效率将非常高。这是因为，一旦某台机器的数据丢失，其上数据段的副本将分布在整个集群的所有机器中，而不是仅在几个副本机器中，从而可以从整个集群同时拷贝恢复数据，而集群中每台数据源机器都可以以非常低的资源做拷贝。作为恢复数据源的机器即使都限速1MB/s，若有100 台机器参与恢复，恢复速度也能达到100MB/s。再者，副本分布与机器无关也利于集群容错。如果出现机器宕机，由于宕机机器上的副本分散于整个集群，其压力也自然分散到整个集群。最后，副本分布与机器无关也利于集群扩展。理论上，设集群规模 为N 台机器，当加入一台新的机器时，只需从各台机器上迁移1/N – 1/N+1 比例的数据段到新机器即实现了新的负载均衡。由于是从集群中各机器迁移数据，与数据恢复同理，效率也较高。工程中，完全按照数据段建立副本会引起需要管理的元数据的开销增大，副本维护的难度也相应增大。一种折中的做法是将某些数据段组成一个数据段分组，按数据段分组为粒度进行副本管理。这样做可以将副本粒度控制在一个较为合适的范围内。 本地化计算在分布式系统中，数据的分布方式也深深影响着计算的分布方式。在分布式系统中计算节点和保存计算数据的存储节点可以在同一台物理机器上，也可以位于不同的物理机器。如果计算节点和存储节点位于不同的物理机器则计算的数据需要通过网络传输，此种方式的开销很大，甚至网络带宽会成为系统的总体瓶颈。另一种思路是，将计算尽量调度到与存储节点在同一台物理机器上的计算节点上进行，这称之为本地化计算。本地化计算是计算调度的一种重要优化，其体现了一种重要的分布式调度思想：“移动数据不如移动计算”。 数据分布方式的选择在实际工程实践中，可以根据需求及实施复杂度合理选择数据分布方式。另外，数据分布方式是可以灵活组合使用的，往往可以兼备各种方式的优点，收到较好的综合效果。 例：数据倾斜问题，在按哈希分数据的基础上引入按数据量分布数据的方式，解决该数据倾斜问题。按用户id 的哈希值分数据，当某个用户id 的数据量特别大时，该用户的数据始终落在某一台机器上。此时，引入按数据量分布数据的方式，统计用户的数据量，并按某一阈值将用户的数据切为多个均匀的数据段，将这些数据段分布到集群中去。由于大部分用户的数据量不会超过阈值，所以元数据中仅仅保存超过阈值的用户的数据段分布信息，从而可以控制元数据的规模。这种哈希分布数据方式与按数据量分布数据方式组合使用的方案，在某真实系统中使用，取得了较好的效果。 基本副本协议副本控制协议指按特定的协议流程控制副本数据的读写行为，使得副本满足一定的可用性和一致性要求的分布式协议。副本控制协议要具有一定的对抗异常状态的容错能力，从而使得系统具有一定的可用性，同时副本控制协议要能提供一定一致性级别。由CAP 原理（在2.9 节详细分析）可知，要设计一种满足强一致性，且在出现任何网络异常时都可用的副本协议是不可能的。为此，实际中的副本控制协议总是在可用性、一致性与性能等各要素之间按照具体需求折中。 副本控制协议可以分为两大类：“中心化(centralized)副本控制协议”和“去中心化(decentralized)副本控制协议”。 中心化副本控制协议中心化副本控制协议的基本思路是由一个中心节点协调副本数据的更新、维护副本之间的一致性。图给出了中心化副本协议的通用架构。中心化副本控制协议的优点是协议相对较为简单，所有的副本相关的控制交由中心节点完成。并发控制将由中心节点完成，从而使得一个分布式并发控制问题，简化为一个单机并发控制问题。所谓并发控制，即多个节点同时需要修改副本数据时，需要解决“写写”、“读写”等并发冲突。单机系统上常用加锁等方式进行并发控制。对于分布式并发控制，加锁也是一个常用的方法，但如果没有中心节点统一进行锁管理，就需要完全分布式化的锁系统，会使得协议非常复杂。中心化副本控制协议的缺点是系统的可用性依赖于中心化节点，当中心节点异常或与中心节点通信中断时，系统将失去某些服务（通常至少失去更新服务），所以中心化副本控制协议的缺点正是存在一定的停服务时间。 primary-secondary 协议在primary-secondary 类型的协议中，副本被分为两大类，其中有且仅有一个副本作为primary 副本，除primary 以外的副本都作为secondary 副本。维护primary 副本的节点作为中心节点，中心节点负责维护数据的更新、并发控制、协调副本的一致性。 Primary-secondary 类型的协议一般要解决四大类问题：数据更新流程、数据读取方式、Primary 副本的确定和切换、数据同步（reconcile）。 数据更新基本流程 数据更新都由primary 节点协调完成。 外部节点将更新操作发给primary 节点 primary 节点进行并发控制即确定并发更新操作的先后顺序 primary 节点将更新操作发送给secondary 节点 primary 根据secondary 节点的完成情况决定更新是否成功并将结果返回外部节点 在工程实践中，如果由primary 直接同时发送给其他N 个副本发送数据，则每个 secondary 的更新吞吐受限于primary 总的出口网络带宽，最大为primary 网络出口带宽的1/N。为了解决这个问题，有些系统（例如，GFS），使用接力的方式同步数据，即primary 将更新发送给第一 个secondary 副本，第一个secondary 副本发送给第二secondary 副本，依次类推。 数据读取方式数据读取方式也与一致性高度相关。如果只需要最终一致性，则读取任何副本都可以满足需求。如果需要会话一致性，则可以为副本设置版本号，每次更新后递增版本号，用户读取副本时验证版本号，从而保证用户读到的数据在会话范围内单调递增。使用primary-secondary 比较困难的是实现强一致性。 由于数据的更新流程都是由primary 控制的，primary 副本上的数据一定是最新的，所以 如果始终只读primary 副本的数据，可以实现强一致性。如果只读primary 副本，则secondary 副本将不提供读服务。实践中，如果副本不与机器绑定，而是按照数据段为单位维护副本，仅有primary 副本提供读服务在很多场景下并不会造出机器资源浪费。 将副本分散到集群中个，假设primary 也是随机的确定的，那么每台机器上都有一些数据的primary 副本，也有另一些数据段的secondary 副本。从而某台服务器实际都提供读写服务。 由primary 控制节点secondary 节点的可用性。当primary 更新某个secondary 副本不成功时，primary 将该secondary 副本标记为不可用，从而用户不再读取该不可用的副本。不可用的 secondary 副本可以继续尝试与primary 同步数据，当与primary 完成数据同步后，primary 可以副本标记为可用。这种方式使得所有的可用的副本，无论是primary 还是secondary 都是可读的，且在一个确定的时间内，某secondary 副本要么更新到与primary 一致的最新状态，要么被标记为不可用，从而符合较高的一致性要求。这种方式依赖于一个中心元数据管理系统，用于记录哪些副本可用，哪些副本不可用。某种意义上，该方式通过降低系统的可用性来提高系统的一致性。 primary 副本的确定与切换在primary-secondary 类型的协议中，另一个核心的问题是如何确定primary 副本，尤其是在原primary 副本所在机器出现宕机等异常时，需要有某种机制切换primary 副本，使得某个secondary 副本成为新的primary 副本。 通常的，在primary-secondary 类型的分布式系统中，哪个副本是primary 这一信息都属于元信息，由专门的元数据服务器维护。执行更新操作时，首先查询元数据服务器获取副本的primary 信息，从而进一步执行数据更新流程。 由于分布式系统中可靠的发现节点异常是需要一定的探测时间的，这样的探测时间通常是10 秒级别，这也意味着一旦primary 异常，最多需要10 秒级别的发现时间，系统才能开始primary 的切换，在这10 秒时间内，由于没有primary，系统不能提供更 新服务，如果系统只能读primary 副本，则这段时间内甚至不能提供读服务。从这里可以看到，primary-backup 类副本协议的最大缺点就是由于primary 切换带来的一定的停服务时间。 数据同步不一致的secondary 副本需要与primary 进行同步（reconcile）。 通常不一致的形式有三种：一、由于网络分化等异常，secondary 上的数据落后于primary 上的数据。二、在某些协议下，secondary 上的数据有可能是脏数据，需要被丢弃。所谓脏数据是由于primary 副本没有进行某一更新操作，而secondary 副本上反而进行的多余的修改操作，从而造成secondary 副本数据错误。三、secondary 是一个新增加的副本，完全没有数据，需要从其他副本上拷贝数据。 对于第一种secondary 数据落后的情况，常见的同步方式是回放primary 上的操作日志（通常是redo 日志），从而追上primary 的更新进度。对于脏数据的情况，较好的做法是设计的分布式协议不产生脏数据。如果协议一定有产生脏数据的可能，则也应该使得产生脏数据的概率降到非常低得情况，从而一旦发生脏数据的情况可以简单的直接丢弃有脏数据的副本，这样相当于副本没有数据。另外，也可以设计一些基于undo 日志的方式从而可以删除脏数据。如果secondary 副本完全没有数据，则常见的做法是直接拷贝primary 副本的数据，这种方法往往比回放日志追更新进度的方法快很多。但拷贝数据时primary 副本需要能够继续提供更新服务，这就要求primary 副本支持快照(snapshot)功能。即对某一刻的副本数据形成快照，然后拷贝快照，拷贝完成后使用回放日志的方式追快照形成后的更新操作。 去中心化副本控制协议去中心化副本控制协议没有中心节点，协议中所有的节点都是完全对等的，节点之间通过平等协商达到一致。从而去中心化协议没有因为中心化节点异常而带来的停服务等问题。 去中心化协议的最大的缺点是协议过程通常比较复杂。尤其当去中心化协议需要实现强一致性时，协议流程变得复杂且不容易理解。由于流程的复杂，去中心化协议的效率或者性能一般也较中心化协议低。一个不恰当的比方就是，中心化副本控制协议类似专制制度，系统效率高但高度依赖于中心节点，一旦中心节点异常，系统受到的影响较大；去中心化副本控制协议类似民主制度，节点集体协商，效率低下，但个别节点的异常不会对系统总体造成太大影响。 Lease 机制Lease 机制是最重要的分布式协议，广泛应用于各种实际的分布式系统中。 基于lease 的分布式cache 系统基本的问题背景如下：在一个分布式系统中，有一个中心服务器节点，中心服务器存储、维护着一些数据，这些数据是系统的元数据。系统中其他的节点通过访问中心服务器节点读取、修改其上的元数据。由于系统中各种操作都依赖于元数据，如果每次读取元数据的操作都访问中心服务器 节点，那么中心服务器节点的性能成为系统的瓶颈。为此，设计一种元数据cache，在各个节点上 cache 元数据信息，从而减少对中心服务器节点的访问，提高性能。另一方面，系统的正确运行严格依赖于元数据的正确，这就要求各个节点上cache 的数据始终与中心服务器上的数据一致，cache 中的数据不能是旧的脏数据。最后，设计的cache 系统要能最大可能的处理节点宕机、网络中断等异常，最大程度的提高系统的可用性。 为此，利用lease 机制设计一套cache 系统，其基本原理为如下。中心服务器在向各节点发送数据时同时向节点颁发一个lease。每个lease 具有一个有效期，和信用卡上的有效期类似，lease 上的 有效期通常是一个明确的时间点，例如12:00:10，一旦真实时间超过这个时间点，则lease 过期失效。这样lease 的有效期与节点收到lease 的时间无关，节点可能收到lease 时该lease 就已经过期失效。这里首先假设中心服务器与各节点的时钟是同步的，在下节中讨论时钟不同步对lease 的影响。中心服务器发出的lease 的含义为：在lease 的有效期内，中心服务器保证不会修改对应数据的值。因此，节点收到数据和lease 后，将数据加入本地Cache，一旦对应的lease 超时，节点将对应的本地cache 数据删除。中心服务器在修改数据时，首先阻塞所有新的读请求，并等待之前为该数据发出的所有lease 超时过期，然后修改数据的值。 基于lease 的cache，客户端节点读取元数据 判断元数据是否已经处于本地cache 且lease 处于有效期内1.1 是：直接返回cache 中的元数据1.2 否：向中心服务器节点请求读取元数据信息1.2.1 服务器收到读取请求后，返回元数据及一个对应的lease 1.2.2 客户端是否成功收到服务器返回的数据 1.2.2.1 失败或超时：退出流程，读取失败，可重试1.2.2.2 成功：将元数据与该元数据的lease 记录到内存中，返回元数据 基于lease 的cache，客户端节点修改元数据流程2.1 节点向服务器发起修改元数据请求。2.2 服务器收到修改请求后，阻塞所有新的读数据请求，即接收读请求，但不返回数据。2.3 服务器等待所有与该元数据相关的lease 超时。2.4 服务器修改元数据并向客户端节点返回修改成功。 上述机制可以保证各个节点上的cache 与中心服务器上的中心始终一致。这是因为中心服务器节点在发送数据的同时授予了节点对应的lease，在lease 有效期内，服务器不会修改数据，从而客户端节点可以放心的在lease 有效期内cache 数据。上述lease 机制可以容错的关键是：服务器一旦 发出数据及lease，无论客户端是否收到，也无论后续客户端是否宕机，也无论后续网络是否正常，服务器只要等待lease 超时，就可以保证对应的客户端节点不会再继续cache 数据，从而可以放心的修改数据而不会破坏cache 的一致性。 上述基础流程有一些性能和可用性上的问题，但可以很容易就优化改性。优化点一：服务器在修改元数据时首先要阻塞所有新的读请求，造成没有读服务。这是为了防止发出新的lease 从而引起不断有新客户端节点持有lease 并缓存着数据，形成“活锁”。优化的方法很简单，服务器在进入修改数据流程后，一旦收到读请求则只返回数据但不颁发lease。从而造成在修改流程执行的过程中，客户端可以读到元数据，只是不能缓存元数据。进一步的优化是，当进入修改流程，服务器颁发的lease 有效期限选择为已发出的lease 的最大有效期限。这样做，客户端可以继续在服务器进入修改流程后继续缓存元数据，但服务器的等待所有lease 过期的时间也不会因为颁发新的lease 而不断延长。 最后，cache 机制与多副本机制的区别。Cache 机制与多副本机制的相似之处都 是将一份数据保存在多个节点上。但Cache 机制却要简单许多，对于cache 的数据，可以随时删除丢弃，并命中cache 的后果仅仅是需要访问数据源读取数据；然而副本机制却不一样，副本是不能随意丢弃的，每失去一个副本，服务质量都在下降，一旦副本数下降到一定程度，则往往服务将不再可用。 lease 机制的分析lease 的定义：Lease 是由颁发者授予的在某一有效期内的承诺。颁发者一旦发出lease，则无论接受方是否收到，也无论后续接收方处于何种状态，只要lease 不过期，颁发者一定严守承诺；另一方面，接收方在lease 的有效期内可以使用颁发者的承诺，但一旦lease 过期，接收方一定不能继续使用颁发者的承诺。 Lease 机制具有很高的容错能力。首先，通过引入有效期，Lease 机制能否非常好的容错网络异常。Lease 颁发过程只依赖于网络可以单向通信，即使接收方无法向颁发者发送消息，也不影响lease 的颁发。由于lease 的有效期是一个确定的时间点，lease 的语义与发送lease 的具体时间无关，所以 同一个lease 可以被颁发者不断重复向接受方发送。即使颁发者偶尔发送lease 失败，颁发者也可以 简单的通过重发的办法解决。一旦lease 被接收方成功接受，后续lease 机制不再依赖于网络通信，即使网络完全中断lease 机制也不受影响。再者，Lease 机制能较好的容错节点宕机。如果颁发者宕机，则宕机的颁发者通常无法改变之前的承诺，不会影响lease 的正确性。在颁发者机恢复后，如果颁发者恢复出了之前的lease 信息，颁发者可以继续遵守lease 的承诺。如果颁发者无法恢复lease 信息，则只需等待一个最大的lease 超时时间就可以使得所有的lease 都失效，从而不破坏lease机制。 例如上节中的cache 系统的例子中，一旦服务器宕机，肯定不会修改元数据，重新恢复后，只需等待一个最大的lease 超时时间，所有节点上的缓存信息都将被清空。对于接受方宕机的情况，颁发者 不需要做更多的容错处理，只需等待lease 过期失效，就可以收回承诺，实践中也就是收回之前赋予的权限、身份等。最后，lease 机制不依赖于存储。颁发者可以持久化颁发过的lease 信息，从而在 宕机恢复后可以使得在有效期的lease 继续有效。但这对于lease 机制只是一个优化，如之前的分析，即使颁发者没有持久化lease 信息，也可以通过等待一个最大的lease 时间的方式使得之前所有颁发 的lease 失效，从而保证机制继续有效。 Lease 机制依赖于有效期，这就要求颁发者和接收者的时钟是同步的。一方面，如果颁发者的 时钟比接收者的时钟慢，则当接收者认为lease 已经过期的时候，颁发者依旧认为lease 有效。接收者可以用在lease 到期前申请新的lease 的方式解决这个问题。另一方面，如果颁发者的时钟比接收 者的时钟快，则当颁发者认为lease 已经过期的时候，接收者依旧认为lease 有效，颁发者可能将lease 颁发给其他节点，造成承诺失效，影响系统的正确性。对于这种时钟不同步，实践中的通常做法是将颁发者的有效期设置得比接收者的略大，只需大过时钟误差就可以避免对lease 的有效性的影响。 基于lease 机制确定节点状态分布式协议依赖于对节点状态认知的全局一致性，即一旦节点Q 认为某个节点 A 异常，则节点A 也必须认为自己异常，从而节点A 停止作为primary，避免“双主”问题的出现。解决这种问题有两种思路，第一、设计的分布式协议可以容忍“双主”错误，即不依赖于对节点状 态的全局一致性认识，或者全局一致性状态是全体协商后的结果；第二、利用lease 机制。对于第一 种思路即放弃使用中心化的设计，而改用去中心化设计，超过本节的讨论范畴。下面着重讨论利用 lease 机制确定节点状态。 由中心节点向其他节点发送lease，若某个节点持有有效的lease，则认为该节点正常可以提供服 务。用于例2.3.1 中，节点A、B、C 依然周期性的发送heart beat 报告自身状态，节点Q 收到heart beat 后发送一个lease，表示节点Q 确认了节点A、B、C 的状态，并允许节点在lease 有效期内正常工 作。节点Q 可以给primary 节点一个特殊的lease，表示节点可以作为primary 工作。一旦节点Q 希望切换新的primary，则只需等前一个primary 的lease 过期，则就可以安全的颁发新的lease 给新的 primary 节点，而不会出现“双主”问题。 在实际系统中，若用一个中心节点发送lease 也有很大的风险，一旦该中心节点宕机或网络异常，则所有的节点没有lease，从而造成系统高度不可用。为此，实际系统总是使用多个中心节点互为副本，成为一个小的集群，该小集群具有高可用性，对外提供颁发lease 的功能。chubby 和zookeeper 都是基于这样的设计。 lease 的有效期时间选择工程中，常选择的lease 时长是10 秒级别，这是一个经过验证的经验值，实践中可以作为参考并综合选择合适的时长。 Quorum 机制先做这样的约定：更新操作（write）是一系列顺序的过程，通过其他机制确定更新操作的顺序（例如primary-secondary 架构中由primary 决定顺序），每个更新操作记为wi， i 为更新操作单调递增的序号，每个wi 执行成功后副本数据都发生变化，称为不同的数据版本，记 作vi。假设每个副本都保存了历史上所有版本的数据。 write-all-read-oneWrite-all-read-one（简称WARO）是一种最简单的副本控制规则，顾名思义即在更新时写所有的副本，只有在所有的副本上更新成功，才认为更新成功，从而保证所有的副本一致，这样在读取数据时可以读任一副本上的数据。 由于更新操作需要在所有的N 个副本上都成功，更新操作才能成 功，所以一旦有一个副本异常，更新操作失败，更新服务不可用。对于更新服务，虽然有N 个副本， 但系统无法容忍任何一个副本异常。另一方面，N 个副本中只要有一个副本正常，系统就可以提供读服务。对于读服务而言，当有N 个副本时，系统可以容忍N-1 个副本异常。从上述分析可以发现WARO 读服务的可用性较高，但更新服务的可用性不高，甚至虽然使用了副本，但更新服务的可用性等效于没有副本。 Quorum 定义在Quorum 机制下，当某次更新操作wi 一旦在所有N 个副本中的W 个副本上都成功，则就称 该更新操作为“成功提交的更新操作”，称对应的数据为“成功提交的数据”。令R&gt;N-W，由于更新 操作wi 仅在W 个副本上成功，所以在读取数据时，最多需要读取R 个副本则一定能读到wi 更新后 的数据vi 。如果某次更新wi 在W 个副本上成功，由于W+R&gt;N，任意R 个副本组成的集合一定与 成功的W个副本组成的集合有交集，所以读取R 个副本一定能读到wi 更新后的数据vi。如图 2-10， Quorum 机制的原理可以文森图表示。 某系统有5 个副本，W=3，R=3，最初5 个副本的数据一致，都是v1，某次更新操作 w2 在前3 副本上成功，副本情况变成（v2 v2 v2 v1 v1）。此时，任意3 个副本组成的集合中一定包括 v2。在上述定义中，令W=N，R=1，就得到WARO，即WARO 是Quorum 机制的一种特例。与分析WARO 相似，分析Quorum 机制的可用性。限制Quorum 参数为W+R=N+1。由于更新 操作需要在W 个副本上都成功，更新操作才能成功，所以一旦N-W+1 个副本异常，更新操作始终无法在W 个副本上成功，更新服务不可用。另一方面，一旦N-R+1 个副本异常，则无法保证一定可以读到与W 个副本有交集的副本集合，则读服务的一致性下降。 再次强调：仅仅依赖quorum 机制是无法保证强一致性的。因为仅有quorum 机制时无法确定最新已成功提交的版本号，除非将最新已提交的版本号作为元数据由特定的元数据服务器或元数据集群管理，否则很难确定最新成功提交的版本号。在下一节中，将讨论在哪些情况下，可以仅仅 通过quorum 机制来确定最新成功提交的版本号。 Quorum 机制的三个系统参数N、W、R 控制了系统的可用性，也是系统对用户的服务承诺：数据最多有N 个副本，但数据更新成功W 个副本即返回用户成功。对于一致性要求较高的Quorum 系统，系统还应该承诺任何时候不读取未成功提交的数据，即读取到的数据都是曾经在W 个副本上成功的数据。 读取最新成功提交的数据Quorum 机制只需成功更新N 个副本中的W 个，在读取R 个副本时，一定可以读到最新的成功提交的数据。但由于有不成功的更新情况存在，仅仅读取R 个副本却不一定能确定哪个版本的数据 是最新的已提交的数据。对于一个强一致性Quorum 系统，若存在个数据少于W 个，假设为X 个，则继续读取其他副本，直若成功读取到W 个 该版本的副本，则该数据为最新的成功提交的数据；如果在所有副本中该数据的个数肯定不满 足W 个，则R 中版本号第二大的为最新的成功提交的副本。例：在读取到（v2 v1 v1）时，继续读取剩余的副本，若读到剩余两个副本 为（v2 v2）则v2 是最新的已提交的副本；若读到剩余的两个副本为（v2 v1）或（v1 v1）则v1 是最新成功提交的版本；若读取后续两个副本有任一超时或失败，则无法判断哪个版本是最新的成功提交的版本。 可以看出，在单纯使用Quorum 机制时，若要确定最新的成功提交的版本，最多需要读取R+ （W-R-1）=N 个副本，当出现任一副本异常时，读最新的成功提交的版本这一功能都有可能不可用。实际工程中，应该尽量通过其他技术手段，回避通过Quorum 机制读取最新的成功提交的版本。例如，当quorum 机制与primary-secondary 控制协议结合使用时，可以通过读取primary 的方式读取到最新的已提交的数据。 基于Quorum 机制选择primary副本读取数据时依照一致性要求的不同可以有不同的做法：如果需要强一致性的立刻读取到最新的成功提交的数据，则可以简单的只读取primary 副本上的数据即可，也可以通过上节的方式读取；如果需要会话一致性，则可以根据之前已经读到的数据版本号在各个副本上进行选择性读取；如果只需要弱一致性，则可以选择任意副本读取。 在primary-secondary 协议中，当primary 异常时，需要选择出一个新的primary，之后secondary 副本与primary 同步数据。通常情况下，选择新的primary 的工作是由某一中心节点完成的，在引入 quorum 机制后，常用的primary 选择方式与读取数据的方式类似，即中心节点读取R 个副本，选择 R 个副本中版本号最高的副本作为新的primary。新primary 与至少W 个副本完成数据同步后作为新的primary 提供读写服务。首先，R 个副本中版本号最高的副本一定蕴含了最新的成功提交的数据。再者，虽然不能确定最高版本号的数是一个成功提交的数据，但新的primary 在随后与secondary 同 步数据，使得该版本的副本个数达到W，从而使得该版本的数据成为成功提交的数据。 例：在N=5，W=3，R=3 的系统中，某时刻副本最大版本号为（v2 v2 v1 v1 v1），此时v1 是系统的最新的成功提交的数据，v2 是一个处于中间状态的未成功提交的数据。假设此刻原primary 副本异常，中心节点进行primary 切换工作。这类“中间态”数据究竟作为“脏数据”被删除，还是作为新的数据被同步后成为生效的数据，完全取决于这个数据能否参与新primary 的选举。下面分别分析这两种情况。 第一、如图 2-12，若中心节点与其中3 个副本通信成功，读取到的版本号为（v1 v1 v1），则任 选一个副本作为primary，新primary 以v1 作为最新的成功提交的版本并与其他副本同步，当与第1、第2 个副本同步数据时，由于第1、第2 个副本版本号大于primary，属于脏数据，可以按照2.2.2.4 节中介绍的处理脏数据的方式解决。实践中，新primary 也有可能与后两个副本完成同步后就提供数据服务，随后自身版本号也更新到v2，如果系统不能保证之后的v2 与之前的v2 完全一样，则新 primary 在与第1、2 个副本同步数据时不但要比较数据版本号还需要比较更新操作的具体内容是否一样。 第二、若中心节点与其他3 个副本通信成功，读取到的版本号为（v2 v1 v1），则选取版本号为 v2 的副本作为新的primary，之后，一旦新primary 与其他2 个副本完成数据同步，则符合v2 的副 本个数达到W 个，成为最新的成功提交的副本，新primary 可以提供正常的读写服务。 日志技术日志技术是宕机恢复的主要技术之一。日志技术最初使用在数据库系统中。严格来说日志技术不是一种分布式系统的技术，但在分布式系统的实践中，却广泛使用了日志技术做宕机恢复，甚 至如BigTable 等系统将日志保存到一个分布式系统中进一步增强了系统容错能力。 Redo Log 与Check point设计一个高速的单机查询系统，将数据全部存放在内存中以实现高速的数据查询，每次更新操作更新一小部分数据（例如 key-value 中的某一个key）。现在问题为利用日志技术实现该内存查询系统的宕机恢复。与数据库的事务不同的是，这个问题模型中的每个成功的更新操作都会生效。这也等效为数据库的每个事务只有一个更新操作，且每次更新操作都可以也必须立即提交（Auto commit）。 Redo Log 将更新操作的结果（例如Set K1=1，则记录K1=1）以追加写（append）的方式写入磁盘的 日志文件 按更新操作修改内存中的数据 返回更新成功 从Redo Log 的流程可以看出，Redo 写入日志的是更新操作完成后的结果（虽然本文不讨论Undo Log，这点是与Undo Log 的区别之一），且由于是顺序追加写日志文件，在磁盘等对顺序写有力的 存储设备上效率较高。 用Redo Log 进行宕机恢复非常简单，只需要“回放”日志即可。 流程2.5.2：Redo Log 的宕机恢复 从头读取日志文件中的每次更新操作的结果，用这些结果修改内存中的数据。 从Redo Log 的宕机恢复流程也可以看出，只有写入日志文件的更新结果才能在宕机后恢复。这也是为什么在Redo Log 流程中需要先更新日志文件再更新内存中的数据的原因。假如先更新内存中的数据，那么用户立刻就能读到更新后的数据，一旦在完成内存修改与写入日志之间发生宕机，那么最后一次更新操作无法恢复，但之前用户可能已经读取到了更新后的数据，从而引起不一致的问题。 Check point 。在简化的模型下，check point 技术的过程即将内存中的数据以某种易于重新加载的数据组织方式完整的dump 到磁盘，从而减少宕机恢复时需要回放的日志数据。 流程：check point 向日志文件中记录“Begin Check Point” 将内存中的数据以某种易于重新加载的数据组织方式dump 到磁盘上 向日志文件中记录“End Check Point” 在check point 流程中，数据可以继续按照流程2.5.1 被更新，这段过程中新更新的数据可以dump 到磁盘也可以不dump 到磁盘，具体取决于实现。例如，check point 开始时k1=v1，check point 过程 中某次更新为k1 = v2，那么dump 到磁盘上的k1 的值可以是v1 也可以是v2。 流程：基于check point 的宕机恢复流程 将dump 到磁盘的数据加载到内存。 从后向前扫描日志文件，寻找最后一个“End Check Point”日志。 从最后一个“End Check Point”日志向前找到最近的一个“Begin Check Point”日志，并回 放该日志之后的所有更新操作日志。 No Undo/No Redo log 若数据维护在磁盘中，某批更新由若干个更新操作组成，这些更新操作需要原子生效，即要么同时生效，要么都不生效。 0/1 目录技术中有两个目录结构，称为目录0(Directory 0)和目录1(Directory 1)。另有一个结构称为主记录（Master record）记录当前正在使用的目录称为活动目录。主记录中要么记录使用目录0，要么记录使用目录1。目录0 或目录1 中记录了各个数据的在日志文件中的位置。0/1 目录的数据更新过程始终在非活动目录上进行，只是在数据生效前，将主记录中的0、1 值反转，从而切换主记录。 流程：0/1 目录数据更新流程 将活动目录完整拷贝到非活动目录。 对于每个更新操作，新建一个日志项纪录操作后的值，并在非活动目录中将相应数据的位置修改为新建的日志项的位置。 原子性修改主记录：反转主记录中的值，使得非活动目录生效。 0/1 目录的更新流程非常简单，通过0、1 目录的主记录切换使得一批修改的生效是原子的。0/1 目录将批量事务操作的原子性通过目录手段归结到主记录的原子切换。由于多条记录的原子修改一般较难实现而单条记录的原子修改往往可以实现，从而降低了问题实现的难度。在工程中0/1 目录的思想运用非常广泛，其形式也不局限在上述流程中，可以是内存中的两个数据结构来回切换，也可以是磁盘上的两个文件目录来回生效切换。 两阶段提交协议两阶段提交协议是一种经典的强一致性中心化副本控制协议。虽然在工程中该协议有较多的问题，但研究该协议能很好的理解分布式系统的几个典型问题。 流程描述两阶段提交协议是一种典型的“中心化副本控制”协议。在该协议中，参与的节点分为两类：一个中心化协调者节点（coordinator）和N 个参与者节点（participant）。每个参与者节点即上文背景介绍中的管理数据库副本的节点。 两阶段提交的思路比较简单，在第一阶段，协调者询问所有的参与者是否可以提交事务（请参与者投票），所有参与者向协调者投票。在第二阶段，协调者根据所有参与者的投票结果做出是否事务可以全局提交的决定，并通知所有的参与者执行该决定。在一个两阶段提交流程中，参与者不能改变自己的投票结果。两阶段提交协议的可以全局提交的前提是所有的参与者都同意提交事务，只要有一个参与者投票选择放弃(abort)事务，则事务必须被放弃。 流程：两阶段提交协调者流程 写本地日志“begin_commit”，并进入WAIT 状态； 向所有参与者发送“prepare 消息”； 等待并接收参与者发送的对“prepare 消息”的响应；3.1 若收到任何一个参与者发送的“vote-abort 消息”；3.1.1 写本地“global-abort”日志，进入ABORT；3.1.2 向所有的参与者发送“global-abort 消息”；3.1.3 进入ABORT 状态；3.2 若收到所有参与者发送的“vote-commit”消息；3.2.1 写本地“global-commit”日志，进入COMMIT 状态；3.1.2 向所有的参与者发送“global-commit 消息”； 等待并接收参与者发送的对“global-abort 消息”或“global-commit 消息”的确认响应消息，一旦收到所有参与者的确认消息，写本地“end_transaction” 日志流程结束。 流程：两阶段提交协调者流程 写本地日志“init”记录，进入INIT 状态 等待并接受协调者发送的“prepare 消息”，收到后 2.1 若参与者可以提交本次事务 2.1.1 写本地日志“ready”，进入READY 状态 2.1.2 向协调者发送“vote-commit”消息 2.1.4 等待协调者的消息2.1.4.1 若收到协调者的“global-abort”消息2.1.4.1.1 写本地日志“abort”，进入ABORT 状态2.1.4.1.2 向协调者发送对“global-abort”的确认消息 2.1.4.2 若收到协调者的“global-commit”消息2.1.4.1.1 写本地日志“commit”，进入COMMIT 状态 2.1.4.1.2 向协调者发送对“global-commit”的确认消息 2.2 若参与者无法提交本次事务 2.2.1 写本地日志“abort”，进入ABORT 状态 2.2.2 向协调者发送“vote-abort”消息 2.2.3 流程对该参与者结束 2.2.4 若后续收到协调者的“global-abort”消息可以响应 即使流程结束，但任何时候收到协调者发送的“global-abort”消息或“global-commit”消息也都要发送一个对应的确认消息。 异常处理宕机恢复 协调者宕机恢复 协调者宕机恢复后，首先通过日志查找到宕机前的状态。如果日志中最后是“begin_commit”记录，说明宕机前协调者处于WAIT 状态，协调者可能已经发送过“prepare 消息”也可能还没发送，但协调者一定还没有发送过“global-commit 消息”或“global-abort 消息”，即事务的全局状态还没有确定。此时，协调者可以重新发送“prepare 消息” 继续两阶段提交流程，即使参与者已经发送过对“prepare 消息”的响应，也不过是再次重传之前的响应而不会影响协议的一致性。如果日志中最后是“global-commit”或“global-abort”记录，说明宕机前协调者处于COMMIT 或ABORT 状态。此时协调者只需重新向所有的参与者发送“global-commit 消息”或“global-abort 消息”就可以继续两阶段提交流程。 参与者宕机恢复参与者宕机恢复后，首先通过日志查找宕机前的状态。如果日志中最后是“init”记录，说明参与者处于INIT 状态，还没有对本次事务做出投票选择，参与者可以继续流程等待协调者发送的“prepare 消息”。如果日志中最后是“ready”记录，说明参与者处于REDAY 状态，此时说明参与者已经就本次 事务做出了投票选择，但宕机前参与者是否已经向协调者发送“vote-commit”消息并不可知。所以此时参与者可以向协调者重发“vote-commit”，并继续协议流程。如果日志中最后是“commit”或“abort”记录，说明参与者已经收到过协调者的“global-commit 消息”（处于COMMIT 状态）或者“global-abort 消息”（处于ABORT 状态）。至于是否向协调者发 送过对“global-commit”或“global-abort”的确认消息则未知。但即使没有发送过确认消息，由于协调者会不断重发“global-commit”或“global-abort”，只需在收到这些消息时发送确认消息既可，不影响协议的全局一致性。 协议分析两阶段提交协议在工程实践中真正使用的较少，主要原因有以下几点： 两阶段提交协议的容错能力较差。从上文的分析可以看出，两阶段提交协议在某些情况下存在流程无法执行下去的情况，且也无法判断流程状态。在工程中好的分布式协议往往总是可以在即使发生异常的情况下也能执行下去。例如，回忆Lease 机制（2.3 ），一旦lease 发出，无论出现任何异常，Lease 服务器节点总是可以通过时间判定出Lease 是否有效，也可以用等待Lease 超时的方法收回Lease 权限，整个Lease 协议的流程不存在任何流程被阻塞而无法执行下去的情况。与Lease 机制的简单有效相比，两阶段提交的协议显得较为复杂且容错能力差。 两阶段提交协议的性能较差。一次成功的两阶段提交协议流程中，协调者与每个参与者 之间至少需要两轮交互4 个消息“prepare”、“vote-commit”、“global-commit”、“确认global-commit”。过多的交互次数会降低性能。另一方面，协调者需要等待所有的参与者的投票结果，一旦存在较慢的参与者，会影响全局流程执行速度。 虽然存在一些改进的两阶段提交协议可以提高容错能力和性能，然而这类协议依旧是在工程中使用较少的一类协议，其理论价值大于实践意义。 MVCCMVCC(Multi-version Cocurrent Control，多版本并发控制)技术。MVCC 技术最初也是在数据库系统中被提出，但这种思想并不局限于单机的分布式系统，在分布式系统中同样有效。 MVCC 即多个不同版本的数据实现并发控制的技术，其基本思想是为每次事务生成 一个新版本的数据，在读数据时选择不同版本的数据即可以实现对事务结果的完整性读取。在使用MVCC 时，每个事务都是基于一个已生效的基础版本进行更新，事务可以并行进行，从而可以产生一种图状结构。 基础数据的版本为1，同时产生了两个事务：事务A 与事务B。这两个事务都各自对数据进行了一些本地修改（这些修改只有事务自己可见，不影响真正的数据），之后事务A 首先提交，生成数据版本2；基于数据版本2，又发起了事务C，事务C 继续提交，生成了数据版 本3；最后事务B 提交，此时事务B 的结果需要与事务C 的结果合并，如果数据没有冲突，即事务 B 没有修改事务A 与事务C 修改过的变量，那么事务B 可以提交，否则事务B 提交失败。MVCC 的流程过程非常类似于SVN 等版本控制系统的流程，或者说SVN 等版本控制系统就是 使用的MVCC 思想。事务在基于基础数据版本做本地修改时，为了不影响真正的数据，通常有两种做法，一是将基础数据版本中的数据完全拷贝出来再修改，SVN 即使用了这种方法，SVN check out 即是拷贝的过程；二是每个事务中只记录更新操作，而不记录完整的数据，读取数据时再将更新操作应用到用基础版本的数据从而计算出结果，这个过程也类似SVN 的增量提交。 Paxos协议Paxos 协议是少数在工程实践中证实的强一致性、高可用的去中心化分布式协议。Paxos 协议的流程较为复杂，但其基本思想却不难理解，类似于人类社会的投票过程。Paxos 协议中，有一组完全对等的参与节点（称为accpetor），这组节点各自就某一事件做出决议，如果某个决议获得了超过半数节点的同意则生效。Paxos 协议中只要有超过一半的节点正常，就可以工作，能很好对抗宕机、网络分化等异常情况。 角色Proposer：提案者。Proposer 可以有多个，Proposer 提出议案（value）。所谓value，在工程中可以是任何操作，例如“修改某个变量的值为某个值”、“设置当前primary 为某个节点”等等。Paxos 协议中统一将这些操作抽象为value。不同的Proposer 可以提出不同的甚至矛盾的value，例如某个Proposer 提议“将变量X 设置为1”，另一个Proposer 提议“将变量X 设置为2”，但对同一轮Paxos 过程，最多只有一个value 被批准。Acceptor：批准者。Acceptor 有N 个，Proposer 提出的value 必须获得超过半数(N/2+1)的Acceptor 批准后才能通过。Acceptor 之间完全对等独立。Learner：学习者。Learner 学习被批准的value。所谓学习就是通过读取各个Proposer 对value 的选择结果，如果某个value 被超过半数Proposer 通过，则Learner 学习到了这个value。回忆（2.4 ） 不难理解，这里类似Quorum 机制，某个value 需要获得W=N/2 + 1 的Acceptor 批准，从而学习者需要至少读取N/2+1 个Accpetor，至多读取N 个Acceptor 的结果后，能学习到一个通过的value。上述三类角色只是逻辑上的划分，实践中一个节点可以同时充当这三类角色。 流程Paxos 协议一轮一轮的进行，每轮都有一个编号。每轮Paxos 协议可能会批准一个value，也可 能无法批准一个value。如果某一轮Paxos 协议批准了某个value，则以后各轮Paxos 只能批准这个 value。上述各轮协议流程组成了一个Paxos 协议实例，即一次Paxos 协议实例只能批准一个value，这也是Paxos 协议强一致性的重要体现。每轮Paxos 协议分为阶段，准备阶段和批准阶段，在这两个阶段Proposer 和Acceptor 有各自的处理流程。 流程：Proposer 的流程 （准备阶段） 向所有的Acceptor 发送消息“Prepare(b)”；这里b 是Paxos 的轮数，每轮递增 如果收到任何一个Acceptor 发送的消息“Reject(B)”，则对于这个Proposer 而言本轮Paxos 失败，将轮数b 设置为B+1 后重新步骤1；（批准阶段，根据收到的Acceptor 的消息作出不同选择） 如果接收到的Acceptor 的“Promise(b, v_i)”消息达到N/2+1 个（N 为Acceptor 总数，除法取整， 下同）；v_i 表示Acceptor 最近一次在i 轮批准过value v。3.1 如果收到的“Promise(b, v)”消息中，v 都为空，Proposer 选择一个value v，向所有Acceptor 广播Accept(b, v)；3.2 否则，在所有收到的“Promise(b, v_i)”消息中，选择i 最大的value v，向所有Acceptor 广播消息Accept(b，v)； 如果收到Nack(B)，将轮数b 设置为B+1 后重新步骤1； 流程：Accpetor 流程 （准备阶段） 接受某个Propeser 的消息Prepare(b)。参数B 是该Acceptor 收到的最大Paxos 轮数编号；V 是Acceptor 批准的value，可以为空 1.1 如果b&gt;B，回复Promise(b, V_B)，设置B=b; 表示保证不再接受编号小于b 的提案。1.2 否则，回复Reject(B) （批准阶段） 接收Accept(b, v)， 2.1 如果b &lt; B, 回复Nack(B)，暗示proposer 有一个更大编号的提案被这个Acceptor 接收了 2.2 否则设置V=v。表示这个Acceptor 批准的Value 是v。广播Accepted 消息。 例子基本例子里有5 个Acceptor，1 个Proposer，不存在任何网络、宕机异常。我们着重考察各个Accpetor 上变量B 和变量V 的变化，及Proposer 上变量b 的变化。 初始状态 Proposer 向所有Accpetor 发送“Prepare(1)”，所有Acceptor 正确处理，并回复Promise(1, NULL) Proposer 收到5 个Promise(1, NULL)，满足多余半数的Promise 的value 为空，此时发送 Accept(1, v1)，其中v1 是Proposer 选择的Value。 此时，v1 被超过半数的Acceptor 批准，v1 即是本次Paxos 协议实例批准的Value。如果Learner 学习value，学到的只能是v1 在同一个Paxos 实例中，批准的Value 是无法改变的，即使后续Proposer 以更高的序号发起Paxos 协议也无法改变value。Paxos 协议的核心就在于“批准的value 无法改变”，这也是整个协议正确性的基础。 Paxos 协议是被人为设计出来，其设计过程也是协议的推导过程。Paxos 协议利用了Quorom 机 制，选择的W=R=N/2+1。简单而言，协议就是Proposer 更新Acceptor 的过程，一旦某个Acceptor 成功更新了超过半数的Acceptor，则更新成功。Learner 按Quorum 去读取Acceptor，一旦某个value 在超过半数的Proposer 上被成功读取，则说明这是一个被批准的value。协议通过引入轮次，使得高轮次的提议抢占低轮次的提议来避免死锁。协议设计关键点是如何满足“在一次Paxos 算法实例过程中只批准一个Value”这一约束条件。 CAPCAP 理论的定义很简单，CAP 三个字母分别代表了分布式系统中三个相互矛盾的属性： Consistency (一致性)：CAP 理论中的副本一致性特指强一致性（1.3.4 ）； Availiablity(可用性)：指系统在出现异常时已经可以提供服务； Tolerance to the partition of network (分区容忍)：指系统可以对网络分区（1.1.4.2 ）这种异常情 况进行容错处理； CAP 理论指出：无法设计一种分布式协议，使得同时完全具备CAP 三个属性，即1)该种协议下的副本始终是强一致性，2)服务始终是可用的，3)协议可以容忍任何网络分区异常；分布式系统协议只能在CAP 这三者间所有折中。 热力学第二定律说明了永动机是不可能存在的，不要去妄图设计永动机。与之类似，CAP 理论的意义就在于明确提出了不要去妄图设计一种对CAP 三大属性都完全拥有的完美系统，因为这种系统在理论上就已经被证明不存在。 Lease 机制: Lease 机制牺牲了部分异常情况下的A，从而获得了完全的C 与很好的P。 Quorum 机制: Quorum 机制，在CAP 三大因素中都各做了折中，有一定的C，有较好 的A，也有较好的P，是一种较为平衡的分布式协议。 两阶段提交协议: 两阶段提交系统具有完全的C，很糟糕的A，很糟糕的P。 Paxos 协议：同样是强一致性协议，Paxos 在CAP 三方面较之两阶段提交协议要优秀得多。Paxos 协议具有 完全的C，较好的A，较好的P。Paxos 的A 与P 的属性与Quorum 机制类似，因为Paxos 的协议本 身就具有Quorum 机制的因素。 分布式服务框架目前业界比较流行的分布式服务框架有：阿里的Dubbo、Spring Cloud。这里不对这些分布式服务框架做对比，简单的说说他们都做了些什么，能使我们掉用远程服务就像掉用本地服务那么简单高效。除下述内容外，分布式系统涉及到的东西还有很多，如：分布式锁、定时调度、数据分片、性能问题、各种中间件的使用等。 服务服务是对使用用户有功能输出的模块，以技术框架作为基础，能实现用户的需求。比如日志记录服务、权限管理服务、后台服务、配置服务、缓存服务、存储服务、消息服务等，这些服务可以灵活的组合在一起，也可以独立运行。服务需要有接口，与系统进行对接。面向服务的开发，应该是把服务拆分开发，把服务组合运行。更加直接的例子如：历史详情、留言板、评论、评级服务等。他们之间能独立运行，也要能组合在一起作为一个整体。 注册中心注册中心对整个分布式系统起着最为核心的整合作用，支持对等集群，需要提供CRUD接口，支持订阅发布机制且可靠性要求非常之高，一般拿zookeeper集群来做为注册中心。 分布式环境中服务提供方的服务会在多台服务器上部署，每台服务器会向注册中心提供服务方标识、服务列表、地址、对应端口、序列化协议等信息。注册中心记录下服务和服务地址的映射关系，一般一个服务会对应多个地址,这个过程我们称之为服务发布或服务注册。服务调用方会根据服务方标识、服务列表从注册中心获取所需服务的信息（地址端口信息、序列化协议等），这些信息会缓存至本地。当服务需要调用其它服务时，直接在这里找到服务的地址，进行调用，这个过程我们称之为服务发现。 注册中心 下面是以zookeeper作为注册中心的简单实现： 1234567891011121314151617181920/** * 创建node节点 * @param node * @param data */ public boolean createNode(String node, String data) &#123; try &#123; byte[] bytes = data.getBytes(); //同步创建临时顺序节点 String path = zk.create(ZkConstant.ZK_RPC_DATA_PATH+\"/\"+node+\"-\", bytes, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); log.info(\"create zookeeper node (&#123;&#125; =&gt; &#123;&#125;)\", path, data); &#125;catch (KeeperException e) &#123; log.error(\"\", e); return false; &#125;catch (InterruptedException ex)&#123; log.error(\"\", ex); return false; &#125; return true; &#125; 如下面zookeeper中写入的临时顺序节点信息： 子节点1子节点2- com.black.blackrpc.test.HelloWord （发布服务时对外的名称）- 00000000010，00000000011 （zk 顺序节点id）- 127.0.0.1:8888，127.0.0.1:8889 （服务地址端口）- Protostuff （序列化方式） 1.0 （权值，负载均衡策略使用）这里使用的是zookeeper的临时顺序节点，为什么使用临时顺序节点。主要是考虑以下两点：一、 当服务提供者异常下线时，与zookeeper的连接会中断，zookeeper服务器会主动删除临时节点，同步给服务消费者。这样就能避免服务消费者去请求异常的服务器。&gt; 校稿注： 一般消费方也会在实际发起请求前，对当前获取到的服务提供方节点进行心跳，避免请求连接有问题的节点二、 zk下面是不允许创建2个名称相同的zk子节点的，通过顺序节点就能避免创建相同的名称。当然也可以不用顺序节点的方式,直接以com.black.blackrpc.test.HelloWord创建节点，在该节点下创建数据节点。下面是zk的数据同步过程：12345678910111213141516171819202122232425262728293031323334353637383940/** * 同步节点 （通知模式） * syncNodes会通过级联方式，在每次watcher被触发后，就会再挂上新的watcher。完成了类似链式触发的功能 */ public boolean syncNodes() &#123; try &#123; List&lt;String&gt; nodeList = zk.getChildren(ZkConstant.ZK_RPC_DATA_PATH, new Watcher() &#123; @Override public void process(WatchedEvent event) &#123; if (event.getType() == Event.EventType.NodeChildrenChanged) &#123; syncNodes(); &#125; &#125; &#125;); Map&lt;String,List&lt;String&gt;&gt; map =new HashMap&lt;String,List&lt;String&gt;&gt;(); for (String node : nodeList) &#123; byte[] bytes = zk.getData(ZkConstant.ZK_RPC_DATA_PATH + \"/\" + node, false, null); String key =node.substring(0, node.lastIndexOf(ZkConstant.DELIMITED_MARKER)); String value=new String(bytes); Object object =map.get(key); if(object!=null)&#123; ((List&lt;String&gt;)object).add(value); &#125;else &#123; List&lt;String&gt; dataList = new ArrayList&lt;String&gt;(); dataList.add(value); map.put(key,dataList); &#125; log.info(\"node: [&#123;&#125;] data: [&#123;&#125;]\",node,new String(bytes)); &#125; /**修改连接的地址缓存*/ if(MapUtil.isNotEmpty(map))&#123; log.debug(\"invoking service cache updateing....\"); InvokingServiceCache.updataInvokingServiceMap(map); &#125; return true; &#125; catch (KeeperException | InterruptedException e) &#123; log.error(e.toString()); return false; &#125; &#125;当数据同步到本地时，一般会写入到本地文件中，防止因zookeeper集群异常下线而无法获取服务提者信息。### 通讯与协议服务消费者无论是与注册中心还是与服务提供者，都需要存在网络连接传输数据，而这就涉及到通讯。笔者之前也做过这方面的工作，当时使用的是java BIO简单的写了一个通讯包，使用场景没有多大的并发,阻塞式的BIO也未暴露太多问题。java BIO因其建立连接之后会阻塞线程等待数据，这种方式必须以一连接一线程的方式，即客户端有连接请求时服务器端就需要启动一个线程进行处理。当连接数过大时，会建立相当多的线程，性能直线下降。- Java NIO : 同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。- Java AIO : 异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理， BIO、NIO、AIO适用场景分析:- BIO 用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，但程序直观简单易理解。- NIO 适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，目前主流的通讯框架 Netty、Apache Mina、Grizzl、NIO Framework都是基于其实现的。- AIO 用于连接数目多且连接比较长（重操作）的架构，比如图片服务器，文件传输等，充分调用OS参与并发操作，编程比较复杂。 (有兴趣可以看看这篇文章：BIO与NIO、AIO的区别 ) ​ 作为基石的通讯，其实要考虑很多东西。如：丢包粘包的情况，心跳机制，断连重连，消息缓存重发，资源的优雅释放，长连接还是短连接等。下面是Netty建立服务端，客户端的简单实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelPipeline;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.codec.LengthFieldBasedFrameDecoder;import io.netty.handler.codec.LengthFieldPrepender;import io.netty.handler.codec.bytes.ByteArrayDecoder;import io.netty.handler.codec.bytes.ByteArrayEncoder;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/*** * netty tcp 服务端 * @author v_wangshiyu * */public class NettyTcpService &#123; private static final Logger log = LoggerFactory.getLogger(NettyTcpService.class); private String host; private int port; public NettyTcpService(String address) throws Exception&#123; String str[] = address.split(\":\"); this.host=str[0]; this.port=Integer.valueOf(str[1]); &#125; public NettyTcpService(String host,int port) throws Exception&#123; this.host=host; this.port=port; &#125; /**用于分配处理业务线程的线程组个数 */ private static final int BIZGROUPSIZE = Runtime.getRuntime().availableProcessors()*2; //默认 /** 业务出现线程大小*/ private static final int BIZTHREADSIZE = 4; /* * NioEventLoopGroup实际上就是个线程, * NioEventLoopGroup在后台启动了n个NioEventLoop来处理Channel事件, * 每一个NioEventLoop负责处理m个Channel, * NioEventLoopGroup从NioEventLoop数组里挨个取出NioEventLoop来处理Channel */ private static final EventLoopGroup bossGroup = new NioEventLoopGroup(BIZGROUPSIZE); private static final EventLoopGroup workerGroup = new NioEventLoopGroup(BIZTHREADSIZE); public void start() throws Exception &#123; log.info(\"Netty Tcp Service Run...\"); ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup); b.channel(NioServerSocketChannel.class); b.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(\"frameDecoder\", new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); pipeline.addLast(\"frameEncoder\", new LengthFieldPrepender(4)); pipeline.addLast(\"decoder\", new ByteArrayDecoder()); pipeline.addLast(\"encoder\", new ByteArrayEncoder()); // pipeline.addLast(new Encoder()); // pipeline.addLast(new Decoder()); pipeline.addLast(new TcpServerHandler()); &#125; &#125;); b.bind(host, port).sync(); log.info(\"Netty Tcp Service Success!\"); &#125; /** * 停止服务并释放资源 */ public void shutdown() &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125;&#125;123456789101112131415import org.slf4j.Logger;import org.slf4j.LoggerFactory;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.SimpleChannelInboundHandler;/** * 服务端处理器 */public class TcpServerHandler extends SimpleChannelInboundHandler&lt;Object&gt;&#123; private static final Logger log = LoggerFactory.getLogger(TcpServerHandler.class); @Override protected void channelRead0(ChannelHandlerContext ctx, Object msg) throws Exception &#123; byte[] data=(byte[])msg; &#125;&#125;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130import org.slf4j.Logger;import org.slf4j.LoggerFactory;import io.netty.bootstrap.Bootstrap;import io.netty.channel.Channel;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.ChannelPipeline;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.nio.NioSocketChannel;import io.netty.handler.codec.LengthFieldBasedFrameDecoder;import io.netty.handler.codec.LengthFieldPrepender;import io.netty.handler.codec.bytes.ByteArrayDecoder;import io.netty.handler.codec.bytes.ByteArrayEncoder;import io.netty.util.concurrent.Future;/** * netty tcp 客户端 * @author v_wangshiyu * */public class NettyTcpClient &#123; private static final Logger log = LoggerFactory.getLogger(NettyTcpClient.class); private String host; private int port; private Bootstrap bootstrap; private Channel channel; private EventLoopGroup group; public NettyTcpClient(String host,int port)&#123; bootstrap=getBootstrap(); channel= getChannel(host,port); this.host=host; this.port=port; &#125; public String getHost() &#123; return host; &#125; public int getPort() &#123; return port; &#125; /** * 初始化Bootstrap * @return */ public final Bootstrap getBootstrap()&#123; group = new NioEventLoopGroup(); Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class); b.handler(new ChannelInitializer&lt;Channel&gt;() &#123; @Override protected void initChannel(Channel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); // pipeline.addLast(new Encoder()); // pipeline.addLast(new Decoder()); pipeline.addLast(\"frameDecoder\", new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); pipeline.addLast(\"frameEncoder\", new LengthFieldPrepender(4)); pipeline.addLast(\"decoder\", new ByteArrayDecoder()); pipeline.addLast(\"encoder\", new ByteArrayEncoder()); pipeline.addLast(\"handler\", new TcpClientHandler()); &#125; &#125;); b.option(ChannelOption.SO_KEEPALIVE, true); return b; &#125; /** * 连接，获取Channel * @param host * @param port * @return */ public final Channel getChannel(String host,int port)&#123; Channel channel = null; try &#123; channel = bootstrap.connect(host, port).sync().channel(); return channel; &#125; catch (Exception e) &#123; log.info(String.format(\"connect Server(IP[%s],PORT[%s]) fail!\", host,port)); return null; &#125; &#125; /** * 发送消息 * @param msg * @throws Exception */ public boolean sendMsg(Object msg) throws Exception &#123; if(channel!=null)&#123; channel.writeAndFlush(msg).sync(); log.debug(\"msg flush success\"); return true; &#125;else&#123; log.debug(\"msg flush fail,connect is null\"); return false; &#125; &#125; /** * 连接断开 * 并且释放资源 * @return */ public boolean disconnectConnect()&#123; //channel.close().awaitUninterruptibly(); Future&lt;?&gt; future =group.shutdownGracefully();//shutdownGracefully释放所有资源，并且关闭所有当前正在使用的channel future.syncUninterruptibly(); return true; &#125;&#125;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.SimpleChannelInboundHandler;/** * 客户端处理器 */public class TcpClientHandler extends SimpleChannelInboundHandler&lt;Object&gt;&#123; private static final Logger log = LoggerFactory.getLogger(TcpClientHandler.class); @Override protected void channelRead0(ChannelHandlerContext ctx, Object msg) throws Exception &#123; byte[] data=(byte[])msg; &#125;&#125;说到通讯就不能不说协议，通信时所遵守的规则，访问什么，传输的格式等都属于协议。作为一个开发人员，应该都了解TCP/IP协议，它是一个网络通信模型，以及一整套网络传输协议家族，是互联网的基础通信架构。也都应该用过http（超文本传输协议），Web服务器传输超文本到本地浏览器的传送协议，该协议建立在TCP/IP协议之上。分布式服务框架服务间的调用也会规定协议。为了支持不同场景，分布式服务框架会存在多种协议，如Dubbo就支持7种协议：dubbo协议(默认)，rmi协议，hessian协议，http协议，webservice协议，thrift协议，memcached协议，redis协议每种协议应对的场景不尽相同，具体场景具体对待。 (这里详细介绍了Dubbo 的协议：Dubbo 的7种协议 )### 服务路由分布式服务上线时都是集群组网部署，集群中会存在某个服务的多实例，消费者如何从服务列表中选择合适的服务提供者进行调用，这就涉及到服务路由。分布式服务框架需要能够满足用户灵活的路由需求。#### 透明化路由很多开源的RPC框架调用者需要配置服务提供者的地址信息，尽管可以通过读取数据库的服务地址列表等方式避免硬编码地址信息，但是消费者依然要感知服务提供者的地址信息，这违反了透明化路由原则。而基于服务注册中心的服务订阅发布，消费者通过主动查询和被动通知的方式获取服务提供者的地址信息，而不再需要通过硬编码方式得到提供者的地址信息，只需要知道当前系统发布了那些服务，而不需要知道服务具体存在于什么位置，这就是透明化路由。 #### 负载均衡负载均衡策略是服务的重要属性，分布式服务框架通常会提供多种负载均衡策略，同时支持用户扩展负载均衡策略。##### 随机通常在对等集群组网中，采用随机算法进行负债均衡，随机路由算法消息分发还是比较均匀的，采用JDK提供的java.util.Random或者java.security.SecureRandom在指定服务提供者列表中生成随机地址。消费者基于随机生成的服务提供者地址进行远程调用。1234567891011/** * 随机 */public class RandomStrategy implements ClusterStrategy &#123; @Override public RemoteServiceBase select(List&lt;RemoteServiceBase&gt; list) &#123; int MAX_LEN = list.size(); int index = RandomUtil.nextInt(MAX_LEN); return list.get(index); &#125;&#125;随机还是存在缺点的，可能出现部分节点的碰撞的概率较高，另外硬件配置差异较大时，会导致各节点负载不均匀。为避免这些问题，需要对服务列表加权，性能好的机器接收的请求的概率应该高于一般机器。1234567891011121314151617181920/** * 加权随机 */public class WeightingRandomStrategy implements ClusterStrategy &#123; @Override public RemoteServiceBase select(List&lt;RemoteServiceBase&gt; list) &#123; //存放加权后的服务提供者列表 List&lt;RemoteServiceBase&gt; weightingList = new ArrayList&lt;RemoteServiceBase&gt;(); for (RemoteServiceBase remoteServiceBase : list) &#123; //扩大10倍 int weight = (int) (remoteServiceBase.getWeight()*10); for (int i = 0; i &lt; weight; i++) &#123; weightingList.add(remoteServiceBase); &#125; &#125; int MAX_LEN = weightingList.size(); int index = RandomUtil.nextInt(MAX_LEN); return weightingList.get(index); &#125;&#125;##### 轮询逐个请求服务地址，到达边界之后，继续绕接。主要缺点：慢的提供者会累积请求。例如第二台机器很慢，但没挂。当请求第二台机器时被卡在那。久而久之，所有请求都卡在第二台机器上。 轮询策略实现非常简单，顺序循环遍历服务提供者列表，达到边界之后重新归零开始，继续顺序循环。123456789101112131415161718192021222324252627282930/** * 轮询 */public class PollingStrategy implements ClusterStrategy &#123; //计数器 private int index = 0; private Lock lock = new ReentrantLock(); @Override public RemoteServiceBase select(List&lt;RemoteServiceBase&gt; list) &#123; RemoteServiceBase service = null; try &#123; lock.tryLock(10, TimeUnit.MILLISECONDS); //若计数大于服务提供者个数,将计数器归0 if (index &gt;= list.size()) &#123; index = 0; &#125; service = list.get(index); index++; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; //兜底,保证程序健壮性,若未取到服务,则直接取第一个 if (service == null) &#123; service = list.get(0); &#125; return service; &#125;&#125;加权轮询的话，需要给服务地址添加权重。123456789101112131415161718192021222324252627282930313233343536373839/** * 加权轮询 */public class WeightingPollingStrategy implements ClusterStrategy &#123; //计数器 private int index = 0; //计数器锁 private Lock lock = new ReentrantLock(); @Override public RemoteServiceBase select(List&lt;RemoteServiceBase&gt; list) &#123; RemoteServiceBase service = null; try &#123; lock.tryLock(10, TimeUnit.MILLISECONDS); //存放加权后的服务提供者列表 List&lt;RemoteServiceBase&gt; weightingList = new ArrayList&lt;RemoteServiceBase&gt;(); for (RemoteServiceBase remoteServiceBase : list) &#123; //扩大10倍 int weight = (int) (remoteServiceBase.getWeight()*10); for (int i = 0; i &lt; weight; i++) &#123; weightingList.add(remoteServiceBase); &#125; &#125; //若计数大于服务提供者个数,将计数器归0 if (index &gt;= weightingList.size()) &#123; index = 0; &#125; service = weightingList.get(index); index++; return service; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; //兜底,保证程序健壮性,若未取到服务,则直接取第一个 return list.get(0); &#125;&#125;##### 服务调用时延消费者缓存所有服务提供者的调用时延，周期性的计算服务调用平均时延。然后计算每个服务提供者服务调用时延与平均时延的差值，根据差值大小动态调整权重，保证服务时延大的服务提供者接收更少的消息，防止消息堆积。 该策略的特点：保证处理能力强的服务接受更多的消息，通过动态的权重分配消除服务调用时延的震荡范围，使所有服务的调用时延接近平均值，实现负载均衡。##### 一致性哈希相同参数的请求总是发送到统一服务提供者，当某一台服务提供者宕机时，原本发往跟提供者的请求，基于虚拟节点，平摊到其他提供者，不会引起剧烈变动，平台提供默认的虚拟节点数，可以通过配置文件修改虚拟节点个数。一致性Hash环工作原理如下图所示：一致性哈希#### 路由规则负载均衡只能保证服务提供者压力的平衡，但是在一些业务场景中需要设置一些过滤规则，比较常用的是基本表达式的条件路由。 通过IP条件表达式配置黑白名单访问控制：consumerIP != 192.168.1.1。 只暴露部分服务提供者，防止这个集群服务都被冲垮，导致其他服务也不可用。例如providerIP = 192.168.3。 读写分离：method=find,list,get,query=&gt;providerIP=192.168.1.。 前后台分离：app=web=&gt;providerIP=192.168.1.,app=java=&gt;providerIP=192.168.2.。 灰度升级：将WEB前台应用理由到新的服务版本上：app=web=&gt;provicerIP=192.168.1.。由于篇幅原因这里不细说，还是丢个说的比较详细的文章地址： 服务路由### 序列化与反序列化把对象转换为字节序列的过程称为序列化，把字节序列恢复为对象的过程称为反序列化。运程调用的时候，我们需要先将Java对象进行序列化，然后通过网络，IO进行传输，当到达目的地之后，再进行反序列化获取到我们想要的结果对象。分布式系统中，传输的对象会很多，这就要求序列化速度快，产生字节序列小的序列化技术。 序列化技术：Serializable, xml, Jackson, MessagePack, fastjson, Protocol Buffer, Thrift,Gson, Avro,Hessian等- Serializable 是java自带的序列化技术，无法跨平台，序列化和反序列化的速度相对较慢。- XML技术多平台支持好，常用于与银行交互的报文，但是其字节序列产生较大，不太适合用作分布式通讯框架。- Fastjson是Java语言编写的高性能的JSON处理器,由阿里巴巴公司开发,字节序列为json串，可读性好，序列化也速度非常的快。- Protocol Buffer 序列化速度非常快，字节序列较小，但是可读性较差。 ( 这里就不一一介绍，有兴趣可以看看这篇文章：序列化技术比较 ) 一般分布式服务框架会内置多种序列化协议可供选择，如Dubbo 支持的7种协议用到的序列化技术就不完全相同。### 服务调用本地环境下，使用某个接口很简单，直接调用就行。分布式环境下就不是那么简单了，消费者方只会存在接口的定义，没有具体的实现。想要像本地环境下直接调用远程接口那就得耗费一些功夫了，需要用到远程代理。 下面是我盗的图：远程代理 通信时序如下： 通信时序 消费者端没有具体的实现，需要调用接口时会动态的去创建一个代理类。与spirng集成的情况，那直接在bean构建的时候注入代理类。 下面是构建代理类： 1234567891011import java.lang.reflect.Proxy;public class JdkProxy &#123; public static Object getInstance(Class&lt;?&gt; cls)&#123; JdkMethodProxy invocationHandler = new JdkMethodProxy(); Object newProxyInstance = Proxy.newProxyInstance( cls.getClassLoader(), new Class[] &#123; cls &#125;, invocationHandler); return (Object)newProxyInstance; &#125;&#125; 12345678910111213141516171819202122import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;public class JdkMethodProxy implements InvocationHandler &#123; @Override public Object invoke(Object proxy, Method method, Object[] parameters) throws Throwable &#123; //如果传进来是一个已实现的具体类 if (Object.class.equals(method.getDeclaringClass())) &#123; try &#123; return method.invoke(this, parameters); &#125; catch (Throwable t) &#123; t.printStackTrace(); &#125; //如果传进来的是一个接口 &#125; else &#123; //实现接口的核心方法 //return RemoteInvoking.invoking(serviceName, serializationType, //timeOut,loadBalanceStrategy,method, parameters); &#125; return null; &#125;&#125; 代理会做很多事情，对请求服务的名称及参数信息的的序列化、通过路由选择最为合适服务提供者、建立通讯连接发送请求信息（或者直接发起http请求）、最后返回获取到的结果。当然这里面需要考虑很多问题，如调用超时，请求异常，通讯连接的缓存，同步服务调用还是异步服务调用等等。 同步服务调用：客户端发起远程服务调用请求，用户线程完成消息序列化之后，将消息投递到通信框架，然后同步阻塞，等待通信线程发送请求并接收到应答之后，唤醒同步等待的用户线程，用户线程获取到应答之后返回。 异步服务调用：基于JAVA的Future机制，客户端发起远程服务调用请求，该请求会被标上requestId,同时建立一个与requestId对应 Future，客户端通过Future 的 get方法获取结果时会被阻塞。服务端收到请求应达会回传requestId，通过requestId去解除对应Future的阻塞，同时set对应结果，最后客户端获取到结果。 构建Future，以requestId为key，put到线程安全的map中。get结果时需要写入timeOut超时时间，防止由于结果的未返回而导致的长时间的阻塞。 12345678910SyncFuture&lt;RpcResponse&gt; syncFuture =new SyncFuture&lt;RpcResponse&gt;();SyncFutureCatch.syncFutureMap.put(rpcRequest.getRequestId(), syncFuture);try &#123; RpcResponse rpcResponse= syncFuture.get(timeOut,TimeUnit.MILLISECONDS); return rpcResponse.getResult();&#125;catch (Exception e)&#123; throw e;&#125;finally &#123; SyncFutureCatch.syncFutureMap.remove(rpcRequest.getRequestId());&#125; 结果返回时通过回传的requestId获取对应Future写入Response,Future线程解除阻塞。 12345log.debug(\"Tcp Client receive head：\"+headAnalysis+\"Tcp Client receive data：\" +rpcResponse);SyncFuture&lt;RpcResponse&gt; syncFuture= SyncFutureCatch.syncFutureMap.get(rpcResponse.getRequestId());if(syncFuture!=null)&#123; syncFuture.setResponse(rpcResponse);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.util.concurrent.CountDownLatch;import java.util.concurrent.Future;import java.util.concurrent.TimeUnit;public class SyncFuture&lt;T&gt; implements Future&lt;T&gt; &#123; // 因为请求和响应是一一对应的，因此初始化CountDownLatch值为1。 private CountDownLatch latch = new CountDownLatch(1); // 需要响应线程设置的响应结果 private T response; // Futrue的请求时间，用于计算Future是否超时 private long beginTime = System.currentTimeMillis(); public SyncFuture() &#123; &#125; @Override public boolean cancel(boolean mayInterruptIfRunning) &#123; return false; &#125; @Override public boolean isCancelled() &#123; return false; &#125; @Override public boolean isDone() &#123; if (response != null) &#123; return true; &#125; return false; &#125; // 获取响应结果，直到有结果才返回。 @Override public T get() throws InterruptedException &#123; latch.await(); return this.response; &#125; // 获取响应结果，直到有结果或者超过指定时间就返回。 @Override public T get(long timeOut, TimeUnit unit) throws InterruptedException &#123; if (latch.await(timeOut, unit)) &#123; return this.response; &#125; return null; &#125; // 用于设置响应结果，并且做countDown操作，通知请求线程 public void setResponse(T response) &#123; this.response = response; latch.countDown(); &#125; public long getBeginTime() &#123; return beginTime; &#125;&#125; 1234SyncFuture&lt;RpcResponse&gt; syncFuture =new SyncFuture&lt;RpcResponse&gt;();SyncFutureCatch.syncFutureMap.put(rpcRequest.getRequestId(), syncFuture);RpcResponse rpcResponse= syncFuture.get(timeOut,TimeUnit.MILLISECONDS);SyncFutureCatch.syncFutureMap.remove(rpcRequest.getRequestId()); 除了同步服务调用，异步服务调用，还有并行服务调用，泛化调用等调用形式 ( 这里就不做介绍，有兴趣可以看看这篇文章：服务框架多形式的服务调用：同步、异步、并用、泛化 ) 高可用简单的介绍了下分布式服务框架，下面来说下分布式系统的高可用。一个系统设计开发出来，三天两晚就出个大问题，导致无法使用，那这个系统也不是什么好系统。业界流传一句话：”我们系统支持X个9的可靠性”。这个X是代表一个数字，X个9表示在系统1年时间的使用过程中，系统可以正常使用时间与总时间（1年）之比。 3个9：(1-99.9%)36524=8.76小时，表示该系统在连续运行1年时间里最多可能的业务中断时间是8.76小时，4个9即52.6分钟，5个9即5.26分钟。要做到如此高的可靠性，是非常大的挑战。一个大型分布式项目可能是由几十上百个项目构成，涉及到的服务成千上万，主链上的一个流程就需要流转多个团队维护的项目。拿4个9的可靠性来说，平摊到每个团队的时间可能不到10分钟。这10分钟内需要顶住压力，以最快的时间找到并解决问题，恢复系统的可用。 下面说说为了提高系统的可靠性都有哪些方案： 服务检测：某台服务器与注册中心的连接中断，其提供的服务也无响应时，系统应该能主动去重启该服务，使其能正常对外提供。 故障隔离：集群环境下，某台服务器能对外提供服务，但是因为其他原因，请求结果始终异常。这时就需要主动将该节点从集群环境中剔除，避免继续对后面的请求造成影响，非高峰时期再尝试修复该问题。至于机房故障的情况，只能去屏蔽整个机房了。目前饿了么做的是异地多活，即便单边机房挂了，流量也可以全量切换至另外一边机房，保证系统的可用。 监控：包含业务监控、服务异常监控、db中间件性能的监控等，系统出现异常的时候能及时的通知到开发人员。等到线下报上来的时候，可能影响已经很大了。 压测：产线主链路的压测是必不可少的，单靠集成测试，有些高并发的场景是无法覆盖到的，压测能暴露平常情况无法出现的问题，也能直观的提现系统的吞吐能力。当业务激增时，可以考虑直接做系统扩容。 sop方案与演练：产线上随时都可能会发生问题，抱着出现问题时再想办法解决的态度是肯定不行的，时间根本来不及。提前做好对应问题的sop方案，能节省大量时间，尽快的恢复系统的正常。当然平常的演练也是不可少的，一旦产线故障可以做到从容不迫的去应对和处理。 除了上述方案外，还可以考虑服务策略的使用： 降级策略业务高峰期，为了保证核心服务，需要停掉一些不太重要的业务，如双十一期间不允许发起退款(*￣▽￣)、只允许查看3个月之内的历史订单等业务的降级，调用服务接口时，直接返回的空结果或异常等服务的降级,都属于分布式系统的降级策略。服务降级是可逆操作，当系统压力恢复到一定值不需要降级服务时，需要去除降级，将服务状态恢复正常。 服务降级主要包括屏蔽降级和容错降级： 屏蔽降级:分布式服务框架直接屏蔽对远程接口的请求，不发起对远程服务的调用，直接返回空结果、抛出指定异常、执行本地模拟接口实现等方式。 容错降级：非核心服务不可调用时，可以对故障服务做业务放通，保证主流程不受影响。如请求超时、消息解码异常、系统拥塞保护异常， 服务提供方系统异常等情况。 笔者之前就碰到过因双方没有做容错降级导致的系统故障的情况。午高峰时期，对方调用我们的一个非核心查询接口，我们系统因为bug问题一直异常，导致对方调用这个接口的页面异常而无法跳转到主流程页面，影响了产线的生产。当时对方紧急发版才使系统恢复正常。 限流策略说到限流，最先想到的就是秒杀活动了，一场秒杀活动的流量可能是正常流量的几百至几千倍，如此高的流量系统根本无法处理，只能通过限流来避免系统的崩溃。服务的限流本质和秒杀活动的限流是一样的，都是限制请求的流入，防止服务提供方因大量的请求而崩溃。 限流算法：令牌桶、漏桶、计数器算法 上述算法适合单机的限流，但涉及到整个集群的限流时，得考虑使用缓存中间件了。例如：某个服务1分钟内只允许请求2次，或者一天只允许使用1000次。由于负载均衡存在，可能集群内每台机器都会收到请求，这种时候就需要缓存来记录调用方某段时间内的请求次数，再做限流处理。redis就很适合做此事。 限流算法的实现 熔断策略熔断本质上是一种过载保护机制，这一概念来源于电子工程中的断路器，当电流过大时，保险丝会熔断，从而保护整个电路。同样在分布式系统中，当被调用的远程服务无法使用时，如果没有过载保护，就会导致请求的资源阻塞在远程服务器上耗尽资源。很多时候，刚开始可能只是出现了局部小规模的故障，然而由于种种原因，故障影响范围越来越大，最终导致全局性的后果。当下游服务因访问压力过大而响应变慢或失败，上游服务为了保护自己以及系统整体的可用性，可以暂时切断对下游服务的调用。 熔断器的设计思路 Closed：初始状态，熔断器关闭，正常提供服务 Open: 失败次数，失败百分比达到一定的阈值之后，熔断器打开，停止访问服务 Half-Open：熔断一定时间之后，小流量尝试调用服务，如果成功则恢复，熔断器变为Closed状态 数据一致性一个系统设计开发出来，必须保证其运行的数据准确和一致性。拿支付系统来说：用户银行卡已经扣款成功，系统里却显示失败，没有给用户的虚拟帐户充值上，这会引起客诉。说的再严重点，用户发起提现，资金已经转到其银行账户，系统却没扣除对应虚拟帐号的余额，直接导致资金损失了。如果这时候用户一直发起提现，那就酸爽了。 CAP原则说到数据一致性，就不得不说到CAP原则。CAP原则中指出任何一个分布式系统中，Consistency（一致性 C）、 Availability（可用性 A）、Partition tolerance（分区容错性P），三者不可兼得。传统单机数据库基于ACID特性（原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）） ，放弃了分区容错性，能做到可用性和一致性。对于一个分布式系统而言，分区容错性是一个最基本的要求。既然是一个分布式系统，那么分布式系统中的组件必然需要被部署到不同的节点，会出现节点与节点之间的网络通讯，而网络问题又是一定会出现的异常情况，分区容错性也就成为了一个分布式系统必然需要面对和解决的问题。系统架构师往往需要把精力花在如何根据业务特点在一致性和可用性之间寻求平衡。 集中式系统，通过数据库事务的控制，能做到数据的强一致性。但是分布式系统中，涉及多服务间的调用，通过分布式事务的方案：两阶段提交（2PC）、三阶段提交（3PC）、补偿事务（TCC）等虽然能实现数据的强一致，但是都是通过牺牲可用性来实现。 BASE理论BASE理论是对CAP原则中一致性和可用性权衡的结果：Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）。BASE理论，其来源于对大规模互联网系统分布式实践的总结，是基于CAP原则逐步演化而来的。其最核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 基本可用基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性，这不等价于系统不可用。 软状态软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时 最终一致性最终一致性强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统的事物ACID特性是相反的，它完全不同于ACID的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性和BASE理论往往又会结合在一起。 下面2篇文章对分布式事务和数据一致性这块有较深的讲解。 聊聊分布式事务，再说说解决方案 微服务下的数据一致性的几种实现方式之概述 微服务下的数据一致性的几种实现方式之概述传统应用的事务管理本地事务再介绍微服务下的数据一致性之前，先简单地介绍一下事务的背景。传统单机应用使用一个RDBMS作为数据源。应用开启事务，进行CRUD，提交或回滚事务，统统发生在本地事务中，由资源管理器（RM）直接提供事务支持。数据的一致性在一个本地事务中得到保证。 分布式事务#####两阶段提交（2PC） 当应用逐渐扩展，出现一个应用使用多个数据源的情况，这个时候本地事务已经无法满足数据一致性的要求。由于多个数据源的同时访问，事务需要跨多个数据源管理，分布式事务应运而生。其中最流行的就是两阶段提交（2PC），分布式事务由事务管理器（TM）统一管理。 两阶段提交分为准备阶段和提交阶段。 两阶段提交-commit 两阶段提交-rollback然而两阶段提交也不能完全保证数据一致性问题，并且有同步阻塞的问题，所以其优化版本三阶段提交（3PC）被发明了出来。 #####三阶段提交（3PC） 三阶段提交然而3PC也只能保证绝大多数情况下的数据一致性。 具体分布式事务2PC和3PC的详细介绍请见关于分布式事务、两阶段提交协议、三阶提交协议。分布式事务不是本文的重点，故不展开。 ###微服务下的事务管理 那么，分布式事务2PC或者3PC是否适合于微服务下的事务管理呢？答案是否定的，原因有三点： 由于微服务间无法直接进行数据访问，微服务间互相调用通常通过RPC（dubbo）或Http API（SpringCloud）进行，所以已经无法使用TM统一管理微服务的RM。 不同的微服务使用的数据源类型可能完全不同，如果微服务使用了NoSQL之类不支持事务的数据库，则事务根本无从谈起。 即使微服务使用的数据源都支持事务，那么如果使用一个大事务将许多微服务的事务管理起来，这个大事务维持的时间，将比本地事务长几个数量级。如此长时间的事务及跨服务的事务，将为产生很多锁及数据不可用，严重影响系统性能。 由此可见，传统的分布式事务已经无法满足微服务架构下的事务管理需求。那么，既然无法满足传统的ACID事务，在微服务下的事务管理必然要遵循新的法则－－BASE理论。 BASE理论由eBay的架构师Dan Pritchett提出，BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性，应用应该可以采用合适的方式达到最终一致性。BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。 基本可用：指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。 软状态：允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。 最终一致性：最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。 BASE中的最终一致性是对于微服务下的事务管理的根本要求，既基于微服务的事务管理无法达到强一致性，但必须保证最重一致性。那么，有哪些方法可以保证微服务下的事务管理的最终一致性呢，按照实现原理分主要有两类，事件通知型和补偿型，其中事件通知型又可分为可靠事件通知模式及最大努力通知模式，而补偿型又可分为TCC模式、和业务补偿模式两种。这四种模式都可以达到微服务下的数据最终一致性。 实现微服务下数据一致性的方式可靠事件通知模式同步事件可靠事件通知模式的设计理念比较容易理解，即是主服务完成后将结果通过事件（常常是消息队列）传递给从服务，从服务在接受到消息后进行消费，完成业务，从而达到主服务与从服务间的消息一致性。首先能想到的也是最简单的就是同步事件通知，业务处理与消息发送同步执行，实现逻辑见下方代码及时序图。 123456789101112public void trans() &#123; try &#123; // 1. 操作数据库 bool result = dao.update(data);// 操作数据库失败，会抛出异常 // 2. 如果数据库操作成功则发送消息 if(result)&#123; mq.send(data);// 如果方法执行失败，会抛出异常 &#125; &#125; catch (Exception e) &#123; roolback();// 如果发生异常，就回滚 &#125;&#125; 上面的逻辑看上去天衣无缝，如果数据库操作失败则直接退出，不发送消息；如果发送消息失败，则数据库回滚；如果数据库操作成功且消息发送成功，则业务成功，消息发送给下游消费。然后仔细思考后，同步消息通知其实有两点不足的地方。 在微服务的架构下，有可能出现网络IO问题或者服务器宕机的问题，如果这些问题出现在时序图的第7步，使得消息投递后无法正常通知主服务（网络问题），或无法继续提交事务（宕机），那么主服务将会认为消息投递失败，会滚主服务业务，然而实际上消息已经被从服务消费，那么就会造成主服务和从服务的数据不一致。具体场景可见下面两张时序图。 事件服务（在这里就是消息服务）与业务过于耦合，如果消息服务不可用，会导致业务不可用。应该将事件服务与业务解耦，独立出来异步执行，或者在业务执行后先尝试发送一次消息，如果消息发送失败，则降级为异步发送。 异步事件本地事件服务为了解决3.1.1中描述的同步事件的问题，异步事件通知模式被发展了出来，既业务服务和事件服务解耦，事件异步进行，由单独的事件服务保证事件的可靠投递。 异步事件通知－本地事件服务 当业务执行时，在同一个本地事务中将事件写入本地事件表，同时投递该事件，如果事件投递成功，则将该事件从事件表中删除。如果投递失败，则使用事件服务定时地异步统一处理投递失败的事件，进行重新投递，直到事件被正确投递，并将事件从事件表中删除。这种方式最大可能地保证了事件投递的实效性，并且当第一次投递失败后，也能使用异步事件服务保证事件至少被投递一次。 然而，这种使用本地事件服务保证可靠事件通知的方式也有它的不足之处，那便是业务仍旧与事件服务有一定耦合（第一次同步投递时），更为严重的是，本地事务需要负责额外的事件表的操作，为数据库带来了压力，在高并发的场景，由于每一个业务操作就要产生相应的事件表操作，几乎将数据库的可用吞吐量砍了一半，这无疑是无法接受的。正是因为这样的原因，可靠事件通知模式进一步地发展－外部事件服务出现在了人们的眼中。 外部事件服务外部事件服务在本地事件服务的基础上更进了一步，将事件服务独立出主业务服务，主业务服务不在对事件服务有任何强依赖。 异步事件通知－外部事件服务 业务服务在提交前，向事件服务发送事件，事件服务只记录事件，并不发送。业务服务在提交或回滚后通知事件服务，事件服务发送事件或者删除事件。不用担心业务系统在提交或者会滚后宕机而无法发送确认事件给事件服务，因为事件服务会定时获取所有仍未发送的事件并且向业务系统查询，根据业务系统的返回来决定发送或者删除该事件。 外部事件虽然能够将业务系统和事件系统解耦，但是也带来了额外的工作量：外部事件服务比起本地事件服务来说多了两次网络通信开销（提交前、提交／回滚后），同时也需要业务系统提供单独的查询接口给事件系统用来判断未发送事件的状态。 可靠事件通知模式的注意事项可靠事件模式需要注意的有两点，1. 事件的正确发送； 2. 事件的重复消费。 通过异步消息服务可以确保事件的正确发送，然而事件是有可能重复发送的，那么就需要消费端保证同一条事件不会重复被消费，简而言之就是保证事件消费的幂等性。 如果事件本身是具备幂等性的状态型事件，如订单状态的通知（已下单、已支付、已发货等），则需要判断事件的顺序。一般通过时间戳来判断，既消费过了新的消息后，当接受到老的消息直接丢弃不予消费。如果无法提供全局时间戳，则应考虑使用全局统一的序列号。 对于不具备幂等性的事件，一般是动作行为事件，如扣款100，存款200，则应该将事件id及事件结果持久化，在消费事件前查询事件id，若已经消费则直接返回执行结果；若是新消息，则执行，并存储执行结果。 最大努力通知模式相比可靠事件通知模式，最大努力通知模式就容易理解多了。最大努力通知型的特点是，业务服务在提交事务后，进行有限次数（设置最大次数限制）的消息发送，比如发送三次消息，若三次消息发送都失败，则不予继续发送。所以有可能导致消息的丢失。同时，主业务方需要提供查询接口给从业务服务，用来恢复丢失消息。最大努力通知型对于时效性保证比较差（既可能会出现较长时间的软状态），所以对于数据一致性的时效性要求比较高的系统无法使用。这种模式通常使用在不同业务平台服务或者对于第三方业务服务的通知，如银行通知、商户通知等，这里不再展开。 业务补偿模式接下来介绍两种补偿模式，补偿模式比起事件通知模式最大的不同是，补偿模式的上游服务依赖于下游服务的运行结果，而事件通知模式上游服务不依赖于下游服务的运行结果。首先介绍业务补偿模式，业务补偿模式是一种纯补偿模式，其设计理念为，业务在调用的时候正常提交，当一个服务失败的时候，所有其依赖的上游服务都进行业务补偿操作。举个例子，小明从杭州出发，去往美国纽约出差，现在他需要定从杭州去往上海的火车票，以及从上海飞往纽约的飞机票。如果小明成功购买了火车票之后发现那天的飞机票已经售空了，那么与其在上海再多待一天，小明还不如取消去上海的火车票，选择飞往北京再转机纽约，所以小明就取消了去上海的火车票。这个例子中购买杭州到上海的火车票是服务a，购买上海到纽约的飞机票是服务b，业务补偿模式就是在服务b失败的时候，对服务a进行补偿操作，在例子中就是取消杭州到上海的火车票。 补偿模式要求每个服务都提供补偿借口，且这种补偿一般来说是不完全补偿，既即使进行了补偿操作，那条取消的火车票记录还是一直存在数据库中可以被追踪（一般是有相信的状态字段“已取消”作为标记），毕竟已经提交的线上数据一般是不能进行物理删除的。 业务补偿模式最大的缺点是软状态的时间比较长，既数据一致性的时效性很低，多个服务常常可能处于数据不一致的情况。 TCC/Try Confirm Cancel模式TCC模式是一种优化了的业务补偿模式，它可以做到完全补偿，既进行补偿后不留下补偿的纪录，就好像什么事情都没有发生过一样。同时，TCC的软状态时间很短，原因是因为TCC是一种两阶段型模式（已经忘了两阶段概念的可以回顾一下1.2.1），只有在所有的服务的第一阶段（try）都成功的时候才进行第二阶段确认（Confirm）操作，否则进行补偿(Cancel)操作，而在try阶段是不会进行真正的业务处理的。 TCC模式 TCC模式的具体流程为两个阶段： Try，业务服务完成所有的业务检查，预留必需的业务资源 如果Try在所有服务中都成功，那么执行Confirm操作，Confirm操作不做任何的业务检查（因为try中已经做过），只是用Try阶段预留的业务资源进行业务处理；否则进行Cancel操作，Cancel操作释放Try阶段预留的业务资源。 这么说可能比较模糊，下面我举一个具体的例子，小明在线从招商银行转账100元到广发银行。这个操作可看作两个服务，服务a从小明的招行账户转出100元，服务b从小明的广发银行帐户汇入100元。 服务a（小明从招行转出100元）: try: update cmb_account set balance=balance-100, freeze=freeze+100 where acc_id=1 and balance&gt;100; confirm: update cmb_account set freeze=freeze-100 where acc_id=1; cancel: update cmb_account set balance=balance+100, freeze=freeze-100 where acc_id=1; 服务b（小明往广发银行汇入100元）: try: update cgb_account set freeze=freeze+100 where acc_id=1; confirm: update cgb_account set balance=balance+100, freeze=freeze-100 where acc_id=1; cancel: update cgb_account set freeze=freeze-100 where acc_id=1; 具体说明： a的try阶段，服务做了两件事，1：业务检查，这里是检查小明的帐户里的钱是否多余100元；2:预留资源，将100元从余额中划入冻结资金。 a的confirm阶段，这里不再进行业务检查，因为try阶段已经做过了，同时由于转账已经成功，将冻结资金扣除。 a的cancel阶段，释放预留资源，既100元冻结资金，并恢复到余额。 b的try阶段进行，预留资源，将100元冻结。 b的confirm阶段，使用try阶段预留的资源，将100元冻结资金划入余额。 b的cancel阶段，释放try阶段的预留资源，将100元从冻结资金中减去。 从上面的简单例子可以看出，TCC模式比纯业务补偿模式更加复杂，所以在实现上每个服务都需要实现Cofirm和Cancel两个接口。 总结下面的表格对这四种常用的模式进行了比较： 类型 名称 数据一致性的实时性 开发成本 上游服务是否依赖下游服务结果 通知型 最大努力 低 低 不依赖 通知型 可靠事件 高 高 不依赖 补偿型 业务补偿 低 低 依赖 补偿型 TCC 高 高 依赖 引用 https://juejin.im/post/5c7cd6eee51d457c042d4b52 https://www.jianshu.com/p/b264a196b177","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/categories/架构设计/"}],"tags":[{"name":"分布式架构","slug":"分布式架构","permalink":"https://vincentruan.github.io/tags/分布式架构/"}]},{"title":"HTTP协议要点","slug":"HTTP协议要点","date":"2020-02-06T06:22:39.000Z","updated":"2020-02-25T15:09:15.032Z","comments":true,"path":"2020/02/06/HTTP协议要点/","link":"","permalink":"https://vincentruan.github.io/2020/02/06/HTTP协议要点/","excerpt":"以下文章来源于Java建设者 ，作者cxuan HTTP 内容协商什么是内容协商在 HTTP 中，内容协商是一种用于在同一 URL 上提供资源的不同表示形式的机制。内容协商机制是指客户端和服务器端就响应的资源内容进行交涉，然后提供给客户端最为适合的资源。内容协商会以响应资源的语言、字符集、编码方式等作为判断的标准。","text":"以下文章来源于Java建设者 ，作者cxuan HTTP 内容协商什么是内容协商在 HTTP 中，内容协商是一种用于在同一 URL 上提供资源的不同表示形式的机制。内容协商机制是指客户端和服务器端就响应的资源内容进行交涉，然后提供给客户端最为适合的资源。内容协商会以响应资源的语言、字符集、编码方式等作为判断的标准。 内容协商的种类内容协商主要有以下3种类型： 服务器驱动协商（Server-driven Negotiation） 这种协商方式是由服务器端进行内容协商。服务器端会根据请求首部字段进行自动处理 客户端驱动协商（Agent-driven Negotiation） 这种协商方式是由客户端来进行内容协商。 透明协商（Transparent Negotiation） 是服务器驱动和客户端驱动的结合体，是由服务器端和客户端各自进行内容协商的一种方法。 内容协商的分类有很多种，主要的几种类型是 Accept、Accept-Charset、Accept-Encoding、Accept-Language、Content-Language。 一般来说，客户端用 Accept 头告诉服务器希望接收什么样的数据，而服务器用 Content 头告诉客户端实际发送了什么样的数据。 为什么需要内容协商我们为什么需要内容协商呢？在回答这个问题前我们先来看一下 TCP 和 HTTP 的不同。 在 TCP / IP 协议栈里，传输数据基本上都是 header+body 的格式。但 TCP、UDP 因为是传输层的协议，它们不会关心 body 数据是什么，只要把数据发送到对方就算是完成了任务。 而 HTTP 协议则不同，它是应用层的协议，数据到达之后需要告诉应用程序这是什么数据。当然不告诉应用这是哪种类型的数据，应用也可以通过不断尝试来判断，但这种方式无疑十分低效，而且有很大几率会检查不出来文件类型。 所以鉴于此，浏览器和服务器需要就数据的传输达成一致，浏览器需要告诉服务器自己希望能够接收什么样的数据，需要什么样的压缩格式，什么语言，哪种字符集等；而服务器需要告诉客户端自己能够提供的服务是什么。 所以我们就引出了内容协商的几种概念，下面依次来进行探讨 内容协商标头Accept接受请求 HTTP 标头会通告客户端自己能够接受的 MIME 类型 那么什么是 MIME 类型呢？在回答这个问题前你应该先了解一下什么是 MIME MIME: MIME (Multipurpose Internet Mail Extensions) 是描述消息内容类型的因特网标准。MIME 消息能包含文本、图像、音频、视频以及其他应用程序专用的数据。 也就是说，MIME 类型其实就是一系列消息内容类型的集合。那么 MIME 类型都有哪些呢？ 文本文件：text/html、text/plain、text/css、application/xhtml+xml、application/xml 图片文件：image/jpeg、image/gif、image/png 视频文件：video/mpeg、video/quicktime 应用程序二进制文件：application/octet-stream、application/zip 比如，如果浏览器不支持 PNG 图片的显示，那 Accept 就不指定image/png，而指定可处理的 image/gif 和 image/jpeg 等图片类型。 一般 MIME 类型也会和 q 这个属性一起使用，q 是什么？q 表示的是权重，来看一个例子 1Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 这是什么意思呢？若想要给显示的媒体类型增加优先级，则使用 q= 来额外表示权重值，没有显示权重的时候默认值是1.0 ，我给你列个表格你就明白了 q MIME 1.0 text/html 1.0 application/xhtml+xml 0.9 application/xml 0.8 / 也就是说，这是一个放置顺序，权重高的在前，低的在后，application/xml;q=0.9 是不可分割的整体。 Accept-CharsetAccept-charset 属性规定服务器处理表单数据所接受的字符编码；Accept-charset 属性允许你指定一系列字符集，服务器必须支持这些字符集，从而得以正确解释表单中的数据。 Accept-Charset 没有对应的标头，服务器会把这个值放在 Content-Type中用charset=xxx来表示， 例如，浏览器请求 GBK 或 UTF-8 的字符集，然后服务器返回的是 UTF-8 编码，就是下面这样 12Accept-Charset: gbk, utf-8Content-Type: text/html; charset=utf-8 Accept-Language首部字段 Accept-Language 用来告知服务器用户代理能够处理的自然语言集（指中文或英文等），以及自然语言集的相对优先级。可一次指定多种自然语言集。和 Accept 首部字段一样，按权重值 q= 来表示相对优先级。 1Accept-Language: en-US,en;q=0.5 Accept-Encoding表示 HTTP 标头会标明客户端希望服务端返回的内容编码，这通常是一种压缩算法。Accept-Encoding 也是属于内容协商 的一部分，使用并通过客户端选择 Content-Encoding 内容进行返回。 即使客户端和服务器都能够支持相同的压缩算法，服务器也可能选择不压缩并返回，这种情况可能是由于这两种情况造成的: 要发送的数据已经被压缩了一次，第二次压缩并不会导致发送的数据更小 服务器过载，无法承受压缩带来的性能开销，通常，如果服务器使用 CPU 超过 80% ，Microsoft 则建议不要使用压缩 下面是 Accept-Encoding 的使用方式 1234567Accept-Encoding: gzipAccept-Encoding: compressAccept-Encoding: deflateAccept-Encoding: brAccept-Encoding: identityAccept-Encoding: *Accept-Encoding: deflate, gzip;q=1.0, *;q=0.5 上面的几种表述方式就已经把 Accept-Encoding 的属性列全了 gzip: 由文件压缩程序 gzip 生成的编码格式，使用 Lempel-Ziv编码（LZ77）和32位CRC的压缩格式，感兴趣的同学可以读一下 （https://en.wikipedia.org/wiki/LZ77_and_LZ78#LZ77） compress: 使用Lempel-Ziv-Welch（LZW）算法的压缩格式，有兴趣的同学可以读 （https://en.wikipedia.org/wiki/LZW） deflate: 使用 zlib 结构和 deflate 压缩算法的压缩格式，参考 （https://en.wikipedia.org/wiki/Zlib） 和 （https://en.wikipedia.org/wiki/DEFLATE） br: 使用 Brotli 算法的压缩格式，参考 （https://en.wikipedia.org/wiki/Brotli） 不执行压缩或不会变化的默认编码格式 * : 匹配标头中未列出的任何内容编码，如果没有列出 Accept-Encoding ，这就是默认值，并不意味着支 持任何算法，只是表示没有偏好 ;q= 采用权重 q 值来表示相对优先级，这点与首部字段 Accept 相同。 Content-TypeContent-Type 实体标头用于指示资源的 MIME 类型。作为响应，Content-Type 标头告诉客户端返回的内容的内容类型实际上是什么。Content-type 有两种值 : MIME 类型和字符集编码，例如 1Content-Type: text/html; charset=UTF-8 在某些情况下，浏览器将执行 MIME 嗅探，并且不一定遵循此标头的值；为防止此行为，可以将标头 X-Content-Type-Options 设置为 nosniff。 Content-EncodingContent-Encoding 实体标头用于压缩媒体类型，它让客户端知道如何进行解码操作，从而使客户端获得 Content-Type 标头引用的 MIME 类型。表示如下 1234567Content-Encoding: gzipContent-Encoding: compressContent-Encoding: deflateContent-Encoding: identityContent-Encoding: brContent-Encoding: gzip, identityContent-Encoding: deflate, gzip Content-LanguageContent-Language 实体标头用于描述面向受众的语言，以便使用户根据用户自己的首选语言进行区分。例如 123Content-Language: de-DEContent-Language: en-USContent-Language: de-DE, en-CA 下面根据内容协商对应的请求/响应标头，我列了一张图供你参考，注意其中 Accept-Charset 没有对应的 Content-Charset ，而是通过 Content-Type 来表示。 HTTP 认证 HTTP 提供了用于访问控制和身份认证的功能，下面就对 HTTP 的权限和认证功能进行介绍 通用 HTTP 认证框架RFC 7235 定义了 HTTP 身份认证框架，服务器可以根据其文档的定义来检查客户端请求。客户端也可以根据其文档定义来提供身份验证信息。 请求/响应的工作流程如下：服务器以401(未授权) 的状态响应客户端告诉客户端服务器需要认证信息，客户端提供至少一个 www-Authenticate 的响应标头进行授权信息的认证。想要通过服务器进行身份认证的客户端可以在请求标头字段中添加认证标头进行身份认证，一般的认证过程如下 首先客户端发起一个 HTTP 请求，不带有任何认证标头，服务器对此 HTTP 请求作出响应，发现此 HTTP 信息未带有认证凭据，服务器通过 www-Authenticate标头返回 401 告诉客户端此请求未通过认证。然后客户端进行用户认证，认证完毕后重新发起 HTTP 请求，这次 HTTP 请求带有用户认证凭据（注意，整个身份认证的过程必须通过 HTTPS 连接保证安全），到达服务器后服务器会检查认证信息，如果不符合服务器认证信息，会返回 403 Forbidden 表示用户认证失败，如果满足认证信息，则返回 200 OK。 我们知道，客户端和服务器之间的 HTTP 连接可以被代理缓存重新发送，所以认证信息也适用于代理服务器。 代理认证由于资源认证和代理认证可以共存，因此需要不同的头和状态码，在代理的情况下，会返回状态码 407(需要代理认证)， Proxy-Authenticate 响应头包含至少一个适用于代理的情况，Proxy-Authorization请求头用于将证书提供给代理服务器。下面分别来认识一下这两个标头 Proxy-AuthenticateHTTP Proxy-Authenticate 响应标头定义了身份验证方法，应使用该身份验证方法来访问代理服务器后面的资源。它将请求认证到代理服务器，从而允许它进一步发送请求。例如 12Proxy-Authenticate: BasicProxy-Authenticate: Basic realm=&quot;Access to the internal site&quot; Proxy-Authorization这个 HTTP 请求标头和上面的 Proxy-Authenticate 拼接很相似，但是概念不同，这个标头用于向代理服务器提供凭据，例如 1Proxy-Authorization: Basic YWxhZGRpbjpvcGVuc2VzYW1l 下面是代理服务器的请求/响应认证过程 这个过程和通用的过程类似，我们就不再详细展开描述了。 禁止访问如果代理服务器收到的有效凭据不足以获取对给定资源的访问权限，则服务器应使用403 Forbidden状态代码进行响应。与 401 Unauthorized 和 407 Proxy Authorization Required 不同，该用户无法进行身份验证。 WWW-Authenticate 和 Proxy-Authenticate 头WWW-Authenticate 和 Proxy-Authenticate 响应头定义了获得对资源访问权限的身份验证方法。他们需要指定使用哪种身份验证方案，以便希望授权的客户端知道如何提供凭据。它们的一般表示形式如下 12WWW-Authenticate: &lt;type&gt; realm=&lt;realm&gt;Proxy-Authenticate: &lt;type&gt; realm=&lt;realm&gt; 我想你从上面看到这里一定会好奇 和 realm是什么东西，现在就来解释下。 是认证协议，Basic 是下面协议中最普遍使用的 RFC 7617 中定义了Basic HTT P身份验证方案，该方案将凭据作为用户ID /密码对传输，并使用 base64 进行编码。(感兴趣的同学可以看看 https://tools.ietf.org/html/rfc7617) 其他的认证协议主要有 认证协议 参考来源 Basic 查阅 RFC 7617，base64编码的凭据 Bearer 查阅 RFC 6750，承载令牌来访问受 OAuth 2.0保护的资源 Digest 查阅 RFC 7616，Firefox仅支持md5哈希，请参见错误bug 472823以获得SHA加密支持 HOBA 查阅 RFC 7486 Mutual 查阅 RFC 8120 AWS4-HMAC-SHA256 查阅 AWS docs realm 用于描述保护区或指示保护范围，这可能是诸如 Access to the staging site(访问登陆站点) 或者类似的，这样用户就可以知道他们要访问哪个区域。 Authorization 和 Proxy-Authorization 标头Authorization 和 Proxy-Authorization 请求标头包含用于通过代理服务器对用户代理进行身份验证的凭据。在此，再次需要类型，其后是凭据，取决于使用哪种身份验证方案，可以对凭据进行编码或加密。一般表示如下 12Authorization: Basic YWxhZGRpbjpvcGVuc2VzYW1lProxy-Authorization: Basic YWxhZGRpbjpvcGVuc2VzYW1l HTTP 缓存通过把请求/响应缓存起来有助于提升系统的性能，Web 缓存减少了延迟和网络传输量，因此减少资源获取锁需要的时间。由于链路漫长，网络时延不可控，浏览器使用 HTTP 获取资源的成本较高。所以，非常有必要把数据缓存起来，下次再请求的时候尽可能地复用。当 Web 缓存在其存储中具有请求的资源时，它将拦截该请求并直接返回资源，而不是到达源服务器重新下载并获取。这样做可以实现两个小目标 减轻服务器负载 提升系统性能 下面我们就一起来探讨一下 HTTP 缓存都有哪些 不同类型的缓存HTTP 缓存有几种不同的类型，这些可以分为两个主要类别：私有缓存 和 共享缓存。 共享缓存：共享缓存是一种缓存，它可以存储多个用户重复使用的请求/响应。 私有缓存：私有缓存也称为专用缓存，它只适用于单个用户。 不缓存过期资源：所有的请求都会直接到达服务器，由服务器来下载资源并返回。 我们主要探讨浏览器缓存和代理缓存，但真实情况不只有这两种缓存，还有网关缓存，CDN，反向代理缓存和负载平衡器，把它们部署在 Web 服务器上，可以提高网站和 Web 应用程序的可靠性，性能和可伸缩性。 不缓存过期资源不缓存过期资源即浏览器和代理不会缓存过期资源，客户端发起的请求会直接到达服务器，可以使用 no-cache 标头代表不缓存过期资源。 no-cache 属于 Cache-Control 通用标头，其一般的表示方法如下 1Cache-Control: no-cache 也可以使用 max-age = 0 来实现不缓存的效果。 1Cache-Control: max-age=0 私有缓存私有缓存只用来缓存单个用户，你可能在浏览器设置中看到了 缓存，浏览器缓存包含服务器通过 HTTP 下载下来的所有文档。这个高速缓存用于使访问的文档可以进行前进/后退，保存操作而无需重新发送请求到源服务器。 可以使用 private 来实现私有缓存，这与 public 的用法相反，缓存服务器只对特定的客户端进行缓存，其他客户端发送过来的请求，缓存服务器则不会返回缓存。它的一般表示方法如下 1Cache-Control: private 共享缓存共享缓存是一种用于存储要由多个用户重用的响应缓存。共享缓存一般使用 public 来表示，public 属性只出现在客户端响应中，表示响应可以被任何缓存所缓存。一般表示方法如下 1Cache-Control: public 缓存控制HTTP/1.1 中的 Cache-Control 常规标头字段用于执行缓存控制，使用此标头可通过其提供的各种指令来定义缓存策略。下面我们依次介绍一下这些属性 不缓存no-store 才是真正意义上的不缓存，每次服务器接受到客户端的请求后，都会返回最新的资源给客户端。 1Cache-Control: no-store 缓存但需要验证同上面的 不缓存过期资源 私有和共享缓存同上 缓存过期缓存中一个很重要的指令就是max-age，这是资源被视为新鲜的最长时间 ，与 Expires相反，此指令是相对于请求时间的。对于应用程序中不会更改的文件，通常可以添加主动缓存。下面是 mag-age 的表示 1Cache-Control: max-age=31536000 缓存验证must-revalidate 表示缓存必须在使用之前验证过时资源的状态，并且不应使用过期的资源。 1Cache-Control: must-revalidate 下面是一个缓存验证图 什么是新鲜的数据 一旦资源存储在缓存中，理论上就可以永远被缓存使用。但是不管是浏览器缓存还是代理缓存，其存储空间是有限的，所以缓存会定期进行清除，这个过程叫做 缓存回收(cache eviction) （自译）。另一方面，服务器上的缓存也会定期进行更新，HTTP 作为应用层的协议，它是一种客户-服务器模式，HTTP 是无状态的协议，因此当资源发生更改时，服务器无法通知缓存和客户端。因此服务器必须通过某种方式告知客户端缓存已经被更新。服务器会提供过期时间这个概念，告知客户端在此到期时间之前，资源是新鲜的，也就是未更改过的。在此到期时间的范围之外，资源已过时。过期算法(Eviction algorithms) 通常会将新资源优先于陈旧资源使用。 这里需要注意一下，过期的资源并不会被回收或忽略，当高速缓存接收到过期资源时，它会使用 If-None-Match 转发此请求，以检查它是否仍然有效。如果有效，服务器会返回 304 Not Modified响应头并且没有任何响应体，从而节省了一些带宽。 下面是使用共享缓存代理的过程 这个图应该比较好理解，只说一下 Age 的作用，Age 是 HTTP 响应标头告诉客户端源服务器在多久之前创建了响应，它的单位为秒，Age 标头通常接近于0，如果是0则可能是从源服务器获取的，如果不是表示可能是由代理服务器创建，那么 Age 的值表示的是缓存后的响应再次发起认证到认证完成的时间值。 缓存的有效性是由多个标头来共同决定的，而并非某一个标头来决定。如果指定了Cache-control:max-age=N ，那么缓存会保存 N 秒。如果这个通用标头不存在的话，则会检查是否存在 Expires 标头。如果 Exprires 标头存在，那么它的值减去 Date 标头的值就可以确定其有效性。最后，如果max-age 和 expires 都不存在，就去寻找 Last-Modified 标头，如果存在此标头，则高速缓存的有效性等于 Date 标头的值减去 Last-modified 标头的值除以10。 缓存验证当到达缓存资源的有效期时，将对其进行验证或再次获取。仅当服务器提供了强验证器或弱验证器时，才可以进行验证。 当用户按下重新加载按钮时，将触发重新验证。如果缓存的响应包含 Cache-control：must-revalidate标头，则在正常浏览下也会触发该事件。另一个因素是 高级 -&gt; 缓存首选项 面板中的缓存验证首选项。有一个选项可在每次加载文档时强制进行验证。 Etag我们上面提到了强验证器和弱验证器，实现验证器功能的标头正式 Etag 的作用，这意味着 HTTP 用户代理（例如浏览器）不知道该字符串表示什么，并且无法预测其值。如果 Etag 标头是资源响应的一部分，则客户端可以在未来请求的标头中发出 If-None-Match，以验证缓存的资源。 Last-Modified响应标头可以用作弱验证器，因为它只有1秒可以分辨的时间。如果响应中存在 Last-Modified标头，则客户端可以发出 If-Modified-Since请求标头来验证缓存资源。（关于 Etag 更多我们会在条件请求介绍） 避免碰撞通过使用 Etag 和 If-Match 标头，你可以检测避免碰撞。 例如，在编辑 MDN 时，将对当前 Wiki 内容进行哈希处理并将其放入响应中的 Etag 中 1Etag: &quot;33a64df551425fcc55e4d42a148795d9f25f89d4&quot; 当将更改保存到 Wiki 页面（发布数据）时，POST 请求将包含 If-Match 标头，其中包含 Etag 值以检查有效性。 1If-Match: &quot;33a64df551425fcc55e4d42a148795d9f25f89d4&quot; 如果哈希值不匹配，则表示文档已在中间进行了编辑，并返回 412 Precondition Failed错误。 缓存未占用资源Etag 标头的另一个典型用法是缓存未更改的资源，如果用户再次访问给定的 URL（已设置Etag），并且该 URL过时，则客户端将在 If-None-Match 标头字段中发送其 Etag 的值 1If-None-Match: &quot;33a64df551425fcc55e4d42a148795d9f25f89d4&quot; 服务器将客户端的 Etag（通过 If-None-Match 发送）与 Etag 进行比较，以获取其当前资源版本，如果两个值都匹配（即资源未更改），则服务器会发回 304 Not Modified状态，没有主体，它告诉客户端响应的缓存仍然可以使用。 HTTP CROS 跨域CROS 的全称是 Cross-Origin Resource Sharing(CROS)，中文译为 跨域资源共享，它是一种机制。是一种什么机制呢？它是一种让运行在一个域(origin)上的 Web 应用被准许访问来自不同源服务器上指定资源的机制。在搞懂这个机制前，你需要线了解什么是 域(origin) OriginWeb 概念中域(Origin) 的内容由scheme(protocol) - 协议，host(domain) - 主机和用于访问它的 URL port - 端口定义。仅仅当 scheme 、host、port 都匹配时，两个对象才有相同的来源。这种协议相同，域名相同，端口相同的安全策略也被称为 同源策略（Same Origin Policy)。某些操作仅限于具有相同来源的内容，可以使用 CORS 取消此限制。 跨域的特点 下面是跨域问题的例子，看看你是否清楚什么是跨域了 12(1) http://example.com/app1/index.html(2) http://example.com/app2/index.html 上面这两个 URL 是否具有跨域问题呢？ 上面两个 URL 是不具有跨域问题的，因为这两个 URL 具有相同的协议(scheme)和主机(host) 那么下面这两个是否具有跨域问题呢？ 12http://Example.com:80http://example.com 这两个 URL 也不具有跨域问题，为什么不具有，端口不一样啊。其实它们两个端口是一样的。 或许你会认为这两个 URL 是不一样的，放心，关于一样不一样的论据我给你抛出来了 协议和域名部分是不区分大小写的，但是路径部分则根据服务器平台而定。Windows 和 Mac OS X 系统是不区分大小写的，而采用UNIX和Linux系的服务器系统是区分大小写的， 也就是说上面的 Example.com 和 example.com 其实是一个网址，并且由于两个地址具有相同的 scheme 和 host ，默认情况下服务器通过端口80传递 HTTP 内容，所以上面这两个地址也是相同的。 下面这两个 URL 地址是否具有跨域问题？ 12http://example.com/app1https://example.com/app2 这两个 URL 的 scheme 不同，所以这两个 URL 具有跨域问题 再看下面这三个 URL 是否具有跨域问题 123http://example.comhttp://www.example.comhttp://myapp.example.com 这三个 URL 也是具有跨域问题的，因为它们隶属于不通服务器的主机 host。 下面这两个 URL 是否具有跨域问题 12http://example.comhttp://example.com:8080 这两个 URL 也是具有跨域问题，因为这两个 URL 的默认端口不一样。 同源策略处于安全的因素，浏览器限制了从脚本发起跨域的 HTTP 请求。XMLHttpRequest 和其他 Fetch 接口 会遵循 同源策略(same-origin policy)。也就是说使用这些 API 的应用程序想要请求相同的资源，那么他们应该具有相同的来源，除非来自其他来源的响应包括正确的 CORS 标头也可以。 同源策略是一种很重要的安全策略，它限制了从一个来源加载的文档或脚本如何与另一个来源的资源进行交互。它有助于隔离潜在的恶意文档，减少可能的攻击媒介。 我们上面提到，如果两个 URL 具有相同的协议、主机和端口号（如果指定）的话，那么两个 URL 具有相同的来源。下面有一些实例，你判断一下是不是具有相同的来源 目标来源 http://store.company.com/dir/page.html 现在我带你认识了两遍不同的源，现在你应该知道如何区分两个 URL 是否属于同一来源了吧！ 好，你现在知道了什么是跨域问题，现在我要问你，哪些请求会产生跨域请求呢？这是我们下面要讨论的问题 跨域请求跨域请求可能会从下面这几种请求中发出： 调用 XMLHttpRequest 或者 Fetch api。 XMLHttpRequest 是什么？（我是后端程序员，前端不太懂，简单解释下，如果解释的不好，还请前端大佬们不要胖揍我） 所有的现代浏览器都有一个内置的 XMLHttpReqeust 对象，这个对象可以用于从服务器请求数据。 XMLHttpReqeust 对于开发人员来说很重要，XMLHttpReqeust 对象可以用来做下面这些事情 更新网页无需重新刷新页面 页面加载后从服务器请求数据 页面加载后从服务端获取数据 在后台将数据发送到服务器 使用 XMLHttpRequest(XHR) 对象与服务器进行交互，你可以从 URL 检索数据从而不必刷新整个页面，这使网页可以更新页面的一部分，而不会中断用户的操作。XMLHttpRequest 在 AJAX 异步编程中使用很广泛。 再来说一下 Fetch API 是什么，Fetch 提供了请求和响应对象（以及其他网络请求）的通用定义。它还提供了相关概念的定义，例如 CORS 和 HTTP Origin 头语义，并在其他地方取代了它们各自的定义。 Web 字体（用于 CSS 中@ font-face中的跨域字体使用），以便服务器可以部署 TrueType 字体，这些字体只能由允许跨站点加载和使用的网站使用。 WebGL 纹理 使用 drawImage() 绘制到画布上的图像/视频帧 图片的 CSS 形状 跨域功能概述跨域资源共享标准通过添加新的 HTTP 标头来工作，这些标头允许服务器描述允许哪些来源从 Web 浏览器读取信息。另外，对于可能导致服务器数据产生副作用的 HTTP 请求方法（尤其是 GET 或者具有某些 MIME 类型 POST 方法以外 HTTP 方法），该规范要求浏览器预检请求，使用 HTTP OPTIONS 请求方法从服务器请求受支持的方法，然后在服务器批准后发送实际请求。服务器还可以通知客户端是否应与请求一起发送凭据（例如 Cookies 和 HTTP 身份验证）。 注意：CORS 故障会导致错误，但是出于安全原因，该错误的详细信息不适用于 JavaScript。所有代码都知道发生了错误。确定具体出问题的唯一方法是查看浏览器的控制台以获取详细信息。 访问控制下面我会和大家探讨三种方案，这些方案都演示了跨域资源共享的工作方式。所有这些示例都使用XMLHttpRequest，它可以在任何支持的浏览器中发出跨站点请求。 简单请求一些请求不会触发 CORS预检（关于预检我们后面再介绍）。简单请求是满足一下所有条件的请求 允许以下的方法：GET、HEAD和 POST 除了由用户代理自动设置的标头（例如 Connection、User-Agent 或者在 Fetch 规范中定义为禁止标头名称的其他标头）外，唯一允许手动设置的标头是那些 Fetch 规范将其定义为 CORS安全列出的请求标头 ，它们是： Accept Accept-Language Content-Language Content-Type（下面会介绍） DPR Downlink Save-Data Viewport-Width Width Content-Type 标头的唯一允许的值是 application/x-www-form-urlencoded multipart/form-data text/plain 没有在请求中使用的任何 XMLHttpRequestUpload 对象上注册事件侦听器；这些可以使用XMLHttpRequest.upload 属性进行访问。 请求中未使用 ReadableStream对象。 例如，假定 web 内容 https://foo.example 想要获取 https://bar.other 域的资源，那么 JavaScript 中的代码可能会像下面这样写 123456const xhr = new XMLHttpRequest();const url = &apos;https://bar.other/resources/public-data/&apos;; xhr.open(&apos;GET&apos;, url);xhr.onreadystatechange = someHandler;xhr.send(); 这使用 CORS 标头来处理特权，从而在客户端和服务器之间执行某种转换。 让我们看看在这种情况下浏览器将发送到服务器的内容，并让我们看看服务器如何响应： 12345678GET /resources/public-data/ HTTP/1.1Host: bar.otherUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: en-us,en;q=0.5Accept-Encoding: gzip,deflateConnection: keep-aliveOrigin: https://foo.example 注意请求的标头 Origin ，它表明调用来自于 https://foo.example。让我们看看服务器是如何响应的 12345678910HTTP/1.1 200 OKDate: Mon, 01 Dec 2008 00:23:53 GMTServer: Apache/2Access-Control-Allow-Origin: *Keep-Alive: timeout=2, max=100Connection: Keep-AliveTransfer-Encoding: chunkedContent-Type: application/xml[…XML Data…] 服务端发送 Access-Control-Allow-Origin 作为响应。使用 Origin 标头和 Access-Control-Allow-Origin 展示了最简单的访问控制协议。在这个事例中，服务端使用Access-Control-Allow-Origin 作为响应，也就说明该资源可以被任何域访问。 如果位于https://bar.other的资源所有者希望将对资源的访问限制为仅来自https://foo.example的请求，他们应该发送如下响应 1Access-Control-Allow-Origin: https://foo.example 现在除了 https://foo.example 之外的任何域都无法以跨域方式访问到 https://bar.other的资源。 预检请求和上面探讨的简单请求不同，预检请求首先通过 OPTIONS 方法向另一个域上的资源发送 HTTP 请求，用来确定实际请求是否可以安全的发送。跨站点这样被预检，因为它们可能会影响用户数据。 下面是一个预检事例 123456const xhr = new XMLHttpRequest();xhr.open(&apos;POST&apos;, &apos;https://bar.other/resources/post-here/&apos;);xhr.setRequestHeader(&apos;X-PINGOTHER&apos;, &apos;pingpong&apos;);xhr.setRequestHeader(&apos;Content-Type&apos;, &apos;application/xml&apos;);xhr.onreadystatechange = handler;xhr.send(&apos;&lt;person&gt;&lt;name&gt;Arun&lt;/name&gt;&lt;/person&gt;&apos;); 上面的事例创建了一个 XML 请求体用来和 POST 请求一起发送。此外，设置了非标准请求头 X-PINGOTHER ，这个标头不是 HTTP/1.1 的一部分，但通常对 Web 程序很有用。由于请求的 Content-Type 使用 application/xml，并且设置了自定义标头，因此该请求被预检。如下图所示 如下所述，实际的 POST 请求不包含 Access-Control-Request- * 标头；只有 OPTIONS 请求才需要它们。 下面我们来看一下完整的客户端/服务器交互，首先是预检请求/响应 1234567891011121314151617181920OPTIONS /resources/post-here/ HTTP/1.1Host: bar.otherUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: en-us,en;q=0.5Accept-Encoding: gzip,deflateConnection: keep-aliveOrigin: http://foo.exampleAccess-Control-Request-Method: POSTAccess-Control-Request-Headers: X-PINGOTHER, Content-TypeHTTP/1.1 204 No ContentDate: Mon, 01 Dec 2008 01:15:39 GMTServer: Apache/2Access-Control-Allow-Origin: https://foo.exampleAccess-Control-Allow-Methods: POST, GET, OPTIONSAccess-Control-Allow-Headers: X-PINGOTHER, Content-TypeAccess-Control-Max-Age: 86400Vary: Accept-Encoding, OriginKeep-Alive: timeout=2, max=100Connection: Keep-Alive 上面的1 -11 行代表预检请求，预检请求使用 OPYIIONS 方法，浏览器根据上面的 JavaScript 代码段所使用的请求参数确定是否需要发送此请求，以便服务器可以响应是否可以使用实际请求参数发送请求。OPTIONS 是一种 HTTP / 1.1方法，用于确定来自服务器的更多信息，并且是一种安全的方法，这意味着它不能用于更改资源。请注意，与 OPTIONS 请求一起，还发送了另外两个请求标头（分别是第9行和第10行） 12Access-Control-Request-Method: POSTAccess-Control-Request-Headers: X-PINGOTHER, Content-Type Access-Control-Request-Method 标头作为预检请求的一部分通知服务器，当发送实际请求时，将使用POST 请求方法发送该请求。 Access-Control-Request-Headers 标头通知服务器，当发送请求时，它将与X-PINGOTHER 和 Content-Type 自定义标头一起发送。服务器可以确定这种情况下是否接受请求。 下面的 1 - 11行是服务器发回的响应，表示POST 请求和 X-PINGOTHER 是可以接受的，我们着重看一下下面这几行 1234Access-Control-Allow-Origin: http://foo.exampleAccess-Control-Allow-Methods: POST, GET, OPTIONSAccess-Control-Allow-Headers: X-PINGOTHER, Content-TypeAccess-Control-Max-Age: 86400 服务器完成响应表明源 http://foo.example 是可以接受的 URL，能够允许 POST、GET、OPTIONS 进行请求，允许自定义标头 X-PINGOTHER, Content-Type。最后，Access-Control-Max-Age 以秒为单位给出一个值，这个值表示对预检请求的响应可以缓存多长时间，在此期间内无需发送其他预检请求。 完成预检请求后，将发送实际请求： 12345678910111213141516171819202122232425262728POST /resources/post-here/ HTTP/1.1Host: bar.otherUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: en-us,en;q=0.5Accept-Encoding: gzip,deflateConnection: keep-aliveX-PINGOTHER: pingpongContent-Type: text/xml; charset=UTF-8Referer: https://foo.example/examples/preflightInvocation.htmlContent-Length: 55Origin: https://foo.examplePragma: no-cacheCache-Control: no-cache&lt;person&gt;&lt;name&gt;Arun&lt;/name&gt;&lt;/person&gt;HTTP/1.1 200 OKDate: Mon, 01 Dec 2008 01:15:40 GMTServer: Apache/2Access-Control-Allow-Origin: https://foo.exampleVary: Accept-Encoding, OriginContent-Encoding: gzipContent-Length: 235Keep-Alive: timeout=2, max=99Connection: Keep-AliveContent-Type: text/plain[Some GZIP&apos;d payload] 正式响应中很多标头我们在之前的文章已经探讨过了，本篇不再做详细的介绍，读者可以参考你还在为 HTTP 的这些概念头疼吗？ 查阅 带凭证的请求XMLHttpRequest 或 Fetch 和 CORS 最有趣的功能就是能够发出知道 HTTP Cookie 和 HTTP 身份验证的 凭证 请求。默认情况下，在跨站点 XMLHttpRequest 或 Fetch 调用中，浏览器将不发送凭据。调用 XMLHttpRequest对象或 Request 构造函数时必须设置一个特定的标志。 在下面这个例子中，最初从 http://foo.example 加载的内容对设置了 Cookies 的http://bar.other 上的资源进行了简单的 GET 请求， foo.example 上可能的代码如下 1234567891011const invocation = new XMLHttpRequest();const url = &apos;http://bar.other/resources/credentialed-content/&apos;; function callOtherDomain() &#123; if (invocation) &#123; invocation.open(&apos;GET&apos;, url, true); invocation.withCredentials = true; invocation.onreadystatechange = handler; invocation.send(); &#125;&#125; 第7行显示 XMLHttpRequest 上的标志，必须设置该标志才能使用 Cookie 进行调用。默认情况下，调用是不在使用 Cookie 的情况下进行的。由于这是一个简单的 GET 请求，因此不会进行预检，但是浏览器将拒绝任何没有 Access-Control-Allow-Credentials 的响应：标头为true，指的是响应不会返回 web 页面的内容。 上面的请求用下图可以表示 这是客户端和服务器之间的示例交换： 123456789101112131415161718192021222324252627GET /resources/access-control-with-credentials/ HTTP/1.1Host: bar.otherUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: en-us,en;q=0.5Accept-Encoding: gzip,deflateConnection: keep-aliveReferer: http://foo.example/examples/credential.htmlOrigin: http://foo.exampleCookie: pageAccess=2HTTP/1.1 200 OKDate: Mon, 01 Dec 2008 01:34:52 GMTServer: Apache/2Access-Control-Allow-Origin: https://foo.exampleAccess-Control-Allow-Credentials: trueCache-Control: no-cachePragma: no-cacheSet-Cookie: pageAccess=3; expires=Wed, 31-Dec-2008 01:34:53 GMTVary: Accept-Encoding, OriginContent-Encoding: gzipContent-Length: 106Keep-Alive: timeout=2, max=100Connection: Keep-AliveContent-Type: text/plain[text/plain payload] 上面第10行包含指向http://bar.other 上的内容 Cookie，但是如果 bar.other 没有以Access-Control-Allow-Credentials:true 响应（下面第五行），响应将被忽略，并且不能使用网站返回的内容。 请求凭证和通配符 当回应凭证请求时，服务器必须在 Access-Control-Allow-Credentials 中指定一个来源，而不能直接写* 通配符 因为上面示例代码中的请求标头包含 Cookie 标头，如果 Access-Control-Allow-Credentials 中是指定的通配符 * 的话，请求会失败。 注意上面示例中的 Set-Cookie 响应标头还设置了另外一个值，如果发生故障，将引发异常（取决于所使用的API）。 HTTP 响应标头下面会列出一些服务器跨域共享规范定义的 HTTP 标头，上面简单概述了一下，现在一起来认识一下，主要会介绍下面这些 Access-Control-Allow-Origin Access-Control-Allow-Credentials Access-Control-Allow-Headers Access-Control-Allow-Methods Access-Control-Expose-Headers Access-Control-Max-Age Access-Control-Request-Headers Access-Control-Request-Method Origin Access-Control-Allow-OriginAccess-Control-Allow-Origin 是 HTTP 响应标头，指示响应是否能够和给定的源共享资源。Access-Control-Allow-Origin 指定单个资源会告诉浏览器允许指定来源访问资源。对于没有凭据的请求 *通配符，告诉浏览器允许任何源访问资源。 例如，如果要允许源 https://mozilla.org 的代码访问资源，可以使用如下的指定方式 12Access-Control-Allow-Origin: https://mozilla.orgVary: Origin 如果服务器指定单个来源而不是*通配符，则服务器还应在 Vary 响应标头中包含该来源。 Access-Control-Allow-CredentialsAccess-Control-Allow-Credentials 是 HTTP 的响应标头，这个标头告诉浏览器，当包含凭证请求（Request.credentials）时是否将响应公开给前端 JavaScript 代码。 这时候你会问到 Request.credentials 是什么玩意？不要着急，来给你看一下，首先来看 Request 是什么玩意， 实际上，Request 是 Fetch API 的一类接口代表着资源请求。一般创建 Request 对象有两种方式 使用 Request() 构造函数创建一个 Request 对象 还可以通过 FetchEvent.request api 操作来创建 再来说下 Request.credentials 是什么意思，Request 接口的凭据只读属性指示在跨域请求的情况下，用户代理是否应从其他域发送 cookie。（其他 Request 对象的方法详见 https://developer.mozilla.org/en-US/docs/Web/API/Request） 当发送的是凭证模式的请求包含 （Request.credentials）时，如果 Access-Control-Allow-Credentials 值为 true，浏览器将仅向前端 JavaScript 代码公开响应。 1Access-Control-Allow-Credentials: true 凭证一般包括 cookie、认证头和 TLS 客户端证书 当用作对预检请求响应的一部分时，这表明是否可以使用凭据发出实际请求。注意简单的GET 请求不会进行预检。 可以参考一个实际的例子 https://www.jianshu.com/p/ea485e5665b3 Access-Control-Allow-HeadersAccess-Control-Allow-Headers 是一个响应标头，这个标头用来响应预检请求，它发出实际请求时可以使用哪些HTTP标头。 示例 自定义标头 这是 Access-Control-Allow-Headers 标头的示例。它表明除了像 CROS 安全列出的请求标头外，对服务器的 CROS 请求还支持名为 X-Custom-Header 的自定义标头。 1Access-Control-Allow-Headers: X-Custom-Header 多个标头 这个例子展示了 Access-Control-Allow-Headers 如何使用多个标头 1Access-Control-Allow-Headers: X-Custom-Header, Upgrade-Insecure-Requests 绕过其他限制 尽管始终允许使用 CORS 安全列出的请求标头，并且通常不需要在 Access-Control-Allow-Headers 中列出这些标头，但是无论如何列出它们都将绕开适用的其他限制。 1Access-Control-Allow-Headers: Accept 这里你可能会有疑问，哪些是 CORS 列出的安全标头？（别嫌累，就是这么麻烦） 有下面这些 Accep、Accept-Language、Content-Language、Content-Type ，当且仅当包含这些标头时，无需在 CORS 上下文中发送预检请求。 Access-Control-Allow-MethodsAccess-Control-Allow-Methods 也是响应标头，它指定了哪些访问资源的方法可以使用预检请求。例如 12Access-Control-Allow-Methods: POST, GET, OPTIONSAccess-Control-Allow-Methods: * Access-Control-Expose-HeadersAccess-Control-Expose-Headers 响应标头表明哪些标头可以作为响应的一部分公开。默认情况下，仅公开6个CORS安全列出的响应标头，分别是 Cache-Control Content-Language Content-Type Expires Last-Modified Pragma 如果希望客户端能够访问其他标头，则必须使用 Access-Control-Expose-Headers 标头列出它们。下面是示例 要公开非 CORS 安全列出的请求标头，可以像如下这样指定 1Access-Control-Expose-Headers: Content-Length 要另外公开自定义标头，例如 X-Kuma-Revision，可以指定多个标头，并用逗号分隔 1Access-Control-Expose-Headers: Content-Length, X-Kuma-Revision 在不是凭证请求中，你还可以使用通配符 1Access-Control-Expose-Headers: * 但是，这不会通配 Authorization 标头，因此如果需要公开它，则需要明确列出 1Access-Control-Expose-Headers: *, Authorization Access-Control-Max-AgeAccess-Control-Max-Age 响应头表示预检请求的结果可以缓存多长时间，例如 1Access-Control-Max-Age: 600 表示预检请求可以缓存10分钟 Access-Control-Request-Headers浏览器在发出预检请求时使用 Access-Control-Request-Headers 请求标头，使服务器知道在发出实际请求时客户端可能发送的 HTTP 标头。 1Access-Control-Request-Headers: X-PINGOTHER, Content-Type Access-Control-Request-Method同样的，Access-Control-Request-Method 响应标头告诉服务器发出预检请求时将使用那种 HTTP 方法。此标头是必需的，因为预检请求始终是 OPTIONS，并且使用的方法与实际请求不同。 1Access-Control-Request-Method: POST OriginOrigin 请求标头表明匹配的来源，它不包含任何信息，仅仅包含服务器名称，它与 CORS 请求以及 POST 请求一起发送，它类似于 Referer 标头，但与此标头不同，它没有公开整个路径。例如 1Origin: https://developer.mozilla.org HTTP 条件请求HTTP 具有条件请求的概念，通过比较资源更新生成的值与验证器的值进行比较，来确定资源是否进行过更新。这样的请求对于验证缓存的内容、条件请求、验证资源的完整性来说非常重要。 原则HTTP 条件请求是根据特定标头的值执行不同的请求，这些标头定义了一个前提条件，如果前提条件匹配或不匹配，则请求的结果将有所不同。 对于 安全 的方法，像是 GET、用于请求文档的资源，仅当条件请求的条件满足时发回文档资源，所以，这种方式可以节约带宽。 什么是安全的方法，对于 HTTP 来说，安全的方法是不会改变服务器状态的方法，换句话说，如果方法只是只读操作，那么它肯定是安全的方法，比如说 GET 请求，它肯定是安全的方法，因为它只是请求资源。几种常见的方法肯定是安全的，它们是 GET、HEAD和 OPTIONS。所有安全的方法都是幂等的（这他妈幂等又是啥意思？）但不是所有幂等的方法都是安全的，例如 PUT 和 DELETE 都是幂等的，但不安全。 幂等性：如果相同的客户端发起一次或者多次 HTTP 请求会得到相同的结果，则说明 HTTP 是幂等的。（我们这次不深究幂等性） 对于 非安全 的方法，像是 PUT，只有原始文档与服务器上存储的资源相同时，才可以使用条件请求来传输文档。（PUT 方法通常用来传输文件，就像 FTP 协议的文件上传一样） 验证所有的条件请求都会尝试检查服务器上存储的资源是否与某个特定版本的资源相匹配。为了满足这种情况，条件请求需要指示资源的版本。由于无法和整个文件逐个字符进行比较，因此需要把整个文件描绘成一个值，然后把此值和服务器上的资源进行比较，这种方式称为比较器，比较器有两个条件 文档的最后修改日期 一个不透明的字符串，用于唯一标识每个版本，称为实体标签或 Etag。 比较两个资源是否时相同的版本有些复杂，根据上下文，有两种相等性检查 当期望的是字节对字节进行比较时，例如在恢复下载时，使用强 Etag进行验证 当用户代理需要比较两个资源是否具有相同的内容时，使用若 Etag 进行验证 HTTP 协议默认使用 强验证，它指定何时进行弱验证 强验证强验证保证的是字节 级别的验证，严格的验证非常严格，可能在服务器级别难以保证，但是它能够保证任何时候都不会丢失数据，但这种验证丢失性能。 要使用 Last-Modified 很难实现强验证，通常，这是通过使用带有资源的 MD5 哈希值的Etag 来完成的。 弱验证弱验证不同于强验证，因为如果内容相等，它将认为文档的两个版本相同，例如，一个页面与另一个页面的不同之处仅在于页脚的日期不同，因此该页面被认为与其他页面相同。而使用强验证时则被认为这两个版本是不同的。构建一个若验证的 Etag 系统可能会非常复杂，因为这需要了解每个页面元素的重要性，但是对于优化缓存性能非常有用。 下面介绍一下 Etag 如何实现强弱验证。 Etag 响应头是特定版本的标识，它能够使缓存变得更高效并能够节省带宽，因为如果缓存内容未发生变更，Web 服务器则不需要重新发送完整的响应。除此之外，Etag 能够防止资源同时更新互相覆盖。 如果给定 URL 上的资源发生变更，必须生成一个新的 Etag 值，通过比较它们可以确定资源的两个表示形式是否相同。 Etag 值有两种，一种是强 Etag，一种是弱 Etag； 强 Etag 值，无论实体发生多么细微的变化都会改变其值，一般的表示如下 1Etag: &quot;33a64df551425fcc55e4d42a148795d9f25f89d4&quot; 弱 Etag 值，弱 Etag 值只用于提示资源是否相同。只有资源发生了根本改变，产生差异时才会改变 Etag 值。这时，会在字段值最开始处附加 W/。 1Etag: W/&quot;0815&quot; 下面就来具体探讨一下条件请求的标头和 Etag 的关系 条件请求条件请求主要包含的标头如下 If-Match If-None-Match If-Modified-Since If-Unmodified-Since If-Range If-Match对于 GET 和 POST 方法，服务器仅在与列出的 Etag（响应标头） 之一匹配时才返回请求的资源。这里又多了一个新词 Etag，我们稍后再说 Etag 的用法。对于像是 PUT和其他非安全的方法，在这种情况下，它仅仅将上传资源。 下面是两种常见的案例 对于 GET 和 POST 方法，会结合使用 Range 标头，它可以确保新发送请求的范围与上一个请求的资源相同，如果不匹配的话，会返回 416 响应。 对于其他方法，特别是 PUT 方法，If-Match 可以防止丢失更新，服务器会比对 If-Match 的字段值和资源的 Etag 值，仅当两者一致时，才会执行请求。反之，则返回状态码 412 Precondition Failed 的响应。例如 12If-Match: &quot;bfc13a64729c4290ef5b2c2730249c88ca92d82d&quot;If-Match: * If-None-Match条件请求，它与 If-Match 的作用相反，仅当 If-None-Match 的字段值与 Etag 值不一致时，可处理该请求。对于GET 和 HEAD ，仅当服务器没有与给定资源匹配的 Etag 时，服务器将返回 200 OK作为响应。对于其他方法，仅当最终现有资源的 Etag 与列出的任何值都不匹配时，才会处理请求。 当 GET 和 POST 发送的 If-None-Match与 Etag 匹配时，服务器会返回 304。 123If-None-Match: &quot;bfc13a64729c4290ef5b2c2730249c88ca92d82d&quot;If-None-Match: W/&quot;67ab43&quot;, &quot;54ed21&quot;, &quot;7892dd&quot;If-None-Match: * If-Modified-SinceIf-Modified-Since 是 HTTP 条件请求的一部分，只有在给定日期之后，服务端修改了请求所需要的资源，才会返回 200 OK 的响应。如果在给定日期之后，服务端没有修改内容，响应会返回 304 并且不带任何响应体。If-Modified-Since 只能使用 GET 和 HEAD请求。 If-Modified-Since 与 If-None-Match 结合使用时，它将被忽略，除非服务器不支持 If-None-Match。一般表示如下 1If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT 注意：这是格林威治标准时间。HTTP 日期始终以格林尼治标准时间表示，而不是本地时间。 If-RangeIf-Range 也是条件请求，如果满足条件（If-Range 的值和 Etag 值或者更新的日期时间一致），则会发出范围请求，否则将会返回全部资源。它的一般表示如下 12If-Range: Wed, 21 Oct 2015 07:28:00 GMTIf-Range: bfc13a64729c4290ef5b2c2730249c88ca92d82d If-Unmodified-SinceIf-Unmodified-Since HTTP 请求标头也是一个条件请求，服务器只有在给定日期之后没有对其进行修改时，服务器才返回请求资源。如果在指定日期时间后发生了更新，则以状态码 412 Precondition Failed 作为响应返回。 1If-Unmodified-Since: Wed, 21 Oct 2015 07:28:00 GMT 条件请求示例缓存更新条件请求最常见的示例就是更新缓存，如果缓存是空或没有缓存，则以200 OK的状态发送回请求的资源。如下图所示 客户端第一次发送请求没有，缓存为空并且没有条件请求，服务器在收到客户端请求后，设置验证器 Last-Modified 和 Etag 标签，并把这两个标签随着响应一起发送回客户端。 下一次客户端再发送相同的请求后，会直接从缓存中提取，只要缓存没有过期，就不会有任何新的请求到达服务器重新下载资源。但是，一旦缓存过期，客户端不会直接使用缓存的值，而是发出条件请求。验证器的值用作 If-Modified-Since 和If-Match标头的参数。 缓存过期后客户端重新发起请求，服务器收到请求后发现如果资源没有更改，服务器会发回 304 Not Modified响应，这使缓存再次刷新，并让客户端使用缓存的资源。尽管有一个响应/请求往返消耗一些资源，但是这比再次通过有线传输整个资源更有效。 如果资源已经发生更改，则服务器仅使用新版本的资源返回 200 OK 响应，就像没有条件请求，并且客户端会重新使用新的资源，从这个角度来讲，缓存是条件请求的前置条件。 断点续传HTTP 可以支持文件的部分下载，通过保留已获得的信息，此功能允许恢复先前的操作，从而节省带宽和时间。 支持断点续传的服务器通过发送 Accept-Ranges 标头广播此消息，一旦发生这种情况，客户端可以通过发送缺少范围的 Ranges标头来恢复下载 这里你可能有疑问 Ranges 和 Content-Range是什么，来解释一下 Range Range HTTP 请求标头指示服务器应返回文档指定部分的资源，可以一次请求一个 Range 来返回多个部分，服务器会将这些资源返回各个文档中。如果服务器成功返回，那么将返回 206 响应；如果 Range 范围无效，服务器返回416 Range Not Satisfiable错误；服务器还可以忽略 Range 标头，并且返回 200 作为响应。 1Range: bytes=200-1000, 2000-6576, 19000- 还有一种表示是 1Range: bytes=0-499, -500 它们分别表示请求前500个字节和最后500个字节，如果范围重叠，则服务器可能会拒绝该请求。 Content-Range HTTP 的 Content-Range 响应标头是针对范围请求而设定的，返回响应时使用首部字段Content-Range，能够告知客户端响应实体的哪部分是符合客户端请求的，字段以字节为单位。它的一般表示如下 1Content-Range: bytes 200-1000/67589 上段代码表示从所有 67589 个字节中返回 200-1000 个字节的内容 那么上面的 Content-Range你也应该知道是什么意思了 断点续传的原理比较简单，但是这种方式存在潜在的问题：如果在两次下载资源的期间进行了资源更新，那么获得的范围将对应于资源的两个不同版本，并且最终文档将被破坏。 为了阻止这种情况的出现，就会使用条件请求。对于范围来说，有两种方法可以做到这一点。一种方法是使用 If-Modified-Since和If-Match，如果前提条件失败，服务器将返回错误；然后客户端从头开始重新下载。 即使此方法有效，当文档资源发生改变时，它也会添加额外的 响应/请求 交换。这会降低性能，并且 HTTP 具有特定的标头来避免这种情况 If-Range。 该解决方案效率更高，但灵活性稍差一些，因为在这种情况下只能使用一个 Etag。 通过乐观锁避免丢失更新Web 应用程序中最普遍的操作是资源更新。这在任何文件系统或应用程序中都很常见，但是任何允许存储远程资源的应用程序都需要这种机制。 使用 put 方法，你可以实现这一点，客户端首先读取原始文件对其进行修改，然后把它们发送到服务器。 上面这种请求响应存在问题，一旦考虑到并发性，事情就会变得不准确。当客户端在本地修改资源打算重新发送之前，第二个客户端可以获取相同的资源并对资源进行修改操作，这样就会造成问题。当它们重新发送请求到服务器时，第一个客户端所做的修改将被第二次客户端的修改所覆盖，因为第二次客户端修改并不知道第一次客户端正在修改。资源提交并更新的一方不会传达给另外一方，所以要保留哪个客户的更改，将随着他们提交的速度而变化；这取决于客户端，服务器的性能，甚至取决于人工在客户端编辑文档的性能。例如下面这个流程 如果没有两个用户同时操作服务器，也就不存在这个问题。但是，现实情况是不可能只有单个用户出现的，所以为了规避或者避免这个问题，我们希望客户端资源在更新时进行提示或者修改被拒绝时收到通知。 条件请求允许实现乐观锁算法。这个概念是允许所有的客户端获取资源的副本，然后让他们在本地修改资源，并成功通过允许第一个客户端提交更新来控制并发，基于此服务端的后面版本的更新都将被拒绝。 这是使用 If-Match 或 If-Unmodified-Since标头实现的。如果 Etag 与原始文件不匹配，或者自获取以来已对文件进行了修改，则更改为拒绝更新，并显示412 Precondition Failed错误。 HTTP CookiesHTTP 协议中的 Cookie 包括 Web Cookie 和浏览器 Cookie，它是服务器发送到 Web 浏览器的一小块数据。服务器发送到浏览器的 Cookie，浏览器会进行存储，并与下一个请求一起发送到服务器。通常，它用于判断两个请求是否来自于同一个浏览器，例如用户保持登录状态。 HTTP Cookie 机制是 HTTP 协议无状态的一种补充和改良 Cookie 主要用于下面三个目的 会话管理 登陆、购物车、游戏得分或者服务器应该记住的其他内容 个性化 用户偏好、主题或者其他设置 追踪 记录和分析用户行为 Cookie 曾经用于一般的客户端存储。虽然这是合法的，因为它们是在客户端上存储数据的唯一方法，但如今建议使用现代存储 API。Cookie 随每个请求一起发送，因此它们可能会降低性能（尤其是对于移动数据连接而言）。客户端存储的现代 API 是 Web 存储 API（localStorage 和 sessionStorage）和 IndexedDB。 创建 Cookie当接收到客户端发出的 HTTP 请求时，服务器可以发送带有响应的 Set-Cookie 标头，Cookie 通常由浏览器存储，然后将 Cookie 与 HTTP 标头一同向服务器发出请求。可以指定到期日期或持续时间，之后将不再发送Cookie。此外，可以设置对特定域和路径的限制，从而限制 cookie 的发送位置。 Set-Cookie 和 Cookie 标头Set-Cookie HTTP 响应标头将 cookie 从服务器发送到用户代理。下面是一个发送 Cookie 的例子 123456HTTP/2.0 200 OKContent-type: text/htmlSet-Cookie: yummy_cookie=chocoSet-Cookie: tasty_cookie=strawberry[page content] 此标头告诉客户端存储 Cookie 现在，随着对服务器的每个新请求，浏览器将使用 Cookie 头将所有以前存储的 cookie 发送回服务器。 123GET /sample_page.html HTTP/2.0Host: www.example.orgCookie: yummy_cookie=choco; tasty_cookie=strawberry Cookie 主要分为三类，它们是 会话Cookie、永久Cookie 和 Cookie的 Secure 和 HttpOnly 标记，下面依次来介绍一下 会话 Cookies上面的示例创建的是会话 Cookie ，会话 Cookie 有个特征，客户端关闭时 Cookie 会删除，因为它没有指定Expires 或 Max-Age 指令。这两个指令你看到这里应该比较熟悉了。 但是，Web 浏览器可能会使用会话还原，这会使大多数会话 Cookie 保持永久状态，就像从未关闭过浏览器一样 永久性 Cookies永久性 Cookie 不会在客户端关闭时过期，而是在特定日期（Expires）或特定时间长度（Max-Age）外过期。例如 1Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Cookie的 Secure 和 HttpOnly 标记安全的 Cookie 需要经过 HTTPS 协议通过加密的方式发送到服务器。即使是安全的，也不应该将敏感信息存储在cookie 中，因为它们本质上是不安全的，并且此标志不能提供真正的保护。 HttpOnly 的作用 会话 cookie 中缺少 HttpOnly 属性会导致攻击者可以通过程序(JS脚本、Applet等)获取到用户的 cookie 信息，造成用户cookie 信息泄露，增加攻击者的跨站脚本攻击威胁。 HttpOnly 是微软对 cookie 做的扩展，该值指定 cookie 是否可通过客户端脚本访问。 如果在 Cookie 中没有设置 HttpOnly 属性为 true，可能导致 Cookie 被窃取。窃取的 Cookie 可以包含标识站点用户的敏感信息，如 ASP.NET 会话 ID 或 Forms 身份验证票证，攻击者可以重播窃取的 Cookie，以便伪装成用户或获取敏感信息，进行跨站脚本攻击等。 Cookie 的作用域Domain 和 Path 标识定义了 Cookie 的作用域：即 Cookie 应该发送给哪些 URL。 Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前主机(不包含子域名）。如果指定了Domain，则一般包含子域名。 例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如developer.mozilla.org）。 例如，设置 Path=/docs，则以下地址都会匹配： 123/docs/docs/Web//docs/Web/HTTP","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://vincentruan.github.io/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://vincentruan.github.io/tags/HTTP/"}]},{"title":"Mermaid 实用教程","slug":"Mermaid-实用教程","date":"2020-02-04T13:40:12.000Z","updated":"2020-02-17T02:40:44.658Z","comments":true,"path":"2020/02/04/Mermaid-实用教程/","link":"","permalink":"https://vincentruan.github.io/2020/02/04/Mermaid-实用教程/","excerpt":"","text":"相关文档官方文档 Github地址 语句末尾分号是可选的。%% 行注释。 流程图语法说明图表方向Mermaid 支持多种图表的方向，语法如下： 12graph 方向描述 图表中的其他语句... 其中“方向描述”为 用词 含义 TB 从上到下 BT 从下到上 RL 从右到左 LR 从左到右 节点定义即流程图中每个文本块，包括开始、结束、处理、判断等。Mermaid 中每个节点都有一个 id，以及节点的文字。 表述 说明 id[文字] 矩形节点 id(文字) 圆角矩形节点 id((文字)) 圆形节点 id&gt;文字] 右向旗帜状节点 id{文字} 菱形节点 需要注意的是，如果节点的文字中包含标点符号，需要时用双引号包裹起来。另外如果希望在文字中使用换行，请使用替换换行 节点间的连线 表述 说明 &gt; 添加尾部箭头 - 不添加尾部箭头 -- 单线 --text-- 单线上加文字 == 粗线 ==text== 粗线加文字 -.- 虚线 -.text.- 虚线加文字 子图表使用以下语法添加子图表 123subgraph 子图表名称 子图表中的描述语句...end123 对 font awesome 的支持使用 fa: #图表名称# 的语法添加 fontawesome。 12345graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D; 方向 TB/TD - top bottom BT - bottom top RL - right left LR - left right 12graph TB Start --&gt; Stop 节点12graph LR id 12graph LR id[带文字节点] 12graph LR id(圆角节点) 12graph LR id((圆形节点)) 12graph LR id&gt;不对称节点] 12graph LR id&#123;菱形节点&#125; 连接线实线，箭头，无文字12graph LR A--&gt;B 实线，无箭头，无文字12graph LR A---B 实线，无箭头，文字前面两个 -，后面三个 - 12graph LR A-- 文字 ---B 或 12graph LR A--- |文字| B 实线，箭头，文字12graph LR A-- 文字 --&gt;B 或 12graph LR A--&gt; |文字| B 虚线，箭头，无文字12graph LR; A-.-&gt;B; 虚线，箭头，文字12graph LR A-. text .-&gt; B 大箭头，无文字12graph LR A ==&gt; B 大箭头，文字12graph LR A == text ==&gt; B 特殊语法引号文字里用引号避免一些特殊字符的错误。比如矩形节点里有 () 时就无法渲染，所以加上引号。 12graph LR id1[\"This is the (text) in the box\"] 实体字符可以使用 HTML 中的实体字符。 12graph LR A[\"A double quote:#quot;\"] --&gt;B[\"A dec char:#9829;\"] 子图1234567891011graph TB c1--&gt;a2 subgraph one a1--&gt;a2 end subgraph two b1--&gt;b2 end subgraph three c1--&gt;c2 end 样式linkStyle 后面的数字表示第几根线，从 0 开始。可以指定颜色和粗细。 1234567graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D; linkStyle 0 stroke:#0ff,stroke-width:2px; linkStyle 3 stroke:#ff3,stroke-width:4px; 可以设置节点背景，边框颜色，粗细，实线还是虚线 1234graph LR id1(Start)--&gt;id2(Stop) style id1 fill:#f9f,stroke:#333,stroke-width:4px style id2 fill:#ccf,stroke:#f66,stroke-width:2px,stroke-dasharray: 5, 5 样式类12345678graph LR A--&gt;B %% 定义样式类 classDef className fill:#f9f,stroke:#333,stroke-width:4px; %% 应用样式类，markdown里没效果 class A className 1classDef default fill:#f9f,stroke:#333,stroke-width:4px; 定义一个名为 default 的类，节点没有指定特定样式类时，将都会应用这个样式类。 图标可以使用 Font Awesome 图标。语法 fa:icon class name。 12345graph TD B[\"fa:fa-twitter for peace\"] B--&gt;C[fa:fa-ban forbidden] B--&gt;D(fa:fa-spinner); B--&gt;E(A fa:fa-camera-retro perhaps?); 时序图1234567891011sequenceDiagram participant Alice participant Bob Alice-&gt;John: Hello John, how are you? loop Healthcheck John-&gt;John: Fight against hypochondria end Note right of John: Rational thoughts &lt;br/&gt;prevail... John--&gt;Alice: Great! John-&gt;Bob: How about you? Bob--&gt;John: Jolly good! 参与者如果不显示声明，参与者将根据第一次出现的顺序排列，如： 123sequenceDiagram Alice-&gt;&gt;John: Hello John, how are you? John--&gt;&gt;Alice: Great! 第一条语句出现了两个参与者角色，而在这条语句中，Alice 在 John 之前，所以图中也是这个顺序。如果不想根据第一次出现的顺序来排，可以主动声明以定义顺序： 12345sequenceDiagram participant John participant Alice Alice-&gt;&gt;John: Hello John, how are you? John--&gt;&gt;Alice: Great! 别名可以给角色写一个简短的别名以方便书写。 12345sequenceDiagram participant A as Alice participant J as John A-&gt;&gt;J: Hello John, how are you? J-&gt;&gt;A: Great! 消息消息连线有六种样式。 有一个-是实线，两个-是虚线。 1234567sequenceDiagram A-&gt;B: 无箭头实线 A--&gt;B: 无箭头虚线(点线) A-&gt;&gt;B: 有箭头实线 A--&gt;&gt;B: 有箭头实线 A-x B: 有箭头实线，加上叉 A--x B: 有箭头虚线，加上叉 活动期1234567sequenceDiagram Alice-&gt;&gt;John: Hello John, how are you? %% activate 角色名 表示激活控制焦点 activate John John--&gt;&gt;Alice: Great! %% deactivate 角色名 表示控制焦点结束 deactivate John 使用 +/- 的更方便的写法： 123sequenceDiagram Alice-&gt;&gt;+John: Hello John, how are you? John--&gt;&gt;-Alice: Great! 可以嵌套： 12345sequenceDiagram Alice-&gt;&gt;+John: Hello John, how are you? Alice-&gt;&gt;+John: John, can you hear me? John--&gt;&gt;-Alice: Hi Alice, I can hear you! John--&gt;&gt;-Alice: I feel great! 备注语法：Note [ right of | left of | over ] [Actor]。 表述 含义 right of 右侧 left of 左侧 over 在当中，可以横跨多个参与者 123sequenceDiagram participant John Note right of John: Text in note over 可用于单独一个角色上，也可以用于相邻两个角色间： 123sequenceDiagram Alice-&gt;John: Hello John, how are you? Note over Alice,John: A typical interaction 循环语法： 12345678910loop Loop text... statements ...endsequenceDiagram Alice-&gt;John: Hello John, how are you? %% loop 后跟循环体说明文字 loop Every minute John--&gt;Alice: Great! %% 标记循环结束 end 选择语法： 12345alt Describing text... statements ...else... statements ...end 可选条件，比如在没有 else 分支的情况下使用，有点类似 java 中的 switch 的 default 分支，代表剩下所有情况。 12345678910111213opt Describing text... statements ...endsequenceDiagram Alice-&gt;&gt;Bob: Hello Bob, how are you? alt is sick Bob-&gt;&gt;Alice: Not so good :( else is well Bob-&gt;&gt;Alice: Feeling fresh like a daisy end opt Extra response Bob-&gt;&gt;Alice: Thanks for asking end","categories":[{"name":"mermaid","slug":"mermaid","permalink":"https://vincentruan.github.io/categories/mermaid/"}],"tags":[{"name":"mermaid","slug":"mermaid","permalink":"https://vincentruan.github.io/tags/mermaid/"}]},{"title":"使用Apache Bench和Gnuplot产生性能测试图","slug":"使用Apache-Bench-和-Gnuplot产生性能测试图","date":"2020-02-04T13:13:26.000Z","updated":"2020-02-25T15:09:15.062Z","comments":true,"path":"2020/02/04/使用Apache-Bench-和-Gnuplot产生性能测试图/","link":"","permalink":"https://vincentruan.github.io/2020/02/04/使用Apache-Bench-和-Gnuplot产生性能测试图/","excerpt":"Apache Beach (ab)是Apache自带的一个性能测试工具，专门用来测试网站的性能， 不仅限于Apache web服务器。 它可以同时模拟多个并发请求，测试Web服务器的最大承载压力，同时也可以根据Apache Bench提供的测试结果对服务器性能参数进行调整。它可以记录测试数据，其它工具比如Gnuplot可以利用测试数据进行分析。它也可以提供一个summary，可以直观显示当前测试的web服务器的性能。","text":"Apache Beach (ab)是Apache自带的一个性能测试工具，专门用来测试网站的性能， 不仅限于Apache web服务器。 它可以同时模拟多个并发请求，测试Web服务器的最大承载压力，同时也可以根据Apache Bench提供的测试结果对服务器性能参数进行调整。它可以记录测试数据，其它工具比如Gnuplot可以利用测试数据进行分析。它也可以提供一个summary，可以直观显示当前测试的web服务器的性能。 安装ab ab是Apache httpd的一部分。不同的发行版提供了不同的安装方法。 比如在笔者使用的redhat 6.4上可以查看此工具在哪个包里： 12345678#yum provides /usr/bin/ab......httpd-tools-2.2.15-30.el6.centos.x86_64 : Tools for use with the Apache HTTP : ServerRepo : updatesMatched from:Filename : /usr/bin/ab...... 它被打包在httpd-tools包里，安装httpd-tools: 1yum install httpd-tools 安装成功后查看帮助： 1ab -h 或 1man ab 运行ab 一个最简单的ab例子就是： 1# ab -n 100 -c 10 http://www.google.com/ 注意网址后面要加”/“或者明确的path如”https://www.google.com/?gfe_rd=cr&amp;ei=_BvfU77ZGMeL8QfugIHAAw&quot;.“-c”是并发数，可以模拟同时有多少个clients并发访问。“-n”表示总的请求数。每个client发送的请求数为此数字除以client数（上面的数字）。“-t”可以指定测试的最大时间，如果还不到此数请求已经发完，那么测试也会结束。当使用-t参数时，ab内部默认最大的请求数为50000，为了同时使用”-n”指定的参数，可以将”-t”参数放在”-n”参数之前， 如果想了解更多的信息， 可以查看这篇文章. 实际运行ab 我使用apache ab要测试的是一个tomcat搭建的集群，上面跑着CPU密集型的一个应用程序，前面使用nginx作为load balancer。 此应用的一个主要的服务通过RESTful service提供， 并且是POST类型的。 Request body是一个XML。 我想随机的替换body中的一个属性，以便测试动态请求对服务器的影响。 但是Apache ab只能提供静态的数据，所以我下载了它的代码并改造了一下。 首先创建了一个request.xml， 并将其中的那个属性改为占位符 修改ab.c文件，将发送请求中的占位符用随机数代替 修改的代码可重用性不高，在这里就不贴了。 写了一个脚本，可以测试不同的并发数： 12345for var in &#123;4,20,50,100,150,200,300&#125;do ab -g plot/biz$var.dat -r -c $&#123;var&#125; -n $&#123;total&#125; -H 'Accept:application/xml' -p request.xml -T 'application/xml' http://localhost:8080/app/bizdone 使用Gnuplot生成图表 在上一步中生成了测试数据，我们可以通过Gnuplot这一强大的工具生成漂亮的图表了。 在生成图表之前，我们还需要处理一下获得的数据， 如果直接使用测试生成报表，我们可能得到这样一个图表： 相应的Gnuplot文件为： 123456789101112131415161718192021222324252627282930#output as png imageset terminal png size 1000,560#save file to \"domain.png\"set output \"biz.png\"#graph titleset title \"Biz Performance\"set key invert reverse Left outside#nicer aspect ratio for image size#set size 1,0.7# y-axis gridset grid y#x-axis labelset xlabel \"requests\"#y-axis labelset ylabel \"response time (ms)\"#plot data from \"biz.dat\" using column 9 with smooth sbezier lines#and title of \"Biz Performance\" for the given dataplot \"biz4.dat\" using 9 smooth sbezier with lines title \"concurrency 4\", \\\"biz20.dat\" using 9 smooth sbezier with lines title \"concurrency 20\", \\\"biz50.dat\" using 9 smooth sbezier with lines title \"concurrency 50\", \\\"biz100.dat\" using 9 smooth sbezier with lines title \"concurrency 100\", \\\"biz150.dat\" using 9 smooth sbezier with lines title \"concurrency 150\", \\\"biz200.dat\" using 9 smooth sbezier with lines title \"concurrency 200\", \\\"biz300.dat\" using 9 smooth sbezier with lines title \"concurrency 300\" 这张图有参考价值，我们可以看到大部分的请求的相应时间落在那个数值段中，但是不能以时间序列显示服务器的性能。 它是以”总用时“ (ttime) 进行排序，所以一般它会一条上升的曲线来显示。这篇文章中指出了一种按照时间序列显示数据的方法。 Apapche ab生成的测试数据中已经包含了时间戳，可以修改Gnuplot生成按时间序列显示的响应时间图：[ Gnuplot文件为： 123456789101112131415161718192021222324252627# Let's output to a jpeg fileset terminal jpeg size 500,500# This sets the aspect ratio of the graphset size 1, 1# The file we'll write toset output \"graphs/timeseries.jpg\"# The graph titleset title \"Benchmark testing\"# Where to place the legend/keyset key left top# Draw gridlines oriented on the y axisset grid y# Specify that the x-series data is time dataset xdata time# Specify the *input* format of the time dataset timefmt \"%s\"# Specify the *output* format for the x-axis tick labelsset format x \"%S\"# Label the x-axisset xlabel 'seconds'# Label the y-axisset ylabel \"response time (ms)\"# Tell gnuplot to use tabs as the delimiter instead of spaces (default)set datafile separator '\\t'# Plot the dataplot \"data/testing.tsv\" every ::2 using 2:5 title 'response time' with pointsexit 为了得到按时间序列显示的吞吐率图表，我们可以处理一下得到的测试数据： 12345for var in &#123;4,20,50,100,150,200,300&#125;do start_time=`awk '&#123;print $6&#125;' plot/biz$var.dat | grep -v 'wait' | sort | uniq -c|head -1|awk '&#123;print $2&#125;'` awk '&#123;print $6&#125;' plot/biz$var.dat | grep -v 'wait' | sort | uniq -c|awk -v t=$start_time '&#123;print $2-t,$1&#125;' &gt; plot/epochtime$var.datdone 然后根据一下的Gnuplot配置生成图表。 1234567891011121314151617181920212223242526272829#output as png imageset terminal png size 1000,560set output \"throughput.png\"#graph titleset title \"Throughput\"set key invert reverse Left outside#nicer aspect ratio for image size#set size 1,0.6# y-axis gridset grid y#x-axis labelset xlabel \"time\"#y-axis labelset ylabel \"responses per second\"plot \"epochtime4.dat\" using 1:2 with lines title \"concurrency 4\", \\\"epochtime20.dat\" using 1:2 with lines title \"concurrency 20\", \\\"epochtime50.dat\" using 1:2 with lines title \"concurrency 50\", \\\"epochtime100.dat\" using 1:2 with lines title \"concurrency 100\", \\\"epochtime150.dat\" using 1:2 with lines title \"concurrency 150\", \\\"epochtime200.dat\" using 1:2 with lines title \"concurrency 200\", \\\"epochtime300.dat\" using 1:2 with lines title \"concurrency 300\"","categories":[{"name":"性能测试","slug":"性能测试","permalink":"https://vincentruan.github.io/categories/性能测试/"}],"tags":[{"name":"Apache Beach","slug":"Apache-Beach","permalink":"https://vincentruan.github.io/tags/Apache-Beach/"},{"name":"Gnuplot","slug":"Gnuplot","permalink":"https://vincentruan.github.io/tags/Gnuplot/"}]},{"title":"12个Git高级命令","slug":"12个Git高级命令","date":"2020-02-04T13:03:00.000Z","updated":"2020-02-25T15:09:15.002Z","comments":true,"path":"2020/02/04/12个Git高级命令/","link":"","permalink":"https://vincentruan.github.io/2020/02/04/12个Git高级命令/","excerpt":"使用Git时常用的命令有pull、commit、push等，貌似很简单。不过，有时你会遇到合并冲突的情况，Git这时会将冲突标记出来，需要你手工来解决。有时，你会不小心将代码提交到错误的分支上，并且又推送到了远程仓库。还有些时候，你需要切换到不同的分支，但Git却不让你这么做，因为还有未保存的修改。如果需要通过另一个分支的提交来为代码打补丁该怎么做呢？本文就将介绍12个Git高级命令，合理使用这些命令可以大大提升应用Git的效率。","text":"使用Git时常用的命令有pull、commit、push等，貌似很简单。不过，有时你会遇到合并冲突的情况，Git这时会将冲突标记出来，需要你手工来解决。有时，你会不小心将代码提交到错误的分支上，并且又推送到了远程仓库。还有些时候，你需要切换到不同的分支，但Git却不让你这么做，因为还有未保存的修改。如果需要通过另一个分支的提交来为代码打补丁该怎么做呢？本文就将介绍12个Git高级命令，合理使用这些命令可以大大提升应用Git的效率。 1. 使用rebase而非merge来拉取上游修改分支合并会被记录为一次合并提交，这种做法是很有意义的。比如说，可以通过这种方式来标识一个新特性被合并到了发布分支中。不过，当多个团队成员工作在一个项目中并使用常规的git pull来同步分支时，提交时间线就会被不必要的合并提交所污染。更好的做法则是使用git rebase将一个feature分支变基到master分支： 12$ git checkout feature$ git rebase master 这么做会将整个feature分支移动到master分支的起点，它会合并master分支上所有新的提交。不过，相比于使用合并提交来说，变基会通过在原来的分支中为每次提交创建全新提交来重写项目历史。变基的主要好处在于你会得到一个更加整洁的项目历史。此外，这里还有关于变基的陷阱的一些讨论。 2. 在执行git rebase后解决合并冲突正如能力越大责任就越大一样。在执行git rebase时，你可能会遇到合并冲突的情况。合并冲突表示两个提交修改了同一个文件的同一行，Git不知道该应用哪一个修改。 Git会为你提供3个选择来修复导致冲突的提交（fa39187）： 可以运行git rebase –abort来完全取消变基。这么做会取消变基修改，并将分支置回到执行git rebase之前的状态。 可以运行git rebase –skip来完全忽略该提交。这样，有问题的提交所引入的变化就不会被添加到历史中。 可以使用与合并冲突相同的标准步骤来解决冲突。 3. 临时性保存修改在工作进行中时，有些东西常常会处于凌乱的状态。如果这时需要切换到不同的分支该怎么办呢？Git是不允许你这么做的，因为还有尚未保存的修改。坦率地说，你并不想将半成品提交上去，后面再来修改。这个问题的解决之道就是使用git stash命令。Stash会接收工作目录的当前状态（比如说，修改了的追踪文件与暂存区的修改等），并将其保存到未完成的修改栈中，这样后面随时可以再来修改。可以通过如下命令来暂存你的工作： 123$ git stashSaved working directory and index state WIP on feature: 3fc175f fix race conditionHEAD is now at 3fc175f fix race condition 现在，工作目录就是干净的了： 123$ git status# On branch featurenothing to commit, working directory clean 这时就可以安全地切换分支做别的事情了。不过不必担心，暂存的提交依旧还在： 12$ git stash liststash@&#123;0&#125;: WIP on feature: 3fc175f fix race condition 稍后，在回到feature分支后，你就可以取回所有暂存的变更了： 1234567$ git stash popOn branch featureChanges not staged for commit: (use \"git add ...\" to update what will be committed) modified: index.htmlDropped refs/stash@&#123;0&#125; (ac2321cc3a33ba712b8e50c99a99d3c20da9d6b8) 关于暂存，还有其他一些选项可用，如下所示： 123$ git stash save \"describe it\" # give the stash a name$ git stash clear # delete a stashed commit$ git stash save --keep-index # stash only unstaged files 4. 克隆一个特定的远程分支如果想要从远程仓库中克隆一个特定的分支该怎么做呢？通常你会使用git clone，不过这么做会将所有其他分支都一并克隆下来。一个便捷的方式是使用git remote add： 123$ git init $ git remote add -t -f origin $ git checkout 5. 将cherry-pick远程提交合并到自己的分支中更有甚者，如果只想将远程仓库的一个特定提交合并到自己的分支中该怎么做呢？可以使用git cherry-pick 来选择给定SHA值的提交，然后将其合并到当前分支中： 1$ git cherry-pick 6. 应用来自于不相关的本地仓库的补丁如果需要将另一个不相关的本地仓库的提交补丁应用到当前仓库该怎么做呢？答案就是下面这条命令： 1$ git --git-dir=/.git format-patch -k -1 --stdout | git am -3 -k 7. 忽略追踪文件中的变更如果你和你的同事操纵的是相同分支，那么很有可能需要频繁执行git merge或是git rebase。不过，这么做可能会重置一些与环境相关的配置文件，这样在每次合并后都需要修改。与之相反，你可以通过如下命令永久性地告诉Git不要管某个本地文件： 1$ git update-index --assume-unchanged 8. 每隔X秒运行一次git pull通常，合并冲突出现的原因在于你正在工作的本地仓库不再反映远程仓库的当前状态。这正是我们为什么每天早晨要首先执行一次git pull的缘故。此外，你还可以在后台通过脚本（或是使用GNU Screen）每隔X秒调用一次git pull： 12$ screen$ for((i=1;i&lt;=10000;i+=1)); do sleep X &amp;&amp; git pull; done 9. 将子目录分隔为新的仓库有时，你可能需要将Git仓库中某个特定的目录转换为一个全新的仓库。这可以通过git filter-branch来实现： 1234$ git filter-branch --prune-empty --subdirectory-filter master# Filter the master branch to your directory and remove empty commitsRewrite 48dc599c80e20527ed902928085e7861e6b3cbe6 (89/89)Ref 'refs/heads/master' was rewritten 现在，仓库会包含指定子目录中的所有文件。虽然之前的所有文件都会被删除，但他们依旧存在于Git历史中。现在可以将新的本地仓库推送到远程了。 10. 清理有时，Git会提示“untracked working tree files”会“overwritten by checkout”。造成这种情况的原因有很多。不过通常来说，我们可以使用如下命令来保持工作树的整洁，从而防止这种情况的发生： 123$ git clean -f # remove untracked files$ git clean -fd # remove untracked files/directories$ git clean -nfd # list all files/directories that would be removed 11. 将项目文件打成tar包，并且排除.git目录有时，你需要将项目副本提供给无法访问GitHub仓库的外部成员。最简单的方式就是使用tar或zip来打包所有的项目文件。不过，如果不小心，隐藏的.git目录就会包含到tar文件中，这会导致文件体积变大；同时，如果里面的文件与接收者自己的Git仓库弄混了，那就更加令人头疼了。轻松的做法则是自动从tar文件中排除掉.git目录： 1$ tar cJf .tar.xz / --exclude-vcs 12. 查找修改者最后，如果出现混乱的情况，你一定想要找出是谁造成的。如果生产服务器宕机，那么找到罪魁祸首是比较容易的事情：只需执行git blame。该命令会显示出文件中每一行的作者，提交hash则会找出该行的上一次修改，还能看到提交的时间戳： 1$ git blame","categories":[{"name":"git","slug":"git","permalink":"https://vincentruan.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://vincentruan.github.io/tags/git/"}]},{"title":"在CentOS上安装Git","slug":"在CentOS上安装Git","date":"2020-02-04T13:00:57.000Z","updated":"2020-02-25T15:09:15.065Z","comments":true,"path":"2020/02/04/在CentOS上安装Git/","link":"","permalink":"https://vincentruan.github.io/2020/02/04/在CentOS上安装Git/","excerpt":"CentOS的yum源中没有git，只能自己编译安装，现在记录下编译安装的内容，留给自己备忘。 确保已安装了依赖的包 12345678yum install curlyum install curl-develyum install zlib-develyum install openssl-develyum install perlyum install cpioyum install expat-develyum install gettext-devel yum install perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker","text":"CentOS的yum源中没有git，只能自己编译安装，现在记录下编译安装的内容，留给自己备忘。 确保已安装了依赖的包 12345678yum install curlyum install curl-develyum install zlib-develyum install openssl-develyum install perlyum install cpioyum install expat-develyum install gettext-devel yum install perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker 下载最新的git包 1234567wget http://www.codemonkey.org.uk/projects/git-snapshots/git/git-latest.tar.gztar xzvf git-latest.tar.gzcd git-2011-11-30 ＃你的目录可能不是这个autoconf./configuremakesudo make install 检查下安装的版本，大功告成 1git --version","categories":[{"name":"git","slug":"git","permalink":"https://vincentruan.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://vincentruan.github.io/tags/git/"},{"name":"centos","slug":"centos","permalink":"https://vincentruan.github.io/tags/centos/"}]},{"title":"大规模网站架构的缓存机制和几何分形学","slug":"大规模网站架构的缓存机制和几何分形学","date":"2020-02-04T09:42:42.000Z","updated":"2020-02-25T15:09:15.066Z","comments":true,"path":"2020/02/04/大规模网站架构的缓存机制和几何分形学/","link":"","permalink":"https://vincentruan.github.io/2020/02/04/大规模网站架构的缓存机制和几何分形学/","excerpt":"缓存机制在我们的实际研发工作中，被极其广泛地应用，通过这些缓存机制来提升系统交互的效率。简单的总结来说，就是在两个环节或者系统之间，会引入一个cache/buffer做为提升整体效率的角色。 而 有趣的是，这种缓存机制令人惊奇并且优美的遵循着“几何分形”的规律，也就是几何分形学中的“自相似性”：从整体上看遵循某种组成规律或者特性，同时从每 一个局部看，仍然遵循某种组成的规律或者特性。我们的这些系统，从整体上看遵循了缓存机制，每一个组成的局部也遵循缓存机制。 等同类比的一个概念，我们常常说的“空间换时间”，牺牲一部分空间代价，来换取整体效率的提升。","text":"缓存机制在我们的实际研发工作中，被极其广泛地应用，通过这些缓存机制来提升系统交互的效率。简单的总结来说，就是在两个环节或者系统之间，会引入一个cache/buffer做为提升整体效率的角色。 而 有趣的是，这种缓存机制令人惊奇并且优美的遵循着“几何分形”的规律，也就是几何分形学中的“自相似性”：从整体上看遵循某种组成规律或者特性，同时从每 一个局部看，仍然遵循某种组成的规律或者特性。我们的这些系统，从整体上看遵循了缓存机制，每一个组成的局部也遵循缓存机制。 等同类比的一个概念，我们常常说的“空间换时间”，牺牲一部分空间代价，来换取整体效率的提升。 graph LR A[A] ==> B(Cache) ==> C[B] C[B] ==> B(Cache) ==> A[A] 例如A和B两者之间的数据交换，为了提升整体的效率，引入角色C，而C被用于当做热点数据的存储，或者是某种中间处理的机制。 我们先从web前端层面开始，看看有哪些比较关键的缓存机制？它们又是怎样协调工作的呢？ 一、前端Cache机制1. 域名转为IP地址（域名服务器DNS缓存）我们知道域名其实只是一个别名，真实的服务器请求地址，实际上是一个IP地址。获得IP地址的方式，就是查询DNS映射表。虽然这是一个非常简单的查询， 但如果每次用户访问一个url都去查询DNS一次，未免显得太频繁，会产生一个可怕的访问量级。DNS服务器会告诉你，你别老是经常过来，万一我挂了，我们就无法愉快地玩耍了。 各个浏览器的缓存时间，会有一定的差别。例如，在chrome浏览器中查看dns的缓存时间的方式是：chrome://net-internals/#dns。 浏览器一般会在本地会建立一个DNS缓存，在一段比较长的时间里，都是使用本地的缓存映射。例如，在Win7系统的cmd里，可以通过“ipconfig /flushdns ”的方式来立刻刷新本地DNS。 graph LR A[浏览器] ==> B(Cache) ==> C[DNS] C[DNS] ==> B(Cache) ==> A[浏览器] 优点：域名映射为IP非常快。 成本：消耗一定的浏览器空间来存储映射关系 2. 访问服务器，获取静态内容（地理位置分布式服务CDN）可能有人会觉得，这个CDN不是缓存。其实，CDN的原理就是将离你很远的东西，放在离你很近的地方，通过这种方式提高用户的访问速度。从这个角 度，它也可以理解为牺牲空间成本换取了时间，本质上也是一种特殊的中间cache。腾讯、阿里等这些大的一线互联网公司一般倾向于自己建立CDN系统，中 小型企业也经常使用第三方的CDN服务。 graph LR A[浏览器] ==> B(CDN) ==> C[很远的服务器] C[很远的服务器] ==> B(Cache) ==> A[浏览器] 优点：解决用户离服务器太远的时候，网络路由中跳来跳去的严重耗时。 成本：全国各地部署多套静态存储服务，管理成本比较高，发布新文件的时候，需要等待全国节点的更新等。 3. 浏览器本地缓存（无网络交互类型）在前端优化原则中，其中一条就是尽量消灭请求，以达到降低服务器压力和提升用户体验的效果。静态文件，例如Js、html、css、图片等内容，很多内容可以1次请求，然后未来就直接访问本地，不再请求web服务器。 常用的实现方法是通过Http协议头中的expire和max-age来控制，这两者的使用方法和区别，我这里就不赘叙了。还有一种HTML5中很热的方式，则是localStorage，尤其在移动端也被做为一个强大的缓存，甚至当做一种本地存储来广泛使用。 graph LR A[浏览器] ==> B(本地缓存localStore) ==> C[web服务器] C[web服务器] ==> B(本地缓存localStore) ==> A[浏览器] 优点：减少网络传输，加快页面内容展示速度，提升用户体验。 成本：占用客户端的部分内存和磁盘，影响实时性。 4. 浏览器和web服务协议缓存（有网络交互类型）浏览器的本地缓存是存在过期时间的，一旦过期，就必须重新向服务器请求。这个时候，会有两种情形： 服务器的文件或者内容没有更新，可以继续使用浏览器本地缓存。 服务器的文件或者内容已经更新，需要重新请求，通过网络传输新的文件或者内容。 这里的协商方式也可以通过Http协议来控制，Last-Modified和Etag，这个时候请求服务器，如果是内容没有发生变更的情况，服务器会返回 304 Not Modified。这样的话，就不需要每次访问服务器都通过网络传输一个比较大的文件或者数据包，只要简单的http应答就可以达到相同的请求文件效果。 graph LR A[浏览器] ==> B(Last-MofifiedEtag机制) ==> C[web服务器] C[web服务器] ==> B(Last-MofifiedEtag机制) ==> A[浏览器] 下图中的例子，是腾讯的自建CDN（imgcache.gtime.cn）： ![image-20200204180300749](大规模网站架构的缓存机制和几何分形学/image-20200204180300749.png) 优点：减少频繁的网络大数据包传输，节约带宽，提升用户体验。 成本：增加了服务器处理的步骤，消耗更多的CPU资源。 ## **5. 浏览器中间代理** 上面的几种cache机制，实际上都是非常常见。但是，在移动互联网时代，流量昂贵是很多用户心中深深的痛。于是，又出现了一种新型的中间cache， 也就是在浏览器和web服务器再架设一个中间代理。这个代理服务器会帮助手机浏览器去请求web页面，然后将web页面进行处理和压缩（例如压缩文件和图片），使页面变小，然后再传输给手机端的浏览器。 graph LR A[手机浏览器] ==> B(浏览器商的中间代理服务器) ==> C[压缩后的Html和图片] ==> A[手机浏览器] B(浏览器商的中间代理服务器) ==> D[www.qq.com的web服务器] D[www.qq.com的web服务器] ==> B(浏览器商的中间代理服务器) 部分手机浏览器（例如Chrome）号称可以节省流量，提升访问速度，实际上就是上述做法。但是，也分为两种情况： - 用户的网络和手机配置都比较差，因为页面被压缩变小，加载和传输速度变快，并且节约了流量。 - 用户的网络和手机配置都比较好，本身直连速度已经很快了，反而因为设置了中间代理，加载速度变慢，也可节约流量。 下图是chrome手机浏览器中，开启和不开启中间代理的对比图： ![image-20200204180713768](大规模网站架构的缓存机制和几何分形学/image-20200204180713768.png) 优点：节约用户流量，大部分情况下提升了加载速度。 成本：需要架设中间代理服务器，对各种文件进行压缩，有比较高的服务器维护成本。 ## **6. 预加载缓存机制** 这种加载方式主要流行在移动端，为了解决手机网速慢和浏览器加载性能问题，浏览器会判断页面的关联内容，进行“预加载”。 也就是说，在用户浏览A页面的时候，就提前下载并且加载B页面的内容。给用户的体验就是，B页面一瞬间就出现了，中间没有任何延迟的感觉，从而带来更好的 极佳的用户体验。 这种实现机制，往往由浏览器来实现，当然，手机页面本身，也可以通过JS来自身实现。而这种机制也存在一些问题，浏览器需要预判用户的浏览行为，在一些场景下，这个预判算法本身不一定准确，如果不准确则带来一定的流量、内存和系统资源的浪费。 graph LR A[浏览器] ==> C[页面内容A] A[浏览器] -.- B(预加载) -.-> D[页面内容B] A[浏览器] -.- E(预加载) -.-> F[页面内容C/D/E/...] 优点：给用户带来极佳的页面展示体验。 缺点：预判实现比较复杂，占据一定的内存和手机系统资源，可能产生流量和资源浪费。 前端的cache当然不仅仅如此简单，如果细致到每一个小环节和组成部分，我们会发现实际上是无处不在的，例如浏览器的渲染行为、网络网卡的传输环节，小环节和小环节之间也有无数这种类型的cache角色。 这个就如同几何分形学中的自相似性：从整体上看符合某种组成规律或者特性，同时，从局部看，仍然符合某种组成的规律或者特性。 几何分形的现象在我们生活中，也是非常常见的，例如： 人体中的几何分形例子，例如：人体有1个头部+4肢，局部上看人的手指也是1个手指头+4个手指；人体无论整体或者局部，都大致遵循黄金分割点0.618的比例来生长（五官按照这个比例越多，越好看）。 例如下图中的叶子，每个局部都和主干组成结构相似。 二、Web系统和几何分形学1. Web系统中的缓存机制看完上面的前端cache，我们会感觉到缓存机制在前端中的确无处不在，那么它在其他地方和环节，是否也无处不在？ 可以看看这张图： graph TB A[浏览器] ==> C[前端cache机制] ==> D[web服务器] D[web服务器] ==> C[前端cache机制] ==> A[浏览器] D[web服务器] ==放大web服务器==> B(memcache缓存) ==> E[MySQL] B(memcache缓存) ==> F[Apache] E[MySQL] ==> B(memcache缓存) F[Apache] ==> B(memcache缓存) E[MySQL] ==放大MySQL==> G(innodb_buffer_pool存放热点数据) ==> H[MySQL内部数据] G(innodb_buffer_pool存放热点数据) ==> I[外界请求] H[MySQL内部数据] ==> G(innodb_buffer_pool存放热点数据) I[外界请求] ==> G(innodb_buffer_pool存放热点数据) 实际上，每一个环节本身是可以又再次被放大的，放大以后，我们又看见了更多缓存机制的“特性”存在。从一个整体来看，符合该规律，从组成部分来看，仍然符合该规律。 每一个组成缓存机制的“成员”的内部，又存在着更多的缓存机制。 Apache内部的一些“缓存机制”： url映射缓存mod_cache（有mode_disk_cache和mod_mem_cache，后者官方已不推荐） 缓存热点文件打开描述符mod_file_cache（对于静态文件的情况，减少打开文件中open行为的耗时） 启动的时候，通过prefork模式设置的StartServers服务进程池，牺牲内存空间。 MySQL内的一些“缓存机制”： 数据库的索引，牺牲磁盘空间（组合索引等会占据很大的磁盘空间） innodb_buffer_pool_size，热点数据的缓存，牺牲内存空间 innodb_flush_method写入磁盘的机制，可以配置成缓冲写入的方式 query_cache_size查询缓存，牺牲内存空间 thread_cache_size数据库连接池的缓存个数，牺牲内存空间 2. 接近硬件层面的“空间换时间”那我们再来看更细小的一个环节，计算机写的操作。我们会发现，在内存和物理磁盘之间，还有一个磁盘缓冲区（页高速缓存）的存在，这个是内存和磁盘之间的“缓存”。当然，读取的操作也是同理。 下图是“放大”MySQL中的写入磁盘： graph LR A[外界请求] ==> C[innodb_buffer_pool存放热点数据] ==> B[MySQL内部数据] B[MySQL内部数据] ==> C[innodb_buffer_pool存放热点数据] ==> A[外界请求] B[MySQL内部数据] ==放大写入数据==> D[磁盘写入缓冲区在内存中] ==> E[MySQL] ==队列满或超时==> F[物理磁盘] G[内存] ==> D[磁盘写入缓冲区在内存中] 实际上，更进一步看，CPU和内存之间也存在缓存机制（常用指令会存在放在寄存器中，因为CPU访问寄存器会远快于访问内存，中间为了缓冲它们之间差距，设置了多级高速缓存）。 graph LR A[Mem] ==Bus总线==> B[L3 Cache] ==> C[L2 Cache] ==> D[L1 Cache] ==> E[CPU core] E[CPU core] ==> D[L1 Cache] ==> C[L2 Cache] ==> B[L3 Cache] ==Bus总线==> A[Mem] 例如下图是Intel i7 920的各级缓存大小： 这个时候，我们可以看出来，计算机系统从大的系统层面看，是遵循“缓存机制”的规律的，同时，在每个局部成员的层面，同样遵循该规律。 3. 现实世界中的“缓存机制”我们现在喝水通常使用的是杯子，杯子实际上也扮演着一个特殊的Cache角色。举个例子：一个人离饮水机比较远，他渴了，他有如下两种“喝水”的方式： 不用杯子，每次渴了直接去饮水机喝（这个比较霸气侧漏，不要在意细节）。结果：频繁跑动，耗费体力。 使用杯子，渴了先喝杯子（Cache）上的水，如果杯子没有，带上杯子去装水，再喝。结果：比较少跑动，节省体力。 这样看不直观，简化为一个流程图如下： graph LR A((人)) -.口渴则过去喝.-> B[比较远的饮水机] A((人)) ==> D[杯子 Cache] --杯子空则过去--> B[比较远的饮水机] 这虽然是个人尽皆知的道理，但是，这个方法本身是“进化”出来的。百万年前的原始人类和其他大自然的动物一样的，喝水遵循了第一种方式，只是随着人类的发展，“进化”出第二种喝水的方式。 这里也存在一个缓存机制，就是用杯子的空间获取喝水效率的时间。 还有一个更为典型的例子，就是坐车/运输，假设我们从深圳去广州，我们会去坐客运车。而客运车（假设上面有40个 座位）实际上相当于一个40个座位的“队列”。遵循着网络传输的相同的规律“队列满或者超时则发送”。客车本身的40个位置，就像一个“发送缓冲区”。使 用和不使用这个大的缓冲区，客车也可以有两者运作方式： 车站发现来一个人，用只能容纳一个人的小车，不等待直接送一个人去广州。 车站发现来一个人，先放进客车buffer中，等待人满或者达到班车约定时间（队列超时）再出发。 graph LR A(深圳车站) -.1.来一个立刻用车运走.-> B(广州车站) A(深圳车站) ==2==> D[40座客车buffer] --> B(广州车站) 显而易见，第一种是太浪费资源了。 除此之外，还有很多各种各样的例子，如江河上的大坝、我们桌面上的一些东西（它们占据宝贵的桌面空间）、我们公司附近小店里的商品、离我们近的东西等等。 看到这里，很多人会渐渐发觉，计算机的一些原理，竟然在现实世界里有无处不在的“映射和影子”。 几何分形学是个非常有趣的东西，某些规律，实际上还贯穿在整个宏观和微观世界中。 例如“绕转”的现象： graph LR A[电子围绕原子核转] ==> B[月球自转] ==> C[月球围绕地球转] ==> D[地月系围绕太阳转] ==> E[太阳系围绕银河系中心转] 4. 现实世界和计算机“缓存机制”原理的关系，为什么遵循“几何分形”？实际上，计算机的原理来源于数学，而数学是日常生活现象和规律的高度抽象，源于生活，高于生活。 graph LR A[现实世界] -.高度抽象.-> B[数学] -.应用实现.-> C[计算机原理] 同时，不仅仅“缓存机制”，还有很多其他技术的原理，也能找到这种遵循“几何分形学”的样子。","categories":[{"name":"缓存","slug":"缓存","permalink":"https://vincentruan.github.io/categories/缓存/"}],"tags":[{"name":"cache","slug":"cache","permalink":"https://vincentruan.github.io/tags/cache/"},{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/tags/架构设计/"}]},{"title":"electron-vue开发入门指南","slug":"electron-vue开发入门指南","date":"2020-01-31T04:48:08.000Z","updated":"2020-02-25T15:09:15.051Z","comments":true,"path":"2020/01/31/electron-vue开发入门指南/","link":"","permalink":"https://vincentruan.github.io/2020/01/31/electron-vue开发入门指南/","excerpt":"Electron概述 GitHub 官网不翻墙太卡，本着能偷懒就偷懒，GayHub就够了，不用翻官网了 中文文档 W3C教程","text":"Electron概述 GitHub 官网不翻墙太卡，本着能偷懒就偷懒，GayHub就够了，不用翻官网了 中文文档 W3C教程 VUE概述 GitHub VUE官网 官网资料齐全，中英文档都齐备，基本看完够搞个工程了 Electron + Vue 联合使用安装Nodejs安装成功之后node -v，会显示版本，版本可以不用这么新，看心情安装。 12$ node -vv12.14.0 搭建Vue开发环境直接使用脚手架工具vue-cli，因为在国内的npm非常慢，所以需要重新设置npm镜像，设置为淘宝的镜像 1npm config set registry https://registry.npm.taobao.org/ 我们可以看一下镜像地址是： 12vue npm config get registry https://registry.npm.taobao.org/ 如果不想修改默认npm地址，也可以设置cnpm(因为自带翻墙光环，考虑到后面可能不方便翻墙，后面全程优先使用墙内网络操作。) 123npm install -g cnpm --registry=https://registry.npm.taobao.org//输入命令,查看是否安装成功cnpm 安装脚手架工具： 1npm install --global vue-cli 安装web-pack： 1npm install -g webpack yarn 使用国内镜像 12yarn config set registry https://registry.npm.taobao.orgyarn config list npm更新package.json将package.json中的依赖更新为最新版 安装 1npm install -g npm-check-updates 显示当前目录下项目中所有新的依赖包 1ncu 更新项目package文件 1ncu -u npm-check-updates更多参数 什么是Yarn和NPM?Yarn:Yet Another Resource Negotiator，是一个快速、可靠、安全的依赖管理工具，一款新的JavaScript包管理工具。 Yarn工作流： Yarn使用方法：https://yarn.bootcss.com/docs/usage/ Yarn使用方法-如图： Yarn是什么：https://yarn.bootcss.com Npm是什么 :https://www.npmjs.cn/ yarn和npm命令对比一、命令对比 yarn npm 命令功能 yarn install npm install 根据pack.json安装项目所需的依赖包 yarn install --flat -- 注释1 yarn install --no-lockfile npm install --no-package-lock 不读取或生成yarn.lock锁文件 yarn install --pure-lockfile -- 不要生成yarn.lock锁文件 yarn add [package] npm install [package] 安装需要的依赖包 yarn add [package] --dev npm install [package] --save-dev 注释2 yarn add [package] --D npm install [package] --save-dev 同上 yarn add [package] --peer -- 注释3 yarn add [package] --P -- 同上 yarn add [package] --optional npm install [package] --save-optional 注释4 yarn add [package] --O npm install [package] --save-optional 同上 yarn add [package] --exact npm install [package] --save-exact 注释5 yarn add [package] --E npm install [package] --save-exact 同上 yarn global add [package] npm install [package] --global 全局安装依赖包 yarn global upgrade npm update --global 全局更新依赖包 yarn add --force npm rebuild 更改包内容后进行重建 yarn remove [package] npm uninstall [package] 卸载已经安装的依赖包 yarn cache clean [package] npm cache clean 注释6 yarn upgrade rm -rf node_modules &amp;&amp; npm install 更新依赖包 yarn version --major npm version major 更新依赖包的版本 yarn version --minor npm version minor 更新依赖包的版本 yarn version --patch npm version patch 更新依赖包的版本 二、命令注释 注释1 ：安装所有依赖项，但每个依赖项只允许一个版本。在第一次运行时，这将提示你为多版本的依赖包选择一个版本，进行安装。这些将添加到您package.json的 resolutions字段下。 12345\"resolutions\": &#123; \"package-a\": \"2.0.0\", \"package-b\": \"5.0.0\", \"package-c\": \"1.5.2\"&#125; 注释2 ：安装所需的依赖包，并将该包的记录写到package.json文件的 devDependencies 选项中。 1234567\"devDependencies\": &#123; \"autoprefixer\": \"^7.1.2\", \"babel-core\": \"^6.22.1\", \"babel-helper-vue-jsx-merge-props\": \"^2.0.3\", \"babel-loader\": \"^7.1.1\", \"babel-plugin-syntax-jsx\": \"^6.18.0\",&#125; 注释3 ：安装所需的依赖包，并将该包的记录写到package.json文件的 peerDependencies 选项中。 注释4 ：安装所需的依赖包，并将该包的记录写到package.json文件的 optionalDependencies 选项中。 注释5 ：安装依赖包的确切版本，默认设置是使用依赖包的最新版本。例如， yarn add foo@1.2.3将接受版本1.9.1，但 yarn add foo@1.2.3 --exact 只接受版本1.2.3。 注释6 ：运行此命令将清除全局缓存依赖包。当再次yarn或yarn install运行，进行下载依赖包 安装Electron1cnpm install -g electron 验证 123&gt;electron -v v7.1.10 搭建electron-vue项目simulatedgreg/electron-vue用的vue-cli2，不建议再使用，如果vue-cli用的3或者4，建议直接跳到下面的章节 相关文档 electron-vue文档 使用electron-vue脚手架工具初始化项目可能会比较慢，可以通过webpack方式初始化vue项目，然后在引入electron方式，这个会快很多 1234567891011121314151617181920212223242526272829$ vue init simulatedgreg/electron-vue alistar? Application Name alistar? Application Id org.evue.alistar? Application Version 0.0.1? Project description 哞利斯塔, 快乐辅助? Use Sass / Scss? Yes? Select which Vue plugins to install axios, vue-electron, vue-router, vuex, vuex-electron? Use linting with ESLint? Yes? Which ESLint config would you like to use? Standard? Set up unit testing with Karma + Mocha? Yes? Set up end-to-end testing with Spectron + Mocha? Yes? What build tool would you like to use? builder? author vincentruan &lt;rzw0813@gmail.com&gt; vue-cli · Generated \"alistar\".---All set. Welcome to your new electron-vue project!Make sure to check out the documentation for this boilerplate athttps://simulatedgreg.gitbooks.io/electron-vue/content/.Next Steps: $ cd alistar $ yarn (or `npm install`) $ yarn run dev (or `npm run dev`) 上面已经有提示下一步做什么了，cd alistar目录下，之后对照执行，如果用yarn记得设置代理或者用国内镜像。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374$ cnpm install| [22/67] Installing get-stdin@^4.0.1platform unsupported babel-loader@7.1.5 › webpack@4.41.5 › watchpack@1.6.0 › chokidar@2.1.8 › fsevents@^1.2.7 Package require os(darwin) not compatible with your platform(win32)[fsevents@^1.2.7] optional install error: Package require os(darwin) not compatible with your platform(win32)√ Installed 67 packages√ Linked 1218 latest versions[1/7] scripts.postinstall babel-core@6.26.3 › babel-register@6.26.0 › core-js@^2.5.0 run \"node -e \\\"try&#123;require('./postinstall')&#125;catch(e)&#123;&#125;\\\"\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_core-js@2.6.11@core-js\"Thank you for using core-js ( https://github.com/zloirock/core-js ) for polyfilling JavaScript standard library!The project needs your help! Please consider supporting of core-js on Open Collective or Patreon:&gt; https://opencollective.com/core-js&gt; https://www.patreon.com/zloirockAlso, the author of core-js ( https://github.com/zloirock ) is looking for a good job -)[1/7] scripts.postinstall babel-core@6.26.3 › babel-register@6.26.0 › core-js@^2.5.0 finished in 2s[2/7] scripts.postinstall electron-builder@20.44.4 › app-builder-lib@20.44.4 › ejs@^2.6.2 run \"node ./postinstall.js\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_ejs@2.7.4@ejs\"Thank you for installing EJS: built with the Jake JavaScript build tool (https://jakejs.com/)[2/7] scripts.postinstall electron-builder@20.44.4 › app-builder-lib@20.44.4 › ejs@^2.6.2 finished in 2s[3/7] scripts.postinstall electron@^2.0.4 run \"node install.js\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_electron@2.0.18@electron\"Downloading SHASUMS256.txt[============================================&gt;] 100.0% of 5.39 kB (5.39 kB/s)[3/7] scripts.postinstall electron@^2.0.4 finished in 17s[4/7] scripts.install spectron@3.8.0 › electron-chromedriver@~1.8.0 run \"node ./download-chromedriver.js\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_electron-chromedriver@1.8.0@electron-chromedriver\"Downloading tmp-2644-1-SHASUMS256.txt-1.8.0[============================================&gt;] 100.0% of 8.02 kB (8.02 kB/s)successfully dowloaded and extracted![4/7] scripts.install spectron@3.8.0 › electron-chromedriver@~1.8.0 finished in 5s[5/7] scripts.install karma@2.0.5 › socket.io@2.0.4 › engine.io@3.1.5 › uws@~9.14.0 run \"node-gyp rebuild &gt; build_log.txt 2&gt;&amp;1 || exit 0\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_uws@9.14.0@uws\"[5/7] scripts.install karma@2.0.5 › socket.io@2.0.4 › engine.io@3.1.5 › uws@~9.14.0 finished in 3s[6/7] scripts.install node-sass@^4.9.2 run \"node scripts/install.js\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_node-sass@4.13.1@node-sass\"Downloading binary from https://cdn.npm.taobao.org/dist/node-sass/v4.13.1/win32-x64-72_binding.nodeDownload completeBinary saved to D:\\gitspace\\alistar\\node_modules\\_node-sass@4.13.1@node-sass\\vendor\\win32-x64-72\\binding.nodeCaching binary to C:\\Users\\vincentruan\\.npminstall_tarball\\node-sass\\4.13.1\\win32-x64-72_binding.node[6/7] scripts.install node-sass@^4.9.2 finished in 4s[6/7] scripts.postinstall node-sass@^4.9.2 run \"node scripts/build.js\", root: \"D:\\\\gitspace\\\\alistar\\\\node_modules\\\\_node-sass@4.13.1@node-sass\"Binary found at D:\\gitspace\\alistar\\node_modules\\_node-sass@4.13.1@node-sass\\vendor\\win32-x64-72\\binding.nodeTesting binaryBinary is fine[6/7] scripts.postinstall node-sass@^4.9.2 finished in 2s[7/7] scripts.postinstall alistar@0.0.1 run \"npm run lint:fix\", root: \"D:\\\\gitspace\\\\alistar\"&gt; alistar@0.0.1 lint:fix D:\\gitspace\\alistar&gt; eslint --ext .js,.vue -f ./node_modules/eslint-friendly-formatter --fix src test[7/7] scripts.postinstall alistar@0.0.1 finished in 11s√ Run 7 scriptspeerDependencies link ajv@5.5.2 in D:\\gitspace\\alistar\\node_modules\\_ajv-keywords@2.1.1@ajv-keywords unmet with D:\\gitspace\\alistar\\node_modules\\ajv(6.11.0)peerDependencies WARNING karma-webpack@^3.0.0 requires a peer of webpack@^2.0.0 || ^3.0.0 but webpack@4.41.5 was installeddeprecate css-loader@0.28.11 › cssnano@3.10.0 › autoprefixer@6.7.7 › browserslist@^1.7.6 Browserslist 2 could fail on reading Browserslist &gt;3.0 config used in other tools.deprecate babel-core@6.26.3 › babel-register@6.26.0 › core-js@^2.5.0 core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3.deprecate eslint@4.19.1 › file-entry-cache@2.0.0 › flat-cache@1.3.4 › circular-json@^0.3.1 CircularJSON is in maintenance only, flatted is its successor.deprecate karma-coverage@1.1.2 › istanbul@^0.4.0 This module is no longer maintained, try this instead: npm i nycVisit https://istanbul.js.org/integrations for other alternatives.deprecate karma@2.0.5 › log4js@2.11.0 › circular-json@^0.5.4 CircularJSON is in maintenance only, flatted is its successor.deprecate karma@2.0.5 › log4js@2.11.0 › nodemailer@^2.5.0 All versions below 4.0.1 of Nodemailer are deprecated. See https://nodemailer.com/status/deprecate karma@2.0.5 › log4js@2.11.0 › nodemailer@2.7.2 › socks@1.1.9 If using 2.x branch, please upgrade to at least 2.1.6 to avoid a serious bug with socket data flow and an import issue introduced in 2.1.0deprecate karma@2.0.5 › log4js@2.11.0 › nodemailer@2.7.2 › mailcomposer@4.0.1 This project is unmaintaineddeprecate karma@2.0.5 › log4js@2.11.0 › loggly@1.1.1 › request@2.75.0 › node-uuid@~1.4.7 Use uuid module insteaddeprecate karma@2.0.5 › log4js@2.11.0 › loggly@1.1.1 › request@2.75.0 › hawk@~3.1.3 This module moved to @hapi/hawk. Please make sure to switch over as this distribution is no longer supported and may contain bugs and critical security issues.deprecate karma@2.0.5 › log4js@2.11.0 › nodemailer@2.7.2 › mailcomposer@4.0.1 › buildmail@4.0.1 This project is unmaintaineddeprecate karma@2.0.5 › log4js@2.11.0 › loggly@1.1.1 › request@2.75.0 › hawk@3.1.3 › cryptiles@2.x.x This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).deprecate karma@2.0.5 › log4js@2.11.0 › loggly@1.1.1 › request@2.75.0 › hawk@3.1.3 › sntp@1.x.x This module moved to @hapi/sntp. Please make sure to switch over as this distribution is no longer supported and may contain bugs and critical security issues.deprecate karma@2.0.5 › log4js@2.11.0 › loggly@1.1.1 › request@2.75.0 › hawk@3.1.3 › hoek@2.x.x This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).deprecate karma@2.0.5 › log4js@2.11.0 › loggly@1.1.1 › request@2.75.0 › hawk@3.1.3 › boom@2.x.x This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).deprecate spectron@3.8.0 › webdriverio@^4.8.0 outdated version, please use @nextdeprecate karma@2.0.5 › socket.io@2.0.4 › engine.io@3.1.5 › uws@~9.14.0 New code is available at github.com/uNetworking/uWebSockets.jsRecently updated (since 2020-01-23): 10 packages (detail see file D:\\gitspace\\alistar\\node_modules\\.recently_updates.txt) Today: → babel-preset-env@1.7.0 › browserslist@3.2.8 › electron-to-chromium@^1.3.47(1.3.342) (09:02:31) → webpack-dev-server@3.10.1 › del@4.1.1 › @types/glob@7.1.1 › @types/node@*(13.5.2) (05:51:42)√ All packages installed (1560 packages installed from npm registry, used 1m(network 27s), speed 2.23MB/s, json 1285(3.12MB), tarball 58.05MB) 编译完成后run dev， 1$ cnpm run dev 问题收集与处理修复问题前先将项目初始化提交github 问题一：ERROR in Template execution failed: ReferenceError: process is not defined高版本的node，大于12的版本时候。使用electron-vue项目时候会报错！Webpack ReferenceError: process is not defined! 123456789101112131415ReferenceError: process is not defined - index.ejs:11 eval [.]/[_html-webpack-plugin@3.2.0@html-webpack-plugin]/lib/loader.js!./src/index.ejs:11:2 - index.ejs:16 module.exports [.]/[_html-webpack-plugin@3.2.0@html-webpack-plugin]/lib/loader.js!./src/index.ejs:16:3 - index.js:284 [alistar]/[_html-webpack-plugin@3.2.0@html-webpack-plugin]/index.js:284:18 - runMicrotasks - task_queues.js:93 processTicksAndRejections internal/process/task_queues.js:93:5 修改 .electron-vue/webpack.renderer.config.js 和 .electron-vue/webpack.web.config.js如下 webpack.renderer.config.js：L125 123456789101112131415161718192021222324new HtmlWebpackPlugin(&#123; filename: 'index.html', template: path.resolve(__dirname, '../src/index.ejs'), minify: &#123; collapseWhitespace: true, removeAttributeQuotes: true, removeComments: true &#125;, templateParameters(compilation, assets, options) &#123; return &#123; compilation: compilation, webpack: compilation.getStats().toJson(), webpackConfig: compilation.options, htmlWebpackPlugin: &#123; files: assets, options: options &#125;, process, &#125;; &#125;, nodeModules: process.env.NODE_ENV !== 'production' ? path.resolve(__dirname, '../node_modules') : false&#125;), webpack.web.config.js: L97 12345678910111213141516171819202122new HtmlWebpackPlugin(&#123; filename: 'index.html', template: path.resolve(__dirname, '../src/index.ejs'), templateParameters(compilation, assets, options) &#123; return &#123; compilation: compilation, webpack: compilation.getStats().toJson(), webpackConfig: compilation.options, htmlWebpackPlugin: &#123; files: assets, options: options &#125;, process, &#125;; &#125;, minify: &#123; collapseWhitespace: true, removeAttributeQuotes: true, removeComments: true &#125;, nodeModules: false&#125;), 重新执行run dev 问题二： Unable to install vue-devtoolselectron-devtools-installer无法安装远程的vue-devtool，采用手动安装方式。 从本地浏览器已安装的插件中拷贝到项目路径，在项目目录下创建文件夹devTools\\vue-devtools，拷贝 C:\\Users\\${userName}\\AppData\\Local\\Google\\Chrome\\User Data\\Default\\Extensions\\nhdogjmejiglipccpnnnanhbledajbpd\\5.1.1_0文件夹内容devTools\\vue-devtools下， 修改src/main/index.dev.js 1234567891011121314151617181920212223242526272829303132/** * This file is used specifically and only for development. It installs * `electron-debug` &amp; `vue-devtools`. There shouldn't be any need to * modify this file, but it can be used to extend your development * environment. *//* eslint-disable */// Install `electron-debug` with `devtron`require('electron-debug')(&#123; showDevTools: true &#125;)// 新增变量定义import &#123; BrowserWindow &#125; from 'electron';import path from 'path';// Install `vue-devtools`require('electron').app.on('ready', () =&gt; &#123; // 注释掉的这部分是 Electron-Vue 中预装devtool的代码，没有用 // let installExtension = require('electron-devtools-installer') // installExtension.default(installExtension.VUEJS_DEVTOOLS) // .then(() =&gt; &#123;&#125;) // .catch(err =&gt; &#123; // console.log('Unable to install `vue-devtools`: \\n', err) // &#125;) // 安装vue-devtools BrowserWindow.addDevToolsExtension(path.resolve(__dirname, '../../devTools/vue-devtools'));&#125;)// Require `main` process to boot apprequire('./index') 应用自动重启，注意首次启动vue插件被&gt;&gt;这个隐藏了，需要手动拖动一下 问题三：ERROR in Error: .\\node_modules\\html-webpack-plugin\\node_modules\\clean-css\\index.js:1 SyntaxError: Invalid or unexpected token找到这个文件发现下载的是一串ASII乱码，尝试删除重新安装，发现用yarn install下载的这个文件总有问题，改为cnpm下载就行了 问题四： ERROR in TypeError: compilation.templatesPlugin is not a functionwebpack不是最新版 解决方法： 1.删除node_modules，重新安装 1npm install 2.安装最新webpack 1npm add webpack@latest 知识库vue项目转换为electron-vue 把原有项目package.json的dependencies，devDependencies中不同的配置项，添加到 my-project 的package.json中 把vue项目src的内容全部拷贝到 my-project/src/renderer 中 安装依赖 npm install 运行 npm run dev 就可以看到跑起来的客户端 打包 npm run build 项目的安装文件放进build里面，执行.exe文件就可以安装了（build文件有点大） electron-vue使用electron-builder指定打包32位//package.json 1234567891011\"win\": &#123; \"icon\": \"build/icons/icon.ico\", \"target\": [ &#123; \"target\": \"nsis\", \"arch\": [ \"ia32\" ] &#125; ]&#125;, electron-vue开发环境跨域代理设置//.electron-vue/dev-runner.js 1234567891011121314function startRenderer()&#123;... proxy: &#123; '/api': &#123; target: 'http://192.168.74.222:6019', // secure: false, // 如果是https接口，需要配置这个参数 changeOrigin: true, // 如果接口跨域，需要进行这个参数配置 pathRewrite: &#123; '^/api': '' &#125; &#125; &#125; ...&#125; 通过BrowserWindow新窗口打开项目内页面123456789101112const BrowserWindow = require('electron').remote.BrowserWindowconst winURL = process.env.NODE_ENV === 'development' ? `http://localhost:9080/#/new` : `file://$&#123;__dirname&#125;/index.html#new`let newWindow = new BrowserWindow(&#123; height: 600, width: 800&#125;)newWindow.loadURL(winURL)newWindow.on('closed', () =&gt; &#123; newWindow = null&#125;) 放弃SimulatedGREG/electron-vueSimulatedGREG/electron-vue已经很久没有更新了，而且其生成的工程结构并不是vue-cli3，在尝试升级vue-cli3过程中，发现简直是无底洞，直接放弃治疗，重头升级！！！ electron-vue3/4从0单排安装/升级vue-cli3/4先执行以下命令，确认下本地安装的vue-cli版本： 1vue -V 如果本地使用的是vue-cli2.x或者更早版本，可先卸载： 1cnpm uninstall vue-cli -g ※注：vue-cli3和vue-cli4使用了新的npm包名，与旧版本不一样。 如果还没有安装vue-cli3/4，先执行以下命令安装： 1cnpm install @vue/cli -g 如果你已安装vue-cli3/4，但不是最新版本，可执行以下命令升级： 1cnpm update @vue/cli -g 直接安装vue-cli4 创建vue项目找个喜欢的目录，执行以下命令，创建vue项目： （这里把项目名称定为alistar） 1vue create alistar 会出现以下选项（如果熟悉此步骤可跳过本节内容）：这里建议直接选择default一步搞定，后续有需要插件自己在package.json选配，刚创建项目没必要折腾 1234Vue CLI v3.8.4? Please pick a preset: (Use arrow keys) default (babel, eslint) &gt; Manually select features 选择“Manually select features” (自定义安装)。 1234567891011? Check the features needed for your project: (Press &lt;space&gt; to select, &lt;a&gt; to toggle all, &lt;i&gt; to invert selection)❯◉ Babel ◯ TypeScript ◯ Progressive Web App (PWA) Support ◉ Router ◉ Vuex ◉ CSS Pre-processors ◉ Linter / Formatter ◯ Unit Testing ◯ E2E Testing 这里选择了常用的模块，请根据实际需求进行选择。 12? Use history mode for router? (Requires proper server setup for index fallback in production) (Y/n) n 如果选择了router，这里会询问是否使用history模式。 vue-router 默认使用hash模式（即通过url#hash来跳转页面），使用URL的hash来模拟一个完整的 URL，当URL改变时，页面不会重新加载。 如果使用history，URL就像正常的url，比较好看。但是还需要后台配置支持。 这里我们选择“n”。 123456? Pick a CSS pre-processor (PostCSS, Autoprefixer and CSS Modules are supported by default): (Use arrow keys) Sass/SCSS (with dart-sass) Sass/SCSS (with node-sass) Less ❯ Stylus 选择CSS预处理模块，这里我们使用“Stylus”。 12345? Pick a linter / formatter config: (Use arrow keys) ESLint with error prevention only ESLint + Airbnb config ❯ ESLint + Standard config ESLint + Prettier 选择ESLint代码格式检查工具的配置，选择“ESLint + Standard config”，标准配置。 1234? Pick additional lint features: (Press &lt;space&gt; to select, &lt;a&gt; to toggle all, &lt;i&gt; to invert selection)❯◉ Lint on save ◯ Lint and fix on commit Line on save表示在保存代码的时候，进行格式检查。 Lint and fix on commit表示在git commit的时候自动纠正格式。 这里只选择“Lint on save”。 123? Where do you prefer placing config for Babel, PostCSS, ESLint, etc.? In dedicated config files ❯ In package.json 这里问把 babel, postcss, eslint 这些配置文件放哪？ In dedicated config files 表示独立文件 In package.json 表示放在package.json里 这里选择“In package.json”。 1? Save this as a preset for future projects? (y/N) N 是否为以后的项目保留这些设置？选择“N”。 然后耐心等待项目安装完成。 自动安装electron使用electron-builder安装 进入到项目根目录，执行： 1vue add electron-builder 在安装过程中，很可能会卡在这一步不动了： 1node ./download-chromedriver.js 没关系，我们先强制结束掉。再执行一次vue add electron-builder，然后就可以顺利通过了。 接下来出现配置选项： 1234? Choose Electron Version ^4.0.0&gt; ^5.0.0 ^6.0.0 选择Electron版本为5.0.0 Electron5.0和6.0的语法变化不大 选用5.0是因为node-ffi第三方修改版也只能支持到5.0 然后耐心等待安装完成。出现报错，跟上面安装的一样VueDevtools不翻墙安装不了，不理他，直接用本地方案开搞 1234567891011- Running completion hooks...error: Unexpected console statement (no-console) at src\\background.js:64:3: 62 | await installVueDevtools() 63 | &#125; catch (e) &#123;&gt; 64 | console.error('Vue Devtools failed to install:', e.toString()) | ^ 65 | &#125; 66 | 67 | &#125;1 error found. 安装完成后会自动在src目录下生成background.js并修改了package.json。 安装依赖包在项目根目录执行，安装全部依赖包： 1yarn 如果安装过程中报错：Error: post install error, please remove node_modules before retry!可以忽略，不影响后续使用。 编译并启动APP执行以下命令，开始编译APP，并启动开发环境APP： 1yarn electron:serve 首次启动可能会等待很久，出现以下信息： 12345INFO Launching Electron...Failed to fetch extension, trying 4 more timesFailed to fetch extension, trying 3 more timesFailed to fetch extension, trying 2 more times... 这是因为在请求安装vuejs devtools插件。需要科学上网才能安装成功。如果不能科学上网也没关系，耐心等待5次请求失败后会自动跳过(可以本地安装）。编译成功后，就会出现开发环境的APP了。 配置ESLint代码格式检查工具ESlint可以高效的检查代码格式，让参与项目的所有工程师都能保持统一的代码风格。其检测精度甚至可以精确到是否多一个空格或者少一个空格。代码格式的统一对提高团队的协同开发效率有很大的帮助，特别是对有代码洁癖的工程师。 在项目根目录下创建.eslintrc.js （注意文件名前面有个“.”） 请粘贴以下代码： 123456789101112131415161718192021222324module.exports = &#123; root: true, env: &#123; node: true &#125;, 'extends': [ 'plugin:vue/essential', '@vue/standard' ], rules: &#123; 'no-debugger': process.env.NODE_ENV === 'production' ? 'error' : 'off', // 不检测语句末尾的分号 'semi': ['off', 'always'], // 强制缩进为2个空格 'indent': ['error', 2], // 关闭函数名称跟括号之间的空格检测 'space-before-function-paren': 0, // 忽略大括号内的空格 'object-curly-spacing': 0 &#125;, parserOptions: &#123; parser: 'babel-eslint' &#125;&#125; 这里说明下关于indent缩进的配置，要配合项目根目录下的.editorconfig 12345[*.&#123;js,jsx,ts,tsx,vue&#125;]indent_style = space &lt;--这里定义缩进类型是空格还是tabindent_size = 2 &lt;--这里需要与.eslintrc.js的indent对应trim_trailing_whitespace = trueinsert_final_newline = true .editorconfig 用于IDE自动格式化代码 .eslintrc.js 用于ESlint检测 以上是常用的配置。如果你有更多的配置需求，可参阅： https://cloud.tencent.com/developer/doc/1078 配置vue在项目根目录下创建vue.config.js，粘贴以下代码： 123456789101112131415161718192021const path = require('path');function resolve (dir) &#123; return path.join(__dirname, dir);&#125;module.exports = &#123; publicPath: './', devServer: &#123; // can be overwritten by process.env.HOST host: '0.0.0.0', port: 8080 &#125;, chainWebpack: config =&gt; &#123; config.resolve.alias .set('@', resolve('src')) .set('src', resolve('src')) .set('common', resolve('src/common')) .set('components', resolve('src/components')); &#125;&#125;; devServer 用于设置开发环境的服务，这里表示在本地8080端口启动web服务。 chainWebpack 我们给项目目录起了“别名(alias)”，在代码中，我们可以直接用“别名”访问资源，省去了每次输入完整相对路径的麻烦。 ※注： ◉ 在js代码中可直接使用别名，例如： @/common/js/xxx.js 等价于 src/common/js/xxx.js common/js/xxx.js 等价于 src/common/js/xxx.js ◉ 在css或者html中使用别名，需要在别名前加“~”，例如： @import “~common/stylus/font.styl”; 项目基本设定主进程和渲染进程简介在开始下面的步骤之前，很有必要简单了解下Electron的应用架构。 主进程Electron 运行 package.json 的 main 脚本（background.js）的进程被称为主进程。 在主进程中运行的脚本通过创建web页面来展示用户界面。 一个 Electron 应用总是有且只有一个主进程。 渲染进程由于 Electron 使用了 Chromium 来展示 web 页面，所以 Chromium 的多进程架构也被使用到。 每个 Electron 中的 web 页面运行在它自己的渲染进程中。 在普通的浏览器中，web页面通常在一个沙盒环境中运行，不被允许去接触原生的资源。 然而 Electron 的用户在 Node.js 的 API 支持下可以在页面中和操作系统进行一些底层交互。 主进程与渲染进程的关系主进程使用 BrowserWindow 实例创建页面。 每个 BrowserWindow 实例都在自己的渲染进程里运行页面。 当一个 BrowserWindow 实例被销毁后，相应的渲染进程也会被终止。 主进程管理所有的web页面和它们对应的渲染进程。 每个渲染进程都是独立的，它只关心它所运行的 web 页面。 具体可参阅官方文档： https://electronjs.org/docs/tutorial/application-architecture#main-and-renderer-processes APP窗口大小修改background.js： 123456789 function createWindow () &#123; // Create the browser window. win = new BrowserWindow(&#123;M width: 1200,M height: 620, webPreferences: &#123; nodeIntegration: true &#125; &#125;) 取消跨域限制修改background.js： 12345678910 function createWindow () &#123; // Create the browser window. win = new BrowserWindow(&#123; width: 1200, height: 620, webPreferences: &#123;+ webSecurity: false, nodeIntegration: true &#125; &#125;) 取消菜单栏在我们生成的桌面APP中，我们可以看到默认的菜单栏。 在windows中，菜单栏在APP窗口内的顶部；在macOS中，菜单栏位于电脑屏幕顶部。 为了方便项目将来也能直接生成纯web应用，尽量把APP的全部功能都做到渲染进程里，这里我们取消菜单栏。 由于macOS的特殊性，顶部菜单栏无法删除，所以我们针对macOS特殊处理，把菜单栏只保留“关于”和“退出”。 修改background.js： 123456789101112131415161718192021222324252627282930313233M import &#123; app, protocol, BrowserWindow, Menu &#125; from &apos;electron&apos; ... function createWindow () &#123; ... win.on(&apos;closed&apos;, () =&gt; &#123; win = null &#125;) + createMenu() &#125; + // 设置菜单栏+ function createMenu() &#123;+ // darwin表示macOS，针对macOS的设置+ if (process.platform === &apos;darwin&apos;) &#123;+ const template = [+ &#123;+ label: &apos;App Demo&apos;,+ submenu: [+ &#123;+ role: &apos;about&apos;+ &#125;,+ &#123;+ role: &apos;quit&apos;+ &#125;]+ &#125;]+ let menu = Menu.buildFromTemplate(template)+ Menu.setApplicationMenu(menu)+ &#125; else &#123;+ // windows及linux系统+ Menu.setApplicationMenu(null)+ &#125;+ &#125; macOS菜单栏名称label的“App Demo”会在build版本生效，dev版本会显示“Electron” 更多关于菜单栏设置，请参阅：https://electronjs.org/docs/api/menu 设置APP窗口图标准备windows和macOS两版图标。 windows: app.ico 最小尺寸：256x256 macOS: app.png或app.icns 最小尺寸：512x512 把图标文件放到public/目录下，项目结构如下： 1234567891011121314151617|- /dist_electron （略）|- /public |- app.icns &lt;-- 本教程暂时未使用icns |- app.ico |- app.png |- favicon.ico |- index.html|- /src （略）|- .editorconfig |- .eslintrc.js|- .gitignore|- babel.config.js|- package.json|- package-lock.json|- README.md 可以顺便把favicon.ico也修改一下，但是在桌面版APP上是用不到的。如果以后生成纯web项目才会用到。 修改background.js，让APP窗口应用图标： 1234567891011 function createWindow () &#123; // Create the browser window. win = new BrowserWindow(&#123; width: 1200, height: 620, webPreferences: &#123; nodeIntegration: true &#125;,+ // eslint-disable-next-line no-undef+ icon: `$&#123;__static&#125;/app.ico` &#125;) 这里的${__static}对应的是public目录 现在，Windows系统上可以看到开发环境的APP窗口图标已经生效了。 macOS图标请参照相关章节，并且需要在build后才能生效。 设置APP窗口标题栏名称修改public/index.html: 我们把electron-vue-demo改为App Demo。 1234567 &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0\"&gt; &lt;link rel=\"icon\" href=\"&lt;%= BASE_URL %&gt;favicon.ico\"&gt;M &lt;title&gt;App Demo&lt;/title&gt; &lt;/head&gt; build最终产品这里我们已经集成了electron-builder工具，官方文档可以参阅：https://www.electron.build/ 设置APP及安装包图标在窗口图标章节，我们的图标生效于运行APP的窗口。本小节将生效于最终生成的可执行文件和安装包图标。需要准备的图标文件请回看对应章节。 修改vue.config.js 1234567891011121314 chainWebpack: config =&gt; &#123;...&#125;,+ pluginOptions: &#123;+ electronBuilder: &#123;+ builderOptions: &#123;+ win: &#123;+ icon: './public/app.ico'+ &#125;,+ mac: &#123;+ icon: './public/app.png'+ &#125;+ &#125;+ &#125;+ &#125; ... 运行build后的mac版本，可以看到图标都已生效了。 安装包和可执行文件的截图就不再放出了。 更多详细介绍，可参阅： https://www.electron.build/icons.html 设置APP名称APP名称包括安装包中APP的名称、可执行文件的文件名。 修改vue.config.js: 12345678910111213 pluginOptions: &#123; electronBuilder: &#123; builderOptions: &#123; win: &#123; icon: './public/app.ico' &#125;, mac: &#123; icon: './public/app.png' &#125;,+ productName: 'AppDemo' &#125; &#125; &#125; 打包APP执行以下命令，可以build工程： 1npm run electron:build 最终在dist_electron目录下生成build后的产品。 windows版本目录如下： 123456789/dist_electron|- /bundled （略）|- /win-unpacked &lt;-- 绿色版 （略）|- AppDemo Setup 0.1.0.exe &lt;-- 安装文件|- AppDemo Setup 0.1.0.exe.blockmap|- builder-effective-config.yaml|- index.js 这里其实就win-unpacked和AppDemo Setup 0.1.0.exe有用。 ※注：在32位环境下打包生成的是32位APP，在64位环境下打包生成的是64位APP。 mac版本12345678910/dist_electron|- /bundled （略）|- /mac |- AppDemo &lt;-- 绿色版|- AppDemo-0.1.0-mac.zip &lt;-- 绿色版压缩包|- AppDemo-0.1.0-mac.dmg &lt;-- 安装包|- AppDemo-0.1.0.dmg.blockmap|- builder-effective-config.yaml|- index.js 可能出现的错误我曾经在Win10 64bit 1809版本上build失败，保存信息中提示： 123Error output:Can't open output fileError - aborting creation process 与此同时，在win7和win10 1803版本build正常。经研究，无果。后来把windows升级到1903版本，问题解决了。应该是vue-cli-plugin-electron-builder插件与系统之间的问题导致。 关于项目开发的一些经验在完成以上章节后，后面基本可以完全按照web方式开发了。这里简单分享下一些小经验。 src目录结构参考1234567891011121314151617181920/src|- /common |- /fonts |- /images |- /js |- api |- libs |- /stylus |- /components |- /base |- /modules |- /moduleA |- /moduleB ... |- /views |- App.vue |- background.js |- main.js |- router.js |- store.js 下面对部分重要目录简要说明： 1234567891011common/ - 项目公用库common/fonts/ - 字体文件common/images/ - 公用图片common/js/ - 公用js目录common/js/api/ - 把api按类别封装成函数，并export出去，减少业务逻辑中的重复代码common/js/lib/ - 存放一些公用函数库、定义的常量库等common/stylus/ - Stylus样式文件components/ - vue组件目录component/base/ - vue基础组件，例如自定义的CheckBox、日期选择器、Dialog、Toaster、分页组件等component/modules/ - vue模块views/ - vue页面 换肤功能的实现很多项目都有实时换肤的需求，在实际开发中，虽然我们使用了Sass、Less、Stylus等高端样式工具，但最终经过编译还是要回归到最原始的CSS。换肤的本质还是实时替换皮肤样式文件。 失败案例以Stylus为例，抽象出皮肤文件skin.styl: 12$color-bg = #fff$color-text = #333 在业务样式中引用： 12345@import 'skin.styl'body background: $color-bg color: $color-text 当经过编译后，生成的css为： 1body &#123;background: #fff; color: #333;&#125; 样式已经写死了，无法换肤。 那么应该怎么做呢？ 成功案例项目根目录下的public目录是静态目录，也就是说在build最终产品的时候，它里面的文件将原封不动保留。所以，可以将皮肤文件放在这里。 1234567891011|- /public+ |- /skin+ |- /skin01+ |- skin.css+ |- /skin02+ |- skin.css |- app.icns |- app.ico |- app.png |- favicon.ico |- index.html 由于Electron的是基于chromium内核，所以不用担心代码的浏览器兼容问题。接下来就是发挥CSS3变量var(–*)的时候了。 public/skin/skin01/skin.css： 1234:root &#123; --color-bg: #fff; --color-text: #333;&#125; public/skin/skin02/skin.css： 1234:root &#123; --color-bg: #263238; --color-text: #b2ccd6;&#125; 修改src/App.vue： 1234567891011121314151617181920 ... &lt;style lang=\"stylus\"&gt;+ body+ background: var(--color-bg)+ color: var(--color-text) #app font-family 'Avenir', Helvetica, Arial, sans-serif -webkit-font-smoothing antialiased -moz-osx-font-smoothing grayscale text-align centerM color: var(--color-text) #nav padding 30px a font-weight boldM color: var(--color-text) &amp;.router-link-exact-active color #42b983 &lt;/style&gt; 在public/index.html引入皮肤样式，注意加上id=”app-skin”： 12345678 &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0\"&gt; &lt;link rel=\"icon\" href=\"&lt;%= BASE_URL %&gt;favicon.ico\"&gt;+ &lt;link rel=\"stylesheet\" href=\"&lt;%= BASE_URL %&gt;skin/skin01/skin.css\" id=\"app-skin\"&gt; &lt;title&gt;App Demo&lt;/title&gt; &lt;/head&gt; 篇幅有限，这里就不写通过js修改皮肤的代码了。通过调试工具手动修改skin的css路径，可看到换肤效果 从Electron4.x升级到5.x如果你之前用的是Electron4.x，升级到5.x很简单。 修改package.json中electron的版本(写作本文时是5.0.6)： 123 ...M \"electron\": \"^5.0.6\", ... 修改background.js中的这部分： 1234567891011// Scheme must be registered before the app is ready// Electron 4.x代码// protocol.registerStandardSchemes(['app'], &#123;secure: true&#125;)// Electron 5.x代码protocol.registerSchemesAsPrivileged([&#123; scheme: 'app', privileges: &#123; secure: true, standard: true &#125;&#125;]) 然后执行，等待升级安装完成： 1yarn","categories":[{"name":"vue","slug":"vue","permalink":"https://vincentruan.github.io/categories/vue/"}],"tags":[{"name":"electron","slug":"electron","permalink":"https://vincentruan.github.io/tags/electron/"},{"name":"vue","slug":"vue","permalink":"https://vincentruan.github.io/tags/vue/"},{"name":"nodejs","slug":"nodejs","permalink":"https://vincentruan.github.io/tags/nodejs/"}]},{"title":"JVM 性能调优监控工具 jps、jstack、jmap、jhat、jstat、hprof 使用详解","slug":"JVM-性能调优监控工具-jps、jstack、jmap、jhat、jstat、hprof-使用详解","date":"2020-01-27T04:51:30.000Z","updated":"2020-02-25T15:09:15.041Z","comments":true,"path":"2020/01/27/JVM-性能调优监控工具-jps、jstack、jmap、jhat、jstat、hprof-使用详解/","link":"","permalink":"https://vincentruan.github.io/2020/01/27/JVM-性能调优监控工具-jps、jstack、jmap、jhat、jstat、hprof-使用详解/","excerpt":"Java应用开发、维护中，有时候我们会碰到下面这些问题： OutOfMemoryError，内存不足 内存泄露 线程死锁 锁争用（Lock Contention） Java进程消耗CPU过高 …… 这些问题在日常开发、维护中可能被很多人忽视（比如有的人遇到上面的问题只是重启服务器或者调大内存，而不会深究问题根源），但能够理解并解决这些问题是Java程序员进阶的必备要求。本文将对一些常用的JVM性能调优监控工具进行介绍，希望能起抛砖引玉之用。","text":"Java应用开发、维护中，有时候我们会碰到下面这些问题： OutOfMemoryError，内存不足 内存泄露 线程死锁 锁争用（Lock Contention） Java进程消耗CPU过高 …… 这些问题在日常开发、维护中可能被很多人忽视（比如有的人遇到上面的问题只是重启服务器或者调大内存，而不会深究问题根源），但能够理解并解决这些问题是Java程序员进阶的必备要求。本文将对一些常用的JVM性能调优监控工具进行介绍，希望能起抛砖引玉之用。 jps(Java Virtual Machine Process Status Tool) ： 基础工具jps主要用来输出JVM中运行的进程状态信息。语法格式如下： 1jps [options] [hostid] 如果不指定hostid就默认为当前主机或服务器。 命令行参数选项说明如下： 1234567-q 不输出类名、Jar名和传入main方法的参数-m 输出传入main方法的参数-l 输出main类或Jar的全限名-v 输出传入JVM的参数 比如下面：12345678root@ubuntu:/# jps -m -l2458 org.artifactory.standalone.main.Main /usr/local/artifactory-2.2.5/etc/jetty.xml29920 com.sun.tools.hat.Main -port 9998 /tmp/dump.dat3149 org.apache.catalina.startup.Bootstrap start30972 sun.tools.jps.Jps -m -l8247 org.apache.catalina.startup.Bootstrap start25687 com.sun.tools.hat.Main -port 9999 dump.dat21711 mrf-center.jar jstackjstack主要用来查看某个Java进程内的线程堆栈信息。语法格式如下：123jstack [option] pidjstack [option] executable corejstack [option] [server-id@]remote-hostname-or-ip 命令行参数选项说明如下：1-l long listings，会打印出额外的锁信息，在发生死锁时可以用jstack -l pid来观察锁持有情况-m mixed mode，不仅会输出Java堆栈信息，还会输出C/C++堆栈信息（比如Native方法） jstack可以定位到线程堆栈，根据堆栈信息我们可以定位到具体代码，所以它在JVM性能调优中使用得非常多。下面我们来一个实例找出某个Java进程中最耗费CPU的Java线程并定位堆栈信息，用到的命令有ps、top、printf、jstack、grep。第一步先找出Java进程ID，我部署在服务器上的Java应用名称为mrf-center： 12root@ubuntu:/# ps -ef | grep mrf-center | grep -v greproot 21711 1 1 14:47 pts/3 00:02:10 java -jar mrf-center.jar 得到进程ID为21711，第二步找出该进程内最耗费CPU的线程，可以使用ps -Lfp pid或者ps -mp pid -o THREAD, tid, time或者top -Hp pid，我这里用第三个，输出如下： TIME列就是各个Java线程耗费的CPU时间，CPU时间最长的是线程ID为21742的线程，用 1printf \"%x\" 21742 得到21742的十六进制值为54ee，下面会用到。OK，下一步终于轮到jstack上场了，它用来输出进程21711的堆栈信息，然后根据线程ID的十六进制值grep，如下：12root@ubuntu:/# jstack 21711 | grep 54ee\"PollIntervalRetrySchedulerThread\" prio=10 tid=0x00007f950043e000 nid=0x54ee in Object.wait() [0x00007f94c6eda000] 可以看到CPU消耗在PollIntervalRetrySchedulerThread这个类的Object.wait()，我找了下我的代码，定位到下面的代码：12345678910111213// Idle waitgetLog().info(\"Thread [\" + getName() + \"] is idle waiting...\");schedulerThreadState = PollTaskSchedulerThreadState.IdleWaiting;long now = System.currentTimeMillis();long waitTime = now + getIdleWaitTime();long timeUntilContinue = waitTime - now;synchronized(sigLock) &#123;try &#123; if(!halted.get()) &#123; sigLock.wait(timeUntilContinue); &#125; &#125; catch (InterruptedException ignore) &#123; &#125;&#125; 它是轮询任务的空闲等待代码，上面的sigLock.wait(timeUntilContinue)就对应了前面的Object.wait()。 jmap（Memory Map）和 jhat（Java Heap Analysis Tool）jmap导出堆内存，生产上使用曾经导致过进程hang住的情况(JDK1.7)，分析可能存在侵入内存区间读取时，有一定概率造成影响，建议如果机器有重要任务在运行或者不能立刻重启的进程谨慎使用！然后使用jhat来进行分析jmap语法格式如下：123jmap [option] pidjmap [option] executable corejmap [option] [server-id@]remote-hostname-or-ip 如果运行在64位JVM上，可能需要指定-J-d64命令选项参数。1jmap -permstat pid 打印进程的类加载器和类加载器加载的持久代对象信息，输出：类加载器名称、对象是否存活（不可靠）、对象地址、父类加载器、已加载的类大小等信息，如下图： 使用jmap -heap pid查看进程堆内存使用情况，包括使用的GC算法、堆配置参数和各代中堆内存使用情况。比如下面的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849root@ubuntu:/# jmap -heap 21711Attaching to process ID 21711, please wait...Debugger attached successfully.Server compiler detected.JVM version is 20.10-b01using thread-local object allocation.Parallel GC with 4 thread(s)Heap Configuration:MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 2067791872 (1972.0MB)NewSize = 1310720 (1.25MB)MaxNewSize = 17592186044415 MBOldSize = 5439488 (5.1875MB)NewRatio = 2 SurvivorRatio = 8 PermSize = 21757952 (20.75MB)MaxPermSize = 85983232 (82.0MB)Heap Usage:PS Young GenerationEden Space: capacity = 6422528 (6.125MB) used = 5445552 (5.1932830810546875MB) free = 976976 (0.9317169189453125MB) 84.78829520089286% usedFrom Space: capacity = 131072 (0.125MB) used = 98304 (0.09375MB) free = 32768 (0.03125MB) 75.0% usedTo Space: capacity = 131072 (0.125MB) used = 0 (0.0MB) free = 131072 (0.125MB) 0.0% usedPS Old Generation capacity = 35258368 (33.625MB) used = 4119544 (3.9287033081054688MB) free = 31138824 (29.69629669189453MB) 11.683876009235595% usedPS Perm Generation capacity = 52428800 (50.0MB) used = 26075168 (24.867218017578125MB) free = 26353632 (25.132781982421875MB) 49.73443603515625% used .... 使用jmap -histo[:live] pid查看堆内存中的对象数目、大小统计直方图，如果带上live则只统计活对象，如下：1234567891011121314151617181920212223242526272829303132333435root@ubuntu:/# jmap -histo:live 21711 | more num #instances #bytes class name---------------------------------------------- 1: 38445 5597736 &lt;constMethodKlass&gt; 2: 38445 5237288 &lt;methodKlass&gt; 3: 3500 3749504 &lt;constantPoolKlass&gt; 4: 60858 3242600 &lt;symbolKlass&gt; 5: 3500 2715264 &lt;instanceKlassKlass&gt; 6: 2796 2131424 &lt;constantPoolCacheKlass&gt; 7: 5543 1317400 [I 8: 13714 1010768 [C 9: 4752 1003344 [B 10: 1225 639656 &lt;methodDataKlass&gt; 11: 14194 454208 java.lang.String 12: 3809 396136 java.lang.Class 13: 4979 311952 [S 14: 5598 287064 [[I 15: 3028 266464 java.lang.reflect.Method 16: 280 163520 &lt;objArrayKlassKlass&gt; 17: 4355 139360 java.util.HashMap$Entry 18: 1869 138568 [Ljava.util.HashMap$Entry; 19: 2443 97720 java.util.LinkedHashMap$Entry 20: 2072 82880 java.lang.ref.SoftReference 21: 1807 71528 [Ljava.lang.Object; 22: 2206 70592 java.lang.ref.WeakReference 23: 934 52304 java.util.LinkedHashMap 24: 871 48776 java.beans.MethodDescriptor 25: 1442 46144 java.util.concurrent.ConcurrentHashMap$HashEntry 26: 804 38592 java.util.HashMap 27: 948 37920 java.util.concurrent.ConcurrentHashMap$Segment 28: 1621 35696 [Ljava.lang.Class; 29: 1313 34880 [Ljava.lang.String; 30: 1396 33504 java.util.LinkedList$Entry 31: 462 33264 java.lang.reflect.Field 32: 1024 32768 java.util.Hashtable$Entry 33: 948 31440 [Ljava.util.concurrent.ConcurrentHashMap$HashEntry; class name是对象类型，说明如下：123456789B byteC charD doubleF floatI intJ longZ boolean[ 数组，如[I表示int[][L+类名 其他对象 还有一个很常用的情况是：用jmap把进程内存使用情况dump到文件中，再用jhat分析查看。jmap进行dump命令格式如下：1jmap -dump:format=b,file=dumpFileName pid 我一样地对上面进程ID为21711进行Dump：123root@ubuntu:/# jmap -dump:format=b,file=/tmp/dump.dat 21711 Dumping heap to /tmp/dump.dat ...Heap dump file created dump出来的文件可以用MAT、VisualVM等工具查看，这里用jhat查看：12345678root@ubuntu:/# jhat -port 9998 /tmp/dump.datReading from /tmp/dump.dat...Dump file created Tue Jan 28 17:46:14 CST 2014Snapshot read, resolving...Resolving 132207 objects...Chasing references, expect 26 dots..........................Eliminating duplicate references..........................Snapshot resolved.Started HTTP server on port 9998Server is ready. 注意如果Dump文件太大，可能需要加上-J-Xmx512m这种参数指定最大堆内存，即jhat -J-Xmx512m -port 9998 /tmp/dump.dat。然后就可以在浏览器中输入主机地址:9998查看了： 上面红线框出来的部分大家可以自己去摸索下，最后一项支持OQL（Object Query Language对象查询语言）。 jstat（JVM统计监测工具）看看各个区内存和GC的情况语法格式如下：1jstat [ generalOption | outputOptions vmid [interval[s|ms] [count]] ] vmid是Java虚拟机ID，在Linux/Unix系统上一般就是进程ID。interval是采样时间间隔。count是采样数目。比如下面输出的是GC信息，采样时间间隔为250ms，采样数为4：123456root@ubuntu:/# jstat -gc 21711 250 4 S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT 192.0 192.0 64.0 0.0 6144.0 1854.9 32000.0 4111.6 55296.0 25472.7 702 0.431 3 0.218 0.649192.0 192.0 64.0 0.0 6144.0 1972.2 32000.0 4111.6 55296.0 25472.7 702 0.431 3 0.218 0.649192.0 192.0 64.0 0.0 6144.0 1972.2 32000.0 4111.6 55296.0 25472.7 702 0.431 3 0.218 0.649192.0 192.0 64.0 0.0 6144.0 2109.7 32000.0 4111.6 55296.0 25472.7 702 0.431 3 0.218 0.649 要明白上面各列的意义，先看JVM堆内存布局： 可以看出： 12堆内存 = 年轻代 + 年老代 + 永久代年轻代 = Eden区 + 两个Survivor区（From和To） 现在来解释各列含义： 1234567S0C、S1C、S0U、S1U：Survivor 0/1区容量（Capacity）和使用量（Used）EC、EU：Eden区容量和使用量OC、OU：年老代容量和使用量PC、PU：永久代容量和使用量YGC、YGT：年轻代GC次数和GC耗时FGC、FGCT：Full GC次数和Full GC耗时GCT：GC总耗时 hprof（Heap/CPU Profiling Tool）hprof能够展现CPU使用率，统计堆内存使用情况。语法格式如下：123java -agentlib:hprof[=options] ToBeProfiledClassjava -Xrunprof[:options] ToBeProfiledClassjavac -J-agentlib:hprof[=options] ToBeProfiledClass 完整的命令选项如下： 1234567891011121314151617Option Name and Value Description Default--------------------- ----------- -------heap=dump|sites|all heap profiling allcpu=samples|times|old CPU usage offmonitor=y|n monitor contention nformat=a|b text(txt) or binary output afile=&lt;file&gt; write data to file java.hprof[.txt]net=&lt;host&gt;:&lt;port&gt; send data over a socket offdepth=&lt;size&gt; stack trace depth 4interval=&lt;ms&gt; sample interval in ms 10cutoff=&lt;value&gt; output cutoff point 0.0001lineno=y|n line number in traces? ythread=y|n thread in traces? ndoe=y|n dump on exit? ymsa=y|n Solaris micro state accounting nforce=y|n force output to &lt;file&gt; yverbose=y|n print messages about dumps y 来几个官方指南上的实例。CPU Usage Sampling Profiling(cpu=samples)的例子：1java -agentlib:hprof=cpu=samples,interval=20,depth=3 Hello 上面每隔20毫秒采样CPU消耗信息，堆栈深度为3，生成的profile文件名称是java.hprof.txt，在当前目录。 CPU Usage Times Profiling(cpu=times)的例子，它相对于CPU Usage Sampling Profile能够获得更加细粒度的CPU消耗信息，能够细到每个方法调用的开始和结束，它的实现使用了字节码注入技术（BCI）： 1javac -J-agentlib:hprof=cpu=times Hello.java Heap Allocation Profiling(heap=sites)的例子：1javac -J-agentlib:hprof=heap=sites Hello.java Heap Dump(heap=dump)的例子，它比上面的Heap Allocation Profiling能生成更详细的Heap Dump信息：1javac -J-agentlib:hprof=heap=dump Hello.java 虽然在JVM启动参数中加入-Xrunprof:heap=sites参数可以生成CPU/Heap Profile文件，但对JVM性能影响非常大，不建议在线上服务器环境使用。","categories":[{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/categories/Java/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/tags/Linux/"},{"name":"Java","slug":"Java","permalink":"https://vincentruan.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://vincentruan.github.io/tags/JVM/"}]},{"title":"Linux命令 - netstat","slug":"Linux命令-netstat","date":"2020-01-27T04:44:15.000Z","updated":"2020-02-25T15:09:15.044Z","comments":true,"path":"2020/01/27/Linux命令-netstat/","link":"","permalink":"https://vincentruan.github.io/2020/01/27/Linux命令-netstat/","excerpt":"概述netstat 是一个告诉我们系统中所有 tcp/udp/unix socket 连接状态的命令行工具。它会列出所有已经连接或者等待连接状态的连接。 该工具在识别某个应用监听哪个端口时特别有用，我们也能用它来判断某个应用是否正常的在监听某个端口。 netstat 命令还能显示其它各种各样的网络相关信息，例如路由表， 网卡统计信息， 虚假连接以及多播成员等。","text":"概述netstat 是一个告诉我们系统中所有 tcp/udp/unix socket 连接状态的命令行工具。它会列出所有已经连接或者等待连接状态的连接。 该工具在识别某个应用监听哪个端口时特别有用，我们也能用它来判断某个应用是否正常的在监听某个端口。 netstat 命令还能显示其它各种各样的网络相关信息，例如路由表， 网卡统计信息， 虚假连接以及多播成员等。 1 - 检查所有的连接使用 a 选项可以列出系统中的所有连接， 1$ netstat -a 这会显示系统所有的 tcp、udp 以及 unix 连接。 2 - 检查所有的 tcp/udp/unix socket 连接使用 t 选项只列出 tcp 连接， 1$ netstat -at 类似的，使用 u 选项只列出 udp 连接， 1$ netstat -au 使用 x 选项只列出 Unix socket 连接， 1$ netstat -ax 3 - 同时列出进程 ID/进程名称使用 p 选项可以在列出连接的同时也显示 PID 或者进程名称，而且它还能与其他选项连用， 1$ netstat -ap 4 - 列出端口号而不是服务名使用 n 选项可以加快输出，它不会执行任何反向查询（LCTT 译注：这里原文有误），而是直接输出数字。 由于无需查询，因此结果输出会快很多。 1$ netstat -an 5 - 只输出监听端口使用 l 选项只输出监听端口。它不能与 a 选项连用，因为 a 会输出所有端口， 1$ netstat -l 6 - 输出网络状态使用 s 选项输出每个协议的统计信息，包括接收/发送的包数量， 1$ netstat -s 7 - 输出网卡状态使用 I 选项只显示网卡的统计信息， 1$ netstat -i 8 - 显示多播组multicast group信息使用 g 选项输出 IPV4 以及 IPV6 的多播组信息， 1$ netstat -g 9 - 显示网络路由信息使用 r 输出网络路由信息， 1$ netstat -r 10 - 持续输出使用 c 选项持续输出结果 1$ netstat -c 11 - 过滤出某个端口与 grep 连用来过滤出某个端口的连接， 1$ netstat -anp | grep 3306 12 - 统计连接个数通过与 wc 和 grep 命令连用，可以统计指定端口的连接数量 1$ netstat -anp | grep 3306 | wc -l 这会输出 mysql 服务端口（即 3306端口）的连接数。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/tags/Linux/"},{"name":"netstat","slug":"netstat","permalink":"https://vincentruan.github.io/tags/netstat/"}]},{"title":"memcached与redis实现的对比","slug":"memcached与redis实现的对比","date":"2019-12-29T07:03:32.000Z","updated":"2020-02-25T15:09:15.054Z","comments":true,"path":"2019/12/29/memcached与redis实现的对比/","link":"","permalink":"https://vincentruan.github.io/2019/12/29/memcached与redis实现的对比/","excerpt":"memcached和redis，作为近些年最常用的缓存服务器，相信大家对它们再熟悉不过了。前两年还在学校时，我曾经读过它们的主要源码，如今写篇笔记从个人角度简单对比一下它们的实现方式，权当做复习，有理解错误之处，欢迎指正。 文中使用的架构类的图片大多来自于网络，有部分图与最新实现有出入，文中已经指出。","text":"memcached和redis，作为近些年最常用的缓存服务器，相信大家对它们再熟悉不过了。前两年还在学校时，我曾经读过它们的主要源码，如今写篇笔记从个人角度简单对比一下它们的实现方式，权当做复习，有理解错误之处，欢迎指正。 文中使用的架构类的图片大多来自于网络，有部分图与最新实现有出入，文中已经指出。 1. 综述 读一个软件的源码，首先要弄懂软件是用作干什么的，那memcached和redis是干啥的？众所周知，数据一般会放在数据库中，但是查询数据会相对比较慢，特别是用户很多时，频繁的查询，需要耗费大量的时间。怎么办呢？数据放在哪里查询快？那肯定是内存中。memcached和redis就是将数据存储在内存中，按照key-value的方式查询，可以大幅度提高效率。所以一般它们都用做缓存服务器，缓存常用的数据，需要查询的时候，直接从它们那儿获取，减少查询数据库的次数，提高查询效率。 2. 服务方式memcached和redis怎么提供服务呢？它们是独立的进程，需要的话，还可以让他们变成daemon进程，所以我们的用户进程要使用memcached和redis的服务的话，就需要进程间通信了。考虑到用户进程和memcached和redis不一定在同一台机器上，所以还需要支持网络间通信。因此，memcached和redis自己本身就是网络服务器，用户进程通过与他们通过网络来传输数据，显然最简单和最常用的就是使用tcp连接了。另外，memcached和redis都支持udp协议。而且当用户进程和memcached和redis在同一机器时，还可以使用unix域套接字通信。 3. 事件模型下面开始讲他们具体是怎么实现的了。首先来看一下它们的事件模型。 自从epoll出来以后，几乎所有的网络服务器全都抛弃select和poll，换成了epoll。redis也一样，只不多它还提供对select和poll的支持，可以自己配置使用哪一个，但是一般都是用epoll。另外针对BSD，还支持使用kqueue。而memcached是基于libevent的，不过libevent底层也是使用epoll的，所以可以认为它们都是使用epoll。epoll的特性这里就不介绍了，网上介绍文章很多。 它们都使用epoll来做事件循环，不过redis是单线程的服务器（redis也是多线程的，只不过除了主线程以外，其他线程没有event loop，只是会进行一些后台存储工作），而memcached是多线程的。 redis的事件模型很简单，只有一个event loop，是简单的reactor实现。不过redis事件模型中有一个亮点，我们知道epoll是针对fd的，它返回的就绪事件也是只有fd，redis里面的fd就是服务器与客户端连接的socket的fd，但是处理的时候，需要根据这个fd找到具体的客户端的信息，怎么找呢？通常的处理方式就是用红黑树将fd与客户端信息保存起来，通过fd查找，效率是lgn。不过redis比较特殊，redis的客户端的数量上限可以设置，即可以知道同一时刻，redis所打开的fd的上限，而我们知道，进程的fd在同一时刻是不会重复的（fd只有关闭后才能复用），所以redis使用一个数组，将fd作为数组的下标，数组的元素就是客户端的信息，这样，直接通过fd就能定位客户端信息，查找效率是O(1)，还省去了复杂的红黑树的实现（我曾经用c写一个网络服务器，就因为要保持fd和connect对应关系，不想自己写红黑树，然后用了STL里面的set，导致项目变成了c++的，最后项目使用g++编译，这事我不说谁知道？）。显然这种方式只能针对connection数量上限已确定，并且不是太大的网络服务器，像nginx这种http服务器就不适用，nginx就是自己写了红黑树。 而memcached是多线程的，使用master-worker的方式，主线程监听端口，建立连接，然后顺序分配给各个工作线程。每一个从线程都有一个event loop，它们服务不同的客户端。master线程和worker线程之间使用管道通信，每一个工作线程都会创建一个管道，然后保存写端和读端，并且将读端加入event loop，监听可读事件。同时，每个从线程都有一个就绪连接队列，主线程连接连接后，将连接的item放入这个队列，然后往该线程的管道的写端写入一个connect命令，这样event loop中加入的管道读端就会就绪，从线程读取命令，解析命令发现是有连接，然后就会去自己的就绪队列中获取连接，并进行处理。多线程的优势就是可以充分发挥多核的优势，不过编写程序麻烦一点，memcached里面就有各种锁和条件变量来进行线程同步。 4. 内存分配memcached和redis的核心任务都是在内存中操作数据，内存管理自然是核心的内容。首先看看他们的内存分配方式。memcached是有自己得内存池的，即预先分配一大块内存，然后接下来分配内存就从内存池中分配，这样可以减少内存分配的次数，提高效率，这也是大部分网络服务器的实现方式，只不过各个内存池的管理方式根据具体情况而不同。而redis没有自己得内存池，而是直接使用时分配，即什么时候需要什么时候分配，内存管理的事交给内核，自己只负责取和释放（redis既是单线程，又没有自己的内存池，是不是感觉实现的太简单了？那是因为它的重点都放在数据库模块了）。不过redis支持使用tcmalloc来替换glibc的malloc，前者是google的产品，比glibc的malloc快。 由于redis没有自己的内存池，所以内存申请和释放的管理就简单很多，直接malloc和free即可，十分方便。而memcached是支持内存池的，所以内存申请是从内存池中获取，而free也是还给内存池，所以需要很多额外的管理操作，实现起来麻烦很多，具体的会在后面memcached的slab机制讲解中分析。 5. 数据库实现接下来看看他们的最核心内容，各自数据库的实现。 5.1 memcached数据库实现memcached只支持key-value，即只能一个key对于一个value。它的数据在内存中也是这样以key-value对的方式存储，它使用slab机制。 首先看memcached是如何存储数据的，即存储key-value对。如下图，每一个key-value对都存储在一个item结构中，包含了相关的属性和key和value的值。 item是保存key-value对的，当item多的时候，怎么查找特定的item是个问题。所以memcached维护了一个hash表，它用于快速查找item。hash表适用开链法（与redis一样）解决键的冲突，每一个hash表的桶里面存储了一个链表，链表节点就是item的指针，如上图中的h_next就是指桶里面的链表的下一个节点。 hash表支持扩容（item的数量是桶的数量的1.5以上时扩容），有一个primary_hashtable，还有一个old_hashtable，其中正常适用primary_hashtable，但是扩容的时候，将old_hashtable = primary_hashtable，然后primary_hashtable设置为新申请的hash表（桶的数量乘以2），然后依次将old_hashtable 里面的数据往新的hash表里面移动，并用一个变量expand_bucket记录以及移动了多少个桶，移动完成后，再free原来的old_hashtable 即可（redis也是有两个hash表，也是移动，不过不是后台线程完成，而是每次移动一个桶）。扩容的操作，专门有一个后台扩容的线程来完成，需要扩容的时候，使用条件变量通知它，完成扩容后，它又考试阻塞等待扩容的条件变量。这样在扩容的时候，查找一个item可能会在primary_hashtable和old_hashtable的任意一个中，需要根据比较它的桶的位置和expand_bucket的大小来比较确定它在哪个表里。 item是从哪里分配的呢？从slab中。如下图，memcached有很多slabclass，它们管理slab，每一个slab其实是trunk的集合，真正的item是在trunk中分配的，一个trunk分配一个item。一个slab中的trunk的大小一样，不同的slab，trunk的大小按比例递增，需要新申请一个item的时候，根据它的大小来选择trunk，规则是比它大的最小的那个trunk。这样，不同大小的item就分配在不同的slab中，归不同的slabclass管理。 这样的缺点是会有部分内存浪费，因为一个trunk可能比item大，如图2，分配100B的item的时候，选择112的trunk，但是会有12B的浪费，这部分内存资源没有使用。 如上图，整个构造就是这样，slabclass管理slab，一个slabclass有一个slab_list，可以管理多个slab，同一个slabclass中的slab的trunk大小都一样。slabclass有一个指针slot，保存了未分配的item已经被free掉的item（不是真的free内存，只是不用了而已），有item不用的时候，就放入slot的头部，这样每次需要在当前slab中分配item的时候，直接取slot取即可，不用管item是未分配过的还是被释放掉的。 然后，每一个slabclass对应一个链表，有head数组和tail数组，它们分别保存了链表的头节点和尾节点。链表中的节点就是改slabclass所分配的item，新分配的放在头部，链表越往后的item，表示它已经很久没有被使用了。当slabclass的内存不足，需要删除一些过期item的时候，就可以从链表的尾部开始删除，没错，这个链表就是为了实现LRU。光靠它还不行，因为链表的查询是O（n）的，所以定位item的时候，使用hash表，这已经有了，所有分配的item已经在hash表中了，所以，hash用于查找item，然后链表有用存储item的最近使用顺序，这也是lru的标准实现方法。 每次需要新分配item的时候，找到slabclass对于的链表，从尾部往前找，看item是否已经过期，过期的话，直接就用这个过期的item当做新的item。没有过期的，则需要从slab中分配trunk，如果slab用完了，则需要往slabclass中添加slab了。 memcached支持设置过期时间，即expire time，但是内部并不定期检查数据是否过期，而是客户进程使用该数据的时候，memcached会检查expire time，如果过期，直接返回错误。这样的优点是，不需要额外的cpu来进行expire time的检查，缺点是有可能过期数据很久不被使用，则一直没有被释放，占用内存。 memcached是多线程的，而且只维护了一个数据库，所以可能有多个客户进程操作同一个数据，这就有可能产生问题。比如，A已经把数据更改了，然后B也更改了改数据，那么A的操作就被覆盖了，而可能A不知道，A任务数据现在的状态时他改完后的那个值，这样就可能产生问题。为了解决这个问题，memcached使用了CAS协议，简单说就是item保存一个64位的unsigned int值，标记数据的版本，每更新一次（数据值有修改），版本号增加，然后每次对数据进行更改操作，需要比对客户进程传来的版本号和服务器这边item的版本号是否一致，一致则可进行更改操作，否则提示脏数据。 以上就是memcached如何实现一个key-value的数据库的介绍。 5.2 redis数据库实现首先redis数据库的功能强大一些，因为不像memcached只支持保存字符串，redis支持string， list， set，sorted set，hash table 5种数据结构。例如存储一个人的信息就可以使用hash table，用人的名字做key，然后name super， age 24， 通过key 和 name，就可以取到名字super，或者通过key和age，就可以取到年龄24。这样，当只需要取得age的时候，不需要把人的整个信息取回来，然后从里面找age，直接获取age即可，高效方便。 为了实现这些数据结构，redis定义了抽象的对象redis object，如下图。每一个对象有类型，一共5种：字符串，链表，集合，有序集合，哈希表。 同时，为了提高效率，redis为每种类型准备了多种实现方式，根据特定的场景来选择合适的实现方式，encoding就是表示对象的实现方式的。然后还有记录了对象的lru，即上次被访问的时间，同时在redis 服务器中会记录一个当前的时间（近似值，因为这个时间只是每隔一定时间，服务器进行自动维护的时候才更新），它们两个只差就可以计算出对象多久没有被访问了。 然后redis object中还有引用计数，这是为了共享对象，然后确定对象的删除时间用的。最后使用一个void*指针来指向对象的真正内容。正式由于使用了抽象redis object，使得数据库操作数据时方便很多，全部统一使用redis object对象即可，需要区分对象类型的时候，再根据type来判断。而且正式由于采用了这种面向对象的方法，让redis的代码看起来很像c++代码，其实全是用c写的。 1234567891011121314151617181920212223242526//#define REDIS_STRING 0 // 字符串类型//#define REDIS_LIST 1 // 链表类型//#define REDIS_SET 2 // 集合类型(无序的)，可以求差集，并集等//#define REDIS_ZSET 3 // 有序的集合类型//#define REDIS_HASH 4 // 哈希类型//#define REDIS_ENCODING_RAW 0 /* Raw representation */ //raw 未加工//#define REDIS_ENCODING_INT 1 /* Encoded as integer *///#define REDIS_ENCODING_HT 2 /* Encoded as hash table *///#define REDIS_ENCODING_ZIPMAP 3 /* Encoded as zipmap *///#define REDIS_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list *///#define REDIS_ENCODING_ZIPLIST 5 /* Encoded as ziplist *///#define REDIS_ENCODING_INTSET 6 /* Encoded as intset *///#define REDIS_ENCODING_SKIPLIST 7 /* Encoded as skiplist *///#define REDIS_ENCODING_EMBSTR 8 /* Embedded sds string encoding */typedef struct redisObject &#123; unsigned type:4; // 对象的类型，包括 /* Object types */unsigned encoding:4; // 底部为了节省空间，一种type的数据， // 可以采用不同的存储方式unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */int refcount; // 引用计数void *ptr;&#125; robj; 说到底redis还是一个key-value的数据库，不管它支持多少种数据结构，最终存储的还是以key-value的方式，只不过value可以是链表，set，sorted set，hash table等。和memcached一样，所有的key都是string，而set，sorted set，hash table等具体存储的时候也用到了string。 而c没有现成的string，所以redis的首要任务就是实现一个string，取名叫sds（simple dynamic string），如下的代码， 非常简单的一个结构体，len存储改string的内存总长度，free表示还有多少字节没有使用，而buf存储具体的数据，显然len-free就是目前字符串的长度。 12345struct sdshdr &#123; int len; int free; char buf[];&#125;; 字符串解决了，所有的key都存成sds就行了，那么key和value怎么关联呢？key-value的格式在脚本语言中很好处理，直接使用字典即可，C没有字典，怎么办呢？自己写一个呗（redis十分热衷于造轮子）。看下面的代码，privdata存额外信息，用的很少，至少我们发现。 dictht是具体的哈希表，一个dict对应两张哈希表，这是为了扩容（包括rehashidx也是为了扩容）。dictType存储了哈希表的属性。redis还为dict实现了迭代器（所以说看起来像c++代码）。 哈希表的具体实现是和mc类似的做法，也是使用开链法来解决冲突，不过里面用到了一些小技巧。比如使用dictType存储函数指针，可以动态配置桶里面元素的操作方法。又比如dictht中保存的sizemask取size（桶的数量）-1，用它与key做&amp;操作来代替取余运算，加快速度等等。总的来看，dict里面有两个哈希表，每个哈希表的桶里面存储dictEntry链表，dictEntry存储具体的key和value。 前面说过，一个dict对于两个dictht，是为了扩容（其实还有缩容）。正常的时候，dict只使用dictht[0]，当dict[0]中已有entry的数量与桶的数量达到一定的比例后，就会触发扩容和缩容操作，我们统称为rehash，这时，为dictht[1]申请rehash后的大小的内存，然后把dictht[0]里的数据往dictht[1]里面移动，并用rehashidx记录当前已经移动万的桶的数量，当所有桶都移完后，rehash完成，这时将dictht[1]变成dictht[0], 将原来的dictht[0]变成dictht[1]，并变为null即可。不同于memcached，这里不用开一个后台线程来做，而是就在event loop中完成，并且rehash不是一次性完成，而是分成多次，每次用户操作dict之前，redis移动一个桶的数据，直到rehash完成。这样就把移动分成多个小移动完成，把rehash的时间开销均分到用户每个操作上，这样避免了用户一个请求导致rehash的时候，需要等待很长时间，直到rehash完成才有返回的情况。不过在rehash期间，每个操作都变慢了点，而且用户还不知道redis在他的请求中间添加了移动数据的操作，感觉redis太贱了 :-D 123456789101112131415161718192021222324252627282930313233typedef struct dict &#123; dictType *type; // 哈希表的相关属性void *privdata; // 额外信息 dictht ht[2]; // 两张哈希表，分主和副，用于扩容int rehashidx; /* rehashing not in progress if rehashidx == -1 */ // 记录当前数据迁移的位置，在扩容的时候用的int iterators; /* number of iterators currently running */ // 目前存在的迭代器的数量&#125; dict;typedef struct dictht &#123; dictEntry **table; // dictEntry是item，多个item组成hash桶里面的链表，table则是多个链表头指针组成的数组的指针unsigned long size; // 这个就是桶的数量 // sizemask取size - 1, 然后一个数据来的时候，通过计算出的hashkey, 让hashkey &amp; sizemask来确定它要放的桶的位置 // 当size取2^n的时候，sizemask就是1...111，这样就和hashkey % size有一样的效果，但是使用&amp;会快很多。这就是原因unsigned long sizemask; unsigned long used; // 已经数值的dictEntry数量&#125; dictht;typedef struct dictType &#123; unsigned int (*hashFunction)(const void *key); // hash的方法void *(*keyDup)(void *privdata, const void *key); // key的复制方法void *(*valDup)(void *privdata, const void *obj); // value的复制方法int (*keyCompare)(void *privdata, const void *key1, const void *key2); // key之间的比较void (*keyDestructor)(void *privdata, void *key); // key的析构void (*valDestructor)(void *privdata, void *obj); // value的析构&#125; dictType;typedef struct dictEntry &#123; void *key; union &#123; void *val; uint64_t u64; int64_t s64; &#125; v; struct dictEntry *next;&#125; dictEntry; 有了dict，数据库就好实现了。所有数据读存储在dict中，key存储成dictEntry中的key（string），用void* 指向一个redis object，它可以是5种类型中的任何一种。如下图，结构构造是这样，不过这个图已经过时了，有一些与redis3.0不符合的地方。 五种type的对象，每一个都至少有两种底层实现方式。string有3种：REDIS_ENCODING_RAW, REDIS_ENCIDING_INT, REDIS_ENCODING_EMBSTR， list有：普通双向链表和压缩链表，压缩链表简单的说，就是讲数组改造成链表，连续的空间，然后通过存储字符串的大小信息来模拟链表，相对普通链表来说可以节省空间，不过有副作用，由于是连续的空间，所以改变内存大小的时候，需要重新分配，并且由于保存了字符串的字节大小，所有有可能引起连续更新（具体实现请详细看代码）。set有dict和intset（全是整数的时候使用它来存储）， sorted set有：skiplist和ziplist， hashtable实现有压缩列表和dict和ziplist。skiplist就是跳表，它有接近于红黑树的效率，但是实现起来比红黑树简单很多，所以被采用（奇怪，这里又不造轮子了，难道因为这个轮子有点难？）。 hash table可以使用dict实现，则改dict中，每个dictentry中key保存了key（这是哈希表中的键值对的key），而value则保存了value，它们都是string。 而set中的dict，每个dictentry中key保存了set中具体的一个元素的值，value则为null。图中的zset（有序集合）有误，zset使用skiplist和ziplist实现，首先skiplist很好理解，就把它当做红黑树的替代品就行，和红黑树一样，它也可以排序。怎么用ziplist存储zset呢？首先在zset中，每个set中的元素都有一个分值score，用它来排序。所以在ziplist中，按照分值大小，先存元素，再存它的score，再存下一个元素，然后score。这样连续存储，所以插入或者删除的时候，都需要重新分配内存。所以当元素超过一定数量，或者某个元素的字符数超过一定数量，redis就会选择使用skiplist来实现zset（如果当前使用的是ziplist，会将这个ziplist中的数据取出，存入一个新的skiplist，然后删除改ziplist，这就是底层实现转换，其余类型的redis object也是可以转换的）。 另外，ziplist如何实现hashtable呢？其实也很简单，就是存储一个key，存储一个value，再存储一个key，再存储一个value。还是顺序存储，与zset实现类似，所以当元素超过一定数量，或者某个元素的字符数超过一定数量时，就会转换成hashtable来实现。各种底层实现方式是可以转换的，redis可以根据情况选择最合适的实现方式，这也是这样使用类似面向对象的实现方式的好处。 需要指出的是，使用skiplist来实现zset的时候，其实还用了一个dict，这个dict存储一样的键值对。为什么呢？因为skiplist的查找只是lgn的（可能变成n），而dict可以到O(1)， 所以使用一个dict来加速查找，由于skiplist和dict可以指向同一个redis object，所以不会浪费太多内存。另外使用ziplist实现zset的时候，为什么不用dict来加速查找呢？因为ziplist支持的元素个数很少（个数多时就转换成skiplist了），顺序遍历也很快，所以不用dict了。 这样看来，上面的dict，dictType，dictHt，dictEntry，redis object都是很有考量的，它们配合实现了一个具有面向对象色彩的灵活、高效数据库。不得不说，redis数据库的设计还是很厉害的。 与memcached不同的是，redis的数据库不止一个，默认就有16个，编号0-15。客户可以选择使用哪一个数据库，默认使用0号数据库。 不同的数据库数据不共享，即在不同的数据库中可以存在同样的key，但是在同一个数据库中，key必须是唯一的。 redis也支持expire time的设置，我们看上面的redis object，里面没有保存expire的字段，那redis怎么记录数据的expire time呢？ redis是为每个数据库又增加了一个dict，这个dict叫expire dict，它里面的dict entry里面的key就是数对的key，而value全是数据为64位int的redis object，这个int就是expire time。这样，判断一个key是否过期的时候，去expire dict里面找到它，取出expire time比对当前时间即可。为什么这样做呢？ 因为并不是所有的key都会设置过期时间，所以，对于不设置expire time的key来说，保存一个expire time会浪费空间，而是用expire dict来单独保存的话，可以根据需要灵活使用内存（检测到key过期时，会把它从expire dict中删除）。 redis的expire 机制是怎样的呢？ 与memcahed类似，redis也是惰性删除，即要用到数据时，先检查key是否过期，过期则删除，然后返回错误。单纯的靠惰性删除，上面说过可能会导致内存浪费，所以redis也有补充方案，redis里面有个定时执行的函数，叫servercron，它是维护服务器的函数，在它里面，会对过期数据进行删除，注意不是全删，而是在一定的时间内，对每个数据库的expire dict里面的数据随机选取出来，如果过期，则删除，否则再选，直到规定的时间到。即随机选取过期的数据删除，这个操作的时间分两种，一种较长，一种较短，一般执行短时间的删除，每隔一定的时间，执行一次长时间的删除。这样可以有效的缓解光采用惰性删除而导致的内存浪费问题。 以上就是redis的数据的实现，与memcached不同，redis还支持数据持久化，这个下面介绍。 5.4 redis数据库持久化redis和memcached的最大不同，就是redis支持数据持久化，这也是很多人选择使用redis而不是memcached的最大原因。 redis的持久化，分为两种策略，用户可以配置使用不同的策略。 5.4.1 RDB持久化用户执行save或者bgsave的时候，就会触发RDB持久化操作。RDB持久化操作的核心思想就是把数据库原封不动的保存在文件里。 那如何存储呢？如下图， 首先存储一个REDIS字符串，起到验证的作用，表示是RDB文件，然后保存redis的版本信息，然后是具体的数据库，然后存储结束符EOF，最后用检验和。关键就是databases，看它的名字也知道，它存储了多个数据库，数据库按照编号顺序存储，0号数据库存储完了，才轮到1，然后是2, 一直到最后一个数据库。 每一个数据库存储方式如下，首先一个1字节的常量SELECTDB，表示切换db了，然后下一个接上数据库的编号，它的长度是可变的，然后接下来就是具体的key-value对的数据了。 1234567891011121314int rdbSaveKeyValuePair(rio *rdb, robj *key, robj *val, long long expiretime, long long now)&#123; /* Save the expire time */if (expiretime != -1) &#123; /* If this key is already expired skip it */if (expiretime &lt; now) return 0; if (rdbSaveType(rdb,REDIS_RDB_OPCODE_EXPIRETIME_MS) == -1) return -1; if (rdbSaveMillisecondTime(rdb,expiretime) == -1) return -1; &#125; /* Save type, key, value */if (rdbSaveObjectType(rdb,val) == -1) return -1; if (rdbSaveStringObject(rdb,key) == -1) return -1; if (rdbSaveObject(rdb,val) == -1) return -1; return 1;&#125; 由上面的代码也可以看出，存储的时候，先检查expire time，如果已经过期，不存就行了，否则，则将expire time存下来，注意，及时是存储expire time，也是先存储它的类型为REDIS_RDB_OPCODE_EXPIRETIME_MS，然后再存储具体过期时间。接下来存储真正的key-value对，首先存储value的类型，然后存储key（它按照字符串存储），然后存储value，如下图。 在rdbsaveobject中，会根据val的不同类型，按照不同的方式存储，不过从根本上来看，最终都是转换成字符串存储，比如val是一个linklist，那么先存储整个list的字节数，然后遍历这个list，把数据取出来，依次按照string写入文件。对于hash table，也是先计算字节数，然后依次取出hash table中的dictEntry，按照string的方式存储它的key和value，然后存储下一个dictEntry。 总之，RDB的存储方式，对一个key-value对，会先存储expire time（如果有的话），然后是value的类型，然后存储key（字符串方式），然后根据value的类型和底层实现方式，将value转换成字符串存储。这里面为了实现数据压缩，以及能够根据文件恢复数据，redis使用了很多编码的技巧，有些我也没太看懂，不过关键还是要理解思想，不要在意这些细节。 保存了RDB文件，当redis再启动的时候，就根据RDB文件来恢复数据库。由于以及在RDB文件中保存了数据库的号码，以及它包含的key-value对，以及每个key-value对中value的具体类型，实现方式，和数据，redis只要顺序读取文件，然后恢复object即可。由于保存了expire time，发现当前的时间已经比expire time大了，即数据已经超时了，则不恢复这个key-value对即可。 保存RDB文件是一个很巨大的工程，所以redis还提供后台保存的机制。即执行bgsave的时候，redis fork出一个子进程，让子进程来执行保存的工作，而父进程继续提供redis正常的数据库服务。由于子进程复制了父进程的地址空间，即子进程拥有父进程fork时的数据库，子进程执行save的操作，把它从父进程那儿继承来的数据库写入一个temp文件即可。在子进程复制期间，redis会记录数据库的修改次数（dirty）。当子进程完成时，发送给父进程SIGUSR1信号，父进程捕捉到这个信号，就知道子进程完成了复制，然后父进程将子进程保存的temp文件改名为真正的rdb文件（即真正保存成功了才改成目标文件，这才是保险的做法）。然后记录下这一次save的结束时间。 这里有一个问题，在子进程保存期间，父进程的数据库已经被修改了，而父进程只是记录了修改的次数（dirty），被没有进行修正操作。似乎使得RDB保存的不是实时的数据库，有点不太高大上的样子。 不过后面要介绍的AOF持久化，就解决了这个问题。 除了客户执行sava或者bgsave命令，还可以配置RDB保存条件。即在配置文件中配置，在t时间内，数据库被修改了dirty次，则进行后台保存。redis在serve cron的时候，会根据dirty数目和上次保存的时间，来判断是否符合条件，符合条件的话，就进行bg save，注意，任意时刻只能有一个子进程来进行后台保存，因为保存是个很费io的操作，多个进程大量io效率不行，而且不好管理。 5.4.2 AOF持久化 首先想一个问题，保存数据库一定需要像RDB那样把数据库里面的所有数据保存下来么？有没有别的方法？ RDB保存的只是最终的数据库，它是一个结果。结果是怎么来的？是通过用户的各个命令建立起来的，所以可以不保存结果，而只保存建立这个结果的命令。 redis的AOF就是这个思想，它不同RDB保存db的数据，它保存的是一条一条建立数据库的命令。 我们首先来看AOF文件的格式，它里面保存的是一条一条的命令，首先存储命令长度，然后存储命令，具体的分隔符什么的可以自己深入研究，这都不是重点，反正知道AOF文件存储的是redis客户端执行的命令即可。 redis server中有一个sds aof_buf, 如果aof持久化打开的话，每个修改数据库的命令都会存入这个aof_buf（保存的是aof文件中命令格式的字符串），然后event loop没循环一次，在server cron中调用flushaofbuf，把aof_buf中的命令写入aof文件（其实是write，真正写入的是内核缓冲区），再清空aof_buf，进入下一次loop。这样所有的数据库的变化，都可以通过aof文件中的命令来还原，达到了保存数据库的效果。 需要注意的是，flushaofbuf中调用的write，它只是把数据写入了内核缓冲区，真正写入文件时内核自己决定的，可能需要延后一段时间。 不过redis支持配置，可以配置每次写入后sync，则在redis里面调用sync，将内核中的数据写入文件，这不过这要耗费一次系统调用，耗费时间而已。还可以配置策略为1秒钟sync一次，则redis会开启一个后台线程（所以说redis不是单线程，只是单eventloop而已），这个后台线程会每一秒调用一次sync。这里要问了，RDB的时候为什么没有考虑sync的事情呢？因为RDB是一次性存储的，不像AOF这样多次存储，RDB的时候调用一次sync也没什么影响，而且使用bg save的时候，子进程会自己退出（exit），这时候exit函数内会冲刷缓冲区，自动就写入了文件中。 再来看，如果不想使用aof_buf保存每次的修改命令，也可以使用aof持久化。redis提供aof_rewrite，即根据现有的数据库生成命令，然后把命令写入aof文件中。很奇特吧？对，就是这么厉害。进行aof_rewrite的时候，redis变量每个数据库，然后根据key-value对中value的具体类型，生成不同的命令，比如是list，则它生成一个保存list的命令，这个命令里包含了保存该list所需要的的数据，如果这个list数据过长，还会分成多条命令，先创建这个list，然后往list里面添加元素，总之，就是根据数据反向生成保存数据的命令。然后将这些命令存储aof文件，这样不就和aof append达到同样的效果了么？ aof格式也支持后台模式。执行aof_bgrewrite的时候，也是fork一个子进程，然后让子进程进行aof_rewrite，把它复制的数据库写入一个临时文件，然后写完后用新号通知父进程。父进程判断子进程的退出信息是否正确，然后将临时文件更名成最终的aof文件。好了，问题来了。在子进程持久化期间，可能父进程的数据库有更新，怎么把这个更新通知子进程呢？难道要用进程间通信么？是不是有点麻烦呢？你猜redis怎么做的？它根本不通知子进程。什么，不通知？那更新怎么办？ 在子进程执行aof_bgrewrite期间，父进程会保存所有对数据库有更改的操作的命令（增，删除，改等），把他们保存在aof_rewrite_buf_blocks中，这是一个链表，每个block都可以保存命令，存不下时，新申请block，然后放入链表后面即可，当子进程通知完成保存后，父进程将aof_rewrite_buf_blocks的命令append 进aof文件就可以了。多么优美的设计，想一想自己当初还考虑用进程间通信，别人直接用最简单的方法就完美的解决了问题，有句话说得真对，越优秀的设计越趋于简单，而复杂的东西往往都是靠不住的。 至于aof文件的载入，也就是一条一条的执行aof文件里面的命令而已。不过考虑到这些命令就是客户端发送给redis的命令，所以redis干脆生成了一个假的客户端，它没有和redis建立网络连接，而是直接执行命令即可。首先搞清楚，这里的假的客户端，并不是真正的客户端，而是存储在redis里面的客户端的信息，里面有写和读的缓冲区，它是存在于redis服务器中的。所以，如下图，直接读入aof的命令，放入客户端的读缓冲区中，然后执行这个客户端的命令即可。这样就完成了aof文件的载入。 123456789101112// 创建伪客户端fakeClient = createFakeClient();while(命令不为空) &#123; // 获取一条命令的参数信息 argc， argv ... // 执行 fakeClient-&gt;argc = argc; fakeClient-&gt;argv = argv; cmd-&gt;proc(fakeClient);&#125; 整个aof持久化的设计，个人认为相当精彩。其中有很多地方，值得膜拜。 5.5 redis的事务 redis另一个比memcached强大的地方，是它支持简单的事务。事务简单说就是把几个命令合并，一次性执行全部命令。对于关系型数据库来说，事务还有回滚机制，即事务命令要么全部执行成功，只要有一条失败就回滚，回到事务执行前的状态。redis不支持回滚，它的事务只保证命令依次被执行，即使中间一条命令出错也会继续往下执行，所以说它只支持简单的事务。 首先看redis事务的执行过程。首先执行multi命令，表示开始事务，然后输入需要执行的命令，最后输入exec执行事务。 redis服务器收到multi命令后，会将对应的client的状态设置为REDIS_MULTI，表示client处于事务阶段，并在client的multiState结构体里面保持事务的命令具体信息（当然首先也会检查命令是否能否识别，错误的命令不会保存），即命令的个数和具体的各个命令，当收到exec命令后，redis会顺序执行multiState里面保存的命令，然后保存每个命令的返回值，当有命令发生错误的时候，redis不会停止事务，而是保存错误信息，然后继续往下执行，当所有的命令都执行完后，将所有命令的返回值一起返回给客户。redis为什么不支持回滚呢？网上看到的解释出现问题是由于客户程序的问题，所以没必要服务器回滚，同时，不支持回滚，redis服务器的运行高效很多。在我看来，redis的事务不是传统关系型数据库的事务，要求CIAD那么非常严格，或者说redis的事务都不是事务，只是提供了一种方式，使得客户端可以一次性执行多条命令而已，就把事务当做普通命令就行了，支持回滚也就没必要了。 我们知道redis是单event loop的，在真正执行一个事物的时候（即redis收到exec命令后），事物的执行过程是不会被打断的，所有命令都会在一个event loop中执行完。但是在用户逐个输入事务的命令的时候，这期间，可能已经有别的客户修改了事务里面用到的数据，这就可能产生问题。所以redis还提供了watch命令，用户可以在输入multi之前，执行watch命令，指定需要观察的数据，这样如果在exec之前，有其他的客户端修改了这些被watch的数据，则exec的时候，执行到处理被修改的数据的命令的时候，会执行失败，提示数据已经dirty。 这是如何是实现的呢？ 原来在每一个redisDb中还有一个dict watched_keys，watched_kesy中dictentry的key是被watch的数据库的key，而value则是一个list，里面存储的是watch它的client。同时，每个client也有一个watched_keys，里面保存的是这个client当前watch的key。在执行watch的时候，redis在对应的数据库的watched_keys中找到这个key（如果没有，则新建一个dictentry），然后在它的客户列表中加入这个client，同时，往这个client的watched_keys中加入这个key。当有客户执行一个命令修改数据的时候，redis首先在watched_keys中找这个key，如果发现有它，证明有client在watch它，则遍历所有watch它的client，将这些client设置为REDIS_DIRTY_CAS，表面有watch的key被dirty了。当客户执行的事务的时候，首先会检查是否被设置了REDIS_DIRTY_CAS，如果是，则表明数据dirty了，事务无法执行，会立即返回错误，只有client没有被设置REDIS_DIRTY_CAS的时候才能够执行事务。 需要指出的是，执行exec后，该client的所有watch的key都会被清除，同时db中该key的client列表也会清除该client，即执行exec后，该client不再watch任何key（即使exec没有执行成功也是一样）。所以说redis的事务是简单的事务，算不上真正的事务。 以上就是redis的事务，感觉实现很简单，实际用处也不是太大。 5.6 redis的发布订阅频道 redis支持频道，即加入一个频道的用户相当于加入了一个群，客户往频道里面发的信息，频道里的所有client都能收到。 实现也很简单，也watch_keys实现差不多，redis server中保存了一个pubsub_channels的dict，里面的key是频道的名称（显然要唯一了），value则是一个链表，保存加入了该频道的client。同时，每个client都有一个pubsub_channels，保存了自己关注的频道。当用用户往频道发消息的时候，首先在server中的pubsub_channels找到改频道，然后遍历client，给他们发消息。而订阅，取消订阅频道不够都是操作pubsub_channels而已，很好理解。 同时，redis还支持模式频道。即通过正则匹配频道，如有模式频道p, 1, 则向普通频道p1发送消息时，会匹配p，1，除了往普通频道发消息外，还会往p，1模式频道中的client发消息。注意，这里是用发布命令里面的普通频道来匹配已有的模式频道，而不是在发布命令里制定模式频道，然后匹配redis里面保存的频道。实现方式也很简单，在redis server里面有个pubsub_patterns的list（这里为什么不用dict？因为pubsub_patterns的个数一般较少，不需要使用dict，简单的list就好了），它里面存储的是pubsubPattern结构体，里面是模式和client信息，如下所示，一个模式，一个client，所以如果有多个clint监听一个pubsub_patterns的话，在list面会有多个pubsubPattern，保存client和pubsub_patterns的对应关系。 同时，在client里面，也有一个pubsub_patterns list，不过里面存储的就是它监听的pubsub_patterns的列表（就是sds），而不是pubsubPattern结构体。 1234typedef struct pubsubPattern &#123; redisClient *client; // 监听的client robj *pattern; // 模式&#125; pubsubPattern; 当用户往一个频道发送消息的时候，首先会在redis server中的pubsub_channels里面查找该频道，然后往它的客户列表发送消息。然后在redis server里面的pubsub_patterns里面查找匹配的模式，然后往client里面发送消息。 这里并没有去除重复的客户，在pubsub_channels可能已经给某一个client发过message了，然后在pubsub_patterns中可能还会给用户再发一次（甚至更多次）。 估计redis认为这是客户程序自己的问题，所以不处理。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/* Publish a message */int pubsubPublishMessage(robj *channel, robj *message) &#123; int receivers = 0; dictEntry *de; listNode *ln; listIter li; /* Send to clients listening for that channel */ de = dictFind(server.pubsub_channels,channel); if (de) &#123; list *list = dictGetVal(de); listNode *ln; listIter li; listRewind(list,&amp;li); while ((ln = listNext(&amp;li)) != NULL) &#123; redisClient *c = ln-&gt;value; addReply(c,shared.mbulkhdr[3]); addReply(c,shared.messagebulk); addReplyBulk(c,channel); addReplyBulk(c,message); receivers++; &#125; &#125; /* Send to clients listening to matching channels */if (listLength(server.pubsub_patterns)) &#123; listRewind(server.pubsub_patterns,&amp;li); channel = getDecodedObject(channel); while ((ln = listNext(&amp;li)) != NULL) &#123; pubsubPattern *pat = ln-&gt;value; if (stringmatchlen((char*)pat-&gt;pattern-&gt;ptr, sdslen(pat-&gt;pattern-&gt;ptr), (char*)channel-&gt;ptr, sdslen(channel-&gt;ptr),0)) &#123; addReply(pat-&gt;client,shared.mbulkhdr[4]); addReply(pat-&gt;client,shared.pmessagebulk); addReplyBulk(pat-&gt;client,pat-&gt;pattern); addReplyBulk(pat-&gt;client,channel); addReplyBulk(pat-&gt;client,message); receivers++; &#125; &#125; decrRefCount(channel); &#125; return receivers;&#125; 6. 总结总的来看，redis比memcached的功能多很多，实现也更复杂。 不过memcached更专注于保存key-value数据（这已经能满足大多数使用场景了），而redis提供更丰富的数据结构及其他的一些功能。不能说redis比memcached好，不过从源码阅读的角度来看，redis的价值或许更大一点。","categories":[{"name":"缓存","slug":"缓存","permalink":"https://vincentruan.github.io/categories/缓存/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://vincentruan.github.io/tags/redis/"},{"name":"memcached","slug":"memcached","permalink":"https://vincentruan.github.io/tags/memcached/"}]},{"title":"[转载]从零开始：史上最详尽V2Ray搭建图文教程","slug":"转载-从零开始：史上最详尽V2Ray搭建图文教程","date":"2019-12-22T09:05:18.000Z","updated":"2020-02-25T15:09:15.073Z","comments":true,"path":"2019/12/22/转载-从零开始：史上最详尽V2Ray搭建图文教程/","link":"","permalink":"https://vincentruan.github.io/2019/12/22/转载-从零开始：史上最详尽V2Ray搭建图文教程/","excerpt":"本文转载自从零开始：史上最详尽V2Ray搭建图文教程，根据实际服务器配置做部分修改。 一、服务端安装以下所有操作都是使用root用户（普通用户自行sudo）进行操作的，服务器centos7。","text":"本文转载自从零开始：史上最详尽V2Ray搭建图文教程，根据实际服务器配置做部分修改。 一、服务端安装以下所有操作都是使用root用户（普通用户自行sudo）进行操作的，服务器centos7。 1.安装wget 如提示没有安装wget，在登录完成的窗口输入下面命令并回车进行wget安装： 1yum -y install wget 2.下载脚本 安装完wget之后就可以进行下载安装v2ray的脚本了，输入如下命令并回车： 1wget https://install.direct/go.sh 3.安装unzip 因为centos不支持apt-get，我们需要安装unzip，详见官方说明： 1yum install -y zip unzip 4.执行安装 输入下面的命令并回车执行安装 123456789101112131415161718192021222324252627[michael@centos74 v2ray]$ bash go.sh Installing V2Ray v3.14 on x86_64Downloading V2Ray. % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 608 0 608 0 0 2229 0 --:--:-- --:--:-- --:--:-- 2235100 8482k 100 8482k 0 0 2501k 0 0:00:03 0:00:03 --:--:-- 2813kExtracting V2Ray package to /tmp/v2ray.Archive: /tmp/v2ray/v2ray.zip creating: /tmp/v2ray/v2ray-v3.14-linux-64/ inflating: /tmp/v2ray/v2ray-v3.14-linux-64/geoip.dat inflating: /tmp/v2ray/v2ray-v3.14-linux-64/geosite.dat inflating: /tmp/v2ray/v2ray-v3.14-linux-64/readme.md creating: /tmp/v2ray/v2ray-v3.14-linux-64/systemd/ inflating: /tmp/v2ray/v2ray-v3.14-linux-64/systemd/v2ray.service creating: /tmp/v2ray/v2ray-v3.14-linux-64/systemv/ inflating: /tmp/v2ray/v2ray-v3.14-linux-64/systemv/v2ray inflating: /tmp/v2ray/v2ray-v3.14-linux-64/v2ctl extracting: /tmp/v2ray/v2ray-v3.14-linux-64/v2ctl.sig inflating: /tmp/v2ray/v2ray-v3.14-linux-64/v2ray extracting: /tmp/v2ray/v2ray-v3.14-linux-64/v2ray.sig inflating: /tmp/v2ray/v2ray-v3.14-linux-64/vpoint_socks_vmess.json inflating: /tmp/v2ray/v2ray-v3.14-linux-64/vpoint_vmess_freedom.json PORT:13437UUID:f500ecf5-e135-49c6-9ce2-78eb490d0aa9Created symlink from /etc/systemd/system/multi-user.target.wants/v2ray.service to /etc/systemd/system/v2ray.service.V2Ray v3.14 is installed. 5.相关命令 在首次安装完成之后，V2Ray不会自动启动，需要手动运行上述启动命令。而在已经运行V2Ray的VPS上再次执行安装脚本，安装脚本会自动停止V2Ray 进程，升级V2Ray程序，然后自动运行V2Ray。在升级过程中，配置文件不会被修改。 1234567891011## 启动systemctl start v2ray## 停止systemctl stop v2ray## 重启systemctl restart v2ray## 开机自启systemctl enable v2ray 关于软件更新：更新 V2Ray 的方法是再次执行安装脚本！再次执行安装脚本！再次执行安装脚本！ 6.配置 如果你按照上面的命令执行安装完成之后，服务端其实是不需要再进行任何配置的，配置文件位于/etc/v2ray/config.json，使用cat /etc/v2ray/config.json查看配置信息。接下来进行客户端配置就行了。 说明： 配置文件中的id、端口、alterId需要和客户端的配置保持一致； 服务端使用脚本安装成功之后默认就是vmess协议； 配置完成之后重启v2ray。 9.防火墙开放端口 有的vps端口默认不开放，可能导致连接不成功，如果有这种情况，详细配置，见CentOs开放端口的方法—二、firewalld。部分服务器的防火墙配置只能在服务提供商的控制台操作，请注意。 12345## 查看已开放端口firewall-cmd --zone=public --list-ports## 添加开放端口firewall-cmd --zone=public --add-port=80/tcp --permanent 二、Windows 客户端1.下载 目前不支持水果系列，水果机只能自行走野路子解决。 1)下载【v2ray-windows-64.zip Github Release】;2)下载【v2rayN-v2rayN.exe-Github Release】； 对v2ray-windows-64.zip进行解压，然后将下载的V2RayN.exe复制到解压后的目录，即两个下载好的文件需要在同一目录。 2.配置 运行V2RayN.exe，然后进行配置，下图中的配置信息，需要和你VPS搭建的时候的配置信息对应，VPS的v2ray配置信息位于/etc/v2ray/config.json文件里。 如果采用上面的默认方式安装，服务端配置是协议vmess，则配置如下： 三、测试打开浏览器，访问www.google.com 四、进阶现在你已经学会使用v2ray了，为了更好的上网效果，建议继续了解一下下面文章： centos7基于nginx搭建v2ray服务端配置vmess+tls+websocket完全手册；【推荐】 使用Google BBR PLUS加速你的VPS网络； 如何以mkcp方式部署v2ray； 五、相关问题 使用v2ray访问谷歌提示异常流量； 启用cloudflare cdn之后v2ray报403错误；","categories":[],"tags":[{"name":"v2ray","slug":"v2ray","permalink":"https://vincentruan.github.io/tags/v2ray/"}]},{"title":"详解分布式协调服务 ZooKeeper","slug":"详解分布式协调服务-ZooKeeper","date":"2018-10-07T04:14:40.000Z","updated":"2020-02-25T15:09:15.072Z","comments":true,"path":"2018/10/07/详解分布式协调服务-ZooKeeper/","link":"","permalink":"https://vincentruan.github.io/2018/10/07/详解分布式协调服务-ZooKeeper/","excerpt":"这篇文章主要会介绍 Zookeeper 的实现原理以及常见的应用 在 2006 年，Google 发表了一篇名为 The Chubby lock service for loosely-coupled distributed systems 的论文，其中描述了一个分布式锁服务 Chubby 的设计理念和实现原理；作为 Google 内部的一个基础服务，虽然 Chubby 与 GFS、Bigtable 和 MapReduce 相比并没有那么大的名气，不过它在 Google 内部也是非常重要的基础设施。 相比于名不见经传的 Chubby，作者相信 Zookeeper 更被广大开发者所熟知，作为非常出名的分布式协调服务，Zookeeper 有非常多的应用，包括发布订阅、命名服务、分数是协调和分布式锁，这篇文章主要会介绍 Zookeeper 的实现原理以及常见的应用，但是在具体介绍 Zookeeper 的功能和原理之前，我们会简单介绍一下分布式锁服务 Chubby 以及它与 Zookeeper 之间的异同。","text":"这篇文章主要会介绍 Zookeeper 的实现原理以及常见的应用 在 2006 年，Google 发表了一篇名为 The Chubby lock service for loosely-coupled distributed systems 的论文，其中描述了一个分布式锁服务 Chubby 的设计理念和实现原理；作为 Google 内部的一个基础服务，虽然 Chubby 与 GFS、Bigtable 和 MapReduce 相比并没有那么大的名气，不过它在 Google 内部也是非常重要的基础设施。 相比于名不见经传的 Chubby，作者相信 Zookeeper 更被广大开发者所熟知，作为非常出名的分布式协调服务，Zookeeper 有非常多的应用，包括发布订阅、命名服务、分数是协调和分布式锁，这篇文章主要会介绍 Zookeeper 的实现原理以及常见的应用，但是在具体介绍 Zookeeper 的功能和原理之前，我们会简单介绍一下分布式锁服务 Chubby 以及它与 Zookeeper 之间的异同。 Chubby作为分布式锁服务，Chubby 的目的就是允许多个客户端对它们的行为进行同步，同时也能够解决客户端的环境相关信息的分发和粗粒度的同步问题，GFS 和 Bigtable 都使用了 Chubby 以解决主节点的选举等问题。在网络上你很难找到关于 Chubby 的相关资料，我们只能从 The Chubby lock service for loosely-coupled distributed systems 一文中窥见它的一些设计思路、技术架构等信息。 虽然 Chubby 和 Zookeeper 有着比较相似的功能，但是它们的设计理念却非常不同，Chubby 在论文的摘要中写道： We describe our experiences with the Chubby lock service, which is intended to provide coarse-grained locking as well as reliable (though low-volume) storage for a loosely-coupled distributed system. 从论文的摘要中我们可以看出 Chubby 首先被定义成一个 分布式的锁服务，它能够为分布式系统提供 松耦合、粗粒度 的分布式锁功能，然而我们并不能依赖于它来做一些重量的数据存储。 Chubby 在设计时做了两个重要的设计决定，一是提供完整、独立的分布式锁服务而非一个用于共识的库或者服务，另一个是选择提供小文件的的读写功能，使得主节点能够方便地发布自己的状态信息。 系统架构Chubby 总共由两部分组成，一部分是用于提供数据的读写接口并管理相关的配置数据的服务端，另一部分就是客户端使用的 SDK，为了提高系统的稳定性，每一个 Chubby 单元都由一组服务器组成，它会使用 共识算法 从集群中选举出主节点。 在一个 Chubby Cell 中，只有 主节点会对外提供读写服务，其他的节点其实都是当前节点的副本（Replica），它们只是维护一个数据的拷贝并会在主节点更新时对它们持有的数据库进行更新；客户端通过向副本发送请求获取主节点的位置，一旦它获取到了主节点的位置，就会向所有的读写请求发送给主节点，直到其不再响应为止。写请求都会通过一致性协议传播到所有的副本中，当集群中的多数节点都同步了请求时就会认为当前的写入已经被确认。 当主节点宕机时，副本会在其租约到期时重新进行选举，副本节点如果在宕机几小时还没有回复，那么系统就会从资源池中选择一个新的节点并在该节点上启动 Chubby 服务并更新 DNS 表。 主节点会不停地轮训 DNS 表获取集群中最新的配置，每次 DNS 表更新时，主节点都会将新的配置下发给 Chubby 集群中其他的副本节点。 Zookeeper很多人都会说 Zookeeper 是 Chubby 的一个开源实现，这其实是有问题的，它们两者只不过都提供了具有层级结构的命名空间： Chubby 和 Zookeeper 从最根本的设计理念上就有着非常明显的不同，在上文中我们已经提到了 Chubby 被设计成一个分布式的锁服务，它能够为分布式系统提供松耦合、粗粒度的分布式锁功能，然而我们并不能依赖于它来做一些重量的数据存储，而 Zookeeper 的论文在摘要中介绍到，它是一个能够为分布式系统提供协调功能的服务： In this paper, we describe ZooKeeper, a service for co- ordinating processes of distributed applications. Zookeeper 的目的是为客户端构建复杂的协调功能提供简单、高效的核心 API，相比于 Chubby 对外提供已经封装好的更上层的功能，Zookeeper 提供了更抽象的接口以便于客户端自行实现想要完成的功能。 Chubby 直接为用户提供封装好的锁和解锁的功能，内部完成了锁的实现，只是将 API 直接暴露给用户，而 Zookeeper 却需要用户自己实现分布式锁；总的来说，使用 Zookeeper 往往需要客户端做更多的事情，但是也享有更多的自由。 技术架构与 Chubby 集群中，多个节点只有一个能够对外提供服务不同，Zookeeper 集群中所有的节点都可以对外提供服务，但是集群中的节点也分为主从两种节点，所有的节点都能处理来自客户端的读请求，但是只有主节点才能处理写入操作： 这里所说的 Zookeeper 集群主从节点实际上分别是 Leader 和 Follower 节点。 客户端使用 Zookeeper 时会连接到集群中的任意节点，所有的节点都能够直接对外提供读操作，但是写操作都会被从节点路由到主节点，由主节点进行处理。 Zookeeper 在设计上提供了以下的两个基本的顺序保证，线性写和先进先出的客户端顺序： 其中线性写是指所有更新 Zookeeper 状态的请求都应该按照既定的顺序串行执行；而先进先出的客户端顺序是指，所有客户端发出的请求会按照发出的顺序执行。 Zab 协议在我们简单介绍 Zookeeper 的技术架构之后，这一节将谈及 Zookeeper 中的 Zab 协议，Zookeeper 的 Zab 协议是为了解决分布式一致性而设计出的一种协议，它的全称是 Zookeeper 原子广播协议，它能够在发生崩溃时快速恢复服务，达到高可用性。 如上一节提到的，客户端在使用 Zookeeper 服务时会随机连接到集群中的一个节点，所有的读请求都会由当前节点处理，而写请求会被路由给主节点并由主节点向其他节点广播事务，与 2PC 非常相似，如果在所有的节点中超过一半都返回成功，那么当前写请求就会被提交。 当主节点崩溃时，其他的 Replica 节点会进入崩溃恢复模式并重新进行选举，Zab 协议必须确保提交已经被 Leader 提交的事务提案，同时舍弃被跳过的提案，这也就是说当前集群中最新 ZXID 最大的服务器会被选举成为 Leader 节点；但是在正式对外提供服务之前，新的 Leader 也需要先与 Follower 中的数据进行同步，确保所有节点拥有完全相同的提案列表。 在上面提到 ZXID 其实就是 Zab 协议中设计的事务编号，它是一个 64 位的整数，其中最低的 32 位是一个计数器，每当客户端修改 Zookeeper 集群状态时，Leader 都会以当前 ZXID 值作为提案的编号创建一个新的事务，在这之后会将当前计数器加一；ZXID 中高的 32 位表示当前 Leader 的任期，每当发生崩溃进入恢复模式，集群的 Leader 重新选举之后都会将 epoch 加一。 Zab 和 PaxosZab 和 Paxos 协议在实现上其实有非常多的相似点，例如： 主节点会向所有的从节点发出提案； 主节点在接收到一组从节点中 50% 以上节点的确认后，才会认为当前提案被提交了； Zab 协议中的每一个提案都包含一个 epoch 值，与 Paxos 中的 Ballot 非常相似； 因为它们有一些相同的特点，所以有的观点会认为 Zab 是 Paxos 的一个简化版本，但是 Zab 和 Paxos 在设计理念上就有着比较大的不同，两者的主要区别就在于 Zab 主要是为构建高可用的主备系统设计的，而 Paxos 能够帮助工程师搭建具有一致性的状态机系统。 作为一个一致性状态机系统，它能够保证集群中任意一个状态机副本都按照客户端的请求执行了相同顺序的请求，即使来自客户端请求是异步的并且不同客户端的接收同一个请求的顺序不同，集群中的这些副本就是会使用 Paxos 或者它的变种对提案达成一致；在集群运行的过程中，如果主节点出现了错误导致宕机，其他的节点会重新开始进行选举并处理未提交的请求。 但是在类似 Zookeeper 的高可用主备系统中，所有的副本都需要对增量的状态更新顺序达成一致，这些状态更新的变量都是由主节点创建并发送给其他的从节点的，每一个从节点都会严格按照顺序逐一的执行主节点生成的状态更新请求，如果 Zookeeper 集群中的主节点发生了宕机，新的主节点也必须严格按照顺序对请求进行恢复。 总的来说，使用状态更新节点数据的主备系统相比根据客户端请求改变状态的状态机系统对于请求的执行顺序有着更严格的要求。 实现原理这一节会简单介绍 Zookeeper 的一些实现原理，重点会介绍以下几个部分的内容：文件系统、临时 / 持久节点和通知的实现原理。 文件系统了解或者使用 Zookeeper 或者其他分布式协调服务的读者对于使用类似文件系统的方式比较熟悉，与 Unix 中的文件系统份上相似的是，Zookeeper 中也使用文件系统组织系统中存储的资源。 Zookeeper 中其实并没有文件和文件夹的概念，它只有一个 Znode 的概念，它既能作为容器存储数据，也可以持有其他的 Znode 形成父子关系。 Znode 其实有 PERSISTENT、PERSISTENT_SEQUENTIAL、EPHEMERAL 和 EPHEMERAL_SEQUENTIAL 四种类型，它们是临时与持久、顺序与非顺序两个不同的方向组合成的四种类型。 临时节点是客户端在连接 Zookeeper 时才会保持存在的节点，一旦客户端和服务端之间的连接中断，当前连接持有的所有节点都会被删除，而持久的节点不会随着会话连接的中断而删除，它们需要被客户端主动删除；Zookeeper 中另一种节点的特性就是顺序和非顺序，如果我们使用 Zookeeper 创建了顺序的节点，那么所有节点就会在名字的末尾附加一个序列号，序列号是一个由父节点维护的单调递增计数器。 通知常见的通知机制往往都有两种，一种是客户端使用『拉』的方式从服务端获取最新的状态，这种方式获取的状态很有可能都是过期的，需要客户端不断地通过轮训的方式获取服务端最新的状态，另一种方式就是在客户端订阅对应节点后由服务端向所有订阅者推送该节点的变化，相比于客户端主动获取数据的方式，服务端主动推送更能够保证客户端数据的实时性。 作为分布式协调工具的 Zookeeper 就实现了这种服务端主动推送请求的机制，也就是 Watch，当客户端使用 getData 等接口获取 Znode 状态时传入了一个用于处理节点变更的回调，那么服务端就会主动向客户端推送节点的变更： 1public byte[] getData(final String path, Watcher watcher, Stat stat) 从这个方法中传入的 Watcher 对象实现了相应的 process 方法，每次对应节点出现了状态的改变，WatchManager 都会通过以下的方式调用传入 Watcher 的方法： 1234567891011Set&lt;Watcher&gt; triggerWatch(String path, EventType type, Set&lt;Watcher&gt; supress) &#123; WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path); Set&lt;Watcher&gt; watchers; synchronized (this) &#123; watchers = watchTable.remove(path); &#125; for (Watcher w : watchers) &#123; w.process(e); &#125; return watchers;&#125; Zookeeper 中的所有数据其实都是由一个名为 DataTree 的数据结构管理的，所有的读写数据的请求最终都会改变这颗树的内容，在发出读请求时可能会传入 Watcher 注册一个回调函数，而写请求就可能会触发相应的回调，由 WatchManager 通知客户端数据的变化。 通知机制的实现其实还是比较简单的，通过读请求设置 Watcher 监听事件，写请求在触发事件时就能将通知发送给指定的客户端。 会话在 Zookeeper 中一个非常重要的概念就是会话，客户端与服务器之间的任何操作都与 Zookeeper 中会话的概念有关，比如我们再上一节中提到的临时节点生命周期以及通知的机制等等，它们都是基于会话来实现的。 每当客户端与服务端建立连接时，其实创建了一个新的会话，在每一个会话的生命周期中，Zookeeper 会在不同的会话状态之间进行切换，比如说：CONNECTING、CONNECTED、RECONNECTING、RECONNECTED 和 CLOSE 等。 作为 Zookeeper 中最重要的概念之一，每一个 Session 都包含四个基本属性，会话的唯一 ID、会话超时时间、下次会话的超时时间点和表示会话是否被关闭的标记。 SessionTracker 是 Zookeeper 中的会话管理器，它负责所有会话的创建、管理以及清理工作，但是它本身只是一个 Java 的接口，定义了一系列用于管理会话的相关接口： 1234567891011121314151617181920public interface SessionTracker &#123; public static interface Session &#123; long getSessionId(); int getTimeout(); boolean isClosing(); &#125; public static interface SessionExpirer &#123; void expire(Session session); long getServerId(); &#125; long createSession(int sessionTimeout); boolean trackSession(long id, int to); boolean commitSession(long id, int to); boolean touchSession(long sessionId, int sessionTimeout); void setSessionClosing(long sessionId); void shutdown(); void removeSession(long sessionId);&#125; 与其他的长连接一样，Zookeeper 中的会话也需要客户端与服务端之间进行心跳检测，客户端会在超时时间内向服务端发送心跳请求来保证会话不会被服务端关闭，一旦服务端检测到某一个会话长时间没有收到心跳包就会中断当前会话释放服务器上的资源。 应用作为分布式协调服务，Zookeeper 能够为集群提供分布式一致性的保证，我们可以通过 Zookeeper 提供的最基本的 API 组合成更高级的功能： 12345678public class Zookeeper &#123; public String create(final String path, byte data[], List&lt;ACL&gt; acl, CreateMode createMode) public void delete(final String path, int version) throws InterruptedException, KeeperException public Stat exists(final String path, Watcher watcher) throws KeeperException, InterruptedException public byte[] getData(final String path, Watcher watcher, Stat stat) throws KeeperException, InterruptedException public Stat setData(final String path, byte data[], int version) throws KeeperException, InterruptedException public void sync(final String path, VoidCallback cb, Object ctx)&#125; 在这一节中，我们将介绍如何在生产环境中使用 Zookeeper 实现发布订阅、命名服务、分布式协调以及分布式锁等功能。 发布订阅通过 Zookeeper 进行数据的发布与订阅其实可以说是它提供的最基本功能，它能够允许多个客户端同时订阅某一个节点的变更并在变更发生时执行我们预先设置好的回调函数，在运行时改变服务的配置和行为： 123456789ZooKeeper zk = new ZooKeeper(\"localhost\", 3000, null);zk.getData(\"/config\", new Watcher() &#123; public void process(WatchedEvent watchedEvent) &#123; System.out.println(watchedEvent.toString()); &#125;&#125;, null);zk.setData(\"/config\", \"draven\".getBytes(), 0);// WatchedEvent state:SyncConnected type:NodeDataChanged path:/config 发布与订阅是 Zookeeper 提供的一个最基本的功能，它的使用非常的简单，我们可以在 getData 中传入实现 process 方法的 Watcher 对象，在每次改变节点的状态时，process 方法都会被调用，在这个方法中就可以对变更进行响应动态修改一些行为。 通过 Zookeeper 这个中枢，每一个客户端对节点状态的改变都能够推送给节点的订阅者，在发布订阅模型中，Zookeeper 的每一个节点都可以被理解成一个主题，每一个客户端都可以向这个主题推送详细，同时也可以订阅这个主题中的消息；只是 Zookeeper 引入了文件系统的父子层级的概念将发布订阅功能实现得更加复杂。 1234567public static enum EventType &#123; None(-1), NodeCreated(1), NodeDeleted(2), NodeDataChanged(3), NodeChildrenChanged(4);&#125; 如果我们订阅了一个节点的变更信息，那么该节点的子节点出现数量变更时就会调用 process 方法通知观察者，这也意味着更复杂的实现，同时和专门做发布订阅的中间件相比也没有性能优势，在海量推送的应用场景下，消息队列更能胜任，而 Zookeeper 更适合做一些类似服务配置的动态下发的工作。 命名服务除了实现服务配置数据的发布与订阅功能，Zookeeper 还能帮助分布式系统实现命名服务，在每一个分布式系统中，客户端应用都有根据指定名字获取资源、服务器地址的需求，在这时就要求整个集群中的全部服务有着唯一的名字。 在大型分布式系统中，有两件事情非常常见，一是不同服务之间的可能拥有相同的名字，另一个是同一个服务可能会在集群中部署很多的节点，Zookeeper 就可以通过文件系统和顺序节点解决这两个问题。 在上图中，我们创建了两个命名空间，/infrastructure 和 /business 分别代表架构和业务部门，两个部门中都拥有名为 metrics 的服务，而业务部门的 metrics 服务也部署了两个节点，在这里使用了命名空间和顺序节点解决唯一标志符的问题。 1234567ZooKeeper zk = new ZooKeeper(\"localhost\", 3000, null);zk.create(\"/metrics\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);zk.create(\"/metrics\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);List children = zk.getChildren(\"/\", null);System.out.println(children);// [metrics0000000001, metrics0000000002] 使用上面的代码就能在 Zookeeper 中创建两个带序号的 metrics 节点，分别是 metrics0000000001 和 metrics0000000002，也就是说 Zookeeper 帮助我们保证了节点的唯一性，让我们能通过唯一的 ID 查找到对应服务的地址等信息。 协调分布式事务Zookeeper 的另一个作用就是担任分布式事务中的协调者角色，在之前介绍 分布式事务 的文章中我们曾经介绍过分布式事务本质上都是通过 2PC 来实现的，在两阶段提交中就需要一个协调者负责协调分布式事务的执行。 123456789ZooKeeper zk = new ZooKeeper(\"localhost\", 3000, null);String path = zk.create(\"/transfer/tx\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);List ops = Arrays.asList( Op.create(path + \"/cohort\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL), Op.create(path + \"/cohort\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL), Op.create(path + \"/cohort\", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL));zk.multi(ops); 当前节点作为协调者在每次发起分布式事务时都会创建一个 /transfer/tx 的持久顺序节点，然后为几个事务的参与者创建几个空白的节点，事务的参与者在收到事务时会向这些空白的节点中写入信息并监听这些节点中的内容。 所有的事务参与者会向当前节点中写入提交或者终止，一旦当前的节点改变了事务的状态，其他节点就会得到通知，如果出现一个写入终止的节点，所有的节点就会回滚对分布式事务进行回滚。 使用 Zookeeper 实现强一致性的分布式事务其实还是一件比较困难的事情，一方面是因为强一致性的分布式事务本身就有一定的复杂性，另一方面就是 Zookeeper 为了给客户端提供更多的自由，对外暴露的都是比较基础的 API，对它们进行组装实现复杂的分布式事务还是比较麻烦的，对于如何使用 Zookeeper 实现分布式事务，我们可以在 ZooKeeper Recipes and Solutions 一文中找到更为详细的内容。 分布式锁在数据库中，锁的概念其实是非常重要的，常见的关系型数据库就会对排他锁和共享锁进行支持，而 Zookeeper 提供的 API 也可以让我们非常简单的实现分布式锁。 1234567891011121314151617181920212223242526272829ZooKeeper zk = new ZooKeeper(\"localhost\", 3000, null);final String resource = \"/resource\";final String lockNumber = zk .create(\"/resource/lock-\", null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);List&lt;String&gt; locks = zk.getChildren(resource, false, null);Collections.sort(locks);if (locks.get(0).equals(lockNumber.replace(\"/resource/\", \"\"))) &#123; System.out.println(\"Acquire Lock\"); zk.delete(lockNumber, 0);&#125; else &#123; zk.getChildren(resource, new Watcher() &#123; public void process(WatchedEvent watchedEvent) &#123; try &#123; ZooKeeper zk = new ZooKeeper(\"localhost\", 3000, null); List locks = zk.getChildren(resource, null, null); Collections.sort(locks); if (locks.get(0).equals(lockNumber.replace(\"/resource/\", \"\"))) &#123; System.out.println(\"Acquire Lock\"); zk.delete(lockNumber, 0); &#125; &#125; catch (Exception e) &#123;&#125; &#125; &#125;, null);&#125; 如果多个服务同时要对某个资源进行修改，就可以使用上述的代码来实现分布式锁，假设集群中存在一个资源 /resource，几个服务需要通过分布式锁保证资源只能同时被一个节点使用，我们可以用创建临时顺序节点的方式实现分布式锁；当我们创建临时节点后，通过 getChildren 获取当前等待锁的全部节点，如果当前节点是所有节点中序号最小的就得到了当前资源的使用权限，在对资源进行处理后，就可以通过删除 /resource/lock-00000000x 来释放锁，如果当前节点不是最小值，就会注册一个 Watcher 等待 /resource 子节点的变化直到当前节点的序列号成为最小值。 上述代码在集群中争夺同一资源的服务器特别多的情况下会出现羊群效应，每次子节点改变时都会通知当前节点，造成资源的浪费，我们其实可以将 getChildren 换成 getData，让当前节点只监听前一个节点的删除事件： 1234567891011121314Integer number = Integer.parseInt(lockNumber.replace(\"/resource/lock-\", \"\")) + 1;String previousLock = \"/resource/lock-\" + String.format(\"%010d\", number);zk.getData(previousLock, new Watcher() &#123; public void process(WatchedEvent watchedEvent) &#123; try &#123; if (watchedEvent.getType() == Event.EventType.NodeDeleted) &#123; System.out.println(\"Acquire Lock\"); ZooKeeper zk = new ZooKeeper(\"localhost\", 3000, null); zk.delete(lockNumber, 0); &#125; &#125; catch (Exception e) &#123;&#125; &#125;&#125;, null); 在新的分布式锁实现中，我们减少了每一个服务需要关注的事情，只让它们监听需要关心的数据变更，减少 Zookeeper 发送不必要的通知影响效率。 分布式锁作为分布式系统中比较重要的一个工具，确实有着比较多的应用，同时也有非常多的实现方式，除了 Zookeeper 之外，其他服务例如 Redis 和 etcd 也能够实现分布式锁，为分布式系统的构建提供支持，不过在这篇文章中就不展开介绍了。 总结我们在这篇文章中简单介绍了 Google 的分布式锁服务 Chubby 以及同样能够提供分布式锁服务功能的 Zookeeper。 作为分布式协调服务，Zookeeper 的应用场景非常广泛，不仅能够用于服务配置的下发、命名服务、协调分布式事务以及分布式锁，还能够用来实现微服务治理中的服务注册以及发现等功能，这些其实都源于 Zookeeper 能够提供高可用的分布式协调服务，能够为客户端提供分布式一致性的支持，在后面的文章中作者也会介绍其他用于分布式协调的服务。 参考资料https://zookeeper.apache.org/doc/r3.4.4/recipes.html https://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf 本文作者 Draveness，文章转载自 https://draveness.me/zookeeper-chubby , 对其内容进行过编辑。","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://vincentruan.github.io/categories/架构设计/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://vincentruan.github.io/tags/zookeeper/"},{"name":"分布式","slug":"分布式","permalink":"https://vincentruan.github.io/tags/分布式/"}]},{"title":"Shadowsocks服务器代理","slug":"Shadowsocks服务器代理","date":"2018-07-13T14:58:47.000Z","updated":"2020-02-25T15:09:15.049Z","comments":true,"path":"2018/07/13/Shadowsocks服务器代理/","link":"","permalink":"https://vincentruan.github.io/2018/07/13/Shadowsocks服务器代理/","excerpt":"前言本文讲述如何安装配置Shadowsocks Server，并支持通过代理方式（http/sock v4/5)连接因特网. 这里主要阐述服务端通过proxy连接的解决方案，shadowsocks server直连网络的方式比较简单，网上这块资料也比较齐全，不做过多描述","text":"前言本文讲述如何安装配置Shadowsocks Server，并支持通过代理方式（http/sock v4/5)连接因特网. 这里主要阐述服务端通过proxy连接的解决方案，shadowsocks server直连网络的方式比较简单，网上这块资料也比较齐全，不做过多描述 ssserver代理安装配置安装Shadowsocks Server参考Install Shadowsocks Server on Windows， 客户端的安装方式参考Shadowsocks Client安装, 这里主要解决服务端通过代理解决shadowsocks server无法直连网络的问题，客户端这块不做过多描述。 更新代理脚本​ 这个问题的解决方案来自github的一个issue 通过猴子补丁的方式给ss添加了一个前置代理的功能 有兴趣深入了解的推荐star一下该作者的项目PySocket ​ 在上述步骤安装了python版的Shadowsocks Server之后，通过猴子补丁的方式给给 shadowsocks 服务端添加前置代理的功能（原则上也适用于客户端），支持 http、socks4、socks5 代理。并且通过 hook 的方式去掉了ss的dns查询，ss在接收到数据之后会直接把域名和请求一起发给代理。 使用的时候修改 socket.py 文件中 PROXY_TYPE、PROXY_ADDR、PROXY_PORT 等字段为你的代理地址，然后把 socket.py 文件放到 shadowsocks 根目录即可生效，不用修改任何源码。 通过pip安装的话要放到ssserver所在的目录，一般都在 Python27\\Scripts （python27上验证OK） 12pip install win_inet_pton --proxy=http://your-proxy-host:your-proxy-portpip install shadowsocks --proxy=http://your-proxy-host:your-proxy-port 配置部分： 1234# the proxy type. SOCKS5 SOCKS4 HTTPPROXY_TYPE = SOCKS5PROXY_ADDR = \"127.0.0.1\"PROXY_PORT = 1080 socket.py 文末部分，因为我选择 hook shadowsocks的代码，实际使用时在del module会报异常，因此将文末修改为 12345678910111213# hook shadowsocks's code remove the dns reqdef new_resolve(self, hostname, callback): callback((hostname, hostname), None)modules_list = [\"shadowsocks.common\", \"shadowsocks.shell\"]for x in modules_list: try: del sys.modules[x] except KeyError: print \"Error: key\", x, \"not found\"import shadowsocks.asyncdnsshadowsocks.asyncdns.DNSResolver.resolve = new_resolve 如果不想 hook shadowsocks的代码的话，把文件中末尾的代码删除即可，原文件代码末尾如下: 12345678910# hook shadowsocks's code remove the dns reqdef new_resolve(self, hostname, callback): callback((hostname, hostname), None)modules_list = [\"shadowsocks.common\", \"shadowsocks.shell\"]for x in modules_list: del sys.modules[x]import shadowsocks.asyncdnsshadowsocks.asyncdns.DNSResolver.resolve = new_resolve ssserver配置参考Configuration via Config File 创建一个配置文件 /etc/shadowsocks.json. 示例如下: 12345678910&#123; \"server\":\"my_server_ip\", \"server_port\":8388, \"local_address\": \"127.0.0.1\", \"local_port\":1080, \"password\":\"mypassword\", \"timeout\":300, \"method\":\"aes-256-cfb\", \"fast_open\": false&#125; 配置文件字段详解: Name Explanation server ssserver监听地址，0.0.0.0监听本地所有网卡地址 server_port ssserver服务端口 local_address 本地监听地址 local_port 本地端口 password 用于加密的密码 timeout 超时设置，单位秒，不建议太长 method 默认: “aes-256-cfb”, 详见 Encryption fast_open 是否使用 TCP_FASTOPEN, true / false workers worker数量, 仅在Unix/Linux生效 在控制台中执行，日志直接显示在控制台，首次测试使用建议该方式，可通过ctrl+C退出: 1ssserver -c /etc/shadowsocks.json 后台静默执行: 1234# 启动服务ssserver -c /etc/shadowsocks.json -d start# 停止服务ssserver -c /etc/shadowsocks.json -d stop","categories":[{"name":"developer tools","slug":"developer-tools","permalink":"https://vincentruan.github.io/categories/developer-tools/"}],"tags":[{"name":"Shadowsocks","slug":"Shadowsocks","permalink":"https://vincentruan.github.io/tags/Shadowsocks/"}]},{"title":"docker碎片拾遗","slug":"docker碎片拾遗","date":"2018-06-24T05:22:34.000Z","updated":"2020-02-17T02:40:44.761Z","comments":true,"path":"2018/06/24/docker碎片拾遗/","link":"","permalink":"https://vincentruan.github.io/2018/06/24/docker碎片拾遗/","excerpt":"","text":"进入shell环境12docker psdocker exec -it &lt;container&gt; bash and run 12apt-get updateapt-get install vim ！不要去改系统配置正常运行的docker先保存一下docker的ID，之后不要去改下面的配置，否则docker会更新为新的那个，导致数据丢失 docker指令1、启动docker1docker run -it --privileged=true -v /home/oracle/download:/usr/Downloads centos /bin/bash 2、查看当前docker运行1docker ps -a 3、提交docker1docker commit 9f73a02d5ef0[CONTAINER ID] docker.io/ubuntu[REPOSITORY] 4、查看容器的root用户密码1docker logs &lt;容器名orID&gt; 2&gt;&amp;1 | grep '^User: ' | tail -n1 因为docker容器启动时的root用户的密码是随机分配的。所以，通过这种方式就可以得到redmine容器的root用户的密码了。 5、查看容器日志1docker logs -f &lt;容器名orID&gt; 6、查看正在运行的容器12docker psdocker ps -a为查看所有的容器，包括已经停止的。 7、删除所有容器1docker rm $(docker ps -a -q) 8、删除单个容器1docker rm &lt;容器名orID&gt; 9、停止、启动、杀死一个容器12345docker stop &lt;容器名orID&gt;docker start &lt;容器名orID&gt;docker kill &lt;容器名orID&gt; 10、查看所有镜像1docker images 11、删除所有镜像1docker rmi $(docker images | grep none | awk '&#123;print $3&#125;' | sort -r) 12、运行一个新容器，同时为它命名、端口映射、文件夹映射。以redmine镜像为例1docker run --name redmine -p 9003:80 -p 9023:22 -d -v /var/redmine/files:/redmine/files -v /var/redmine/mysql:/var/lib/mysql sameersbn/redmine 13、一个容器连接到另一个容器1docker run -i -t --name sonar -d -link mmysql:db tpires/sonar-server sonar容器连接到mmysql容器，并将mmysql容器重命名为db。这样，sonar容器就可以使用db的相关的环境变量了。 14、拉取镜像1docker pull &lt;镜像名:tag&gt; 如docker pull sameersbn/redmine:latest 当需要把一台机器上的镜像迁移到另一台机器的时候，需要保存镜像与加载镜像。 机器a1docker save busybox-1 &gt; /home/save.tar 使用scp将save.tar拷到机器b上，然后：1docker load &lt; /home/save.tar 15、构建自己的镜像1docker build -t &lt;镜像名&gt; &lt;Dockerfile路径&gt; 如Dockerfile在当前路径：docker build -t xx/gitlab .","categories":[{"name":"docker","slug":"docker","permalink":"https://vincentruan.github.io/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://vincentruan.github.io/tags/docker/"}]},{"title":"Xshell显示X11图形化界面","slug":"Xshell显示X11图形化界面","date":"2018-06-17T15:10:35.000Z","updated":"2020-02-25T15:09:15.050Z","comments":true,"path":"2018/06/17/Xshell显示X11图形化界面/","link":"","permalink":"https://vincentruan.github.io/2018/06/17/Xshell显示X11图形化界面/","excerpt":"安装Xmanager全家桶使用前检查一下是否安装了Xshell、Xstart、Xmanager - Passive，正常安装Xmanager全家桶应该是全的","text":"安装Xmanager全家桶使用前检查一下是否安装了Xshell、Xstart、Xmanager - Passive，正常安装Xmanager全家桶应该是全的 使用XStart登录通过SSH的方式尝试登录VPS， 正常成功后会这样提示 当然更多的可能是弹出个错误框提示“已拒绝X11转移申请”，这是因为默认的VPS一般不会安装XAUTH导致， 1sudo yum install xorg-x11-xauth 这里可能会缺一些其他组件，见招拆招即可，谷歌或者百度解决 设置XSHELL 打开会话对话框 选择要激活X11转发功能的会话 点击[属性]按钮 在[类别]中选择[连接-&gt;SSH-&gt;隧道] 选择[转发X11连接到] 如用户的PC上已安装Xmanager，请勾选[Xmanager(M)]。如使用其他PC X 服务器，请选择[X DISPLAY(D)]后输入适用的DISPLAY 点击[确定] 检查当前监听端口IMPORTANT 1sudo netstat -tnlp|grep sshd 注意上面监听的6010，Xmanager会把X DISPLAY选项自动查找为Xshell。其他 PC X 服务器程序需由用户进行设置。如果PC X 服务器使用TCP 6000号端口，DISPLAY设置为“localhost:0.0” ，也就是说，X11的偏移量是6000，因此下面需要设置一个最终要的DISPLAY的值:10.0，如下 123export DISPLAY=:10.0或者export DISPLAY=localhost:10.0 测试X11 DISPLAY如果本地已经有需要X11界面展示的应用，直接运行查看即可，如无，推荐使用xclock检查是否生效[以下步骤不是必须，自行选择] 1sudo yum install xclock 这里可能出现乱码之类的，可能需要安装x窗口相关包，和字体显示包 1sudo yum groupinstall \"X Window System\" \"Fonts\" 然后执行xclock，看是否在PC桌面显示对应的时钟图形。如果xclock出现Warning: Missing charsets in String to FontSet conversion，可以执行下面执行，然后重新执行 1export LC_ALL=C","categories":[{"name":"Linux","slug":"Linux","permalink":"https://vincentruan.github.io/categories/Linux/"}],"tags":[{"name":"X11 Display","slug":"X11-Display","permalink":"https://vincentruan.github.io/tags/X11-Display/"},{"name":"XSHELL","slug":"XSHELL","permalink":"https://vincentruan.github.io/tags/XSHELL/"}]},{"title":"Hexo添加Gitalk评论插件","slug":"Hexo添加Gitalk评论插件","date":"2018-06-01T15:55:56.000Z","updated":"2018-06-01T16:18:58.699Z","comments":true,"path":"2018/06/01/Hexo添加Gitalk评论插件/","link":"","permalink":"https://vincentruan.github.io/2018/06/01/Hexo添加Gitalk评论插件/","excerpt":"","text":"安装Gitalk提供了两种方式： 直接引入 1234567&lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css\"&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js\"&gt;&lt;/script&gt;&lt;!-- or --&gt;&lt;link rel=\"stylesheet\" href=\"https://unpkg.com/gitalk/dist/gitalk.css\"&gt;&lt;script src=\"https://unpkg.com/gitalk/dist/gitalk.min.js\"&gt;&lt;/script&gt; npm安装 123npm i --save gitalkimport &apos;gitalk/dist/gitalk.css&apos;import Gitalk from &apos;gitalk&apos; 相对来说第一种会更简单。 使用A GitHub Application is needed for authorization, if you don’t have one, Click here to register a new one. Note: You must specify the website domain url in the Authorization callback URL field. 1234567891011const gitalk = new Gitalk(&#123; clientID: &apos;GitHub Application Client ID&apos;, clientSecret: &apos;GitHub Application Client Secret&apos;, repo: &apos;GitHub repo&apos;, owner: &apos;GitHub repo owner&apos;, admin: [&apos;GitHub repo owner and collaborators, only these guys can initialize github issues&apos;], id: location.pathname, // Ensure uniqueness and length less than 50 distractionFreeMode: false // Facebook-like distraction free mode&#125;)gitalk.render(&apos;gitalk-container&apos;) 修改主题文件 这里以next主题为例，参考Feature: Add Gitalk Support 不同的主题目录和模板引擎不同，可以自己修改, 修改next主题配置文件_config.yml，添加字段： 12345678910# Gitalk# more info please open https://github.com/gitalk/gitalkgitalk: enable: false clientID: clientSecret: repo: owner: admin: # support multiple admins split with comma, e.g. foo,bar pagerDirection: first 找到next/layout/_third-party/comments文件夹，新建gitalk.swig文件，代码如下： 1234567891011121314151617181920&#123;% if not (theme.duoshuo and theme.duoshuo.shortname) and not theme.duoshuo_shortname %&#125; &#123;% if theme.gitalk.enable %&#125; &#123;% if page.comments %&#125; &lt;script src=&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; const gitalk = new Gitalk(&#123; clientID: &apos;&#123;&#123;theme.gitalk.clientID&#125;&#125;&apos;, clientSecret: &apos;&#123;&#123;theme.gitalk.clientSecret&#125;&#125;&apos;, repo: &apos;&#123;&#123;theme.gitalk.repo&#125;&#125;&apos;, owner: &apos;&#123;&#123;theme.gitalk.owner&#125;&#125;&apos;, admin: &apos;&#123;&#123;theme.gitalk.admin&#125;&#125;&apos;.split(&apos;,&apos;), pagerDirection: &apos;&#123;&#123;theme.gitalk.pagerDirection&#125;&#125;&apos;, // facebook-like distraction free mode distractionFreeMode: false &#125;) gitalk.render(&apos;gitalk-container&apos;) &lt;/script&gt; &#123;% endif %&#125; &#123;% endif %&#125;&#123;% endif %&#125; 同目录下在index.swig文件末尾添加： 1&#123;% include &apos;gitalk.swig&apos; %&#125; 下步搞起，next/layout/_partials文件夹下，找到comments.swig文件，添加代码： 123&#123;% elseif theme.gitalk.enable %&#125; &lt;div id=&quot;gitalk-container&quot;&gt;&lt;/div&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;&gt; 因为github限制了issue的提交title长度不能超过50，可能会遇到Error: Validation Failed 按照这里的方案，使用MD5的方式降低长度即可 参考文档 Hexo添加Gitalk评论插件 Next 第三方服务集成 在hexo next主题上使用gitalk","categories":[{"name":"Hexo使用攻略","slug":"Hexo使用攻略","permalink":"https://vincentruan.github.io/categories/Hexo使用攻略/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://vincentruan.github.io/tags/hexo/"}]},{"title":"Hexo集成Algolia搜索插件","slug":"Hexo集成Algolia搜索插件","date":"2018-06-01T15:14:36.000Z","updated":"2020-02-25T15:09:15.035Z","comments":true,"path":"2018/06/01/Hexo集成Algolia搜索插件/","link":"","permalink":"https://vincentruan.github.io/2018/06/01/Hexo集成Algolia搜索插件/","excerpt":"前言个人博客自从2016年10月21日搭建以来，迄今为止已经有49 篇日志了。虽然不是很多篇文章，但是搜索站内的内容已经力不从心了。 搜索了网上很多关于“Hexo 站内搜索”的内容，发现大部分都是使用Swiftype，但是发现Swiftype 搜索只有15 天的免费，之后就需要开始收费了。 因为只是为自己的个人博客 使用站内搜索，所以希望找一个类似与Swiftype 的，但是免费的站内搜索。最后找了Algolia 这个免费版本替代。","text":"前言个人博客自从2016年10月21日搭建以来，迄今为止已经有49 篇日志了。虽然不是很多篇文章，但是搜索站内的内容已经力不从心了。 搜索了网上很多关于“Hexo 站内搜索”的内容，发现大部分都是使用Swiftype，但是发现Swiftype 搜索只有15 天的免费，之后就需要开始收费了。 因为只是为自己的个人博客 使用站内搜索，所以希望找一个类似与Swiftype 的，但是免费的站内搜索。最后找了Algolia 这个免费版本替代。 下面简单说下搭建过程： 搭建过程前提条件如果你的Next 版本为5.1.0 之后，可以使用Algolia。如果不是，请先升级到5.1.0 版本之后 一个Algolia 帐号官网地址 使用GitHub 或Google 帐号登录。 创建Index进入Dashboard，选择Indices 新建一个Index。 安装Hexo AlgoliaIndex 创建完成后，此时Index 为包含任何数据。需要安装Hexo Aloglia 扩展，这个扩展的功能是搜集站点的内容并通过API 发送给Aloglia。前往站点根目录，执行命令安装： 1npm install --save hexo-algolia 获取Key，更新站点信配置点击Dashborad 左侧的API Keys，其中的信息接下来将会被用到。包括Application ID 、Search-Only API Key 和 Admin API Key，其中Admin API Key需要保密保存 编辑站点配置文件，新增以下配置： 123456algolia: applicationID: &apos;SV57WJ53OS&apos; apiKey: &apos;c7d219504e44d09ab55f5f7a195fce98&apos; adminApiKey: &apos;adminApiKey&apos; indexName: &apos;dev_jobbymsblog&apos; chunkSize: 5000 更新Index当配置完成，在站点根目录下执行hexo algolia 来更新Index。请注意观察命令的输出。 主题集成更改主题配置文件，找到Algolia Search 配置部分： 123456789# Algolia Searchalgolia_search: enable: false hits: per_page: 10 labels: input_placeholder: Search for Posts hits_empty: &quot;We didn&apos;t find any results for the search: $&#123;query&#125;&quot; hits_stats: &quot;$&#123;hits&#125; results found in $&#123;time&#125; ms&quot; 将enable 改为true 即可，根据需要你可以调整labels 中的文本。 问题11. 点击搜索结果，结果跳转地址为： 1Cannot GET /undefined/ 按照5.1.0使用algolia搜索问题这里进行的处理，在这里总结一下： 因为hexo-aloglia 的作者没有把post.path 加入index，所以data.path 是undefined。 遇到这个问题，首先运行npm uninstll hexo-algolia 卸载之前的版本，再运行npm install hexo-algolia@0.2.0 --save,最后运行hexo algolia 命令重新index 就可以了。 参考文档 Swiftype站内搜索 Next 第三方服务集成 本文转载自Hexo集成Algolia搜索插件","categories":[{"name":"Hexo使用攻略","slug":"Hexo使用攻略","permalink":"https://vincentruan.github.io/categories/Hexo使用攻略/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://vincentruan.github.io/tags/Hexo/"},{"name":"Algolia","slug":"Algolia","permalink":"https://vincentruan.github.io/tags/Algolia/"}]},{"title":"Linux xmr-stak挖矿教程","slug":"Linux-xmr-stak挖矿教程","date":"2018-05-27T13:51:10.000Z","updated":"2018-06-08T17:29:23.624Z","comments":true,"path":"2018/05/27/Linux-xmr-stak挖矿教程/","link":"","permalink":"https://vincentruan.github.io/2018/05/27/Linux-xmr-stak挖矿教程/","excerpt":"","text":"在Linux上编译 xmr-stakInstall DependenciesAMD APP SDK 3.0 (only needed to use AMD GPUs) download and install the latest version from https://www.dropbox.com/sh/mpg882ekirnsfa7/AADWz5X-TgVdsmWt0QwMgTWLa/AMD-APP-SDKInstaller-v3.0.130.136-GA-linux64.tar.bz2?dl=0(do not wonder why it is a link to a dropbox but AMD has removed the SDK downloads, see https://community.amd.com/thread/228059) Cuda 8.0+ (only needed to use NVIDIA GPUs) download and install https://developer.nvidia.com/cuda-downloads for minimal install choose Custom installation options during the install and select CUDA/Develpment CUDA/Runtime Driver components GNU Compiler12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# Ubuntu / Debiansudo apt install libmicrohttpd-dev libssl-dev cmake build-essential libhwloc-devgit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake ..make install# Archsudo pacman -S --needed base-devel hwloc openssl cmake libmicrohttpdgit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake ..make install# Fedorasudo dnf install gcc gcc-c++ hwloc-devel libmicrohttpd-devel libstdc++-static make openssl-devel cmakegit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake ..make install# CentOSsudo yum install centos-release-scl epel-releasesudo yum install cmake3 devtoolset-4-gcc* hwloc-devel libmicrohttpd-devel openssl-devel makescl enable devtoolset-4 bashgit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake3 ..make install# Ubuntu 14.04sudo add-apt-repository ppa:ubuntu-toolchain-r/testsudo apt updatesudo apt install gcc-5 g++-5 makesudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 1 --slave /usr/bin/g++ g++ /usr/bin/g++-5curl -L http://www.cmake.org/files/v3.4/cmake-3.4.1.tar.gz | tar -xvzf - -C /tmp/cd /tmp/cmake-3.4.1/ &amp;&amp; ./configure &amp;&amp; make &amp;&amp; sudo make install &amp;&amp; cd -sudo update-alternatives --install /usr/bin/cmake cmake /usr/local/bin/cmake 1 --forcesudo apt install libmicrohttpd-dev libssl-dev libhwloc-devgit clone https://github.com/fireice-uk/xmr-stak.gitmkdir xmr-stak/buildcd xmr-stak/buildcmake ..make install# TinyCore Linux 8.x# TinyCore is 32-bit only, but there is an x86-64 port, known as &quot;Pure 64,&quot;# hosted on the TinyCore home page, and it works well.# Beware that huge page support is not enabled in the kernel distributed# with Pure 64. Consider http://wiki.tinycorelinux.net/wiki:custom_kernel# Note that as of yet there are no distro packages for microhttpd or hwloc.# hwloc is easy enough to install manually though, shown below.# Also note that only CPU mining has been tested on this platform, thus the# disabling of CUDA and OpenCL shown below.tce-load -iw openssl-dev.tcz cmake.tcz make.tcz gcc.tcz git.tcz \\ glibc_base-dev.tcz linux-4.8.1_api_headers.tcz \\ glibc_add_lib.tczwget https://www.open-mpi.org/software/hwloc/v1.11/downloads/hwloc-1.11.8.tar.gztar xzvf hwloc-1.11.8.tar.gzcd hwloc-1.11.8./configure --prefix=/usr/localmakesudo make installcd ..git clone http://github.com/fireice-uk/xmr-stakcd xmr-stakmkdir buildcd buildCC=gcc cmake .. -DCUDA_ENABLE=OFF \\ -DOpenCL_ENABLE=OFF \\ -DMICROHTTPD_ENABLE=OFFmake install g++ version 5.1 or higher is required for full C++11 support.If you want to compile the binary without installing libraries / compiler or just compile binary for some other distribution, please check the build_xmr-stak_docker.sh script. Some newer gcc versions are not supported by CUDA (e.g. Ubuntu 17.10). It will require installing gcc 5 but you can avoid changing defaults. In that case you can force CUDA to use an older compiler in the following way:1cmake -DCUDA_HOST_COMPILER=/usr/bin/gcc-5 .. To do a generic and static build for a system without gcc 5.1+1234cmake -DCMAKE_LINK_STATIC=ON -DXMR-STAK_COMPILE=generic .make installcd bin\\Releasecopy C:\\xmr-stak-dep\\openssl\\bin\\* . Note - cmake caches variables, so if you want to do a dynamic build later you need to specify ‘-DCMAKE_LINK_STATIC=OFF’ Reference xmr-stak","categories":[{"name":"block-chain","slug":"block-chain","permalink":"https://vincentruan.github.io/categories/block-chain/"}],"tags":[{"name":"xmr","slug":"xmr","permalink":"https://vincentruan.github.io/tags/xmr/"}]},{"title":"Day 1: Bower —— 管理你的客户端依赖关系","slug":"Day-1-Bower-——-管理你的客户端依赖关系","date":"2018-05-26T14:27:38.000Z","updated":"2020-02-25T15:09:15.021Z","comments":true,"path":"2018/05/26/Day-1-Bower-——-管理你的客户端依赖关系/","link":"","permalink":"https://vincentruan.github.io/2018/05/26/Day-1-Bower-——-管理你的客户端依赖关系/","excerpt":"编者注：我们发现了比较有趣的系列文章《30天学习30种新技术》，准备翻译，一天一篇更新，年终礼包。以下是第一天技术的译文。 我决定将第一天的学习主题选为Bower。","text":"编者注：我们发现了比较有趣的系列文章《30天学习30种新技术》，准备翻译，一天一篇更新，年终礼包。以下是第一天技术的译文。 我决定将第一天的学习主题选为Bower。 什么是Bower？Bower是一个客户端技术的软件包管理器，它可用于搜索、安装和卸载如JavaScript、HTML、CSS之类的网络资源。其他一些建立在Bower基础之上的开发工具，如YeoMan和Grunt，这个会在以后的文章中介绍。 为什么我会在意Bower？ 节省时间。为什么要学习Bower的第一个原因，就是它会为你节省寻找客户端的依赖关系的时间。每次我需要安装jQuery的时候，我都需要去jQuery网站下载包或使用CDN版本。但是有了Bower，你只需要输入一个命令，jquery就会安装在本地计算机上，你不需要去记版本号之类的东西，你也可以通过Bower的info命令去查看任意库的信息。 脱机工作。Bower会在用户主目录下创建一个.bower的文件夹，这个文件夹会下载所有的资源、并安装一个软件包使它们可以离线使用。如果你熟悉Java，Bower即是一个类似于现在流行的Maven构建系统的.m2仓库。每次你下载任何资源库都将被安装在两个文件夹中 —— 一个在的应用程序文件夹，另一个在用户主目录下的.bower文件夹。因此，下一次你需要这个仓库时，就会用那个用户主目录下.bower中的版本。 可以很容易地展现客户端的依赖关系。你可以创建一个名为bower.json的文件，在这个文件里你可以指定所有客户端的依赖关系，任何时候你需要弄清楚你正在使用哪些库，你可以参考这个文件。 让升级变得简单。假设某个库的新版本发布了一个重要的安全修补程序，为了安装新版本，你只需要运行一个命令，bower会自动更新所有有关新版本的依赖关系。 前提准备为了安装bower，你首先需要安装如下文件： Node：下载最新版本的node.js NPM：NPM是node程序包管理器。它是捆绑在nodejs的安装程序上的，所以一旦你已经安装了node，NPM也就安装好了。 Git：你需要从git仓库获取一些代码包。 安装Bower一旦你已经安装了上面所说的所有必要文件，键入以下命令安装Bower： 1$ npm install -g bower 这行命令是Bower的全局安装，-g 操作表示全局。 开始使用Bower安装完bower之后就可以使用所有的bower命令了。可以键入help 命令来查看bower可以完成那些操作，如下： 1234567891011121314151617181920212223242526272829303132$ bower helpUsage: bower &lt;command&gt; [&lt;args&gt;] [&lt;options&gt;]Commands: cache Manage bower cache help Display help information about Bower home Opens a package homepage into your favorite browser info Info of a particular package init Interactively create a bower.json file install Install a package locally link Symlink a package folder list List local packages lookup Look up a package URL by name prune Removes local extraneous packages register Register a package search Search for a package by name update Update a local package uninstall Remove a local packageOptions: -f, --force Makes various commands more forceful -j, --json Output consumable JSON -l, --log-level What level of logs to report -o, --offline Do not hit the network -q, --quiet Only output important information -s, --silent Do not output anything, besides errors -V, --verbose Makes output more verbose --allow-root Allows running commands as root 包的安装Bower是一个软件包管理器，所以你可以在应用程序中用它来安装新的软件包。举例来看一下来如何使用Bower安装JQuery，在你想要安装该包的地方创建一个新的文件夹，键入如下命令： 1$ bower install jquery 上述命令完成以后，你会在你刚才创建的目录下看到一个bower_components的文件夹，其中目录如下： 123456789101112131415$ tree bower_components/bower_components/└── jquery ├── README.md ├── bower.json ├── component.json ├── composer.json ├── jquery-migrate.js ├── jquery-migrate.min.js ├── jquery.js ├── jquery.min.js ├── jquery.min.map └── package.json1 directory, 10 files 包的使用现在就可以在应用程序中使用jQuery包了，在jQuery里创建一个简单的html5文件： 12345678910111213141516171819202122&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Learning Bower&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;button&gt;Animate Me!!&lt;/button&gt;&lt;div style=&quot;background:red;height:100px;width:100px;position:absolute;&quot;&gt;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;bower_components/jquery/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; $(document).ready(function()&#123; $(&quot;button&quot;).click(function()&#123; $(&quot;div&quot;).animate(&#123;left:&apos;250px&apos;&#125;); &#125;); &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 正如你所看到的，你刚刚引用jquery.min.js文件，现阶段完成。 所有包的列表如果你想找出所有安装在应用程序中的包，可以使用list命令： 1234$ bower listbower check-new Checking for new versions of the project dependencies..blog /Users/shekhargulati/day1/blog└── jquery#2.0.3 extraneous 包的搜索假如你想在你的应用程序中使用twitter的bootstrap框架，但你不确定包的名字，这时你可以使用search 命令： 123456$ bower search bootstrapSearch results: bootstrap git://github.com/twbs/bootstrap.git angular-bootstrap git://github.com/angular-ui/bootstrap-bower.git sass-bootstrap git://github.com/jlong/sass-twitter-bootstrap.git 包的信息如果你想看到关于特定的包的信息，可以使用info 命令来查看该包的所有信息： 1234567891011121314151617181920212223242526272829$ bower info bootstrapbower bootstrap#* not-cached git://github.com/twbs/bootstrap.git#*bower bootstrap#* resolve git://github.com/twbs/bootstrap.git#*bower bootstrap#* download https://github.com/twbs/bootstrap/archive/v3.0.0.tar.gzbower bootstrap#* extract archive.tar.gzbower bootstrap#* resolved git://github.com/twbs/bootstrap.git#3.0.0&#123; name: &apos;bootstrap&apos;, version: &apos;3.0.0&apos;, main: [ &apos;./dist/js/bootstrap.js&apos;, &apos;./dist/css/bootstrap.css&apos; ], ignore: [ &apos;**/.*&apos; ], dependencies: &#123; jquery: &apos;&gt;= 1.9.0&apos; &#125;, homepage: &apos;https://github.com/twbs/bootstrap&apos;&#125;Available versions: - 3.0.0 - 3.0.0-rc1 - 3.0.0-rc.2 - 2.3.2 ..... 如果你想得到单个包的信息，也可以使用info 命令： 12345678910111213141516171819$ bower info bootstrap#3.0.0bower bootstrap#3.0.0 cached git://github.com/twbs/bootstrap.git#3.0.0bower bootstrap#3.0.0 validate 3.0.0 against git://github.com/twbs/bootstrap.git#3.0.0&#123; name: &apos;bootstrap&apos;, version: &apos;3.0.0&apos;, main: [ &apos;./dist/js/bootstrap.js&apos;, &apos;./dist/css/bootstrap.css&apos; ], ignore: [ &apos;**/.*&apos; ], dependencies: &#123; jquery: &apos;&gt;= 1.9.0&apos; &#125;, homepage: &apos;https://github.com/twbs/bootstrap&apos;&#125; 包的卸载卸载包可以使用uninstall 命令： 1$ bower uninstall jquery bower.json文件的使用bower.json文件的使用可以让包的安装更容易，你可以在应用程序的根目录下创建一个名为“bower.json”的文件，并定义它的依赖关系。使用bower init 命令来创建bower.json文件： 123456789101112131415161718192021222324252627282930313233$ bower init[?] name: blog[?] version: 0.0.1[?] description:[?] main file:[?] keywords:[?] authors: Shekhar Gulati &lt;shekhargulati84@gmail.com&gt;[?] license: MIT[?] homepage:[?] set currently installed components as dependencies? Yes[?] add commonly ignored files to ignore list? Yes[?] would you like to mark this package as private which prevents it from being accidentally published to the registry? No&#123; name: &apos;blog&apos;, version: &apos;0.0.1&apos;, authors: [ &apos;Shekhar Gulati &lt;shekhargulati84@gmail.com&gt;&apos; ], license: &apos;MIT&apos;, ignore: [ &apos;**/.*&apos;, &apos;node_modules&apos;, &apos;bower_components&apos;, &apos;test&apos;, &apos;tests&apos; ], dependencies: &#123; jquery: &apos;~2.0.3&apos; &#125;&#125;[?] Looks good? Yes 可以查看该文件： 123456789101112131415161718&#123; &quot;name&quot;: &quot;blog&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;authors&quot;: [ &quot;Shekhar Gulati &lt;shekhargulati84@gmail.com&gt;&quot; ], &quot;license&quot;: &quot;MIT&quot;, &quot;ignore&quot;: [ &quot;**/.*&quot;, &quot;node_modules&quot;, &quot;bower_components&quot;, &quot;test&quot;, &quot;tests&quot; ], &quot;dependencies&quot;: &#123; &quot;jquery&quot;: &quot;~2.0.3&quot; &#125;&#125; 注意看，它已经加入了jQuery依赖关系。 现在假设也想用twitter bootstrap，我们可以用下面的命令安装twitter bootstrap并更新bower.json文件： 1$ bower install bootstrap --save 它会自动安装最新版本的bootstrap并更新bower.json文件： 12345678910111213141516171819&#123; &quot;name&quot;: &quot;blog&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;authors&quot;: [ &quot;Shekhar Gulati &lt;shekhargulati84@gmail.com&gt;&quot; ], &quot;license&quot;: &quot;MIT&quot;, &quot;ignore&quot;: [ &quot;**/.*&quot;, &quot;node_modules&quot;, &quot;bower_components&quot;, &quot;test&quot;, &quot;tests&quot; ], &quot;dependencies&quot;: &#123; &quot;jquery&quot;: &quot;~2.0.3&quot;, &quot;bootstrap&quot;: &quot;~3.0.0&quot; &#125;&#125; 这就是今天的学习，希望能让你对bower有个足够的了解，最好可以自己尝试一下。 原文 Day 1: Bower–Manage Your Client Side Dependencies翻译 SegmentFault","categories":[{"name":"30天学习30种新技术系列","slug":"30天学习30种新技术系列","permalink":"https://vincentruan.github.io/categories/30天学习30种新技术系列/"}],"tags":[{"name":"30天学习30种新技术系列","slug":"30天学习30种新技术系列","permalink":"https://vincentruan.github.io/tags/30天学习30种新技术系列/"}]},{"title":"30天学习30种新技术系列","slug":"30-天学习-30-种新技术系列","date":"2018-05-26T14:27:27.000Z","updated":"2020-02-25T15:09:15.018Z","comments":true,"path":"2018/05/26/30-天学习-30-种新技术系列/","link":"","permalink":"https://vincentruan.github.io/2018/05/26/30-天学习-30-种新技术系列/","excerpt":"编者注：我们发现了比较有趣的系列文章《30 天学习 30 种新技术》，准备翻译，一天一篇更新，年终礼包。以下是译文，英文标题表示还未翻译，附原文链接；中文标题表示已翻译，附译文链接。","text":"编者注：我们发现了比较有趣的系列文章《30 天学习 30 种新技术》，准备翻译，一天一篇更新，年终礼包。以下是译文，英文标题表示还未翻译，附原文链接；中文标题表示已翻译，附译文链接。 更新：全系列已经全部翻译完成。 让你 30 天学习 30 种新技术，你会觉得这是挑战吗？ 我已经接受了挑战，我会在一个月的时间内每天学习一门新技术，挑战开始于 2013 年 10 月 29 日。下面就是我将要学习的新技术的列表，我会把每天学到的内容写出来。在我每天正常的工作之后，我会花几个小时学习一门新技术，再用一小时将今天学到的写在博客上。这项活动的目的是熟悉许多在开发者社区所使用的新技术。 我会把重点放在 JavaScript 及其相关技术的学习上，当然也会去了解一下像 Java 这类我比较感兴趣的其他技术。我也可能会在一门技术上花费好几天的时间，但我每次会选择和这门技术相关的不同的主题来讲。只要是有意义的，我将尽量展示它如何与 OpenShift 工作，我希望这是一次充满乐趣并能学到很多东西的旅程。（你可以在 twitter 上follow 我） 下边是学习列表： 2013.10.29 - Day 1: Bower —— 管理你的客户端依赖关系 2013.10.30 - Day 2: AngularJS —— 对 AngularJS 的初步认识 2013.10.31 - Day 3: Flask —— 使用 Python 和 OpenShift 进行即时 Web 开发 2013.11.01 - Day 4: PredictionIO —— 如何创建一个博客推荐器 2013.11.02 - Day 5: GruntJS —— 重复乏味的工作总会有人做（反正我不做） 2013.11.03 - Day 6: 在 Java 虚拟机上使用 Grails 进行快速 Web 开发 2013.11.04 - Day 7: GruntJS 在线重载 提升生产率至新境界 2013.11.05 - Day 8: Harp.JS —— 现代静态 Web 服务器 2013.11.06 - Day 9: TextBlob —— 对文本进行情感分析 2013.11.07 - Day 10: PhoneGap —— 开发手机应用如此简单 2013.11.08 - Day 11: AeroGear 推送服务器：使应用的通知推送变得简单 2013.11.09 - Day 12: OpenCV —— Java 开发者的人脸检测 2013.11.10 - Day 13: Dropwizard —— 非常棒的 Java REST 服务器栈 2013.11.11 - Day14：使用斯坦福 NER 软件包实现你自己的命名实体识别器（Named Entity Recognition，NER） 2013.11.12 - Day 15：Meteor —— 从零开始创建一个 Web 应用 2013.11.13 - Day 16: Goose Extractor —— 好用的文章提取工具 2013.11.14 - Day 17: 使用 JBoss Forge 和 OpenShift 构建部署 JAVA EE 6 应用 2013.11.15 - Day 18: BoilerPipe —— Java开发者的文章提取工具 2013.11.16 - Day 19: EmberJS 入门指南 2013.11.17 - Day 20: 斯坦福CoreNLP —— 用 Java 给 Twitter 情感分析 2013.11.18 - Day 21：Docker 入门教程 2013.11.19 - Day 22： 使用 Spring、MongoDB 和 AngularJS 开发单页面应用 2013.11.20 - Day 23： 使用 TimelineJS 构建精美的时间轴 2013.11.21 - Day 24: 使用 Yeoman 自动构建 Ember 项目 2013.11.22 - Day 25: Tornado —— 联合 Tornado、MongoDB 和 AngularJS 进行应用开发 2013.11.23 - Day 26: TogetherJS —— 让我们一起来编程！ 2013.11.24 - Day 27: Restify —— 在Node.js中构建正确的REST Web服务 2013.11.25 - Day 28: OpenShift 的 Eclipse 集成 2013.11.26 - Day 29: 编写你的第一个 Google Chrome 扩展程序 2013.11.27 - Day 30: Play Framework —— Java 开发者的梦想框架 原文 Learning 30 Technologies in 30 Days: A Developer Challenge翻译 SegmentFault","categories":[{"name":"30天学习30种新技术系列","slug":"30天学习30种新技术系列","permalink":"https://vincentruan.github.io/categories/30天学习30种新技术系列/"}],"tags":[{"name":"30天学习30种新技术系列","slug":"30天学习30种新技术系列","permalink":"https://vincentruan.github.io/tags/30天学习30种新技术系列/"}]},{"title":"教你免费搭建个人博客，Hexo&Github","slug":"教你免费搭建个人博客，Hexo-Github","date":"2018-05-26T09:39:47.000Z","updated":"2020-02-25T15:09:15.070Z","comments":true,"path":"2018/05/26/教你免费搭建个人博客，Hexo-Github/","link":"","permalink":"https://vincentruan.github.io/2018/05/26/教你免费搭建个人博客，Hexo-Github/","excerpt":"什么是 Hexo？https://hexo.io/zh-cn/docs/ Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。","text":"什么是 Hexo？https://hexo.io/zh-cn/docs/ Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 一、配置Github首先注册、登录 https://github.com/ 记住自己的Username（很重要） 然后右上角选择 Create a new repository https://github.com/new Repository name （填自己的名字） yourname.github.io(yourname与你的注册用户名一致,这个就是你博客的域名了) 例如，我的域名是github.com/zhihuya，就填入zhihuya.github.io。成功后出现下面的画面 二、环境安装（node、git）1、安装 Node.js https://nodejs.org/en/ 2、安装 Git https://github.com/waylau/git-for-win Git教程 https://github.com/waylau/git-for-win廖雪峰老师的教程，非常好。 3、安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，名称和邮箱是Github上的 4、安装 Hexo。所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。 1$ npm install -g hexo-cli （使用的cmder，超级好用~~。等待时间可能有点长） 好了到这一步我们环境全部安装好了。 三、设置在电脑F盘（自己随意）目录下新建文件夹 test，进入test，按住Shift键点击鼠标右键 因为我有安装Cmder，没有安装的点击“在此处打开命令窗口”，输入 1hexo init blog 稍微等待下，速度有点慢。成功提示 1INFO Start blogging with Hexo! 因为你初始化hexo 之后source目录下自带一篇hello world文章, 所以直接执行下方命令 123456$ hexo generate# 启动本地服务器$ hexo server# 在浏览器输入 http://localhost:4000/就可以看见网页和模板了INFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 访问http://localhost:4000/，便可以看到网站初步的模样，不要激动，我们还要把网页发布到Github上去。 重新打开CMD，输入： 1ssh-keygen -t rsa -C &quot;Github的注册邮箱地址&quot; 一路Enter过来就好，得到信息： 1Your public key has been saved in /c/Users/user/.ssh/id_rsa.pub. 找到该文件，打开（sublime text），Ctrl + a复制里面的所有内容，然后进入Sign in to GitHub：https://github.com/settings/ssh New SSH key ——Title：blog —— Key：输入刚才复制的—— Add SSH key 四、配置博客在blog目录下，用sublime打开_config.yml文件，修改参数信息 特别提醒，在每个参数的：后都要加一个空格 修改网站相关信息 123456title: 崔斯特测试所用博客subtitle: 副标题description: 网页描述author: 崔斯特language: zh-CNtimezone: Asia/Shanghai 配置部署（我的是zhihuya，修改成自己的） 1234deploy: type: git repo: https://github.com/zhihuya/zhihuya.github.io.git branch: master 五、发表文章在CMD中输入 12$ hexo new &quot;崔斯特测试文章&quot;INFO Created: F:\\test\\blog\\source\\_posts\\崔斯特测试文章.md 找到该文章，打开，使用Markdown语法，该语法介绍可以查看https://zhangslob.github.io/2017/02/26/%E5%88%A9%E7%94%A8HEXO%E6%90%AD%E5%BB%BA%E7%9A%84%E5%8D%9A%E5%AE%A2/ 123456---title: 崔斯特测试文章date: 2017-02-28 13:03:44tags:---这是一篇测试文章，欢迎关注作者博客[1]: https://zhangslob.github.io/ 保存，然后执行下列步骤： 12345678910111213141516F:\\test\\blog$ hexo cleanINFO Deleted database.INFO Deleted public folder.F:\\test\\blog$ hexo generateINFO Start processingINFO Files loaded in 1.48 s#省略INFO 29 files generated in 4.27 sF:\\test\\blog$ hexo serverINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 这个时候，打开http://localhost:4000/，发现刚才的文章已经成功了 最后一步，发布到网上，执行： 123456F:\\test\\blog$ hexo deployINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...#省略 其中会跳出Github登录，直接登录，如果没有问题输入zhihuya（换成你的）.github.io/ 崔斯特测试所用博客https://zhihuya.github.io/ 然后就可以看到已经发布了 六、总结发布文章的步骤： 1、hexo new 创建文章 2、Markdown语法编辑文章 3、部署（所有打开CMD都是在blog目录下） 1234hexo clean #清除缓存 网页正常情况下可以忽略此条命令hexo generate #生成hexo server #启动服务预览，非必要，可本地浏览网页hexo deploy #部署发布 简写Tips： hexo n “我的博客” == hexo new “我的博客” #新建文章 hexo p == hexo publish hexo g == hexo generate#生成 hexo s == hexo server #启动服务预览 hexo d == hexo deploy#部署 如果在执行 hexo deploy 后,出现 error deployer not found:github 的错误，执行： 1npm install hexo-deployer-git --save 出错是正常的，出错了自己先百度或google，实在不知道的可以询问我。 托管的话不仅有github可以用，还有个国内的https://coding.net/可选 引用说明 作者：zhangslob 链接：https://zhangslob.github.io/2017/02/28/教你免费搭建个人博客，Hexo-Github","categories":[{"name":"Hexo使用攻略","slug":"Hexo使用攻略","permalink":"https://vincentruan.github.io/categories/Hexo使用攻略/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://vincentruan.github.io/tags/hexo/"},{"name":"个人博客搭建","slug":"个人博客搭建","permalink":"https://vincentruan.github.io/tags/个人博客搭建/"},{"name":"github","slug":"github","permalink":"https://vincentruan.github.io/tags/github/"}]},{"title":"Hexo使用攻略-添加分类及标签","slug":"Hexo使用攻略-添加分类及标签","date":"2018-05-26T09:16:29.000Z","updated":"2020-02-25T15:09:15.033Z","comments":true,"path":"2018/05/26/Hexo使用攻略-添加分类及标签/","link":"","permalink":"https://vincentruan.github.io/2018/05/26/Hexo使用攻略-添加分类及标签/","excerpt":"","text":"1、创建“分类”选项1.1 生成“分类”页并添加tpye属性打开命令行，进入博客所在文件夹。执行命令 1$ hexo new page categories 成功后会提示： 1INFO Created: ~/Documents/blog/source/categories/index.md 根据上面的路径，找到index.md这个文件，打开后默认内容是这样的： 1234---title: 文章分类date: 2017-05-27 13:47:40--- 添加type: &quot;categories&quot;到内容中，添加后是这样的： 123456---title: 文章分类date: 2017-05-27 13:47:40type: &quot;categories&quot;comments: false--- 保存并关闭文件。 1.2 给文章添加“categories”属性打开需要添加分类的文章，为其添加categories属性。下方的categories: web前端表示添加这篇文章到“web前端”这个分类。注意：hexo一篇文章只能属于一个分类，也就是说如果在“- web前端”下方添加“-xxx”，hexo不会产生两个分类，而是把分类嵌套（即该文章属于 “- web前端”下的 “-xxx ”分类）。 123456---title: jQuery对表单的操作及更多应用date: 2017-05-26 12:12:57categories: - web前端--- 至此，成功给文章添加分类，点击首页的“分类”可以看到该分类下的所有文章。当然，只有添加了categories: xxx的文章才会被收录到首页的“分类”中。 2、创建“标签”选项2.1 生成“标签”页并添加tpye属性打开命令行，进入博客所在文件夹。执行命令 1$ hexo new page tags 成功后会提示： 1INFO Created: ~/Documents/blog/source/tags/index.md 根据上面的路径，找到index.md这个文件，打开后默认内容是这样的： 1234---title: 标签date: 2017-05-27 14:22:08--- 添加type: &quot;tags&quot;到内容中，添加后是这样的： 123456---title: 文章分类date: 2017-05-27 13:47:40type: &quot;tags&quot;comments: false--- 保存并关闭文件。 2.2 给文章添加“tags”属性打开需要添加标签的文章，为其添加tags属性。下方的tags:下方的- jQuery - 表格 - 表单验证就是这篇文章的标签了 12345678910---title: jQuery对表单的操作及更多应用date: 2017-05-26 12:12:57categories: - web前端tags:- jQuery- 表格- 表单验证--- 至此，成功给文章添加分类，点击首页的“标签”可以看到该标签下的所有文章。当然，只有添加了tags: xxx的文章才会被收录到首页的“标签”中。 细心的朋友可能已经发现，这两个的设置几乎一模一样！是的，没错，思路都是一样的。所以我们可以打开scaffolds/post.md文件，在tages:上面加入categories:,保存后，之后执行hexo new 文章名命令生成的文件，页面里就有categories:项了。 scaffolds目录下，是新建页面的模板，执行新建命令时，是根据这里的模板页来完成的，所以可以在这里根据你自己的需求添加一些默认值。","categories":[{"name":"Hexo使用攻略","slug":"Hexo使用攻略","permalink":"https://vincentruan.github.io/categories/Hexo使用攻略/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://vincentruan.github.io/tags/hexo/"}]},{"title":"Hexo Hello World","slug":"hexo-hello-world","date":"2018-05-26T09:16:29.000Z","updated":"2020-02-25T15:09:15.052Z","comments":true,"path":"2018/05/26/hexo-hello-world/","link":"","permalink":"https://vincentruan.github.io/2018/05/26/hexo-hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment hexo algolia12$ export HEXO_ALGOLIA_INDEXING_KEY=[algolia.apiKey]$ hexo algolia CI with jenkins使用Jenkins实现Hexo自动部署 hexo使用jenkins自动部署到阿里云 ###Cooperation 使用git clonegit@github.com:vincentruan/vincentruan.github.io.git拷贝仓库（git checkout -b hexo）； 在新拷贝的vincentruan.github.io文件夹下通过Git bash依次执行下列指令： npm install hexo-cli -g(首次安装)、npm install hexo、npm install、npm install hexo-deployer-git（记得，不需要hexo init这条指令,如果不慎在此时用了hexo init，则站点的配置文件_config.yml里面内容会被清空使用默认值，所以这一步一定要慎重 ）","categories":[{"name":"Hexo使用攻略","slug":"Hexo使用攻略","permalink":"https://vincentruan.github.io/categories/Hexo使用攻略/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://vincentruan.github.io/tags/hexo/"}]},{"title":"Markdown吃了吗?","slug":"Markdown吃了吗","date":"2018-05-20T11:00:56.000Z","updated":"2020-02-25T15:09:15.045Z","comments":true,"path":"2018/05/20/Markdown吃了吗/","link":"","permalink":"https://vincentruan.github.io/2018/05/20/Markdown吃了吗/","excerpt":"markdown 介绍 Markdown 是一种轻量级标记语言，它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML(或者HTML)文档”。 - wikipedia Daring Fireball: Markdown Project markdown Markdown wikipedia 介绍 MultiMarkdown 引入更多标记特性和输出选项的改进版Markdown","text":"markdown 介绍 Markdown 是一种轻量级标记语言，它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML(或者HTML)文档”。 - wikipedia Daring Fireball: Markdown Project markdown Markdown wikipedia 介绍 MultiMarkdown 引入更多标记特性和输出选项的改进版Markdown why markdown 纯文本，兼容性极强，可以用任意文本编辑器打开. 语法简单（the syntax is so simple you can barely call it “syntax.”），零学习成本，极好的可读性，让你专注于文字写作而不是页面排版，并且兼容 HTML，simple but powerful . 格式转换方便，Markdown 的文本你可以轻松转换为 html、pdf、epub、电子书等。 适合团队协作，可以使用 git/svn 等进行版本控制管理。 阳志平：为什么 Markdown 成为科技界写作主流？ 图灵社区：用Markdown来写自由书籍-开源技术的方案 目前很多在线服务商均支持使用markdown编写： Github 最先支持，使用Markdown的一个分支版本来格式化评论、消息以及其它内容。 Stack Overflow 使用一种 Markdown 的分支作为它的文章格式化系统。 博客园 国内技术人的博客家园，每天活跃上万用户，高质量社区。 CSDN 号称全球最大中文IT社区，涵盖了多种语言、架构、博客、俱乐部等模块的技术论坛。 图灵社区 使用markdown语法供用户写作电子书. 简书 重拾文字的力量，交流故事，沟通想法，一个基于内容分享的社区。 为知笔记 国内顶尖笔记软件，支持使用Markdown语法编辑笔记。 有道云笔记 最新版本开始支持，并且支持一些扩展语法。 …… markdown 使用 Markdown: Basics （快速入门） Markdown 完整语法说明 (简体中文版) Github: Mastering Markdown GitHub 帮助中关于 Markdown 的语法帮助 MarkDown 语法团队规范 语法规范简洁版 Markdown Style Guide 语法规范复杂版 Markdown Cheatsheet GitHub Flavored Markdown GitHub 使用的 Markdown 语法，略微不同于标准 Markdown 语法。提供了一些更加简洁的语法，类似 URL autolinking, Strikethrough, Fenced code blocks, Syntax highlighting 等等 MultiMarkdown 介绍 对 markdown 进行的扩展功能 markdown 工具 马克飞象 web/chrome 离线客户端，markdown 全功能支持，最大特点内容能够同步到印象笔记（evernote）中，笔记的用户重度推荐，按年收费，目前作者 @weibo 正在开发跨平台的客户端。 StackEdit 在线 markdown 编辑器，可同步文档到Google Drive和 Dropbox，可发布文章到 Blogger，GitHub，Google Drive，Dropbox，Tumblr和WordPress。 cmd 作业部落 支持 win/mac/linux/web/chrome 全平台，支持实时同步预览，支持代码高亮、数学公式，区分写作和阅读模式，支持在线存储，分享文稿网址。 MacDown OSX 上的 Markdown 开源编辑器，支持代码高亮，实时预览等。 MarkdownPad Windows上的全功能Markdown编辑器，推荐win上使用，基本全部功能。 Marked2 多种 md 显示方案，不能够编辑文件，只用来展示文件，配合 subline text markdown edit 插件，完美使用； MWeb 专业的 Markdown 写作、记笔记、静态博客生成软件，由国内独立开发者@oulvhai开发，支持Toc、Table、代码高亮、支持发布到 Wordrpess 博客、支持 Metaweblog API 的博客服务、Wordpress.com、Evernote 和印象笔记、Blogger、Scriptogr.am、Tumblr等服务。 Haroopad 又一款简洁多功能的跨平台编辑器，全功能支持，再加上对社交网络友好的连接，多种主题等，感兴趣的可以看看。详情参考issue#1 Typora 不分栏，实时展示看到写出的内容，对于不喜欢「两栏」设计的人来说是一个选择 MarkEditor - ME MarkEditor以markdown为基础语法，多标签栏、文件夹结构，纯文本的方式带来优雅、高效的体验。 确实很棒的工具，带来很多新鲜的理念，支持、重构、提升 markdown，加快写作的体验。具体可以查看几篇评测文章： 简洁与强大，从不是矛盾的事物：写作工具 MarkEditor 功能详解 不止是一款简单的码字工具：MarkEditor 进阶功能介绍 码字必备：18 款优秀的 Markdown 写作工具 | 2015 年度盘点 喜欢哪一款，就看你的了。 这几款就够了，多了就有选择症 …… markdown流程图1.1 流程图1.1 横向流程图源码格式:graph LR A[方形] --> B(圆角) B --> C{条件a} C --> |a=1| D[结果1] C --> |a=2| E[结果2] F[横向流程图] 1.2 竖向流程图源码格式:graph TD A[方形] --> B(圆角) B --> C{条件a} C --> |a=1| D[结果1] C --> |a=2| E[结果2] F[竖向流程图] 1.3 标准流程图源码格式: 1.4 标准流程图源码格式(横向): 1.2 UML时序图1.2.1 UML时序图源码样例: 1.2.2 UML时序图源码复杂样例: 1.2.3 UML标准时序图样例:%%时序图例子, -> 实线, --> 虚线, ->> 实线箭头 sequenceDiagram participant 张三 participant 李四 张三 -> 王五: 王五你好吗? loop 健康检查 王五 -> 王五: 与疾病战斗 end Note right of 王五: 合理饮食 看医生... 李四 ->> 张三: 很好! 王五 -> 李四: 你怎么样? 李四 --> 王五: 很好! 1.3 甘特图样例:%%语法示例 gantt dateFormat YYYY-MM-DD title 软件开发甘特图 section 设计 需求 :done, des1, 2014-01-06, 2014-01-08 原型 :active, des2, 2014-01-09, 3d UI设计 :des3, after des2, 5d 未来任务: :des4, after des3, 5d section 开发 学习准备理解需求 :crit, done, 2014-01-06, 24h 设计框架 :crit, done, after des2, 2d 开发 :crit, active, 3d 未来任务 :crit, 5d 耍 :2d section 测试 功能测试 :active, a1, after des3, 3d 压力测试 :after a1, 20h 测试报告 :48h 数学公式矩阵方程$$\\begin{matrix} 1 &amp; x &amp; x^2 \\ 1 &amp; y &amp; y^2 \\ 1 &amp; z &amp; z^2 \\ \\end{matrix}$$ reference 参考 Why Markdown? A two-minute explanation 简书：献给写作者的 Markdown 新手指南 Markdown simple world MathJax语法规则 Mermaid语法规则 Mermaid官方教程 Mermaid Github仓库 [MathJax Github仓库](https://github.com/mathjax/MathJaxst=>start: 开始框 op=>operation: 处理框 cond=>condition: 判断框 sub1=>subroutine: 子流程 io=>inputoutput: 输入输出框 e=>end: 结束框 st->op->cond cond(yes)->io->e cond(no)->sub1(right)->op{\"theme\":\"simple\",\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options);st=>start: 开始框 op=>operation: 处理框 cond=>condition: 判断框(是或否?) sub1=>subroutine: 子流程 io=>inputoutput: 输入输出框 e=>end: 结束框 st(right)->op(right)->cond cond(yes)->io(bottom)->e cond(no)->sub1(right)->op{\"theme\":\"simple\",\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-1-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-1-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-1\", options);对象A->对象B: 对象B你好吗? (请求) Note right of 对象B: 对象B的描述 Note left of 对象A: 对象A的描述(提示) 对象B --> 对象A: 我很好(响应) 对象A --> 对象B: 你真的好吗?{\"theme\":\"simple\",\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"sequence-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"sequence-0-options\").value)); var diagram = Diagram.parse(code); diagram.drawSVG(\"sequence-0\", options);Title: 标题: 复杂使用 对象A -> 对象B: 对象B你好吗? (请求) Note right of 对象B: 对象B的描述 Note right of 对象A: 对象A的描述(提示) 对象B --> 对象A: 我很好(响应) 对象B --> 小三: 你好吗? 小三 -> 对象A: 对象B找我了 对象A --> 对象B: 你真的好吗? Note over 小三, 对象B: 我们是朋友 participant C Note right of C: 没人陪我玩{\"theme\":\"simple\",\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"sequence-1-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"sequence-1-options\").value)); var diagram = Diagram.parse(code); diagram.drawSVG(\"sequence-1\", options);","categories":[{"name":"Hexo使用攻略","slug":"Hexo使用攻略","permalink":"https://vincentruan.github.io/categories/Hexo使用攻略/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://vincentruan.github.io/tags/markdown/"},{"name":"流程图","slug":"流程图","permalink":"https://vincentruan.github.io/tags/流程图/"}]}]}